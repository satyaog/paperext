{
  "paper": "2310.18807.txt",
  "words": 9765,
  "extractions": {
    "title": {
      "value": "OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning",
      "justification": "The title is clearly mentioned at the beginning of the paper.",
      "quote": "OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning"
    },
    "description": "This paper introduces an object-centric compositional neural module network (OC-NMN) designed for visual generative reasoning tasks. The model decomposes tasks into a series of primitives applied to objects using modularity. This approach aims to improve out-of-distribution generalization by leveraging neural templates composed of neural modules. The proposed method is evaluated using a new benchmark, Arith-MNIST, which involves arithmetic operations on visual digits.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents experimental results from applying the proposed model to a new benchmark dataset called Arith-MNIST and compares it to existing baselines.",
      "quote": "Using this benchmark, we evaluate the systematic compositional generalization of models on a set of controlled and easily extendable axes and show the benefits of object-centric inductive biases."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper addresses visual generative reasoning tasks, which fall under the domain of computer vision.",
        "quote": "In this work, in the context of visual reasoning, we show how modularity can be leveraged to derive a compositional data augmentation framework inspired by imagination."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Visual Reasoning",
          "justification": "The paper specifically focuses on visual generative reasoning tasks and introduces a model designed for such tasks.",
          "quote": "Our model OC-NMN (Object-centric Compositional Neural Module Network) can be seen as part of the neural module networks (NMNs) family of models, adapted to generative visual analogical reasoning tasks like ARC."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "OC-NMN",
          "justification": "The paper proposes this new model for compositional neural module networks applied to visual reasoning tasks.",
          "quote": "Our method, denoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes visual generative reasoning tasks into a series of primitives applied to objects without using a domain-specific language."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_inference_only": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Arith-MNIST",
          "justification": "The paper introduces this dataset as a new benchmark for evaluating visual reasoning models on arithmetic tasks involving MNIST digits.",
          "quote": "We propose a simpler set of tasks that involve a set of controlled arithmetic operations on digits."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Slot Attention",
          "justification": "The model uses Slot Attention as part of its perception network to map visual inputs to object-centric slots.",
          "quote": "The computation steps (and parts of OC-NMN) are the following : (1) A perception network maps the visual inputs x to Ns object-centric slots using a slot attention (Locatello et al., 2020) mechanism."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 736,
    "prompt_tokens": 16078,
    "total_tokens": 16814
  }
}