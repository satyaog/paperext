{
  "paper": "2404.09939.txt",
  "words": 12371,
  "extractions": {
    "title": {
      "value": "A Survey on Deep Learning for Theorem Proving",
      "justification": "The title is explicitly mentioned at the beginning of the paper and reflects the core focus of the survey.",
      "quote": "A Survey on Deep Learning for Theorem Proving"
    },
    "description": "This paper is a comprehensive survey on deep learning approaches for theorem proving, providing a systematic overview of more than 170 research papers. The survey covers various tasks such as autoformalization, premise selection, proofstep generation, and proof search, as well as datasets and evaluation metrics. The paper also discusses challenges and future directions in this field.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper is empirical as it systematically reviews over 170 research papers, summarizing existing approaches, datasets, and performance metrics across different tasks within deep learning for theorem proving.",
      "quote": "In this paper, we provide a comprehensive survey of more than 170 research papers in deep learning for theorem proving"
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The survey focuses on the applications and advancements of deep learning techniques specifically for theorem proving.",
        "quote": "The recent development of deep learning, especially with the evolution of large language models (LLMs), has ignited a wave of research interest in this area again."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Theorem Proving",
          "justification": "The sub-research field is specifically centered around using deep learning techniques to enhance and automate the process of theorem proving.",
          "quote": "This paper presents a pioneering comprehensive survey of deep learning for theorem proving by offering i) a thorough review of existing approaches..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-f",
          "justification": "GPT-f is listed in the context of proofstep generation and various models have been referenced including GPT-3 and GPT-4.",
          "quote": "Specifically, GPT-f (Polu & Sutskever, 2020) first apply a conditional language modeling objective to train decoder-only Transformers to generate a proof step..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Inference"
        },
        "is_inference_only": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Thor",
          "justification": "Thor is mentioned as a model that integrates language models with automated theorem provers, enhancing the process of generating proofs.",
          "quote": "Thor (Jiang et al., 2022) adds a <hammer> token to learn when to invoke an ATP tool for premise selection to simplify the proof."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Inference"
        },
        "is_inference_only": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "NaturalProver",
          "justification": "NaturalProver is described as employing constrained decoding to aid in proof generation, leveraging GPT-3.",
          "quote": "NaturalProver (Welleck et al., 2022) trains GPT-3 (Brown et al., 2020) with constrained decoding to encourage using retrieved references in the proof steps."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Inference"
        },
        "is_inference_only": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "PRISM",
          "justification": "PRISM is mentioned as one of the datasets that contain formal theorems and proofs extracted for the Coq proof assistant.",
          "quote": "Notable datasets for Coq include Gamepad, CoqGym, and PRISM (Reichel et al., 2023), with CoqGym constructing a dataset from 123 projects encompassing 71k proofs."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "MiniF2F",
          "justification": "MiniF2F is highlighted as a dataset that contains Olympiad-level problems manually formalized in multiple proof systems.",
          "quote": "Notably, MiniF2F (Zheng et al., 2022) manually formalizes 488 Olympiad-level problems across 4 proof systems and equally splits them into a validation set and a test set."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "ProofNet",
          "justification": "ProofNet is mentioned as a dataset for formalizing IMO and undergraduate-level problems.",
          "quote": "ProofNet (Azerbayev et al., 2023) formalizes the theorem statements of IMO and undergraduate-level problems in Lean."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "HolStep",
          "justification": "HolStep is noted as a dataset for the HOL Light proof assistant, facilitating research in premise selection and proof generation.",
          "quote": "Notable datasets for Coq include Gamepad, CoqGym, and PRISM... Datasets for other proof assistants include HolStep (Kaliszyk et al., 2017) and HOList (Bansal et al., 2019) for HOL Light"
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Vampire",
          "justification": "Vampire is described as an automated theorem proving system employed extensively in the field.",
          "quote": "Saturation-based theorem provers, including E (Schulz, 2002) and Vampire (Ková́cs & Voronkov, 2013), mainly operate on first-order logic (FOL)..."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "leanCoP",
          "justification": "leanCoP is a tableau-based method referenced for its approach in automated theorem proving.",
          "quote": "Similarly, geometric ATP systems such as GEX (Chou et al., 2000) prove geometry problems by iteratively applying deduction rules. Other approaches, such as tableau-based methods like leanCoP (Otten & Bibel, 2003)..."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "leanRoP",
          "justification": "leanRoP is included for its relevance in connection-based theorem proving methods.",
          "quote": "Other approaches, such as tableau-based methods like leanCoP... and connection tableau methods like leanRoP (Gauthier et al., 2020), use other forms of proof calculi for proof construction."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1352,
    "prompt_tokens": 23004,
    "total_tokens": 24356
  }
}