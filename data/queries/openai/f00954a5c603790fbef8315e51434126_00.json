{
  "paper": "f00954a5c603790fbef8315e51434126.txt",
  "words": 9995,
  "extractions": {
    "title": {
      "value": "FairPrism: Evaluating Fairness-Related Harms in Text Generation",
      "justification": "The title is explicitly stated at the beginning of the paper.",
      "quote": "FairPrism: Evaluating Fairness-Related Harms in Text Generation"
    },
    "description": "This paper introduces FairPrism, a dataset comprising 5,000 examples of AI-generated English text annotated for fairness-related harms, especially those related to gender and sexuality. The dataset aims to address limitations in existing resources like transparency, dataset coverage, and context-dependent harms, providing detailed insights to measure and mitigate sterotyping and demeaning harms caused by AI systems.",
    "type": {
      "value": "Empirical Research",
      "justification": "The paper involves the creation and annotation of a dataset to examine and categorize fairness-related harms in AI-generated text. This involves empirical investigation through data collection and analysis.",
      "quote": "To that end, we introduce FairPrism, a dataset of 5,000 examples of AI-generated English text with detailed human annotations covering a diverse set of harms relating to gender and sexuality."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The study focuses on understanding and mitigating harms in AI-generated text, a key application area of Natural Language Processing (NLP).",
        "quote": "It is critical to measure and mitigate fairness-related harms caused by AI text generation systems, including stereotyping and demeaning harms."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Fairness in AI",
          "justification": "The primary objective of the paper is to address fairness-related harms in AI-generated text, which falls within the broader realm of fairness in AI.",
          "quote": "FairPrism aims to address several limitations of existing datasets for measuring and mitigating fairness-related harms, including improved transparency, clearer specification of dataset coverage, and accounting for annotator disagreement and harms that are context-dependent."
        },
        "aliases": [
          "Fairness in Artificial Intelligence"
        ]
      },
      {
        "name": {
          "value": "Ethics in NLP",
          "justification": "The paper deals with ethical concerns about stereotyping and demeaning content in AI text generation, which aligns with the ethics in NLP.",
          "quote": "The process we followed to develop FairPrism offers a recipe for building improved datasets for measuring and mitigating harms caused by AI systems."
        },
        "aliases": [
          "Ethical Natural Language Processing"
        ]
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "FairPrism",
          "justification": "The dataset, FairPrism, is the primary contribution of the paper, explicitly mentioned and described in detail.",
          "quote": "To that end, we introduce FairPrism, a dataset of 5,000 examples of AI-generated English text with detailed human annotations covering a diverse set of harms relating to gender and sexuality."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "None",
          "justification": "FairPrism is introduced and contributed by the authors of this paper, so there is no external reference paper.",
          "quote": "To that end, we introduce FairPrism, a dataset of 5,000 examples of AI-generated English text with detailed human annotations covering a diverse set of harms relating to gender and sexuality."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Amazon Mechanical Turk (MTurk)",
          "justification": "Amazon Mechanical Turk (MTurk) is used for the data annotation process in the paper, as workers were recruited from this platform.",
          "quote": "We used Amazon Mechanical Turk (MTurk) to collect FairPrism’s annotations."
        },
        "aliases": [
          "MTurk"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "MTurk is a widely recognized platform for crowdsourcing and does not have a specific reference paper.",
          "quote": "We used Amazon Mechanical Turk (MTurk) to collect FairPrism’s annotations."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 761,
    "prompt_tokens": 16743,
    "total_tokens": 17504
  }
}