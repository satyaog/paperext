{
  "paper": "2210.03150.txt",
  "words": 14092,
  "extractions": {
    "title": {
      "value": "Towards Out-of-Distribution Adversarial Robustness",
      "justification": "The title accurately reflects the main focus of the research paper, as it summarizes the investigation into improving adversarial robustness in out-of-distribution settings.",
      "quote": "Towards Out-of-Distribution Adversarial Robustness"
    },
    "description": "This paper investigates the use of domain generalisation techniques, specifically the Risk Extrapolation method (REx), to improve adversarial robustness in deep learning models. The study shows that REx can enhance worst-case adversarial robustness against various attacks, both seen and unseen during training, by treating each type of attack as a domain and promoting consistent performance across these domains.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts experiments with several learning models, datasets, and defenses to empirically evaluate the effectiveness of the Risk Extrapolation method (REx) in improving adversarial robustness.",
      "quote": "Our results show that the answer to both questions is yes on the ensembles of attacks used in this work. We show that REx consistently yields benefits across variations in: datasets, architectures, multi-perturbation defenses, hyperparameter tuning, attacks seen during training, and attack types or tunings only encountered at test time."
    },
    "primary_research_field": {
      "name": {
        "value": "Adversarial Machine Learning",
        "justification": "The paper focuses on improving adversarial robustness, which is a key concern in adversarial machine learning, through the use of domain generalisation techniques.",
        "quote": "Adversarial robustness continues to be a major challenge for deep learning."
      },
      "aliases": [
        "Adversarial ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Domain Generalization",
          "justification": "The study leverages domain generalization techniques such as Risk Extrapolation (REx) to achieve robustness against multiple adversarial attacks.",
          "quote": "In order to be robust against multiple attacks, we draw inspiration from domain generalisation."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Model Robustness",
          "justification": "The research emphasizes enhancing the robustness of machine learning models against adversarial attacks, regardless of whether they were seen during training.",
          "quote": "Second, can REx improve robustness against unseen attacks, that is, attacks only seen at test time?"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "REx",
          "justification": "REx, or Risk Extrapolation, is the primary model proposed and evaluated in the paper for improving adversarial robustness.",
          "quote": "Concretely, we treat each type of attack as a domain, and apply the Risk Extrapolation method (REx), which promotes similar levels of robustness against all training attacks."
        },
        "aliases": [
          "Risk Extrapolation"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The REx model is introduced and evaluated as a novel contribution within the scope of this paper.",
          "quote": "we propose to regularise the average loss over a set of training domains D by the variance of the losses on the different domains"
        },
        "is_executed": {
          "value": 1,
          "justification": "The REx model is experimentally evaluated using computations, implying its execution during the experiments.",
          "quote": "In this work, we apply the method of variance-based risk extrapolation (REx), which simply adds as a loss penalty the variance of the ERM loss across different domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "REx is compared numerically to other baseline models in terms of adversarial robustness across different datasets and architectures.",
          "quote": "Additionally, we also report results on CIFAR10-C (Hendrycks & Dietterich, 2019) in Table 4. The dataset consists in mimicking several natural corruptions on CIFAR10 images at various strength, which as argued before, can be seen as a non-adversarial analogue of trying both different types, and tunings of adversarial attacks. While this is not an adversarial robustness benchmark, it shows that REx significantly improves robustness of multi-perturbation defenses to non-adversarial shifts it is used on, in spite of what REx modelsâ€™ lower in-distribution clean accuracy on CIFAR10 may have suggested in Table 2."
        },
        "referenced_paper_title": {
          "value": "Out-of-distribution generalization via risk extrapolation (rex)",
          "justification": "The referenced paper likely introduces the Risk Extrapolation (REx) method which is adapted and applied in this research.",
          "quote": "We choose variance REx (Krueger et al., 2021), which consists in using as a loss penalty the variance on the different training domains of the empirical risk minimisation loss."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is one of the main datasets used in the experiments to evaluate the REx model's performance.",
          "quote": "On ensembles of attacks, our approach improves the accuracy from 3.4% with the best existing baseline to 25.9% on MNIST"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Gradient-based learning applied to document recognition",
          "justification": "The referenced paper likely introduces the MNIST dataset, which is used in this research for evaluation purposes.",
          "quote": "MNIST (LeCun et al., 1998)"
        }
      },
      {
        "name": {
          "value": "CIFAR10",
          "justification": "CIFAR10 is one of the main datasets used in the experiments to evaluate the REx model's performance.",
          "quote": "from 16.9% to 23.5% on CIFAR10."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper likely introduces the CIFAR10 dataset, which is used in this research for evaluation purposes.",
          "quote": "CIFAR10 (Krizhevsky et al., 2009)"
        }
      },
      {
        "name": {
          "value": "CIFAR10-C",
          "justification": "CIFAR10-C is also used to further validate the robustness of the REx model against natural corruptions.",
          "quote": "Additionally, we also report results on CIFAR10-C (Hendrycks & Dietterich, 2019)"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Benchmarking neural network robustness to common corruptions and perturbations",
          "justification": "The referenced paper likely introduces the CIFAR10-C dataset, which is used in this research for additional evaluation purposes.",
          "quote": "CIFAR10-C (Hendrycks & Dietterich, 2019)"
        }
      },
      {
        "name": {
          "value": "CIFAR100",
          "justification": "CIFAR100 is used to test the transferability of the REx model by fine-tuning it on this dataset after training on CIFAR10.",
          "quote": "Table 7: Accuracies of tuned CIFAR10 models fine-tuned on CIFAR100, averaged over 3 fine-tunings with different seeds per defense."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper likely introduces the CIFAR100 dataset, which is used in this research for transfer learning purposes.",
          "quote": "CIFAR100 (Krizhevsky et al., 2009)"
        }
      },
      {
        "name": {
          "value": "SVHN",
          "justification": "SVHN dataset is used to further test the transferability of the REx model by fine-tuning it on this dataset after training on CIFAR10.",
          "quote": "We also attempt a similar fine-tuning on the SVHN dataset"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reading digits in natural images with unsupervised feature learning",
          "justification": "The referenced paper likely introduces the SVHN dataset, which is used in this research for transfer learning purposes.",
          "quote": "SVHN (Netzer et al., 2011)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper mentions the use of PyTorch for implementing the adversarial robustness toolbox.",
          "quote": "We use the Advertorch implementation of these attacks (Ding et al., 2019)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Advertorch v0.1: An adversarial robustness toolbox based on pytorch",
          "justification": "The referenced paper likely details the PyTorch-based toolbox used for implementing adversarial attacks and defenses in this research.",
          "quote": "We use the Advertorch implementation of these attacks (Ding et al., 2019)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1738,
    "prompt_tokens": 25210,
    "total_tokens": 26948
  }
}