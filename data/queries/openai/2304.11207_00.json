{
  "paper": "2304.11207.txt",
  "words": 7373,
  "extractions": {
    "title": {
      "value": "SSS3D: Fast Neural Architecture Search For Efficient Three-Dimensional Semantic Segmentation",
      "justification": "This is the exact title given at the beginning of the research paper.",
      "quote": "SSS3D: Fast Neural Architecture Search For Efficient Three-Dimensional Semantic Segmentation"
    },
    "description": "The paper presents SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks. It optimizes the RandLA-Net framework for accuracy, size, and computational cost using a two-stage genetic algorithm-based search.",
    "type": {
      "value": "Empirical",
      "justification": "The paper primarily discusses the implementation and results of a new neural architecture search framework applied to 3D semantic segmentation, presenting experimental results and comparisons.",
      "quote": "We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper is centered around 3D semantic scene segmentation, which is a subfield of Computer Vision.",
        "quote": "SSS3D: Fast Neural Architecture Search For Efficient Three-Dimensional Semantic Segmentation (..). 3D point clouds are increasingly used (..)."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "3D Semantic Segmentation",
          "justification": "The main focus of the paper is on developing and optimizing networks for 3D semantic segmentation.",
          "quote": "We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Neural Architecture Search",
          "justification": "The paper describes the SSS3D framework which uses neural architecture search techniques.",
          "quote": "SSS3D is a fast multi-objective NAS framework that uses NSGA-II [13], an elitist genetic algorithm (GA), to optimize the inner structure and the sampling choices of its RandLA-Net super-network."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "SSS3D",
          "justification": "SSS3D is the primary model presented and contributed by this paper.",
          "quote": "We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The SSS3D model is proposed, developed, and analyzed in this paper.",
          "quote": "We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes execution of SSS3D for evaluating its performance and efficiency.",
          "quote": "SSS3D finds efficient variations of RandLA-Net in 1.04 to 2.69 GPU days."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the performance of SSS3D with the original RandLA-Net, as well as other models.",
          "quote": "SSS3D found two networks, SAP-1 and SF-1, that outperform the original RandLA-Net."
        },
        "referenced_paper_title": {
          "value": "Not Applicable",
          "justification": "SSS3D is a new model proposed by this paper and does not have a separate reference paper.",
          "quote": "We present SSS3D, a fast multi-objective NAS framework designed to find computationally efficient 3D semantic scene segmentation networks."
        }
      },
      {
        "name": {
          "value": "RandLA-Net",
          "justification": "RandLA-Net is used as the baseline model that SSS3D aims to optimize.",
          "quote": "It uses RandLA-Net, an off-the-shelf point-based network, as a super-network to enable weight sharing and reduce search time by 99.67% for single-stage searches."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "RandLA-Net is not a new contribution of this paper; it is utilized within the SSS3D framework.",
          "quote": "RandLA-Net is a point-based 3D semantic segmentation network with an encoder-decoder structure."
        },
        "is_executed": {
          "value": 1,
          "justification": "The performance of RandLA-Net is evaluated as part of the baseline comparisons.",
          "quote": "On S3DIS [2], RandLA-Net has 5M parameters and uses 17G FLOPs to achieve 62.78% mIoU."
        },
        "is_compared": {
          "value": 1,
          "justification": "RandLA-Net is compared to the variations found through the SSS3D framework.",
          "quote": "SSS3D found two networks, SAP-1 and SF-1, that outperform the original RandLA-Net."
        },
        "referenced_paper_title": {
          "value": "RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds",
          "justification": "The reference paper where RandLA-Net was originally proposed.",
          "quote": "RandLA-Net [20] addresses this issue by using random sampling and an efficient context aggregation module."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "S3DIS",
          "justification": "S3DIS is the primary dataset used for training, fine-tuning, and evaluation in this paper.",
          "quote": "The dataset used by SSS3D for training, fine-tuning and evaluation is the Stanford 3D indoor scene dataset (S3DIS) [2, 3]."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Joint 2D-3D-Semantic Data for Indoor Scene Understanding",
          "justification": "The reference paper for the S3DIS dataset.",
          "quote": "The dataset used by SSS3D for training, fine-tuning and evaluation is the Stanford 3D indoor scene dataset (S3DIS) [2, 3]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "NSGA-II",
          "justification": "NSGA-II is the genetic algorithm used within the SSS3D framework for optimization.",
          "quote": "SSS3D is a fast multi-objective NAS framework that uses NSGA-II [13], an elitist genetic algorithm (GA), to optimize the inner structure and the sampling choices of its RandLA-Net super-network."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "A fast and elitist multiobjective genetic algorithm: NSGA-II",
          "justification": "The reference paper describing the NSGA-II algorithm.",
          "quote": "NSGA-II [13], an elitist genetic algorithm (GA)."
        }
      },
      {
        "name": {
          "value": "Once-for-All",
          "justification": "Once-for-All inspired the weight sharing mechanism used in the SSS3D framework.",
          "quote": "SSS3D employs weight sharing inspired by Once-for-All [7], reducing overall training time by 99.67% by eliminating candidate training."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "Once-for-All: Train one network and specialize it for efficient deployment",
          "justification": "The reference paper for the Once-for-All method.",
          "quote": "Once-for-All [7]"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1787,
    "prompt_tokens": 14488,
    "total_tokens": 16275
  }
}