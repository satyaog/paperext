{
  "paper": "GAGpLgWAWX.txt",
  "words": 14534,
  "extractions": {
    "title": {
      "value": "FACTORS INFLUENCING GENERALIZATION IN CHAOTIC DYNAMICAL SYSTEMS",
      "justification": "This can be clearly identified as the title of the paper.",
      "quote": "FACTORS INFLUENCING GENERALIZATION IN CHAOTIC DYNAMICAL SYSTEMS"
    },
    "description": "This paper explores and identifies key factors that lead to good generalization in chaotic dynamical systems. By using a lightweight evaluation framework called ValiDyna and conducting various experiments, the paper aims to understand the generalization capabilities of deep learning models on data exhibiting chaotic behavior.",
    "type": {
      "value": "Empirical",
      "justification": "The paper conducts empirical experiments using various models and datasets to identify factors that affect generalization in chaotic dynamical systems.",
      "quote": "Thus, this work explores and identifies key factors which lead to good generalization. We observe a variety of interesting phenomena, including: learned representations transfer much better when fine-tuned vs. frozen; forecasting appears to be the best pre-training task..."
    },
    "primary_research_field": {
      "name": {
        "value": "Representation Learning",
        "justification": "The primary research field is Representation Learning as the paper investigates how well learned representations generalize in chaotic dynamical systems.",
        "quote": "This makes chaotic systems a compelling challenge for machine learning, particularly representation learning: Can models learn representations that capture high-level patterns and are useful across other tasks?"
      },
      "aliases": [
        "RepL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Time Series Forecasting",
          "justification": "The study involves forecasting time series data generated from chaotic dynamical systems.",
          "quote": "This makes chaotic systems a compelling challenge for machine learning, particularly representation learning... forecasting appears to be the best pre-training task."
        },
        "aliases": [
          "TSF"
        ]
      },
      {
        "name": {
          "value": "Meta-Learning",
          "justification": "The paper explores generalized learning across different tasks, which aligns with meta-learning.",
          "quote": "ValiDyna currently includes three tasks on learned representations from with time series data: 1. (Task S) Self-supervised featurisation (aka feature extraction)..."
        },
        "aliases": [
          "ML"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GRU",
          "justification": "GRU is mentioned as one of the models evaluated for generalization in chaotic dynamical systems.",
          "quote": "We present ValiDyna, an open-source, lightweight framework built on top of Pytorch and Lightning. It is built with extensibility in mind, so that new model architectures... ValiDyna currently includes 4 machine learning architectures often used for temporal data: • GRU (Cho et al., 2014)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The GRU model is not a contribution of this paper, but it is utilized for experiments.",
          "quote": "These Recurrent Neural Networks (RNNs) are likely the most popular ML architectures to be used for time series as they allow crunching a series of variable size into a fixed-size representations."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify whether the GRU model was executed on GPU or CPU.",
          "quote": "N/A"
        },
        "is_compared": {
          "value": 1,
          "justification": "GRU is compared with other models in terms of in- and out-of-distribution generalization.",
          "quote": "Table 3: Feature-freeze experiment: final task metrics as a function of the pre-training task. We highlight the best metric value obtained for each model-set pair."
        },
        "referenced_paper_title": {
          "value": "On the properties of neural machine translation: Encoder-decoder approaches",
          "justification": "The GRU model's referenced paper title is given to provide credit to its original development.",
          "quote": "KyungHyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua Bengio. On the properties of neural machine translation: Encoder-decoder approaches."
        }
      },
      {
        "name": {
          "value": "LSTM",
          "justification": "LSTM is one of the models evaluated for generalization in chaotic dynamical systems.",
          "quote": "We present ValiDyna... ValiDyna currently includes 4 machine learning architectures often used for temporal data: • LSTM (Hochreiter & Schmidhuber, 1997)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The LSTM model is not a contribution of this paper, but is used for experiments.",
          "quote": "These Recurrent Neural Networks (RNNs) are likely the most popular ML architectures to be used for time series as they allow crunching a series of variable size into a fixed-size representations."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify whether the LSTM model was executed on GPU or CPU.",
          "quote": "N/A"
        },
        "is_compared": {
          "value": 1,
          "justification": "LSTM is compared with other models in terms of in- and out-of-distribution generalization.",
          "quote": "Table 3: Feature-freeze experiment: final task metrics as a function of the pre-training task. We highlight the best metric value obtained for each model-set pair."
        },
        "referenced_paper_title": {
          "value": "Long short-term memory",
          "justification": "The LSTM model's referenced paper title is given to provide credit to its original development.",
          "quote": "Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory."
        }
      },
      {
        "name": {
          "value": "Transformer",
          "justification": "Transformer is one of the models evaluated for generalization in chaotic dynamical systems.",
          "quote": "We present ValiDyna... ValiDyna currently includes 4 machine learning architectures often used for temporal data: • Transformer (Vaswani et al., 2017)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The Transformer model is not a contribution of this paper, but is used for experiments.",
          "quote": "an attention-based architecture that achieves state-of-the-art performance for seq2seq, and has replaced LSTMs in many time series tasks."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify whether the Transformer model was executed on GPU or CPU.",
          "quote": "N/A"
        },
        "is_compared": {
          "value": 1,
          "justification": "The Transformer model is compared with other models in terms of in- and out-of-distribution generalization.",
          "quote": "Table 3: Feature-freeze experiment: final task metrics as a function of the pre-training task. We highlight the best metric value obtained for each model-set pair."
        },
        "referenced_paper_title": {
          "value": "Attention Is All You Need",
          "justification": "The Transformer's referenced paper title is given to provide credit to its original development.",
          "quote": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need."
        }
      },
      {
        "name": {
          "value": "N-BEATS",
          "justification": "N-BEATS is one of the models evaluated for generalization in chaotic dynamical systems.",
          "quote": "We present ValiDyna... ValiDyna currently includes 4 machine learning architectures often used for temporal data: • N-BEATS (Oreshkin et al., 2020)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The N-BEATS model is not a contribution of this paper, but is used for experiments.",
          "quote": "a purely deep neural state-of-the-art forecasting architecture based on residual blocks."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify whether the N-BEATS model was executed on GPU or CPU.",
          "quote": "N/A"
        },
        "is_compared": {
          "value": 1,
          "justification": "N-BEATS is compared with other models in terms of in- and out-of-distribution generalization.",
          "quote": "Table 3: Feature-freeze experiment: final task metrics as a function of the pre-training task. We highlight the best metric value obtained for each model-set pair."
        },
        "referenced_paper_title": {
          "value": "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting",
          "justification": "The N-BEATS model's referenced paper title is given to provide credit to its original development.",
          "quote": "Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. N-BEATS: Neural basis expansion analysis for interpretable time series forecasting."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "dysts",
          "justification": "dysts is the dataset library used for generating chaotic dynamical systems data.",
          "quote": "Our data is generated using dysts, a Python library of 130+ chaotic dynamical systems published by Gilpin (2021)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Chaos as an interpretable benchmark for forecasting and data-driven modelling",
          "justification": "The referenced paper title for dysts is provided to give credit to its original development.",
          "quote": "William Gilpin. Chaos as an interpretable benchmark for forecasting and data-driven modelling."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is explicitly mentioned as a library on which the ValiDyna framework is built.",
          "quote": "We present ValiDyna, an open-source, lightweight framework built on top of Pytorch and Lightning."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "The referenced paper title for PyTorch is provided to give credit to its original development.",
          "quote": "We present ValiDyna, an open-source, lightweight framework built on top of Pytorch and Lightning."
        }
      },
      {
        "name": {
          "value": "Lightning",
          "justification": "Lightning is explicitly mentioned as a library on which the ValiDyna framework is built.",
          "quote": "We present ValiDyna, an open-source, lightweight framework built on top of Pytorch and Lightning."
        },
        "aliases": [
          "PyTorch Lightning"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch Lightning",
          "justification": "The referenced paper title for Lightning is provided to give credit to its original development.",
          "quote": "We present ValiDyna, an open-source, lightweight framework built on top of Pytorch and Lightning."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2112,
    "prompt_tokens": 34712,
    "total_tokens": 36824
  }
}