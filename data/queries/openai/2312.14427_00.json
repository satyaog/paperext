{
  "paper": "2312.14427.txt",
  "words": 7233,
  "extractions": {
    "title": {
      "value": "GROOD: GRadient-aware Out-Distribution detection in interpolated manifolds",
      "justification": "This is the title given at the beginning of the paper.",
      "quote": "GROOD: GRadient-aware Out-Distribution detection in interpolated manifolds"
    },
    "description": "This paper introduces GROOD, a novel method for Out-Of-Distribution (OOD) detection that leverages gradient information in combination with distance metrics to detect OOD samples in deep neural networks. The method creates a gradient space that distinguishes between in-distribution (ID) and OOD samples, utilizing class prototypes and a targeted mix-up operation on early layers of the network. GROOD shows state-of-the-art performance across multiple datasets, such as ImageNet-1K, CIFAR-10, and CIFAR-100.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts extensive experiments to demonstrate the efficacy of the GROOD method on various datasets and architectures.",
      "quote": "We conduct an extensive empirical study following the recent methodology introduced in OpenOOD Benchmark [69], but we also evaluate our method on other recent architectures."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The primary focus of the paper is on image classification and Out-Of-Distribution detection using deep neural networks, which is a sub-field of Computer Vision.",
        "quote": "Experimental evaluations substantiate that the introduction of targeted input mix-up amplifies the separation between ID and OOD in the gradient space, yielding impressive results across diverse datasets. Notably, when benchmarked on ImageNet-1k, GROOD surpasses the established robustness of state-of-the-art baselines."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Out-Of-Distribution Detection",
          "justification": "The paper mainly delves into the challenge of identifying out-of-distribution samples in neural networks, which is a particular area of research within computer vision.",
          "quote": "We introduce GRadient-aware Out-Of-Distribution detection in interpolated manifolds (GROOD), a novel post-hoc method that relies on the discriminative power of gradient space to distinguish between in-distribution (ID) and OOD samples."
        },
        "aliases": [
          "OOD"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GROOD",
          "justification": "GROOD is the novel method proposed by the paper for OOD detection leveraging gradient information and class prototypes.",
          "quote": "To address this gap, we introduce GRadient-aware Out-Of-Distribution detection in interpolated manifolds (GROOD), a novel post-hoc method that relies on the discriminative power of gradient space to distinguish between in-distribution (ID) and OOD samples."
        },
        "aliases": [
          "GROOD"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "GROOD is introduced in this paper as the primary contribution to the field of OOD detection.",
          "quote": "In this work, we introduce a new method that we call GROOD."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes extensive empirical evaluations of the GROOD model on various datasets.",
          "quote": "We conduct an extensive empirical study following the recent methodology introduced in OpenOOD Benchmark [69], but we also evaluate our method on other recent architectures."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper demonstrates the performance of GROOD by comparing it to other state-of-the-art methods.",
          "quote": "GROOD provides effective detection in both the near and the far OOD regimes with AUROC performance either on par with or above state-of-the-art post-hoc methods across all setups."
        },
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no referenced paper since GROOD is introduced for the first time in this paper.",
          "quote": "We introduce a new method that we call GROOD."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is one of the main datasets used for evaluating the performance of GROOD.",
          "quote": "We conduct an extensive empirical study following the recent methodology introduced in OpenOOD Benchmark [69], but we also evaluate our method on other recent architectures. The following results highlight the following key advantages of GROOD...On ImageNet-1K ..., CIFAR-10, GROOD consistently shows superior performance for various architectures, including ViT-B-16."
        },
        "aliases": [
          "CIFAR-10"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-10 dataset is established and its reference paper is by A. Krizhevsky et al.",
          "quote": "Krizhevsky, Alex, and Geoffrey Hinton. \"Learning multiple layers of features from tiny images.\" Technical report, University of Toronto, 2009."
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is used alongside CIFAR-10 to evaluate the performance of GROOD.",
          "quote": "Our evaluation involves four core ID datasets: CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K."
        },
        "aliases": [
          "CIFAR-100"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-100 dataset is established and its reference paper is by A. Krizhevsky et al.",
          "quote": "Krizhevsky, Alex, and Geoffrey Hinton. \"Learning multiple layers of features from tiny images.\" Technical report, University of Toronto, 2009."
        }
      },
      {
        "name": {
          "value": "ImageNet-1K",
          "justification": "ImageNet-1K is one of the large-scale datasets used to evaluate the effectiveness of GROOD for OOD detection.",
          "quote": "Our evaluation involves four core ID datasets: CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K."
        },
        "aliases": [
          "ImageNet-1000"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Classification with Deep Convolutional Neural Networks",
          "justification": "The ImageNet-1K dataset is established and its reference paper is by A. Krizhevsky et al.",
          "quote": "Krizhevsky, Alex, Ilya Sutskever, and Geoffrey Hinton. \"ImageNet classification with deep convolutional neural networks.\" Advances in neural information processing systems 25 (2012): 1097-1105."
        }
      },
      {
        "name": {
          "value": "OpenImage-O",
          "justification": "OpenImage-O is used as an OOD dataset to test the GROOD model's performance in detecting out-of-distribution samples.",
          "quote": "For robustness, each evaluation metric except for ImageNet-1K is derived from three runs with unique initialization seeds. In the case of ImageNet-1K, we report results based on a single seed run provided by torchvision Author [2]."
        },
        "aliases": [
          "OpenImage-O"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Open Images: A Public Dataset for Large-Scale Multi-Label and Multi-Class Image Classification.",
          "justification": "The OpenImage-O dataset is established and its reference paper is by Alina Kuznetsova et al.",
          "quote": "Kuznetsova, Alina, Hassan Rom, Naiyan Wang, et al. \"Open Images: A Public Dataset for Large-Scale Multi-Label and Multi-Class Image Classification.\" (2018)."
        }
      },
      {
        "name": {
          "value": "NINCO",
          "justification": "NINCO is used as a near-OOD dataset to test the GROOD model's performance.",
          "quote": "Evaluation involves four core ID datasets: CIFAR-10, CIFAR-100, ImageNet-200, and ImageNet-1K. Despite the existing literature predominantly addressing far-OOD rather than near-OOD scenarios, we also scrutinize in the relatively neglected realm of near-OOD by using datasets like NINCO."
        },
        "aliases": [
          "NINCO"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "NINCO: Near-ImageNet Contamination.",
          "justification": "The NINCO dataset is established and its reference paper is by Jingkang Yang et al.",
          "quote": "Yang, Jingkang, Pengyun Wang, Dejian Zou, et al. \"NINCO: Near-ImageNet Contamination\" (2023)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenOOD",
          "justification": "OpenOOD is used as the primary benchmark framework to evaluate the performance of the GROOD method in detecting OOD samples.",
          "quote": "We conduct an extensive empirical study following the recent methodology introduced in OpenOOD Benchmark [69], but we also evaluate our method on other recent architectures."
        },
        "aliases": [
          "OpenOOD"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "OpenOOD: Benchmarking Generalized Out-of-distribution Detection.",
          "justification": "The OpenOOD framework is established and its reference paper is by Jingkang Yang et al.",
          "quote": "Yang, Jingkang, et al. \"OpenOOD: Benchmarking Generalized Out-of-distribution Detection.\" (2022)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2212,
    "prompt_tokens": 31153,
    "total_tokens": 33365
  }
}