{
  "paper": "J4mJjotSauh.txt",
  "words": 13802,
  "extractions": {
    "title": {
      "value": "FOOL SHAP WITH STEALTHILY BIASED SAMPLING.",
      "justification": "This is the title of the paper.",
      "quote": "FOOL SHAP WITH STEALTHILY BIASED SAMPLING."
    },
    "description": "This paper presents an attack on SHAP explanations in machine learning. The attack manipulates SHAP values using stealthily biased sampling of data points to produce desired explanations without altering the black-box model itself.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper performs experiments on synthetic and real-world datasets to demonstrate the effectiveness of the proposed attack.",
      "quote": "Experiments performed on real-world datasets showed that our attack could yield up to a 90% relative decrease in amplitude of the sensitive feature attribution."
    },
    "primary_research_field": {
      "name": {
        "value": "Explainable AI (XAI)",
        "justification": "The paper focuses on SHAP explanations, a tool for model-agnostic explanations, and how they can be manipulated.",
        "quote": "SHAP explanations aim at identifying which features contribute the most to the difference in model prediction at a specific input versus a background distribution."
      },
      "aliases": [
        "XAI"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Fairness in AI",
          "justification": "The paper discusses the implications of their attack on fairness auditing in machine learning models.",
          "quote": "In the context of fairness audit, we show that our attack can reduce the importance of a sensitive feature when explaining the difference in outcomes between groups while remaining undetected."
        },
        "aliases": [
          "AI Fairness"
        ]
      },
      {
        "name": {
          "value": "Adversarial Machine Learning",
          "justification": "The paper proposes an adversarial attack method to manipulate SHAP explanations.",
          "quote": "Recent studies have shown that they can be manipulated by malicious adversaries to produce arbitrary desired explanations."
        },
        "aliases": [
          "Adversarial ML"
        ]
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "Adult Income",
          "justification": "This is one of the real-world datasets used to demonstrate the effectiveness of the proposed attack.",
          "quote": "Figure 1 illustrates the impact of our attack in an explanation scenario with the Adult Income dataset."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "COMPAS",
          "justification": "This is one of the real-world datasets used to demonstrate the effectiveness of the proposed attack.",
          "quote": "Experimentally (Section 5), we illustrate the impact of the proposed manipulation attack on a synthetic dataset and four popular datasets, namely Adult Income, COMPAS, Marketing, and Communities."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Marketing",
          "justification": "This is one of the real-world datasets used to demonstrate the effectiveness of the proposed attack.",
          "quote": "Experimentally (Section 5), we illustrate the impact of the proposed manipulation attack on a synthetic dataset and four popular datasets, namely Adult Income, COMPAS, Marketing, and Communities."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Communities",
          "justification": "This is one of the real-world datasets used to demonstrate the effectiveness of the proposed attack.",
          "quote": "Experimentally (Section 5), we illustrate the impact of the proposed manipulation attack on a synthetic dataset and four popular datasets, namely Adult Income, COMPAS, Marketing, and Communities."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "SHAP",
          "justification": "The SHAP library is explicitly mentioned as being used for computing the SHAP values that are manipulated in the experiments.",
          "quote": "The benchmark dataset ensures the external auditors reproduce the reported feature attributions using the existing SHAP library."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "A Unified Approach to Interpreting Model Predictions",
          "justification": "This is the foundational paper describing the SHAP library.",
          "quote": "For instance, SHAP (Lundberg & Lee, 2017) has risen in popularity as a means to extract model-agnostic local feature attributions."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1120,
    "prompt_tokens": 23966,
    "total_tokens": 25086
  }
}