{
  "paper": "2209.11924.txt",
  "words": 22708,
  "extractions": {
    "title": {
      "value": "Interventional Causal Representation Learning",
      "justification": "This is the title provided at the beginning of the paper.",
      "quote": "Interventional Causal Representation Learning"
    },
    "description": "The paper explores the utility of interventional data in causal representation learning, establishing theoretical guarantees for identifying latent factors up to certain transformations. The authors show that interventions introduce geometric signatures in the data that can be leveraged to identify causal factors without strong assumptions about their distributions or dependencies. They also provide empirical results supporting their theoretical claims using synthetic datasets and real-world image data generated from a rendering engine.",
    "type": {
      "value": "Theoretical",
      "justification": "The paper primarily focuses on establishing theoretical guarantees regarding the identification of latent factors in causal representation learning.",
      "quote": "This work establishes representation identification guarantees without strong distributional assumptions on the latents in the following settings."
    },
    "primary_research_field": {
      "name": {
        "value": "Causal Representation Learning",
        "justification": "The paper explicitly states its focus on the emerging field of causal representation learning.",
        "quote": "This question is central to the emerging field of causal representation learning (SchoÌˆlkopf et al., 2021)."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Learning",
          "justification": "The paper positions its contributions within the broader field of machine learning, specifically addressing challenges in representation learning.",
          "quote": "Proceedings of the 40 International Conference on Machine Learning, Honolulu, Hawaii, USA."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computer Vision",
          "justification": "While the primary focus is causal representation learning, the empirical demonstrations include image data, making it relevant to computer vision.",
          "quote": "Moreover, the code repository can be accessed github.com/facebookresearch/CausalRepID."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-18",
          "justification": "The paper uses ResNet-18 for image-based experiments as the encoder model.",
          "quote": "For image-based experiments we use a ResNet-18 as the encoder (He et al., 2016)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The paper leverages an existing model, ResNet-18, and does not claim it as a novel contribution.",
          "quote": "For image-based experiments we use a ResNet-18 as the encoder (He et al., 2016)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The ResNet-18 model is executed as part of the image-based experiments.",
          "quote": "For image-based experiments we use a ResNet-18 as the encoder (He et al., 2016)."
        },
        "is_compared": {
          "value": 0,
          "justification": "The main purpose of using ResNet-18 was for encoding image data rather than comparing its performance against other models.",
          "quote": "For image-based experiments we use a ResNet-18 as the encoder (He et al., 2016)."
        },
        "referenced_paper_title": {
          "value": "Deep residual learning for image recognition",
          "justification": "The referenced paper provides the details of the ResNet-18 model, which is cited in the paper.",
          "quote": "For image-based experiments we use a ResNet-18 as the encoder (He et al., 2016)."
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "PyGame",
          "justification": "The PyGame library is used for generating synthetic image data in the experiments.",
          "quote": "We used the PyGame (Shinners, 2011) rendering engine."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no reference paper provided for PyGame.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "scikit-learn",
          "justification": "The scikit-learn library is used for its regression models and other utilities in experiments.",
          "quote": "We use the default linear regression class from scikit-learn (Pedregosa et al., 2011)."
        },
        "aliases": [
          "sklearn"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Scikit-learn: Machine learning in Python",
          "justification": "The referenced paper provides details of the scikit-learn library.",
          "quote": "We use the default linear regression class from scikit-learn (Pedregosa et al., 2011)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1938,
    "prompt_tokens": 84892,
    "total_tokens": 86830
  }
}