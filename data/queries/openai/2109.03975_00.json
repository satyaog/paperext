{
  "paper": "2109.03975.txt",
  "words": 9879,
  "extractions": {
    "title": {
      "value": "Membership Inference Attacks Against Temporally Correlated Data in Deep Reinforcement Learning",
      "justification": "The title of the paper as stated in the provided text.",
      "quote": "Membership Inference Attacks Against Temporally Correlated Data in Deep Reinforcement Learning"
    },
    "description": "This study explores the vulnerability of deep reinforcement learning algorithms to membership inference attacks, focusing on the temporal correlation inherent in reinforcement learning data. The authors propose an adversarial attack framework and conduct experiments to assess the impact of temporal correlation, as well as the comparative performance of collective and individual membership attacks across three continuous control Mujoco tasks.",
    "type": {
      "value": "Empirical",
      "justification": "The paper involves designing an adversarial attack framework and conducting various experiments to test it, which indicates an empirical study.",
      "quote": "In particular, we design a series of experiments to investigate the impact of temporal correlation, which naturally exists in reinforcement learning training data, on the probability of information leakage."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The primary focus of the paper is on deep reinforcement learning algorithms and their vulnerability to membership inference attacks.",
        "quote": "One of the major challenges in the implementation of MIAs in deep RL settings is the sequential and correlated nature of deep RL data points."
      },
      "aliases": [
        "RL",
        "Deep Reinforcement Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Adversarial Machine Learning",
          "justification": "The study is centered on designing and evaluating adversarial attacks against deep reinforcement learning models, which falls under adversarial machine learning.",
          "quote": "To address this gap, we propose an adversarial attack framework designed for testing the vulnerability of a state-of-the-art deep reinforcement learning algorithm to a membership inference attack."
        },
        "aliases": [
          "AML"
        ]
      },
      {
        "name": {
          "value": "Privacy",
          "justification": "The paper investigates the privacy implications of deep reinforcement learning algorithms by exploring membership inference attacks.",
          "quote": "This raises serious privacy concerns in this regard."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Batch-Constrained deep Q-learning (BCQ)",
          "justification": "The paper explicitly mentions using the state-of-the-art Batch-Constrained deep Q-learning (BCQ) model for the deep reinforcement learning experiments.",
          "quote": "In this study, we choose to work with the state-of-the-art Batch-Constrained deep Q-learning (BCQ) model."
        },
        "aliases": [
          "BCQ"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The BCQ model is used in the experiments but is not a novel contribution of this paper.",
          "quote": "The state-of-the-art Batch-Constrained deep Q-learning (BCQ) model, which is widely used as the basis of other deep RL algorithms and exhibits remarkable performance in complex control tasks."
        },
        "is_executed": {
          "value": 1,
          "justification": "The BCQ model is implemented and used in the experiments within the paper.",
          "quote": "In this study, we choose to work with the state-of-the-art Batch-Constrained deep Q-learning (BCQ) model."
        },
        "is_compared": {
          "value": 0,
          "justification": "The BCQ model is not compared numerically to other models within the scope of this paper.",
          "quote": "The paper focuses on the privacy vulnerabilities of BCQ rather than comparing its performance with other models."
        },
        "referenced_paper_title": {
          "value": "Off-policy deep reinforcement learning without exploration",
          "justification": "The original paper that introduced the BCQ model.",
          "quote": "Batch-Constrained Deep Q-learning (BCQ) [34]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Hopper-v2",
          "justification": "Hopper-v2 is one of the continuous control tasks in the MuJoCo environment used in the experiments.",
          "quote": "Experimental results show that the proposed adversarial attack framework is surprisingly effective at inferring data with an accuracy exceeding 84% in individual and 97% in collective modes in three different continuous control Mujoco tasks."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "OpenAI Gym",
          "justification": "The dataset Hopper-v2 is part of the OpenAI Gym environment.",
          "quote": "OpenAI Gym environments [35] powered by MuJoCo physics engine"
        }
      },
      {
        "name": {
          "value": "HalfCheetah-v2",
          "justification": "HalfCheetah-v2 is another continuous control task used in the experiments.",
          "quote": "We train the deep RL agent on three high-dimensional continuous control tasks: Hopper-v2 (A ⊂ R^3 and S ⊂ R^11), Half Cheetah-v2 (A ⊂ R^6 and S ⊂ R^17), and Ant-v2 (A ⊂ R^8 and S ⊂ R^111)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "OpenAI Gym",
          "justification": "The dataset HalfCheetah-v2 is part of the OpenAI Gym environment.",
          "quote": "OpenAI Gym environments [35] powered by MuJoCo physics engine"
        }
      },
      {
        "name": {
          "value": "Ant-v2",
          "justification": "Ant-v2 is another continuous control task used in the experiments.",
          "quote": "We train the deep RL agent on three high-dimensional continuous control tasks: Hopper-v2 (A ⊂ R^3 and S ⊂ R^11), Half Cheetah-v2 (A ⊂ R^6 and S ⊂ R^17), and Ant-v2 (A ⊂ R^8 and S ⊂ R^111)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "OpenAI Gym",
          "justification": "The dataset Ant-v2 is part of the OpenAI Gym environment.",
          "quote": "OpenAI Gym environments [35] powered by MuJoCo physics engine"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1450,
    "prompt_tokens": 16330,
    "total_tokens": 17780
  }
}