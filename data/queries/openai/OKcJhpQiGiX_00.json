{
  "paper": "OKcJhpQiGiX.txt",
  "words": 14520,
  "extractions": {
    "title": {
      "value": "Disentanglement of Correlated Factors via Hausdorff Factorized Support",
      "justification": "This is the exact title displayed at the top of the paper.",
      "quote": "Disentanglement of Correlated Factors via Hausdorff Factorized Support"
    },
    "description": "This paper introduces a method to relax the unrealistic assumption of statistically independent factors in disentanglement methods. The proposed approach, Hausdorff Factorized Support (HFS), encourages pairwise factorized support by minimizing the Hausdorff distance. This new criterion shows improved disentanglement and recovery of ground-truth factors across various settings, even under severe correlations.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents empirical evaluations of the proposed method across benchmarks and correlation settings. It offers experimental results and comparisons with existing methods.",
      "quote": "We show that the use of HFS consistently facilitates disentanglement and recovery of ground-truth factors across a variety of correlation settings and benchmarks... Extensive experiments on three main benchmarks and up to 14 increasingly difficult correlations settings over more than 20k models."
    },
    "primary_research_field": {
      "name": {
        "value": "Representation Learning",
        "justification": "The paper focuses on disentangled representation learning, which falls under the broader category of representation learning in deep learning.",
        "quote": "A grand goal in deep learning research is to learn representations capable of generalizing across distribution shifts. Disentanglement is one promising direction aimed at aligning a model’s representation with the underlying factors generating the data."
      },
      "aliases": [
        "Representation Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Disentangled Representation Learning",
          "justification": "The primary contribution of the paper is a new method for disentangled representation learning, which is a subfield of representation learning.",
          "quote": "Disentangled representation learning (Bengio et al., 2013; Higgins et al., 2018) is a promising path to facilitate reliable generalization to in- and out-of-distribution downstream tasks."
        },
        "aliases": [
          "Disentangled Representation Learning"
        ]
      },
      {
        "name": {
          "value": "Unsupervised Learning",
          "justification": "The proposed method is applied in an unsupervised learning setting, focusing on learning without labeled data.",
          "quote": "But fully unsupervised disentanglement – our focus in this study – is in theory impossible to achieve in the general unconstrained nonlinear case."
        },
        "aliases": [
          "Unsupervised Learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Hausdorff Factorized Support (HFS)",
          "justification": "The paper introduces the Hausdorff Factorized Support (HFS) criterion as a new method for disentanglement.",
          "quote": "To address this limitation, we consider the use of a relaxed disentanglement criterion – the Hausdorff Factorized Support (HFS) criterion – that encourages only pairwise factorized support."
        },
        "aliases": [
          "HFS"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "HFS is introduced in this paper as a new method for disentanglement.",
          "quote": "To address this limitation, we consider the use of a relaxed disentanglement criterion – the Hausdorff Factorized Support (HFS) criterion – that encourages only pairwise factorized support."
        },
        "is_executed": {
          "value": 1,
          "justification": "The method was empirically tested in experiments detailed in the paper.",
          "quote": "We show that the use of HFS consistently facilitates disentanglement and recovery of ground-truth factors across a variety of correlation settings and benchmarks... Extensive experiments on three main benchmarks and up to 14 increasingly difficult correlations settings over more than 20k models."
        },
        "is_compared": {
          "value": 1,
          "justification": "HFS is compared with other disentanglement methods like β-VAE, FactorVAE, etc., showing significant improvements.",
          "quote": "Extensive experiments on three main benchmarks and up to 14 increasingly difficult correlations settings over more than 20k models, show HFS systematically improving disentanglement (as measured by DCI-D) by up to +61% over standard methods (β/TC/Factor/Annealed-VAE, c.f. §4.1, Tab. 1)."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "This model is newly introduced in this paper, so there is no referenced paper for it.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Shapes3D",
          "justification": "Shapes3D is one of the key datasets used to evaluate the proposed HFS method.",
          "quote": "We study the behaviour of HFS and baselines on standard disentanglement learning benchmarks and correlated variants thereof (see §4) - Shapes3D (Kim & Mnih, 2018)."
        },
        "aliases": [
          "3D Shapes"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Disentangling by factorising",
          "justification": "Shapes3D dataset is referenced from the paper 'Disentangling by factorising'.",
          "quote": "Shapes3D (Kim & Mnih, 2018)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper mentions the use of the PyTorch framework for implementing their experiments.",
          "quote": "We implement all our experiments using the PyTorch framework."
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The reference paper for PyTorch is titled 'PyTorch: An imperative style, high-performance deep learning library'.",
          "quote": "For replicability, we provide a copy of Fig. 2 with the exact utilised correlation settings in Fig. 10."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1146,
    "prompt_tokens": 29435,
    "total_tokens": 30581
  }
}