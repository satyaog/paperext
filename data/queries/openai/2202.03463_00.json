{
  "paper": "2202.03463.txt",
  "words": 14568,
  "extractions": {
    "title": {
      "value": "On learning Whittle index policy for restless bandits with scalable regret",
      "justification": "This is the title provided at the beginning of the text.",
      "quote": "On learning Whittle index policy for restless bandits with scalable regret"
    },
    "description": "The paper discusses a model-based reinforcement learning algorithm tailored for restless bandit problems. It introduces a Thompson-sampling based approach to achieve scalable regret bounds, and benchmarks its performance against the Whittle index policy.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents numerical results to illustrate the performance of the proposed algorithm.",
      "quote": "We present numerical examples to illustrate the salient features of the algorithm."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The context and problems addressed in the paper revolve around optimizing policies based on reinforcement learning techniques.",
        "quote": "Reinforcement learning is an attractive approach to learn good resource allocation and scheduling policies based on data when the system model is unknown."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Resource Allocation",
          "justification": "The primary application discussed involves resource allocation and scheduling problems.",
          "quote": "Resource allocation and scheduling problems arise in control of networked systems."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Multi-armed Bandits",
          "justification": "The restless bandit problem, a type of multi-armed bandit problem, is central to the paper's discussion.",
          "quote": "Restless bandits (RBs) have emerged as a popular solution heuristic for such problems."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "RB-TSDE",
          "justification": "The paper proposes a Thompson-sampling based learning algorithm called RB-TSDE.",
          "quote": "we propose a Thompson-sampling based learning algorithm for RB, which we call RB-TSDE."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The algorithm is specifically introduced and analyzed within this paper.",
          "quote": "The main contribution of this paper is to characterize the regret of a general RL algorithm for general RBs. In particular, we propose a Thompson-sampling based learning algorithm for RB, which we call RB-TSDE."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper presents numerical examples and experimental results for the proposed algorithm.",
          "quote": "In Sec. V, we demonstrate a numerical example of the regret of our algorithm."
        },
        "is_compared": {
          "value": false,
          "justification": "There is no explicit mention of a numerical comparison with other models.",
          "quote": "We present numerical examples to illustrate the salient features of the algorithm."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference to a prior paper for RB-TSDE.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 733,
    "prompt_tokens": 25680,
    "total_tokens": 26413
  }
}