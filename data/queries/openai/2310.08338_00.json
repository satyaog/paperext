{
  "paper": "2310.08338.txt",
  "words": 8890,
  "extractions": {
    "title": {
      "value": "A Cry for Help: Early Detection of Brain Injury in Newborns",
      "justification": "Title identified directly from the research paper.",
      "quote": "A Cry for Help: Early Detection of Brain Injury in Newborns"
    },
    "description": "This research focuses on the development and validation of a deep learning system named 'Roseline' for early detection of neonatal brain injury using audio recordings of infant cries. The study analyzes patterns in infant cries to identify neurological injury, leveraging a large, geographically diverse dataset. The technology aims to provide an accessible, non-invasive screening tool for low-resource settings.",
    "type": {
      "value": "Empirical",
      "justification": "The study involves experimental data collection, model development, and validation through empirical methods.",
      "quote": "we acquired a large and geographically diverse clinical database of cry recordings and developed a new training methodology for audio-based pathology detection models."
    },
    "primary_research_field": {
      "name": {
        "value": "Bioacoustic AI",
        "justification": "The work utilizes AI algorithms to analyze bioacoustic signals (infant cries) for medical diagnosis.",
        "quote": "Our system extracts interpretable acoustic biomarkers that support clinical decisions and is able to accurately detect neurological injury from newborns’ cries."
      },
      "aliases": [
        "Neonatal Acoustic Analysis"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Medical Signal Processing",
          "justification": "The research focuses on processing cry signals to extract medically relevant features.",
          "quote": "Using only cry sounds at birth, our system...is able to identify evolving neurological injury with an AUC of 92.5%."
        },
        "aliases": [
          "Bio-signal Processing"
        ]
      },
      {
        "name": {
          "value": "Machine Learning for Healthcare",
          "justification": "The deep learning model 'Roseline' is developed for the purpose of health screening and diagnosis.",
          "quote": "We develop a new training methodology for audio-based pathology detection models and evaluate this system on a large database of newborn cry sounds."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Roseline",
          "justification": "The model 'Roseline' is introduced in the paper for detecting neurological injury from infant cries.",
          "quote": "Roseline (Reduction Of Self-supervised Entropy to Learn and Infer Neonatal Encephalopathy)"
        },
        "aliases": [
          "Reduction Of Self-supervised Entropy to Learn and Infer Neonatal Encephalopathy"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "Roseline is the main contribution of this paper, specifically developed for detecting brain injury in newborns.",
          "quote": "we report on the first inter-continental clinical study to demonstrate that neonatal brain injury can be reliably determined from recorded infant cries using an AI algorithm we call Roseline."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was trained and tested using computational resources as described in the methods section.",
          "quote": "For reliable LAM evaluation, the model was trained 10 times with different random seeds and tested on a held-out set."
        },
        "is_compared": {
          "value": 0,
          "justification": "There is no mention of direct numerical comparison with other models within this paper.",
          "quote": "we achieved good results using the created model; however, there are no explicit comparisons with others."
        },
        "referenced_paper_title": {
          "value": "Not Applicable",
          "justification": "Roseline is a new model proposed in this paper, not referenced from a previous publication.",
          "quote": "reduction of self-supervised entropy to learn and infer neonatal encephalopathy"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Ubenwa Cry Database",
          "justification": "Used as the primary dataset for training and evaluating the model.",
          "quote": "Using only cry sounds at birth, our system, depicted in Fig. 1a, which we name Roseline, is able to identify evolving neurological injury."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Not Applicable",
          "justification": "This dataset is a collection developed for this specific study as described in the methodology.",
          "quote": "The dataset of cries and associated clinical information was collected by five hospitals between 2020 and 2023."
        }
      },
      {
        "name": {
          "value": "VGGSound",
          "justification": "Used for pre-training the model in the first stage of the training process.",
          "quote": "we use the well-known VGG sound database, which contains 550 hours of over 300 audio classes."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Chen, H., Xie, W., Vedaldi, A. & Zisserman, A. VGGSound: A Large-Scale Audio-Visual Dataset. in ICASSP 2020 721-725 (IEEE, 2020).",
          "justification": "Referenced appropriately in the research paper.",
          "quote": "For pre-training, we use the well-known VGG sound database, which contains 550 hours of over 300 audio classes."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "librosa",
          "justification": "Librosa is used to process and extract audio features from cry recordings.",
          "quote": "Spectral flatness computed with Librosa"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "McFee, B. et al. librosa: 0.10.0. (2023) doi:10.5281/ZENODO.591533.",
          "justification": "Full citation provided in the research paper.",
          "quote": "Librosa 0.10.0. (2023) doi:10.5281/ZENODO.591533."
        }
      },
      {
        "name": {
          "value": "openSMILE",
          "justification": "openSMILE toolkit is used for extracting audio features for analysis.",
          "quote": "Generic voice features used in this study were computed using openSMILE (open-source Speech and Music Interpretation by Large-space Extraction)"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Eyben, F., Wöllmer, M. & Schuller, B. opensmile: the Munich Versatile and Fast Open-source Audio Feature Extractor. in ACM Multimedia Conference 1459–1462 (ACM, 2010).",
          "justification": "Full citation provided in the research paper.",
          "quote": "We utilized the openSMILE toolkit (Eyben et al., 2010)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2836,
    "prompt_tokens": 40191,
    "total_tokens": 43027
  }
}