{
  "paper": "2211.09066.txt",
  "words": 19578,
  "extractions": {
    "title": {
      "value": "Teaching Algorithmic Reasoning via In-context Learning",
      "justification": "This is the title of the paper.",
      "quote": "Teaching Algorithmic Reasoning via In-context Learning"
    },
    "description": "This paper focuses on teaching algorithmic reasoning to Large Language Models (LLMs) via in-context learning. The authors identify and explore four key stages: formulating algorithms as skills, teaching multiple skills simultaneously, skill composition, and using skills as tools. They propose an approach called algorithmic prompting and show that it significantly boosts performance on arithmetic and quantitative reasoning tasks.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes various experiments evaluating different prompting strategies and their effectiveness in teaching algorithmic reasoning to LLMs.",
      "quote": "We show that it is possible to teach algorithmic reasoning to LLMs via in-context learning, which we refer to as algorithmic prompting. We evaluate our approach on a variety of arithmetic and quantitative reasoning tasks, and demonstrate significant boosts in performance over existing prompting techniques."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research focuses on teaching algorithmic reasoning to Large Language Models (LLMs) via in-context learning, a topic within Natural Language Processing.",
        "quote": "In this work, we investigate how to teach algorithms and compositions of algorithms to LLMs via in-context learning."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Algorithmic Reasoning",
          "justification": "The study specifically targets the capability of LLMs to perform algorithmic reasoning, evaluating various strategies to improve this ability.",
          "quote": "We identify and study four key stages for successfully teaching algorithmic reasoning to LLMs."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Arithmetic Reasoning",
          "justification": "The paper evaluates its techniques on arithmetic tasks such as addition, subtraction, and multiplication, making it a sub-field of focus.",
          "quote": "We focus on arithmetic algorithms such as addition, subtraction and multiplication as they have been widely benchmarked."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "In-context Learning",
          "justification": "The core method discussed in the paper is in-context learning, and the experiments are designed to evaluate its effectiveness in teaching algorithmic reasoning.",
          "quote": "We show that it is possible to teach algorithmic reasoning to LLMs via in-context learning."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Codex",
          "justification": "The Codex model (code-davinci-002 from OpenAI) is used for all the experiments in this paper.",
          "quote": "For all the experiments in the paper, we use the Codex model code-davinci-002 from OpenAI."
        },
        "aliases": [
          "code-davinci-002"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The Codex model is used for experiments but is not a contribution of this paper.",
          "quote": "For all the experiments in the paper, we use the Codex model code-davinci-002 from OpenAI."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify whether Codex was executed on GPU or CPU.",
          "quote": "For all the experiments in the paper, we use the Codex model code-davinci-002 from OpenAI."
        },
        "is_compared": {
          "value": 1,
          "justification": "The Codex model is compared to other models and prompting techniques in the experiments.",
          "quote": "We demonstrate that algorithmic prompting significantly outperforms existing prompting techniques on several algorithmic tasks."
        },
        "referenced_paper_title": {
          "value": "Evaluating large language models trained on code",
          "justification": "This is the reference paper for the Codex model used in this study.",
          "quote": "For all the experiments in the paper, we use the Codex model code-davinci-002 from OpenAI."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "GSM8k",
          "justification": "The GSM8k dataset is used to evaluate the effectiveness of the proposed method in solving math word problems.",
          "quote": "We consider the following two math word problem datasets: GSM8k and GSM8k-Hard"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Training Verifiers to Solve Math Word Problems",
          "justification": "This is the reference paper where the GSM8k dataset is introduced.",
          "quote": "GSM8k (Cobbe et al., 2021) consists of high-quality mathematical reasoning problems presented as natural language questions."
        }
      },
      {
        "name": {
          "value": "GSM8k-Hard",
          "justification": "GSM8k-Hard is a modified version of the GSM8k dataset created by the authors to increase the difficulty of the problems.",
          "quote": "We create a hard dataset called GSM8k-Hard, which consists of 50 examples from the pure-addition subset of the GSM8k."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "Training Verifiers to Solve Math Word Problems",
          "justification": "The GSM8k-Hard is based on the GSM8k dataset, which is introduced in this reference paper.",
          "quote": "GSM8k (Cobbe et al., 2021) consists of high-quality mathematical reasoning problems presented as natural language questions."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenAI Codex",
          "justification": "The Codex model from OpenAI is explicitly used for all experiments in the paper.",
          "quote": "For all the experiments in the paper, we use the Codex model code-davinci-002 from OpenAI."
        },
        "aliases": [
          "code-davinci-002"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Evaluating large language models trained on code",
          "justification": "This is the paper that details the Codex model used in this study.",
          "quote": "For all the experiments in the paper, we use the Codex model code-davinci-002 from OpenAI."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1190,
    "prompt_tokens": 38147,
    "total_tokens": 39337
  }
}