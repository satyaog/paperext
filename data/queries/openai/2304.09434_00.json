{
  "paper": "2304.09434.txt",
  "words": 8089,
  "extractions": {
    "title": {
      "value": "Torque-based Deep Reinforcement Learning for Task-and-Robot Agnostic Learning on Bipedal Robots Using Sim-to-Real Transfer",
      "justification": "This is the exact title of the paper provided.",
      "quote": "Torque-based Deep Reinforcement Learning for Task-and-Robot Agnostic Learning on Bipedal Robots Using Sim-to-Real Transfer"
    },
    "description": "This paper explores the use of torque-based deep reinforcement learning (RL) for controlling bipedal robots. It focuses on task-and-robot agnostic learning, sim-to-real transfer, and overcoming the limitations of position-based deepRL methods. The research highlights the advantages of torque-based control in terms of compliance, reduced parameter tuning, and successful real-world implementation on human-sized biped robots.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves experiments and comparisons between torque-based and position-based deepRL methods using simulations and real-world robot hardware. It assesses the effectiveness of the proposed methods through empirical results.",
      "quote": "By analyzing the proposed torque-based deepRL policy alongside the widely-used position-based deepRL policy, it is demonstrated that the torque-based deepRL policy can learn to squat, walk, and run with minimal tuning."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper focuses on the application and evaluation of reinforcement learning methods for controlling bipedal robots.",
        "quote": "Recently, reinforcement learning (RL) has become a popular method for implementing robotic controllers, in part due to its ability to be applied to challenging tasks and robots."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Robotics",
          "justification": "The research addresses control algorithms and hardware implementations for bipedal robots.",
          "quote": "Control algorithms for robots can be extremely complex and difficult to implement. They change widely based on the robot themselves and tasks, and a continuing line of robotics research has shown the difficulties faced when high-dof multi-link robots, such as biped robots, are controlled."
        },
        "aliases": [
          "Humanoid Robotics"
        ]
      },
      {
        "name": {
          "value": "Sim-to-Real Transfer",
          "justification": "The paper tackles the sim-to-real transfer problem, emphasizing the need for control methods that work both in simulation and on real hardware.",
          "quote": "However, since the reality gap exists between simulation and the real-world due to various factors, such as contact dynamics and state estimation gap, we should promote control methods that can be used more broadly whether in a simulation or real robot."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Control Systems",
          "justification": "It discusses various control strategies for robots, including position-based and torque-based deepRL.",
          "quote": "Additionally, since the reality gap exists between simulation and the real-world due to various factors, such as contact dynamics and state estimation gap, we should promote control methods that can be used more broadly whether in a simulation or real robot."
        },
        "aliases": [
          "Control Algorithms"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Torque-based Deep Reinforcement Learning Policy",
          "justification": "The model focuses on torque-based actions rather than position-based actions to improve performance and compliance.",
          "quote": "We show that instead, using a torque-based action space enables task-and-robot agnostic learning with less parameter tuning and mitigates the sim-to-reality gap by taking advantage of torque control’s inherent compliance."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The primary focus of the paper is the development and evaluation of the torque-based deep reinforcement learning policy for bipedal robots.",
          "quote": "We propose to pre-train the torque-based policy with the gravity compensation torque to accelerate initial training and reduce the sample inefficiency."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed in real-world robot hardware as well as in simulations.",
          "quote": "The paper showcases the first successful sim-to-real transfer of a torque-based deep reinforcement learning policy on a real human-sized biped robot."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model was compared with position-based deepRL policies through various experiments.",
          "quote": "By analyzing the proposed torque-based deepRL policy alongside the widely-used position-based deepRL policy, it is demonstrated that the torque-based deepRL policy can learn to squat, walk, and run with minimal tuning."
        },
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "This model does not refer to another paper for its introduction; it is proposed within this paper itself.",
          "quote": "We propose to pre-train the torque-based policy with the gravity compensation torque to accelerate initial training and reduce the sample inefficiency."
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "MuJoCo",
          "justification": "MuJoCo is mentioned as the simulation environment used for the experiments.",
          "quote": "The height of the uneven terrain is randomly generated using the ’hfield’ asset of MuJoCo, as depicted in Fig. 8."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "The library itself is utilized within the scope of this paper and is not a contribution or explicit reference.",
          "quote": "The height of the uneven terrain is randomly generated using the ’hfield’ asset of MuJoCo, as depicted in Fig. 8."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1064,
    "prompt_tokens": 13908,
    "total_tokens": 14972
  }
}