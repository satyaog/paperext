{
  "paper": "2307.03201.txt",
  "words": 14818,
  "extractions": {
    "title": {
      "value": "Scaling Laws Do Not Scale",
      "justification": "The best literal title we can extract from the paper is directly given in the metadata and the document header.",
      "quote": "Scaling Laws Do Not Scale"
    },
    "description": "The paper challenges the prevailing notion of 'scaling laws' in artificial intelligence, which posit a predictable relationship between increasing dataset sizes (or model parameters) and corresponding performance improvements. The authors argue that this relationship fails to account for the diverse values and preferences of different subpopulations within the data, leading to potential biases and performance disparities. They propose a third dimension for scaling laws that considers the size of the evaluation dataset and highlight the complexities introduced by growing subpopulations. The paper concludes with recommendations for more inclusive and context-aware evaluation metrics to better reflect diverse user values.",
    "type": {
      "value": "theoretical",
      "justification": "The authors conduct a theoretical analysis challenging existing concepts in AI scaling laws by considering social dynamics, evaluation metrics, and subpopulation diversity. They do not present new empirical data or experimental results but rather provide a critical review and conceptual framework for understanding scaling laws.",
      "quote": "We demonstrate that current AI scaling law analyses overlook the large and diverse set of constructs required to truly assess performance for large and diverse sets of communities."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper discusses scaling laws in the context of training large AI models, which is a fundamental topic in Deep Learning research. The arguments and recommendations pertain directly to the development and evaluation of deep learning systems.",
        "quote": "Recent work has proposed a power law relationship, referred to as 'scaling laws,' between the performance of artificial intelligence (AI) models and aspects of those models’ design (e.g., dataset size)."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Evaluation Metrics",
          "justification": "The primary focus of the paper is on challenging and redefining the evaluation metrics used to measure the performance of AI models as they scale. The authors highlight the limitations of current metrics and propose new approaches for more inclusive and representative evaluations.",
          "quote": "We propose that for a given metric and sampling procedure, scaling laws consider, in addition to the two axes of (training) dataset size and performance on a given metric, a third axis indicating the size of the evaluation data set."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "Colossal Clean Crawled Corpus",
          "justification": "The C4 dataset is mentioned as an example of a large dataset used for training language models. The authors discuss it in the context of the limitations of scaling laws and the representativeness of evaluation datasets.",
          "quote": "This relationship has been used to justify the collection of ever-larger datasets (e.g., the Colossal Clean Crawled Corpus) used to train large language models."
        },
        "aliases": [
          "C4"
        ],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "LAION",
          "justification": "The LAION dataset is mentioned in a similar context to C4, discussing the potential biases and representativeness challenges inherent in large-scale web crawled datasets.",
          "quote": "Similarly, massive datasets used to train large models, such as the Colossal Clean Crawled Corpus (C4), trained on a crawl of the web, or others such as LAION."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "World Values Survey",
          "justification": "The World Values Survey is used as a reference to discuss cross-cultural variations in values and preferences, highlighting how different groups might have incompatible evaluation metrics for AI models.",
          "quote": "They found substantial cross-cultural variation in preferences, and they attempted to explain that variation by drawing on various economic and cultural indicators, such as the World Values Survey."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Pew American Trends",
          "justification": "Pew American Trends data is referenced to illustrate variations in public opinion that reflect the diverse values and preferences of different subpopulations, which is critical to the paper's arguments around scaling laws and evaluation metrics.",
          "quote": "Recent work has explored the relationship between different groups’ responses to public opinion polls (e.g., Pew American Trends and the World Values Survey) and the output of large language models."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "BBQ Benchmark",
          "justification": "The BBQ Benchmark is discussed as a tool for evaluating biases in AI models, emphasizing the need for context-specific metrics to reflect the values of different communities.",
          "quote": "Parrish et al. developed a bias benchmark dataset (BBQ) for question-answering to evaluate the performance of large language models."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1075,
    "prompt_tokens": 24467,
    "total_tokens": 25542
  }
}