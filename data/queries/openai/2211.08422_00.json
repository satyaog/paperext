{
  "paper": "2211.08422.txt",
  "words": 24895,
  "extractions": {
    "title": {
      "value": "Mechanistic Mode Connectivity",
      "justification": "Directly mentioned at the start of the document.",
      "quote": "Mechanistic Mode Connectivity"
    },
    "description": "The paper investigates the loss landscapes of neural networks through the concept of mode connectivity and the mechanisms by which neural network models make their predictions. It proposes mechanistic similarity as a metric for evaluating models' reliance on specific input features and introduces connectivity-based fine-tuning (CBFT) to alter models' mechanisms effectively.",
    "type": {
      "value": "empirical",
      "justification": "The work involves extensive experiments to demonstrate various properties of mechanistic mode connectivity.",
      "quote": "Extensive experiments on synthetic datasets show CBFT is more effective than recent methods"
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The primary focus is on understanding and improving the training and fine-tuning processes of machine learning models.",
        "quote": "Proceedings of the 40 th International Conference on Machine Learning"
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Neural Networks",
          "justification": "The investigation revolves around the mechanisms and loss landscapes of neural networks specifically.",
          "quote": "We study neural network loss landscapes"
        },
        "aliases": [
          "NN"
        ]
      },
      {
        "name": {
          "value": "Optimization",
          "justification": "The work digs deeply into the optimization processes, specifically focusing on connectivity and loss barriers.",
          "quote": "We argue prior literature analyzing connectivity properties in DNN loss landscapes"
        },
        "aliases": [
          "Optimization"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-18",
          "justification": "ResNet-18 was one of the models used for experiments to demonstrate mechanistic connectivity.",
          "quote": "We train ResNet-18 models on our synthetic CIFAR-10 datasets"
        },
        "aliases": [
          "ResNet"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The model ResNet-18 was used for experiments but is not a new contribution.",
          "quote": "We train ResNet-18 models"
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments involved executing ResNet-18 models.",
          "quote": "We train ResNet-18 models"
        },
        "is_compared": {
          "value": 1,
          "justification": "ResNet-18 is compared against other models and methods like VGG-13 and CBFT.",
          "quote": "Our results suggest CBFT is more effective"
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "This is the original paper for ResNet models which includes ResNet-18.",
          "quote": "Deep Residual Learning for Image Recognition"
        }
      },
      {
        "name": {
          "value": "VGG-13",
          "justification": "VGG-13 was one of the models used for experiments to demonstrate mechanistic connectivity.",
          "quote": "We train VGG-13 models on our synthetic datasets"
        },
        "aliases": [
          "VGG"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The model VGG-13 was used for experiments but is not a new contribution.",
          "quote": "We train VGG-13 models"
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments involved executing VGG-13 models.",
          "quote": "We train VGG-13 models"
        },
        "is_compared": {
          "value": 1,
          "justification": "VGG-13 is compared against other models and methods like ResNet-18 and CBFT.",
          "quote": "θC and θNC; VGG-13 and ResNet-18 models"
        },
        "referenced_paper_title": {
          "value": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
          "justification": "This is the original paper for VGG models which includes VGG-13.",
          "quote": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is used extensively to test the proposed methods and models in the paper.",
          "quote": "experiments on synthetic datasets show CBFT is more effective"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-10 dataset was first introduced in this technical report.",
          "quote": "Learning Multiple Layers of Features from Tiny Images"
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is another dataset used in the experiments to evaluate the proposed methods.",
          "quote": "experiments on synthetic datasets show CBFT is more effective"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-100 dataset was first introduced in this technical report.",
          "quote": "Learning Multiple Layers of Features from Tiny Images"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1256,
    "prompt_tokens": 47291,
    "total_tokens": 48547
  }
}