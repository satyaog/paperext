{
  "paper": "2304.06638.txt",
  "words": 2870,
  "extractions": {
    "title": {
      "value": "How Useful are Educational Questions Generated by Large Language Models?",
      "justification": "The title is provided at the beginning of the paper.",
      "quote": "How Useful are Educational Questions Generated by Large Language Models?"
    },
    "description": "This paper investigates the effectiveness of Controllable Text Generation (CTG) by Large Language Models (LLMs) for generating educational questions. The study conducts a human evaluation with teachers to assess the quality and usefulness of questions created using CTG and question taxonomies like Bloom’s taxonomy and a difficulty taxonomy. The findings suggest that these generated questions are of high quality and useful for educational purposes.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts a human evaluation through experiments involving teachers who assessed the generated questions, which indicates that it is an empirical study.",
      "quote": "We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom’s and a difficulty taxonomy)."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on Controllable Text Generation (CTG) and Prompting which fall under the Natural Language Processing (NLP) subfield.",
        "quote": "Controllable text generation (CTG) by large language models has a huge potential to transform education for teachers and students alike."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Controllable Text Generation",
          "justification": "The study specifically evaluates the usefulness of questions generated by combining CTG and question taxonomies.",
          "quote": "We conduct a human evaluation with teachers to assess the quality and usefulness of outputs from combining CTG and question taxonomies (Bloom’s and a difficulty taxonomy)."
        },
        "aliases": [
          "CTG"
        ]
      },
      {
        "name": {
          "value": "Question Generation",
          "justification": "The paper addresses question generation by using LLMs and evaluates its quality and usefulness in educational settings.",
          "quote": "A robust question generation (QG) system has the potential to empower teachers by decreasing their cognitive load while creating teaching material."
        },
        "aliases": [
          "QG"
        ]
      },
      {
        "name": {
          "value": "Prompt Engineering",
          "justification": "The paper discusses prompting methods for controllable text generation as a key part of its methodology.",
          "quote": "One of the most common approaches to prompt engineering involves prepending a string to the context given to a LLM for generation."
        },
        "aliases": [
          "Prompting"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-3",
          "justification": "GPT-3 is explicitly mentioned in the paper as one of the models used for generating questions.",
          "quote": "An example of an auto-regressive LLM is the GPT family of models, such as GPT-3."
        },
        "aliases": [
          "GPT-3"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "GPT-3 is a pre-existing model and is not contributed by this paper.",
          "quote": "An example of an auto-regressive LLM is the GPT family of models, such as GPT-3."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper mentions using InstructGPT, a version fine-tuned from GPT-3, indicating that they executed the model.",
          "quote": "Using hand-crafted examples for 5-shot prompting, InstructGPT was prompted to generate 612 candidate questions."
        },
        "is_compared": {
          "value": 0,
          "justification": "The paper does not compare GPT-3 numerically to other models; it focuses on the usefulness of generated questions evaluated by teachers.",
          "quote": "We do not include baselines because the goal is not to show these questions are better than others, only to show they are of high enough quality."
        },
        "referenced_paper_title": {
          "value": "Language Models are Few-Shot Learners",
          "justification": "This is the reference paper for GPT-3.",
          "quote": "An example of an auto-regressive LLM is the GPT family of models, such as GPT-3."
        }
      },
      {
        "name": {
          "value": "InstructGPT",
          "justification": "InstructGPT is explicitly mentioned as a derived model used for generating questions.",
          "quote": "Recently, GPT-3 has been fine-tuned with reinforcement learning to create a powerful LLM called InstructGPT."
        },
        "aliases": [
          "InstructGPT"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "InstructGPT is a pre-existing model and not contributed by this paper.",
          "quote": "Recently, GPT-3 has been fine-tuned with reinforcement learning to create a powerful LLM called InstructGPT."
        },
        "is_executed": {
          "value": 1,
          "justification": "InstructGPT has been used to generate the educational questions in the study.",
          "quote": "Using hand-crafted examples for 5-shot prompting, InstructGPT was prompted to generate 612 candidate questions."
        },
        "is_compared": {
          "value": 0,
          "justification": "The paper does not compare InstructGPT numerically to other models; it focuses on the usefulness of generated questions evaluated by teachers.",
          "quote": "We do not include baselines because the goal is not to show these questions are better than others, only to show they are of high enough quality."
        },
        "referenced_paper_title": {
          "value": "Training language models to follow instructions with human feedback",
          "justification": "This is the reference paper for InstructGPT.",
          "quote": "Recently, GPT-3 has been fine-tuned with reinforcement learning to create a powerful LLM called InstructGPT."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Wikipedia",
          "justification": "The paper mentions that context passages used for generating questions were pulled from Wikipedia.",
          "quote": "There are 68 ‘long’ context passages (6-9 sentences) pulled from Wikipedia (31 are ML, 37 are BIO)."
        },
        "aliases": [
          "Wikipedia"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "The Text Retrieval Conference (TREC) 2004 Question Answering Track: A Complete Evaluation of Question Series",
          "justification": "This is a frequently cited paper for Wikipedia in NLP tasks.",
          "quote": "There are 68 ‘long’ context passages (6-9 sentences) pulled from Wikipedia (31 are ML, 37 are BIO)."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1226,
    "prompt_tokens": 5544,
    "total_tokens": 6770
  }
}