{
  "paper": "2208.12136.txt",
  "words": 23707,
  "extractions": {
    "title": {
      "value": "A Comparison of Reinforcement Learning Frameworks for Software Testing Tasks",
      "justification": "The title is explicitly mentioned at the beginning of the paper.",
      "quote": "A Comparison of Reinforcement Learning Frameworks for Software Testing Tasks"
    },
    "description": "This paper investigates the effectiveness and performance of various Deep Reinforcement Learning (DRL) algorithms from popular DRL frameworks on two essential software testing tasks: game testing and test case prioritization in Continuous Integration (CI). The study aims to help practitioners select the most suitable DRL framework for their specific software testing needs.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper involves empirical comparisons through experiments and evaluations on different datasets and tasks.",
      "quote": "In this paper, therefore, we empirically investigate the applications of carefully selected DRL algorithms (based on the characteristics of algorithms and environments) on two important software testing tasks"
    },
    "primary_research_field": {
      "name": {
        "value": "Software Testing",
        "justification": "The primary focus of the paper is on evaluating DRL frameworks for software testing tasks.",
        "quote": "In this paper, therefore, we empirically investigate the applications of carefully selected DRL algorithms ... on two important software testing tasks"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The study evaluates various Deep Reinforcement Learning (DRL) algorithms and their effectiveness.",
          "quote": "we empirically investigate the applications of carefully selected DRL algorithms (based on the characteristics of algorithms and environments)"
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Continuous Integration",
          "justification": "One of the key tasks evaluated in the paper is test case prioritization in the context of Continuous Integration.",
          "quote": "To prioritize test cases, we run extensive experiments on a CI environment where DRL algorithms from different frameworks are used to rank the test cases."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Game Testing",
          "justification": "The paper evaluates DRL frameworks in the context of game testing as one of its primary tasks.",
          "quote": "For the game testing task, we conduct experiments on a simple game and use DRL algorithms to explore the game to detect bugs."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Advantage Actor Critic (A2C)",
          "justification": "A2C is explicitly mentioned as one of the evaluated algorithms in the paper.",
          "quote": "For example, Kim et al. [31] leveraged the Keras-rl framework to apply DRL to test data generation."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model is not new and is discussed for evaluation purposes, not introduced by this paper.",
          "quote": "In this paper, we perform a comprehensive comparison of different DRL algorithms implemented in three frameworks, i.e., Stable-baselines3 [43], Keras-rl [42], and Tensorforce [47]."
        },
        "is_executed": {
          "value": 1,
          "justification": "A2C was executed in the experiments conducted in the paper.",
          "quote": "Since the authors of wuji did not consider the average cumulative reward as a metric in the original work, we did not report it here."
        },
        "is_compared": {
          "value": 1,
          "justification": "A2C is compared against other DRL algorithms in the study.",
          "quote": "we empirically investigate the applications of carefully selected DRL algorithms ... To prioritize test cases, we run extensive experiments on a CI environment where DRL algorithms from different frameworks are used to rank the test cases."
        },
        "referenced_paper_title": {
          "value": "Asynchronous methods for deep reinforcement learning",
          "justification": "The original paper on A2C is cited.",
          "quote": "Mnih V, Badia AP, Mirza M, Graves A, Lillicrap T, Harley T, Silver D, Kavukcuoglu K (2016) Asynchronous methods for deep reinforcement learning"
        }
      },
      {
        "name": {
          "value": "Deep Q-Networks (DQN)",
          "justification": "DQN is explicitly mentioned and evaluated in the paper.",
          "quote": "For the test case prioritization problem, similar to [8], we study test case prioritization in the context of Continuous Integration (CI)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model is not new and is discussed for evaluation purposes, not introduced by this paper.",
          "quote": "Several strategies, such as random testing by Hamlet et al. [27], coverage-based testing by Zhu et al.[63] and search-based testing by Harman et al. [28] have been proposed to evaluate that a software product does what it is supposed to do."
        },
        "is_executed": {
          "value": 1,
          "justification": "DQN was executed in the experiments conducted in the paper.",
          "quote": "For the test case prioritization problem, similar to [8], we study test case prioritization in the context of Continuous Integration (CI)."
        },
        "is_compared": {
          "value": 1,
          "justification": "DQN is compared against other DRL algorithms in the study.",
          "quote": "If we consider the game as an environment that the agent interacts with, each state refers to observations of the environment perceived by the agent at every time stamp."
        },
        "referenced_paper_title": {
          "value": "Playing atari with deep reinforcement learning",
          "justification": "The original paper on DQN is cited.",
          "quote": "Mnih V, Kavukcuoglu K, Silver D, Graves A, Antonoglou I, Wierstra D, Riedmiller M (2013) Playing atari with deep reinforcement learning. arXiv preprint arXiv:13125602"
        }
      },
      {
        "name": {
          "value": "Proximal Policy Optimization (PPO)",
          "justification": "PPO is explicitly mentioned as one of the evaluated algorithms in the paper.",
          "quote": "we empirically investigate the applications of carefully selected DRL algorithms ... To prioritize test cases, we run extensive experiments on a CI environment where DRL algorithms from different frameworks are used to rank the test cases."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model is not new and is discussed for evaluation purposes, not introduced by this paper.",
          "quote": "In this paper, we perform a comprehensive comparison of different DRL algorithms implemented in three frameworks, i.e., Stable-baselines3 [43], Keras-rl [42], and Tensorforce [47]."
        },
        "is_executed": {
          "value": 1,
          "justification": "PPO was executed in the experiments conducted in the paper.",
          "quote": "This paper, we perform a comprehensive comparison of different DRL algorithms implemented in three frameworks, i.e., Stable-baselines3 [43], Keras-rl [42], and Tensorforce [47]."
        },
        "is_compared": {
          "value": 1,
          "justification": "PPO is compared against other DRL algorithms in the study.",
          "quote": "Given the state st at time step t the agent selects an action at to interact with the game environment and receives a reward st from the environment."
        },
        "referenced_paper_title": {
          "value": "Proximal Policy Optimization Algorithms",
          "justification": "The original paper on PPO is cited.",
          "quote": "Schulman J, Wolski F, Dhariwal P, Radford A, Klimov O (2017) Proximal Policy Optimization Algorithms. arXiv preprint arXiv:170706347"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Paint-Control",
          "justification": "Paint-Control is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "IOFROL",
          "justification": "IOFROL is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "Codec",
          "justification": "Codec is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "Compress",
          "justification": "Compress is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "Imaging",
          "justification": "Imaging is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "IO",
          "justification": "IO is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "Lang",
          "justification": "Lang is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      },
      {
        "name": {
          "value": "Math",
          "justification": "Math is one of the datasets used for evaluating DRL algorithms in the test case prioritization experiments.",
          "quote": "Datasets: Simple and enriched historical data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Reinforcement learning for automatic test case prioritization and selection in continuous integration",
          "justification": "The dataset is referred to and used in the context of evaluating DRL algorithms for test case prioritization.",
          "quote": "Datasets: Simple and enriched historical data sets."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Stable-baselines",
          "justification": "The paper evaluates various DRL algorithms implemented in the Stable-baselines framework.",
          "quote": "In this paper, we perform a comprehensive comparison of different DRL algorithms implemented in three frameworks, i.e., Stable-baselines3 [43], Keras-rl [42], and Tensorforce [47]."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Stable-baselines3: Reliable reinforcement learning implementations",
          "justification": "The original paper on the Stable-baselines library is cited.",
          "quote": "Raffin A, Hill A, Gleave A, Kanervisto A, Ernestus M, Dormann N (2021) Stable-baselines3: Reliable reinforcement learning implementations. Journal of Machine Learning Research."
        }
      },
      {
        "name": {
          "value": "Keras-rl",
          "justification": "The paper evaluates various DRL algorithms implemented in the Keras-rl framework.",
          "quote": "In this paper, we perform a comprehensive comparison of different DRL algorithms implemented in three frameworks, i.e., Stable-baselines3 [43], Keras-rl [42], and Tensorforce [47]."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "keras-rl",
          "justification": "The original paper on the Keras-rl library is cited.",
          "quote": "Plappert M (2016) keras-rl. https://github.com/keras-rl/keras-rl"
        }
      },
      {
        "name": {
          "value": "Tensorforce",
          "justification": "The paper evaluates various DRL algorithms implemented in the Tensorforce framework.",
          "quote": "In this paper, we perform a comprehensive comparison of different DRL algorithms implemented in three frameworks, i.e., Stable-baselines3 [43], Keras-rl [42], and Tensorforce [47]."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Lift: Reinforcement learning in computer systems by learning from demonstrations",
          "justification": "The original paper on the Tensorforce library is cited.",
          "quote": " Schaarschmidt M, Kuhnle A, Ellis B, Fricke K, Gessert F, Yoneki E (2018). Lift: Reinforcement learning in computer systems by learning from demonstrations. arXiv preprint arXiv:180807903"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3561,
    "prompt_tokens": 51547,
    "total_tokens": 55108
  }
}