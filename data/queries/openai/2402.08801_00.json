{
  "paper": "2402.08801.txt",
  "words": 14981,
  "extractions": {
    "title": {
      "value": "ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions",
      "justification": "The paper focuses on a comparative analysis between ChatGPT and LLaMA concerning their impact, reliability, and challenges in the context of Stack Overflow discussions.",
      "quote": "ChatGPT vs LLaMA: Impact, Reliability, and Challenges in Stack Overflow Discussions"
    },
    "description": "This research paper conducts an empirical study analyzing questions from Stack Overflow and using LLMs (ChatGPT and LLaMA) to address them. The paper aims to measure user engagement evolution with Stack Overflow, quantify the reliability of LLMsâ€™ answers, identify why LLMs fail, and compare these models. It evaluates the potential of these models as replacements for Stack Overflow and discusses their strengths and limitations.",
    "type": {
      "value": "empirical study",
      "justification": "The paper is based on an empirical analysis where the researchers study questions and answers in Stack Overflow utilizing LLMs to investigate various aspects.",
      "quote": "We conducted an empirical study analyzing questions from Stack Overflow and using these LLMs to address them."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The focus is on utilizing Large Language Models (LLMs) which are central to Deep Learning research.",
        "quote": "With the advance of Large Language Models (LLMs)..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The paper deals specifically with LLMs applied to Natural Language Processing tasks, such as generating human-like responses.",
          "quote": "LLMs exhibit a capacity to prompt for a variety of subjects and instantaneously provide comprehensive and concise explanations."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ChatGPT-3.5",
          "justification": "The study evaluates ChatGPT-3.5 in the context of answering questions from Stack Overflow.",
          "quote": "While ChatGPT has been largely explored by practitioners and researchers, LLaMA represents an alternative option for similar proposes."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "LLaMA-2",
          "justification": "The study evaluates LLaMA-2 in the context of answering questions from Stack Overflow.",
          "quote": "This way, based on the results of the previous RQ, we investigate two models: ChatGPT-3.5 and LLaMA-2."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Stack Overflow Dataset",
          "justification": "The paper uses questions and answers mined from Stack Overflow for its empirical analysis.",
          "quote": "We perform an empirical study analyzing questions and associated answers mined from Stack Overflow."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 813,
    "prompt_tokens": 22629,
    "total_tokens": 23442
  }
}