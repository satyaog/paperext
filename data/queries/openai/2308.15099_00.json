{
  "paper": "2308.15099.txt",
  "words": 14000,
  "extractions": {
    "title": {
      "value": "Probabilistic Dataset Reconstruction from Interpretable Models",
      "justification": "The title of the paper as provided in the document.",
      "quote": "Probabilistic Dataset Reconstruction from Interpretable Models"
    },
    "description": "The paper investigates the privacy implications of using interpretable models for machine learning, such as decision trees and rule lists. It proposes a novel framework to quantify the information leaks associated with these models by probabilistic reconstruction of the training datasets. The paper demonstrates how this reconstructed data can be computed efficiently and compares its information leak metrics against different model learning strategies.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper contains experiments and empirical evaluations comparing different methods for model construction and information leak measurement.",
      "quote": "we implement the proposed approach and compare the reconstruction quality from optimal and heuristically-built models, for both decision trees and rule lists."
    },
    "primary_research_field": {
      "name": {
        "value": "Privacy in Machine Learning",
        "justification": "The primary focus of the paper is on measuring and mitigating privacy risks associated with machine learning models.",
        "quote": "learning and releasing models that are inherently interpretable leaks information regarding the underlying training data. As such disclosure may directly conflict with privacy, a precise quantification of the privacy impact of such breach is a fundamental problem."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Interpretable Models",
          "justification": "The paper explicitly discusses and evaluates different types of interpretable models, including decision trees and rule lists.",
          "quote": "Common types of interpretable models [12] include rule lists [13], [14], rule sets [15] and decision trees [16]."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Reconstruction Attacks",
          "justification": "The paper focuses on reconstruction attacks as a method to measure information leaks from interpretable models.",
          "quote": "An efficient linear program for reconstructing private bits of the database leveraging counting queries was proposed [20] and later improved and generalized to handle other types of queries [21]."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Decision Tree",
          "justification": "The paper uses decision trees as one of the interpretable models to demonstrate the probabilistic reconstruction approach.",
          "quote": "For instance, the second rule captures two training examples belonging to class 0 (here, x′3 and x′4)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "Decision trees are not introduced in this paper but are used to illustrate the proposed method.",
          "quote": "For instance, previous work [1] have shown that the structure of a decision tree can be leveraged to build a probabilistic reconstruction of its training dataset."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper implemented and ran experiments using decision trees.",
          "quote": "we implement the proposed approach and compare the reconstruction quality from optimal and heuristically-built models, for both decision trees and rule lists."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the information leak metrics and reconstruction quality between different decision-tree-based methods.",
          "quote": "we demonstrate that in the specific case of decision trees and rule lists, the success of a probabilistic reconstruction attack can be estimated efficiently, and theoretically compare the reconstruction quality between these two hypothesis classes."
        },
        "referenced_paper_title": {
          "value": "Classification and Regression Trees",
          "justification": "The foundational paper on decision trees is referenced in this study.",
          "quote": "Common types of interpretable models [12] include rule lists [13], [14], rule sets [15] and decision trees [16]."
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "Scikit-learn",
          "justification": "The scikit-learn library is used for implementing and running decision tree experiments.",
          "quote": "This decision tree, learnt using the scikit-learn python library [36], provides the per-label number of training examples in each internal node and each leaf."
        },
        "aliases": [
          "scikit",
          "sklearn"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Scikit-learn: Machine learning in Python",
          "justification": "The primary reference paper for the scikit-learn library.",
          "quote": "learnt using the scikit-learn python library [36]"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 846,
    "prompt_tokens": 24093,
    "total_tokens": 24939
  }
}