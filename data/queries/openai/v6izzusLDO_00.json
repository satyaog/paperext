{
  "paper": "v6izzusLDO.txt",
  "words": 10224,
  "extractions": {
    "title": {
      "value": "Sampling-Based Accuracy Testing of Posterior Estimators for General Inference",
      "justification": "This is the exact title of the paper.",
      "quote": "Sampling-Based Accuracy Testing of Posterior Estimators for General Inference"
    },
    "description": "The paper introduces Tests of Accuracy with Random Points (TARP) as a method to estimate coverage probabilities of generative posterior estimators. It differentiates itself from previous methods by not requiring posterior evaluations. The theoretical foundation and empirical validation through various experiments are provided, including high-dimensional spaces and specific applications like gravitational lensing source reconstruction.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents new methods (TARP), provides theoretical foundations, and validates them through empirical experiments and simulations.",
      "quote": "We demonstrate the method on a variety of synthetic examples, and show that TARP can be used to test the results of posterior inference analyses in high-dimensional spaces. We also show that our method can detect inaccurate inferences in cases where existing methods fail."
    },
    "primary_research_field": {
      "name": {
        "value": "Simulation-Based Inference (SBI)",
        "justification": "The paper primarily addresses the accuracy testing of posterior estimators within the context of Simulation-Based Inference (SBI).",
        "quote": "Simulation-based inference (SBI, e.g. Cranmer et al., 2020), also known as likelihood-free inference (LFI) or implicit likelihood inference (ILI), has gained significant popularity in recent years."
      },
      "aliases": [
        "Likelihood-Free Inference (LFI)",
        "Implicit Likelihood Inference (ILI)"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper extensively discusses generative models for posterior approximation.",
          "quote": "Generative models, such as Generative Adversarial Networks GANs (Goodfellow et al., 2014), Normalizing Flows (Dinh et al., 2014; Rezende & Mohamed, 2015; Papamakarios et al., 2021), Variational Autoencoders (Kingma & Welling, 2013), and Score-Based/Diffusion Models (Song et al., 2020; Ho et al., 2020; Sohl-Dickstein et al., 2015), are powerful ways to encode approximate posteriors in such settings."
        },
        "aliases": [
          "GANs",
          "VAE",
          "Normalizing Flows",
          "Score-Based Models"
        ]
      },
      {
        "name": {
          "value": "Posterior Estimation",
          "justification": "The paper's primary focus is on developing methods for accurate posterior estimation.",
          "quote": "Generative models can be used as an alternative to Markov Chain Monte Carlo methods for conducting posterior inference, both in likelihood-based and simulation-based problems."
        },
        "aliases": [
          "Posterior Inference"
        ]
      },
      {
        "name": {
          "value": "High-Dimensional Inference",
          "justification": "The paper particularly emphasizes validation of posterior estimators in high-dimensional parameter spaces.",
          "quote": "Recently there has been substantial interest in applying SBI in high-dimensional parameter spaces."
        },
        "aliases": [
          "High-Dimensional Spaces"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Generative Adversarial Networks (GANs)",
          "justification": "GANs are mentioned as one type of generative model used in the context of posterior estimation.",
          "quote": "Generative models, such as Generative Adversarial Networks GANs (Goodfellow et al., 2014)..."
        },
        "aliases": [
          "GANs"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The paper does not claim to have developed GANs; it uses them as part of the broader category of generative models.",
          "quote": "Generative Adversarial Networks GANs (Goodfellow et al., 2014)..."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify if the models were executed on GPU or CPU.",
          "quote": "The paper does not specify if the models were executed on GPU or CPU."
        },
        "is_compared": {
          "value": 0,
          "justification": "There is no specific numeric comparison of GANs with other models in the paper.",
          "quote": "There is no specific numeric comparison of GANs with other models in the paper."
        },
        "referenced_paper_title": {
          "value": "Generative Adversarial Nets",
          "justification": "This is the foundational paper introducing GANs.",
          "quote": "Goodfellow, I. J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. Generative adversarial nets. stat, 1050:10, 2014."
        }
      },
      {
        "name": {
          "value": "Normalizing Flows",
          "justification": "Normalizing Flows are mentioned as one type of generative model used in the context of posterior estimation.",
          "quote": "Normalizing Flows (Dinh et al., 2014; Rezende & Mohamed, 2015; Papamakarios et al., 2021)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The paper does not claim to have developed Normalizing Flows; it uses them as part of the broader category of generative models.",
          "quote": "Normalizing Flows (Dinh et al., 2014; Rezende & Mohamed, 2015; Papamakarios et al., 2021)."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify if the models were executed on GPU or CPU.",
          "quote": "The paper does not specify if the models were executed on GPU or CPU."
        },
        "is_compared": {
          "value": 0,
          "justification": "There is no specific numeric comparison of Normalizing Flows with other models in the paper.",
          "quote": "There is no specific numeric comparison of Normalizing Flows with other models in the paper."
        },
        "referenced_paper_title": {
          "value": "Variational inference with normalizing flows",
          "justification": "This is the foundational paper introducing Normalizing Flows.",
          "quote": "Rezende, D. and Mohamed, S. Variational inference with normalizing flows. In International conference on machine learning, pp. 1530–1538. PMLR, 2015."
        }
      },
      {
        "name": {
          "value": "Variational Autoencoders (VAEs)",
          "justification": "VAEs are another type of generative model discussed in the paper for posterior estimation.",
          "quote": "Variational Autoencoders (Kingma & Welling, 2013)."
        },
        "aliases": [
          "VAEs"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The paper does not claim to have developed VAEs; it uses them as part of the broader category of generative models.",
          "quote": "Variational Autoencoders (Kingma & Welling, 2013)."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify if the models were executed on GPU or CPU.",
          "quote": "The paper does not specify if the models were executed on GPU or CPU."
        },
        "is_compared": {
          "value": 0,
          "justification": "There is no specific numeric comparison of VAEs with other models in the paper.",
          "quote": "There is no specific numeric comparison of VAEs with other models in the paper."
        },
        "referenced_paper_title": {
          "value": "Auto-encoding variational bayes",
          "justification": "This is the foundational paper introducing VAEs.",
          "quote": "Kingma, D. P. and Welling, M. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013."
        }
      },
      {
        "name": {
          "value": "Score-Based Models",
          "justification": "Score-Based Models are discussed as a type of generative model relevant to the paper's context.",
          "quote": "Score-Based/Diffusion Models (Song et al., 2020; Ho et al., 2020; Sohl-Dickstein et al., 2015), are powerful ways to encode approximate posteriors in such settings."
        },
        "aliases": [
          "Diffusion Models"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The paper does not claim to have developed Score-Based Models; it uses them to discuss generative models and posterior estimation.",
          "quote": "Score-Based/Diffusion Models (Song et al., 2020; Ho et al., 2020; Sohl-Dickstein et al., 2015)."
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify if the models were executed on GPU or CPU.",
          "quote": "The paper does not specify if the models were executed on GPU or CPU."
        },
        "is_compared": {
          "value": 0,
          "justification": "There is no specific numeric comparison of Score-Based Models with other models in the paper.",
          "quote": "There is no specific numeric comparison of Score-Based Models with other models in the paper."
        },
        "referenced_paper_title": {
          "value": "Denoising diffusion probabilistic models",
          "justification": "This is one of the key papers on Score-Based Models.",
          "quote": "Ho, J., Jain, A., and Abbeel, P. Denoising diffusion probabilistic models. CoRR, abs/2006.11239, 2020. URL https://arxiv.org/abs/2006.11239."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "PROBES dataset",
          "justification": "The dataset is explicitly mentioned as being used for fitting a multivariate Gaussian in an experiment.",
          "quote": "For simplicity, instead of fitting a score-based model, we fit a multivariate Gaussian to the PROBES dataset of galaxy images as our prior, giving p(θ) = N (µ0, Σ0 )."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "The Intrinsic Scatter of Galaxy Scaling Relations",
          "justification": "This is the reference paper for the PROBES dataset.",
          "quote": "Stone, C., Courteau, S., and Arora, N. The Intrinsic Scatter of Galaxy Scaling Relations. The Astrophysical Journal, 912(1):41, May 2021. doi: 10.3847/1538-4357/abebe4."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2062,
    "prompt_tokens": 19034,
    "total_tokens": 21096
  }
}