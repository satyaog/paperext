{
  "paper": "2310.00229.txt",
  "words": 21727,
  "extractions": {
    "title": {
      "value": "C ONSCIOUSNESS -I NSPIRED S PATIO -T EMPORAL A B STRACTIONS FOR B ETTER G ENERALIZATION IN R EIN FORCEMENT L EARNING",
      "justification": "The title is clearly stated at the beginning of the document.",
      "quote": "C ONSCIOUSNESS -I NSPIRED S PATIO -T EMPORAL A B STRACTIONS FOR B ETTER G ENERALIZATION IN R EIN FORCEMENT L EARNING"
    },
    "description": "Inspired by human conscious planning, this paper proposes Skipper, a model-based reinforcement learning framework that utilizes spatio-temporal abstractions to improve generalization in novel situations. It automatically decomposes tasks into smaller subtasks, enabling sparse decision-making and focused computation on relevant environment parts. The framework demonstrates significant advantages in zero-shot generalization over state-of-the-art methods.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents experiments and empirical evaluations to validate the performance of Skipper against baseline methods.",
      "quote": "Generalization-focused experiments validate Skipper’s significant advantage in zero-shot generalization, compared to some existing state-of-the-art hierarchical planning methods."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper focuses on improving reinforcement learning using a model-based framework with spatio-temporal abstractions for better generalization.",
        "quote": "In contrast, existing Reinforcement Learning (RL) agents either operate solely based on intuition (model-free methods) or are limited to reasoning over mostly relatively shortsighted plans (model-based methods) Kahneman (2017)."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Hierarchical Reinforcement Learning",
          "justification": "The study compares its proposed framework to hierarchical planning methods and focuses on breaking down tasks into subtasks.",
          "quote": "Generalization-focused experiments validate Skipper’s significant advantage in zero-shot generalization, compared to some existing state-of-the-art hierarchical planning methods."
        },
        "aliases": [
          "HRL"
        ]
      },
      {
        "name": {
          "value": "Model-based Reinforcement Learning",
          "justification": "Skipper is explicitly a model-based reinforcement learning framework that uses predictive models to guide policy search and generalization.",
          "quote": "Deep Model-based RL. Deep model-based RL uses predictive or generative models to guide the search for policies (Silver et al., 2017)."
        },
        "aliases": [
          "MBRL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Skipper",
          "justification": "Skipper is the primary deep learning model proposed and evaluated in the paper.",
          "quote": "we propose Skipper, a model-based reinforcement learning framework utilizing spatio-temporal abstractions to generalize better in novel situations."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "Skipper is introduced and evaluated as the contribution of this paper.",
          "quote": "Inspired by human conscious planning, we propose Skipper, a model-based reinforcement learning framework utilizing spatio-temporal abstractions to generalize better in novel situations."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper provides empirical evaluations by running experiments using Skipper.",
          "quote": "Generalization-focused experiments validate Skipper’s significant advantage in zero-shot generalization, compared to some existing state-of-the-art hierarchical planning methods."
        },
        "is_compared": {
          "value": 1,
          "justification": "Skipper's performance is compared against state-of-the-art hierarchical planning methods and baselines such as LEAP and Director.",
          "quote": "Generalization-focused experiments validate Skipper’s significant advantage in zero-shot generalization, compared to some existing state-of-the-art hierarchical planning methods."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no referenced paper title available for Skipper as it is the primary contribution of this paper.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "LEAP",
          "justification": "LEAP is one of the state-of-the-art models against which Skipper's performance is compared.",
          "quote": "We compare Skipper against two state-of-the-art Hierarchical Planning (HP) methods: LEAP (Nasiriany et al., 2019) and Director (Hafner et al., 2022)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "LEAP is used for comparative evaluation, not as a contribution of this paper.",
          "quote": "We compare Skipper against two state-of-the-art Hierarchical Planning (HP) methods: LEAP (Nasiriany et al., 2019) and Director (Hafner et al., 2022)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments running LEAP for comparison with Skipper.",
          "quote": "The results indicate that LEAP benefits largely from the delusion suppression technique."
        },
        "is_compared": {
          "value": 1,
          "justification": "LEAP is used as a baseline to compare the performance of Skipper.",
          "quote": "We show through detailed controlled experiments that the proposed framework, named Skipper, in most cases performs significantly better in terms of zero-shot generalization, compared to the baselines and to some state-of-the-art Hierarchical Planning (HP) methods (Nasiriany et al., 2019; Hafner et al., 2022)."
        },
        "referenced_paper_title": {
          "value": "Planning with Goal-Conditioned Policies",
          "justification": "The referenced title for LEAP is provided in the paper's citations.",
          "quote": "Nasiriany et al., 2019."
        }
      },
      {
        "name": {
          "value": "Director",
          "justification": "Director is one of the state-of-the-art models against which Skipper's performance is compared.",
          "quote": "We compare Skipper against two state-of-the-art Hierarchical Planning (HP) methods: LEAP (Nasiriany et al., 2019) and Director (Hafner et al., 2022)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "Director is used for comparative evaluation, not as a contribution of this paper.",
          "quote": "We compare Skipper against two state-of-the-art Hierarchical Planning (HP) methods: LEAP (Nasiriany et al., 2019) and Director (Hafner et al., 2022)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments running Director for comparison with Skipper.",
          "quote": "The Director agents suffer in these experiments despite their good performance in the single environment experimental settings reported by Hafner et al. (2022)."
        },
        "is_compared": {
          "value": 1,
          "justification": "Director is used as a baseline to compare the performance of Skipper.",
          "quote": "We show through detailed controlled experiments that the proposed framework, named Skipper, in most cases performs significantly better in terms of zero-shot generalization, compared to the baselines and to some state-of-the-art Hierarchical Planning (HP) methods (Nasiriany et al., 2019; Hafner et al., 2022)."
        },
        "referenced_paper_title": {
          "value": "Deep Hierarchical Planning from Pixels",
          "justification": "The referenced title for Director is provided in the paper's citations.",
          "quote": "Hafner et al., 2022."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1464,
    "prompt_tokens": 49312,
    "total_tokens": 50776
  }
}