{
  "paper": "2305.12542.txt",
  "words": 6014,
  "extractions": {
    "title": {
      "value": "ToxBuster: In-game Chat Toxicity Buster with BERT",
      "justification": "Title of the paper based on the provided text.",
      "quote": "ToxBuster: In-game Chat Toxicity Buster with BERT"
    },
    "description": "This paper introduces ToxBuster, a model designed to detect toxicity in online gaming chat. The model is trained on a dataset of annotated game chat lines from games like Rainbow Six Siege and For Honor. ToxBuster leverages BERT for improved detection accuracy and is evaluated against existing state-of-the-art methods, showing significant improvements in precision and recall.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents an experimental setup, training a model on datasets and comparing its performance to other models, which is characteristic of empirical research.",
      "quote": "Here, we propose the first in-game chat toxicity detection model which can effectively incorporate broader context for a significant boost in performance. More specifically, we trained ToxBuster on our annotated dataset."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research is focused on processing and understanding natural language text from online gaming chats, which falls under Natural Language Processing (NLP).",
        "quote": "Detecting toxicity is a supervised classification task that can be tackled with traditional NLP models paired with manual feature engineering (Watanabe et al., 2018), deep neural networks (Gambäck and Sikdar, 2017; Zhong et al., 2016; Gao and Huang, 2017; Fehn Unsvåg and Gambäck, 2018), and pretrained language models (Almerekhi et al., 2022; Jhaveri et al., 2022; Pavlopoulos et al., 2020a; Lees et al., 2022)."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Toxic Language Detection",
          "justification": "The primary aim of the paper is to detect toxic language in online game chats.",
          "quote": "This paper introduces ToxBuster, a model designed to detect toxicity in online gaming chat."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Conversational AI",
          "justification": "The study builds on innovations in conversational AI to improve toxicity detection in multi-turn conversations.",
          "quote": "Lastly, toxicity detection on social media platforms and in-game chat can be reframed as a problem around conversational AI. Hence, we also look at innovations from (multi-turn) conversational models."
        },
        "aliases": [
          "Dialogue Systems"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "ToxBuster",
          "justification": "Model introduced and developed as a contribution by the authors.",
          "quote": "We introduce ToxBuster, a simple and scalable model trained on a relatively large dataset of 194k lines of game chat from Rainbow Six Siege and For Honor, carefully annotated for different kinds of toxicity."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The model is introduced and developed by the authors, making it a contribution to the research field.",
          "quote": "We introduce ToxBuster, a simple and scalable model."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is trained and evaluated using computational experiments, implying it was executed during the study.",
          "quote": "More specifically, we trained ToxBuster on our annotated dataset."
        },
        "is_compared": {
          "value": true,
          "justification": "ToxBuster is compared against other models like Perspective API, Detoxify, and Cleanspeak in terms of performance metrics such as precision and recall.",
          "quote": "We compare ToxBuster with baselines on 5 different test splits of our S1&S2 dataset in Table 4."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "ToxBuster is the main contribution of this paper, hence no referenced paper title is applicable.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Rainbow Six Siege Chat Dataset",
          "justification": "Dataset of game chat lines from Rainbow Six Siege used to train and evaluate ToxBuster.",
          "quote": "The first two sessions are from Rainbow Six Siege (R6S) which is a multiplayer first person shooter."
        },
        "aliases": [
          "R6S Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "The dataset is introduced and used within this paper, so no external reference is applicable.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "For Honor Chat Dataset",
          "justification": "Dataset of game chat lines from For Honor used to train and evaluate ToxBuster.",
          "quote": "The last session is from For Honor (FH), a multi-player melee action game."
        },
        "aliases": [
          "FH Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "The dataset is introduced and used within this paper, so no external reference is applicable.",
          "quote": "N/A"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "BERT",
          "justification": "BERT is the core language model utilized for developing ToxBuster.",
          "quote": "In particular, contextual language embeddings (such as BERT (Devlin et al., 2018)) are at the core of many state-of-the-art toxic speech detection models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
          "justification": "BERT is used as the foundational model for ToxBuster.",
          "quote": "In particular, contextual language embeddings (such as BERT (Devlin et al., 2018)) are at the core of many state-of-the-art toxic speech detection models."
        }
      },
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is used for implementing and executing the ToxBuster model.",
          "quote": "All experiments with ToxBuster used a 60-20-20 train-val-test split with 5 different random seeds. We report mean and standard deviations of each metric. Our model gained performance through two methods: Chat History and Chat Speaker Segmentation."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "PyTorch is used as a toolkit for implementation; hence no reference paper title is applicable.",
          "quote": "N/A"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1279,
    "prompt_tokens": 11431,
    "total_tokens": 12710
  }
}