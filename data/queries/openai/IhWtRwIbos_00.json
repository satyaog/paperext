{
  "paper": "IhWtRwIbos.txt",
  "words": 11511,
  "extractions": {
    "title": {
      "value": "DISCOVERING ENVIRONMENTS WITH XRM",
      "justification": "This is the title of the research paper provided.",
      "quote": "DISCOVERING ENVIRONMENTS WITH XRM"
    },
    "description": "This paper introduces CROSS-RISK MINIMIZATION (XRM), a novel algorithm to discover environments for out-of-distribution generalization without requiring human annotations. XRM improves domain generalization by training twin networks to identify spurious correlations in the training data.",
    "type": {
      "value": "theoretical study",
      "justification": "This paper proposes a new algorithm and provides theoretical justifications for its design and performance improvements in domain generalization tasks.",
      "quote": "We propose CROSS-RISK MINIMIZATION (XRM), a simple method for environment discovery that requires no human environment annotations whatsoever."
    },
    "primary_research_field": {
      "name": {
        "value": "Domain Generalization",
        "justification": "The paper focuses on improving domain generalization techniques by introducing the XRM algorithm.",
        "quote": "In domain generalization (DG), our goal is to build learning systems that perform well beyond the distribution of the training data."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Algorithm Development",
          "justification": "The primary contribution of the paper is the introduction and development of the XRM algorithm.",
          "quote": "We propose CROSS-RISK MINIMIZATION (XRM), a simple method for environment discovery that requires no human environment annotations whatsoever."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Sub-population Shift",
          "justification": "The motivation for developing XRM is to handle sub-population shifts effectively.",
          "quote": "Generally speaking, AI systems perform worse on groups of examples under-represented in the training data (Barocas et al., 2019)."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Out-of-Distribution Generalization",
          "justification": "XRM is designed to improve out-of-distribution generalization of machine learning models.",
          "quote": "XRM provides a recipe for hyper-parameter tuning, does not require early-stopping, and can discover environments for all training and validation data. Domain generalization algorithms built on top of XRM environments achieve oracle worst-group-accuracy, solving a long-standing problem in out-of-distribution generalization."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "CROSS-RISK MINIMIZATION (XRM)",
          "justification": "XRM is the proposed method in the paper to improve environment discovery for domain generalization.",
          "quote": "We propose CROSS-RISK MINIMIZATION (XRM), a simple method for environment discovery that requires no human environment annotations whatsoever."
        },
        "aliases": [
          "XRM"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The paper introduces XRM as its main contribution to the research field.",
          "quote": "We propose CROSS-RISK MINIMIZATION (XRM), a simple method for environment discovery that requires no human environment annotations whatsoever."
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments in the paper include the implementation and execution of the XRM model.",
          "quote": "Algorithm 1 serves as a companion to the descriptions below; appendix G contains a real PyTorch implementation."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of XRM is compared with several other environment discovery methods and domain generalization algorithms in the paper.",
          "quote": "For instance, we observe that XRM+GroupDRO converges to 87% worst-group-accuracy on Waterbirds, matching the oracle!"
        },
        "referenced_paper_title": {
          "value": "DISCOVERING ENVIRONMENTS WITH XRM",
          "justification": "As XRM is introduced in this paper, it is its own reference.",
          "quote": "For instance, we observe that XRM+GroupDRO converges to 87% worst-group-accuracy on Waterbirds, matching the oracle!"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Waterbirds",
          "justification": "Waterbirds dataset is used as one of the benchmarks to evaluate the performance of the XRM algorithm.",
          "quote": "Returning one final time to figure 1, we observe that XRM+GroupDRO converges to 87% worst-group-accuracy on Waterbirds, matching the oracle!"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Caltech-UCSD Birds-200-2011 Dataset",
          "justification": "This dataset is typically referenced by its original title to provide context on the data used.",
          "quote": "Returning one final time to figure 1, we observe that XRM+GroupDRO converges to 87% worst-group-accuracy on Waterbirds, matching the oracle!"
        }
      },
      {
        "name": {
          "value": "CelebA",
          "justification": "CelebA dataset is another benchmark dataset used to assess XRM’s effectiveness.",
          "quote": "For the commonly-reported quartet of Waterbirds, CelebA, MultiNLI, and CivilComments, human annotations induce an average oracle worst-group-accuracy 80.6%, while XRM environments endow a super-human performance of 80.9%."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deep Learning Face Attributes in the Wild",
          "justification": "This dataset is commonly referenced by the title of the seminal paper that introduces it.",
          "quote": "For CelebA, predictors map pixel intensities into a binary “blonde/not-blonde” label."
        }
      },
      {
        "name": {
          "value": "MultiNLI",
          "justification": "The MultiNLI dataset is employed in the experiments to demonstrate the domain generalization capabilities of XRM.",
          "quote": "For the commonly-reported quartet of Waterbirds, CelebA, MultiNLI, and CivilComments, human annotations induce an average oracle worst-group-accuracy 80.6%, while XRM environments endow a super-human performance of 80.9%."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
          "justification": "This dataset title is referenced to provide clarity on the data used in the experiment.",
          "quote": "Experiments in Section 5 show that DG algorithms built on top of XRM environments achieve oracle-like performance, and Section 6 closes with thoughts for future work."
        }
      },
      {
        "name": {
          "value": "CivilComments",
          "justification": "CivilComments dataset is used as one of the datasets to evaluate XRM.",
          "quote": "For the commonly-reported quartet of Waterbirds, CelebA, MultiNLI, and CivilComments, human annotations induce an average oracle worst-group-accuracy 80.6%, while XRM environments endow a super-human performance of 80.9%."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Nuanced Metrics for Measuring Unintended Bias with Real Data for Text Classification",
          "justification": "The dataset is cited with its full title to indicate the nature of data and its role in text classification.",
          "quote": "For the commonly-reported quartet of Waterbirds, CelebA, MultiNLI, and CivilComments, human annotations induce an average oracle worst-group-accuracy 80.6%, while XRM environments endow a super-human performance of 80.9%."
        }
      },
      {
        "name": {
          "value": "ColorMNIST",
          "justification": "ColorMNIST is used in the experiments, particularly for demonstrating how XRM handles subpopulation shifts.",
          "quote": "For the commonly-reported quartet of Waterbirds, CelebA, MultiNLI, and CivilComments, human annotations induce an average oracle worst-group-accuracy 80.6%, while XRM environments endow a super-human performance of 80.9%."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Invariant Risk Minimization",
          "justification": "ColorMNIST is a dataset introduced to evaluate Invariant Risk Minimization (IRM).",
          "quote": "To reiterate, by “counting flips” we simply compare the vector of current labels with the vector of original labels—therefore, we do not accumulate counts of double or multiple flips per label. To understand why, recall that each label flip signifies one example that is confidently misclassified when held-out. Therefore, each label flip is evidence about reliance on spurious correlation, which consequently brings us closer to a clear-cut identification of the minority group."
        }
      },
      {
        "name": {
          "value": "SubpopBench suite",
          "justification": "SubpopBench suite is cited as the source for multiple datasets used in evaluations, including settings for commonly used deep learning benchmarks.",
          "quote": "We consider six standard datasets from the SubpopBench suite (Yang et al., 2023). These are the four image datasets Waterbirds (Wah et al., 2011), CelebA (Liu et al., 2015), MetaShift (Liang and Zou, 2022), and ImageNetBG (Xiao et al., 2020); and the two natural language datasets MultiNLI (Williams et al., 2017) and CivilComments (Borkan et al., 2019)."
        },
        "aliases": [
          "Subpopulation Benchmarks"
        ],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "Change is Hard: A Closer Look at Subpopulation Shift",
          "justification": "This reference provides context for the SubpopBench suite, detailing the benchmarks for deep learning.",
          "quote": "These are the four image datasets Waterbirds (Wah et al., 2011), CelebA (Liu et al., 2015), MetaShift (Liang and Zou, 2022), and ImageNetBG (Xiao et al., 2020); and the two natural language datasets MultiNLI (Williams et al., 2017) and CivilComments (Borkan et al., 2019)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper mentions using PyTorch for implementing XRM.",
          "quote": "Appendix G contains a real PyTorch implementation."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "This citation provides background on the PyTorch library used for implementation in the paper.",
          "quote": "Appendix G contains a real PyTorch implementation."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2066,
    "prompt_tokens": 22649,
    "total_tokens": 24715
  }
}