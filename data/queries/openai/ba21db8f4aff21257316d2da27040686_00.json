{
  "paper": "ba21db8f4aff21257316d2da27040686.txt",
  "words": 9811,
  "extractions": {
    "title": {
      "value": "Decoding face recognition abilities in the human brain",
      "justification": "The title clearly states the focus of the research paper on understanding brain mechanisms behind face recognition abilities.",
      "quote": "Decoding face recognition abilities in the human brain"
    },
    "description": "This research paper investigates why some individuals excel in recognizing faces by using neuroimaging, computational modeling, and behavioral tests. The study focuses on super-recognizers and typical recognizers, decoding face recognition abilities from EEG brain activity with high accuracy. The research finds stronger associations between brain representations of super-recognizers and artificial neural network models, suggesting the involvement of semantic computations in face recognition abilities.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments involving EEG recordings and data analysis to understand face recognition abilities.",
      "quote": "Using a multimodal data-driven approach combining neuroimaging, computational modeling, and behavioral tests."
    },
    "primary_research_field": {
      "name": {
        "value": "Cognitive Neuroscience",
        "justification": "The paper focuses on the neural mechanisms behind cognitive abilities like face recognition, which falls under cognitive neuroscience.",
        "quote": "Uncovering the neural mechanisms supporting face recognition ability has proven elusive."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The study involves comparisons with artificial neural network models of vision, aligning with the field of computer vision.",
          "quote": "We compared representations in the brains of our participants with those in artificial neural network models of vision..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Neuroimaging",
          "justification": "The paper makes significant use of EEG for brain activity measurement.",
          "quote": "We recorded the high-density electroencephalographic brain activity of individuals..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "AlexNet",
          "justification": "AlexNet is explicitly mentioned in the context of comparing its layers' representations with brain data.",
          "quote": "We used a pretrained AlexNet as one model of the visual computations along the ventral stream."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "AlexNet is a well-known pre-existing model used for comparison and not developed in this paper.",
          "quote": "We used a pretrained AlexNet..."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper applies AlexNet for comparisons with brain data to understand face recognition abilities.",
          "quote": "...layerwise RDMs were constructed comparing the unit activation patterns..."
        },
        "is_compared": {
          "value": true,
          "justification": "AlexNet's layers' representations are compared to brain activity data in this study.",
          "quote": "We found greater similarity with midlevel visual representations in the brains of super-recognizers..."
        },
        "referenced_paper_title": {
          "value": "Imagenet classification with deep convolutional neural networks",
          "justification": "The paper references AlexNet, which is introduced in 'Imagenet classification with deep convolutional neural networks'.",
          "quote": "Krizhevsky A, Sutskever I, Hinton GE. 2012. Imagenet classification with deep convolutional neural networks."
        }
      },
      {
        "name": {
          "value": "VGG-16",
          "justification": "VGG-16 is mentioned as one of the models used for comparison with brain EEG data.",
          "quote": "Similarly, we computed layerwise RDMs from another well-known CNN, VGG-16 (see Fig. S5)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "VGG-16 was used as a pre-existing model in the study for comparison purposes.",
          "quote": "...we computed layerwise RDMs from another well-known CNN, VGG-16..."
        },
        "is_executed": {
          "value": true,
          "justification": "The study involves executing VGG-16 to construct representational dissimilarity matrices.",
          "quote": "Similarly, we computed layerwise RDMs from another well-known CNN, VGG-16 (see Fig. S5)."
        },
        "is_compared": {
          "value": true,
          "justification": "The representations from VGG-16 were compared with brain data to draw insights about face recognition.",
          "quote": "We compared, using representational similarity analysis ... the brain representations of our participants to that of convolutional neural networks..."
        },
        "referenced_paper_title": {
          "value": "Very deep convolutional networks for large-scale image recognition",
          "justification": "The model VGG-16 comes from the paper 'Very deep convolutional networks for large-scale image recognition'.",
          "quote": "Simonyan K, Zisserman A. 2014. Very deep convolutional networks for large-scale image recognition."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Cambridge Face Memory Test long form (CFMT+)",
          "justification": "The CFMT+ test is used to evaluate the face recognition abilities of participants in the study.",
          "quote": "All participantsâ€™ face recognition ability was assessed using the Cambridge Face Memory Test long form (CFMT+) (8)."
        },
        "aliases": [
          "CFMT+"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Cambridge face memory test: results for neurologically intact individuals and an investigation of its validity using inverted face stimuli and prosopagnosic participants",
          "justification": "The paper references CFMT+ to describe face recognition evaluation, originally detailed in the referenced paper.",
          "quote": "Duchaine B, Nakayama K. 2006. The Cambridge face memory test: results for neurologically intact individuals and an investigation of its validity using inverted face stimuli and prosopagnosic participants."
        }
      },
      {
        "name": {
          "value": "Radboud Face Database",
          "justification": "The study utilizes face images sourced from the Radboud Face Database.",
          "quote": "The 24 faces (13 identities, 8 males, and 8 neutral, 8 happy, 8 fearful expressions) were sampled from the Radboud Face dataset."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Presentation and validation of the Radboud faces database",
          "justification": "The paper states the use of face images from the Radboud Face Dataset, which was presented and validated in the referenced work.",
          "quote": "Langner O, et al. 2010. Presentation and validation of the Radboud faces database."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "FieldTrip",
          "justification": "FieldTrip is explicitly mentioned as the toolbox used for EEG data preprocessing.",
          "quote": "EEG data were preprocessed using FieldTrip..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data",
          "justification": "FieldTrip is used for EEG preprocessing, as described in the referenced paper about the software.",
          "quote": "Oostenveld R, Fries P, Maris E, Schoffelen J-M. 2011. FieldTrip: open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data."
        }
      },
      {
        "name": {
          "value": "GUSE (Google Universal Sentence Encoder)",
          "justification": "The paper mentions GUSE as a tool used for transforming sentence captions into embeddings.",
          "quote": "GUSE has been trained to predict semantic textual similarity from human judgments, and its embeddings generalize to an array of other semantic judgment tasks (50)."
        },
        "aliases": [
          "Google Universal Sentence Encoder"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Universal sentence encoder",
          "justification": "GUSE is used to transform sentence captions into embeddings, as detailed in the referenced paper.",
          "quote": "Cer D, et al. 2018. Universal sentence encoder, arXiv, arXiv:1803.11175."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1543,
    "prompt_tokens": 17664,
    "total_tokens": 19207,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}