{
  "paper": "2310.11634.txt",
  "words": 11266,
  "extractions": {
    "title": {
      "value": "MAGNIFIC O: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
      "justification": "The title of the paper as provided by the user.",
      "quote": "MAGNIFIC O: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations"
    },
    "description": "This paper introduces MAGNIFIC O, an evaluation suite designed within a text-to-SQL semantic parsing framework. It systematically analyzes the ability of Large Language Models (LLMs) to acquire novel interpretations using in-context learning by incorporating diverse tokens and prompt settings to simulate real-world complexity.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper systematically analyzes the ability of LLMs through experiments and evaluation, indicating empirical methods.",
      "quote": "In this paper, we systematically analyse the ability of LLMs to acquire novel interpretations using in-context learning."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research focuses on the capabilities of large language models, which are a core area within the field of Natural Language Processing.",
        "quote": "However, Large Language Models (LLMs) have a knowledge cutoff and are costly to finetune repeatedly."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Text-to-SQL",
          "justification": "The evaluation suite MAGNIFIC O is implemented within a text-to-SQL semantic parsing framework.",
          "quote": "To facilitate our study, we introduce MAGNIFIC O, an evaluation suite implemented within a text-to-SQL semantic parsing framework."
        },
        "aliases": [
          "text-to-sql semantic parsing"
        ]
      },
      {
        "name": {
          "value": "In-Context Learning",
          "justification": "The primary focus of the paper is to evaluate how well LLMs can acquire novel interpretations in-context.",
          "quote": "In this paper, we systematically analyse the ability of LLMs to acquire novel interpretations using in-context learning."
        },
        "aliases": [
          "ICL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-3.5-Turbo",
          "justification": "The paper mentions that GPT-3.5-Turbo was one of the LLMs evaluated.",
          "quote": "We experiment with OpenAI GPT-3.5-Turbo (v0301) (Brown et al., 2020)."
        },
        "aliases": [
          "GPT-3.5"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "GPT-3.5-Turbo is not a contribution of this paper; it is an existing model evaluated within the study.",
          "quote": "We experiment with OpenAI GPT-3.5-Turbo (v0301) (Brown et al., 2020)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed since the experimental results and evaluations are based on its performance.",
          "quote": "Experimental results on MAGNIFIC O..."
        },
        "is_compared": {
          "value": 1,
          "justification": "GPT-3.5-Turbo's performance is compared with several other models within the paper.",
          "quote": "We experiment with OpenAI GPT-3.5-Turbo (v0301) (Brown et al., 2020)"
        },
        "referenced_paper_title": {
          "value": "Language models are few-shot learners",
          "justification": "The referenced paper for GPT-3.5-Turbo is provided in the references section.",
          "quote": "We experiment with OpenAI GPT-3.5-Turbo (v0301) (Brown et al., 2020)."
        }
      },
      {
        "name": {
          "value": "StarCoder",
          "justification": "The paper mentions that StarCoder was one of the LLMs evaluated.",
          "quote": "We experiment with StarCoder (Li et al., 2023b)."
        },
        "aliases": [
          "StarCoder"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "StarCoder is not a contribution of this paper; it is an existing model evaluated within the study.",
          "quote": "We experiment with StarCoder (Li et al., 2023b)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed since the experimental results and evaluations are based on its performance.",
          "quote": "Experimental results on MAGNIFIC O..."
        },
        "is_compared": {
          "value": 1,
          "justification": "StarCoder's performance is compared with several other models within the paper.",
          "quote": "We experiment with StarCoder (Li et al., 2023b)"
        },
        "referenced_paper_title": {
          "value": "Starcoder: may the source be with you",
          "justification": "The referenced paper for StarCoder is provided in the references section.",
          "quote": "We experiment with StarCoder (Li et al., 2023b)."
        }
      },
      {
        "name": {
          "value": "LLaMA (7B, 13B, 30B)",
          "justification": "The paper mentions that multiple versions of the LLaMA model were evaluated.",
          "quote": "We experiment with LLaMA-7B,13B,30B (Touvron et al., 2023a)."
        },
        "aliases": [
          "LLaMA"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "LLaMA is not a contribution of this paper; it is an existing model evaluated within the study.",
          "quote": "We experiment with LLaMA-7B,13B,30B (Touvron et al., 2023a)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed since the experimental results and evaluations are based on its performance.",
          "quote": "Experimental results on MAGNIFIC O..."
        },
        "is_compared": {
          "value": 1,
          "justification": "LLaMA's performance is compared with several other models within the paper.",
          "quote": "We experiment with LLaMA-7B,13B,30B (Touvron et al., 2023a)"
        },
        "referenced_paper_title": {
          "value": "Llama: Open and efficient foundation language models",
          "justification": "The referenced paper for LLaMA is provided in the references section.",
          "quote": "We experiment with LLaMA-7B,13B,30B (Touvron et al., 2023a)."
        }
      },
      {
        "name": {
          "value": "Alpaca (7B)",
          "justification": "The paper mentions that Alpaca-7B was one of the LLMs evaluated.",
          "quote": "We experiment with Alpaca-7B (Taori et al., 2023)."
        },
        "aliases": [
          "Alpaca"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Alpaca is not a contribution of this paper; it is an existing model evaluated within the study.",
          "quote": "We experiment with Alpaca-7B (Taori et al., 2023)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed since the experimental results and evaluations are based on its performance.",
          "quote": "Experimental results on MAGNIFIC O..."
        },
        "is_compared": {
          "value": 1,
          "justification": "Alpaca-7B's performance is compared with several other models within the paper.",
          "quote": "We experiment with Alpaca-7B (Taori et al., 2023)"
        },
        "referenced_paper_title": {
          "value": "Alpaca: A strong, replicable instruction-following model",
          "justification": "The referenced paper for Alpaca-7B is provided in the references section.",
          "quote": "We experiment with Alpaca-7B (Taori et al., 2023)."
        }
      },
      {
        "name": {
          "value": "MPT-7B, MPT-7B-Instruct",
          "justification": "The paper mentions that MPT-7B and its instruct version were evaluated.",
          "quote": "We experiment with MPT-7B and MPT-7B-Instruct."
        },
        "aliases": [
          "MPT"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "MPT-7B and MPT-7B-Instruct are not contributions of this paper; they are existing models evaluated within the study.",
          "quote": "We experiment with MPT-7B and MPT-7B-Instruct."
        },
        "is_executed": {
          "value": 1,
          "justification": "The models were executed since the experimental results and evaluations are based on their performance.",
          "quote": "Experimental results on MAGNIFIC O..."
        },
        "is_compared": {
          "value": 1,
          "justification": "MPT-7B and MPT-7B-Instruct's performance is compared with several other models within the paper.",
          "quote": "We experiment with MPT-7B and MPT-7B-Instruct."
        },
        "referenced_paper_title": {
          "value": "MPT-7B: A new model for efficient language processing",
          "justification": "The referenced paper for MPT-7B and MPT-7B-Instruct is provided in the references section.",
          "quote": "We experiment with MPT-7B and MPT-7B-Instruct."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MAGNIFIC O",
          "justification": "MAGNIFIC O is the evaluation suite introduced by the authors to evaluate the in-context learning abilities of LLMs in acquiring novel interpretations.",
          "quote": "To facilitate our study, we introduce MAGNIFIC O, an evaluation suite implemented within a text-to-SQL semantic parsing framework."
        },
        "aliases": [
          "MAGNIFIC O"
        ],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "MAGNIFIC O: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations",
          "justification": "The dataset is introduced by the authors in this paper itself.",
          "quote": "To facilitate our study, we introduce MAGNIFIC O, an evaluation suite implemented within a text-to-SQL semantic parsing framework."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The authors mention the implementation of their code in PyTorch.",
          "quote": "Our code is implemented in PyTorch (Paszke et al., 2019)."
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The referenced paper for PyTorch is provided in the references section.",
          "quote": "Our code is implemented in PyTorch (Paszke et al., 2019)."
        }
      },
      {
        "name": {
          "value": "Transformers",
          "justification": "The authors mention the use of the HuggingFace Transformers library in their implementation.",
          "quote": "Our code is implemented in PyTorch (Paszke et al., 2019) and makes use of the HuggingFace Transformers library (Wolf et al., 2020)."
        },
        "aliases": [
          "HuggingFace"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Transformers: State-of-the-art natural language processing",
          "justification": "The referenced paper for the Transformers library is provided in the references section.",
          "quote": "Our code is implemented in PyTorch (Paszke et al., 2019) and makes use of the HuggingFace Transformers library (Wolf et al., 2020)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2239,
    "prompt_tokens": 20091,
    "total_tokens": 22330
  }
}