{
  "paper": "2205.11690.txt",
  "words": 13974,
  "extractions": {
    "title": {
      "value": "Workflow Discovery from Dialogues in the Low Data Regime",
      "justification": "Title is clearly mentioned at the beginning of the paper.",
      "quote": "Workflow Discovery from Dialogues in the Low Data Regime"
    },
    "description": "This paper introduces a novel problem formulation called Workflow Discovery (WD), which aims to extract workflows from dialogues, especially in cases where formal workflows do not exist. It evaluates a sequence-to-sequence (Seq2Seq) approach to solve this task and presents experiments on the Action-Based Conversations Dataset (ABCD) to demonstrate its efficacy. The paper also explores zero-shot and few-shot performance improvements by conditioning models on possible actions.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical evaluations of the proposed WD approach by applying it to datasets and measuring its performance using various metrics.",
      "quote": "We introduce a new problem formulation... We also examine a sequence-to-sequence (Seq2Seq) approach... We present experiments... We propose and evaluate an approach..."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The main focus is on extracting workflows from dialogues, a topic within Natural Language Processing.",
        "quote": "We introduce a new problem formulation that we call Workflow Discovery (WD) in which we are interested... examining a sequence-to-sequence (Seq2Seq) approach for this novel task..."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Dialogue Systems",
          "justification": "The study deals with task-oriented dialogues and dialogue systems for extracting workflows.",
          "quote": "Task-oriented dialogues are ubiquitous in everyday life and customer service in particular... In this work, we focus on 'workflow discovery' (WD) â€“ the extraction of workflows that have either implicitly or explicitly guided task-oriented dialogues..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Sequence-to-Sequence Models",
          "justification": "The paper evaluates a sequence-to-sequence (Seq2Seq) approach for workflow extraction.",
          "quote": "We also examine a sequence-to-sequence (Seq2Seq) approach for this novel task."
        },
        "aliases": [
          "Seq2Seq"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "T5",
          "justification": "The T5 model is described and evaluated in various scales (Small, Base, Large) for the Workflow Discovery task.",
          "quote": "In our experimentation, we used the T5 (Raffel et al., 2020b)... For T5, we use the small (60M parameters), base (220M parameters), and large (770M parameters) variants..."
        },
        "aliases": [
          "Text-To-Text Transfer Transformer"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The T5 model is used but not introduced by this paper.",
          "quote": "In our experimentation, we used the T5 (Raffel et al., 2020b)..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The T5 model was executed to evaluate its performance on the Workflow Discovery task.",
          "quote": "In our experimentation, we used the T5 (Raffel et al., 2020b)..."
        },
        "is_compared": {
          "value": 1,
          "justification": "The T5 model was compared with other models like BART and PEGASUS in the experiments.",
          "quote": "In our experimentation, we used the T5, BART, and PEGASUS models..."
        },
        "referenced_paper_title": {
          "value": "Exploring the limits of transfer learning with a unified text-to-text transformer",
          "justification": "This is the original paper in which the T5 model was introduced.",
          "quote": "Exploring the limits of transfer learning with a unified text-to-text transformer"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Action-Based Conversations Dataset",
          "justification": "The ABCD dataset is used for experiments in this paper.",
          "quote": "We present experiments where we extract workflows from dialogues in the Action-Based Conversations Dataset (ABCD)."
        },
        "aliases": [
          "ABCD"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Action-based conversations dataset: A corpus for building more in-depth task-oriented dialogue systems",
          "justification": "This is the reference paper for the Action-Based Conversations Dataset (ABCD).",
          "quote": "Action-based conversations dataset: A corpus for building more in-depth task-oriented dialogue systems"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Transformers",
          "justification": "The paper explicitly mentions using the Huggingface Transformers library for implementation.",
          "quote": "We use the Huggingface Transformers Pytorch implementation..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Hugging Face's Transformers: State-of-the-art natural language processing",
          "justification": "This is the reference paper for the Huggingface Transformers library.",
          "quote": "We use the Huggingface Transformers Pytorch implementation"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 964,
    "prompt_tokens": 22846,
    "total_tokens": 23810
  }
}