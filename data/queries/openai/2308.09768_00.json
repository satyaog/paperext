{
  "paper": "2308.09768.txt",
  "words": 2989,
  "extractions": {
    "title": {
      "value": "NAIJA RC: A Multi-Choice Reading Comprehension Dataset for Nigerian Languages",
      "justification": "The exact title of the paper as given at the beginning.",
      "quote": "NAIJA RC: A M ULTI - CHOICE R EADING C OMPREHEN SION DATASET FOR N IGERIAN L ANGUAGES"
    },
    "description": "The paper introduces and details NaijaRC, a multi-choice reading comprehension dataset specifically for Nigerian languages. It discusses the dataset collection, evaluation using pre-trained models and large language models, and presents experimental results.",
    "type": {
      "value": "Empirical",
      "justification": "The paper presents the construction of a new dataset, performs experiments with existing models, and provides results and analysis.",
      "quote": "In this paper, we create NaijaRC—a new multi-choice Nigerian Reading Comprehension dataset that is based on high-school RC examination for three Nigerian national languages: Hausa (hau), Igbo (ibo), and Yorùbá (yor). We provide baseline results by performing cross-lingual transfer using the Belebele training data... We provide results by prompting large language models (LLMs) like GPT-4... The experimental results are presented in Table 1(b)."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on reading comprehension, a core task in Natural Language Processing.",
        "quote": "Reading Comprehension (RC) requires the ability to read a text and demonstrate understanding by answering questions about it."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Dataset Creation",
          "justification": "The paper's primary contribution is the creation of the NaijaRC dataset.",
          "quote": "In this paper, we create NaijaRC—a new multi-choice Nigerian Reading Comprehension dataset..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Multilingual NLP",
          "justification": "The dataset and experiments focus on Nigerian languages, contributing to the domain of multilingual natural language processing.",
          "quote": "...based on high-school RC examination for three Nigerian national languages: Hausa (hau), Igbo (ibo), and Yorùbá (yor)."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "AfroXLMR-base",
          "justification": "AfroXLMR-base is one of the models evaluated in the experiments.",
          "quote": "AfroXLMR-base has highest accuracy on Yorùbá (34.0%)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model was used but not introduced in this paper.",
          "quote": "AfroXLMR-base Alabi et al. (2022)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experiments.",
          "quote": "we evaluated the performance of fine-tuned pre-trained encoder-only models, specifically AfroXLMR-base..."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance results are provided and compared.",
          "quote": "The result shows that GPT-4 achieved the highest overall accuracy... AfroXLMR-base has highest accuracy on Yorùbá (34.0%)"
        },
        "referenced_paper_title": {
          "value": "Adapting pre-trained language models to African languages via multilingual adaptive fine-tuning",
          "justification": "Explicitly mentioned as a reference for AfroXLMR-base.",
          "quote": "AfroXLMR-base Alabi et al. (2022)"
        }
      },
      {
        "name": {
          "value": "Serengeti",
          "justification": "Serengeti is one of the models evaluated in the work.",
          "quote": "Serengeti outperformed others on Hausa (50.0%)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model was used but not introduced in this paper.",
          "quote": "Serengeti (Adebara et al., 2023)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experiments.",
          "quote": "we evaluated the performance of fine-tuned pre-trained encoder-only models, specifically... Serengeti"
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance results are provided and compared.",
          "quote": "The result shows that GPT-4 achieved the highest overall accuracy... Serengeti outperformed others on Hausa"
        },
        "referenced_paper_title": {
          "value": "SERENGETI: Massively multilingual language models for Africa",
          "justification": "The paper on Serengeti is referenced in this paper.",
          "quote": "Serengeti (Adebara et al., 2023)"
        }
      },
      {
        "name": {
          "value": "OFA-768",
          "justification": "OFA-768 is one of the models evaluated in the experiments.",
          "quote": "OFA-768 outperformed others on Igbo (48.9%)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model was used but not introduced in this paper.",
          "quote": "OFA-768 (Liu et al., 2023)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experiments.",
          "quote": "we evaluated the performance of fine-tuned pre-trained encoder-only models... and OFA-768"
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance results are provided and compared.",
          "quote": "The result shows that GPT-4 achieved the highest overall accuracy... OFA-768 outperformed others on Igbo (48.9%)"
        },
        "referenced_paper_title": {
          "value": "OFA: A framework of initializing unseen subword embeddings for efficient large-scale multilingual continued pretraining",
          "justification": "The publication is referenced for the model OFA-768.",
          "quote": "OFA-768 (Liu et al., 2023)"
        }
      },
      {
        "name": {
          "value": "GPT-3.5",
          "justification": "GPT-3.5 is one of the models evaluated in the experiments.",
          "quote": "Furthermore, we prompted GPT-3.5... GPT-3.5 and GPT-4 showed relatively lower performance compared to multilingual PLMs on the Nigerian languages."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "GPT-3.5 was used but not introduced in this paper.",
          "quote": "we prompted GPT-3.5"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experiments.",
          "quote": "Furthermore, we prompted GPT-3.5"
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance results are provided and compared.",
          "quote": "GPT-3.5 and GPT-4 showed relatively lower performance compared to multilingual PLMs"
        },
        "referenced_paper_title": {
          "value": "Language Models are Few-Shot Learners",
          "justification": "This paper is a major reference for GPT-3.5.",
          "quote": "GPT-3.5 Brown et al. (2020)"
        }
      },
      {
        "name": {
          "value": "GPT-4",
          "justification": "GPT-4 is one of the models evaluated in the experiments.",
          "quote": "GPT-4 achieved the highest overall accuracy across the four languages, with an accuracy of 51.4%"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "GPT-4 was used but not introduced in this paper.",
          "quote": "Furthermore, we prompted GPT-3.5 and GPT-4"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experiments.",
          "quote": "Furthermore, we prompted... GPT-4"
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance results are provided and compared.",
          "quote": "GPT-4 achieved the highest overall accuracy across the four languages... GPT-4 showing relatively lower performance compared to multilingual PLMs."
        },
        "referenced_paper_title": {
          "value": "GPT-4 Technical Report",
          "justification": "This paper is a major reference for GPT-4.",
          "quote": "GPT-4 OpenAI (2023)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "NaijaRC",
          "justification": "NaijaRC is the newly introduced dataset in this paper.",
          "quote": "In this paper, we create NaijaRC—a new multi-choice Nigerian Reading Comprehension dataset that is based on high-school RC examination for three Nigerian national languages."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "NaijaRC is introduced in this paper and hence does not reference another paper.",
          "quote": "In this paper, we create NaijaRC"
        }
      },
      {
        "name": {
          "value": "Belebele",
          "justification": "Belebele dataset is used for training and as a benchmark in this work.",
          "quote": "we fine-tuned the model on the training split of Belebele 3 (Bandarkar et al., 2023) dataset for 3 epochs and evaluated the performance of the resulting model on NaijaRC."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Belebele benchmark: a parallel reading comprehension dataset in 122 language variants",
          "justification": "The paper references the Belebele benchmark dataset.",
          "quote": "Belebele 3 (Bandarkar et al., 2023)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Google OCR",
          "justification": "Google OCR was used to digitize printed documents.",
          "quote": "...we had to make use of Optical Character Recognition tools like Google Lens..."
        },
        "aliases": [
          "Google Lens"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "References are not usually provided for tools like OCR methods in such papers.",
          "quote": "we had to make use of Optical Character Recognition tools like Google Lens and Apple’s OCR"
        }
      },
      {
        "name": {
          "value": "Apple OCR",
          "justification": "Apple OCR was used to digitize printed documents.",
          "quote": "and Apple’s OCR to convert the printed format into a digitised version."
        },
        "aliases": [
          "Apple's OCR"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "References are not usually provided for tools like OCR methods in such papers.",
          "quote": "we had to make use of Optical Character Recognition tools like Google Lens and Apple’s OCR"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2080,
    "prompt_tokens": 7675,
    "total_tokens": 9755
  }
}