{
  "paper": "2401.16618.txt",
  "words": 5841,
  "extractions": {
    "title": {
      "value": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking",
      "justification": "This title encompasses the main focus of the paper, which compares RL-based controllers with PID controllers for specific applications related to 6-DOF swimming robots and underwater object tracking.",
      "quote": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking"
    },
    "description": "This paper explores and compares the use of centralized Deep Q-Network (DQN) controllers with traditional PID controllers for 6-DOF swimming robots in underwater object tracking tasks. It aims to illustrate the advantages of using RL-based controllers in such complex environments, showcasing improved performance and adaptability compared to traditional methods.",
    "type": {
      "value": "empirical",
      "justification": "The study includes experiments conducted within a Unity-based simulator to validate the effectiveness of a centralized RL agent over PID controllers, indicating it is empirical in nature.",
      "quote": "Our experiments, conducted within a Unity-based simulator, validate the effectiveness of a centralized RL agent over separated PID controllers."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper uses Deep Q-Networks (DQN), a Deep Learning approach, to control 6-DOF swimming robots, making its primary research field Deep Learning.",
        "quote": "In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The focus is on applying Deep Q-Networks, an approach within Reinforcement Learning, to control robots, making the sub-research field Reinforcement Learning.",
          "quote": "Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Deep Q-Network",
          "justification": "The paper explores the application of DQN for controlling 6-DOF swimming robots, highlighting its practical advantages.",
          "quote": "Our primary focus centers on illustrating this transition with the specific case of underwater object tracking. DQN offers advantages such as data efficiency and off-policy learning, while remaining simpler to implement than other reinforcement learning methods."
        },
        "aliases": [
          "DQN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "YOLOv7",
          "justification": "The paper employs YOLOv7 for object detection as part of its vision module, which is integral to the research on underwater object tracking.",
          "quote": "We have adopted the methodology outlined in [5], using YOLOv7 for object detection, and then employing SORT for detection matching and implementing tracking-by-detection."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "SORT",
          "justification": "SORT is used for detection matching and implementing tracking-by-detection in the vision module of the study.",
          "quote": "We have adopted the methodology outlined in [5], using YOLOv7 for object detection, and then employing SORT for detection matching and implementing tracking-by-detection."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "R-CNN",
          "justification": "R-CNN is listed among the deep learning-based object detection models used for underwater object detection in the related work section.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "SSD",
          "justification": "SSD is another deep learning-based object detection model mentioned in the related work section for its use in underwater detection tasks.",
          "quote": "Our study uses deep learning-based object detection models like YOLO [24], R-CNN [25], and SSD [26], which are widely used for real-world tasks and being continually improved [27], [28]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "OpenAI Gym",
          "justification": "The paper references OpenAI Gym as a widely adopted reinforcement learning environment for its simulated experiments.",
          "quote": "This model is widely adopted in many benchmark environments of OpenAIGym/MuJoCo [50], [51]."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "MuJoCo",
          "justification": "MuJoCo is mentioned as another benchmark environment utilized for reinforcement learning implementations in the study.",
          "quote": "This model is widely adopted in many benchmark environments of OpenAIGym/MuJoCo [50], [51]."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1333,
    "prompt_tokens": 9850,
    "total_tokens": 11183
  }
}