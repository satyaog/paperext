{
  "paper": "04K3PMtMckp.txt",
  "words": 14213,
  "extractions": {
    "title": {
      "value": "The Hidden Uniform Cluster Prior in Self-Supervised Learning",
      "justification": "The title explicitly states the main focus of the paper",
      "quote": "THE HIDDEN UNIFORM CLUSTER PRIOR IN SELF â€“ SUPERVISED LEARNING"
    },
    "description": "This paper explores how a common but overlooked uniform feature prior in popular self-supervised learning methods affects the performance of these methods when applied to class-imbalanced datasets. It introduces Prior Matching for Siamese Networks (PMSN) to address these limitations.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents experimental results to demonstrate the impact of uniform priors and the improvements introduced by PMSN.",
      "quote": "In this section, we empirically validate that joint-embedding methods employing volume maximization regularizers are sensitive to the mini-batch class distributions."
    },
    "primary_research_field": {
      "name": {
        "value": "Representation Learning",
        "justification": "The primary focus of the paper is on learning representations using self-supervised methods.",
        "quote": "A successful paradigm in representation learning is to perform self-supervised pretraining using tasks based on mini-batch statistics."
      },
      "aliases": [
        "Self-Supervised Learning",
        "SSL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Unsupervised Learning",
          "justification": "The paper discusses self-supervised pretraining, which falls under unsupervised learning.",
          "quote": "Self-supervised pretraining has emerged as a highly effective strategy for unsupervised representation learning."
        },
        "aliases": [
          "SSL",
          "Self-Supervised Learning"
        ]
      },
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The experimental validation involves visual data such as images from ImageNet.",
          "quote": "When pretrained on the ImageNet dataset, these methods have been shown to produce representations that encode highly semantic features."
        },
        "aliases": [
          "CV"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Masked Siamese Networks (MSN)",
          "justification": "MSN is used for comparing the effectiveness of the proposed method against existing methods.",
          "quote": "In particular, we extend Masked Siamese Networks (MSN) of Assran et al. (2022) to support the use of arbitrary features priors."
        },
        "aliases": [
          "MSN"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "MSN is referenced from prior work.",
          "quote": "In particular, we extend Masked Siamese Networks (MSN) of Assran et al. (2022) to support the use of arbitrary features priors."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is used in empirical validations.",
          "quote": "Figure 2, we use RCDM to visualize the prototypes learned by an MSN model pretrained on IN1K with either class-balanced or class-imbalanced mini-batch distributions."
        },
        "is_compared": {
          "value": 1,
          "justification": "MSN is compared to other models like SimCLR and VICReg in the experimental section.",
          "quote": "We explore three joint-embedding methods employing diverse collapse prevention strategies: SimCLR, VICReg, and MSN."
        },
        "referenced_paper_title": {
          "value": "Masked Siamese Networks for Label-Efficient Learning",
          "justification": "The referenced paper provides the original definition and implementation of MSN.",
          "quote": "In particular, we extend Masked Siamese Networks (MSN) of Assran et al. (2022) to support the use of arbitrary features priors."
        }
      },
      {
        "name": {
          "value": "SimCLR",
          "justification": "SimCLR is one of the baseline models used for comparison.",
          "quote": "Second, we empirically validate that joint-embedding methods employing volume maximization regularizers such as VICReg (Bardes et al., 2021), SwAV (Caron et al., 2020), MSN (Assran et al., 2022) and SimCLR (Chen et al., 2020b)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "SimCLR is not introduced by this paper.",
          "quote": "SimCLR (Chen et al., 2020b)"
        },
        "is_executed": {
          "value": 1,
          "justification": "SimCLR is executed as part of the empirical validations.",
          "quote": "We explore three joint-embedding methods employing diverse collapse prevention strategies: SimCLR (Chen et al., 2020b), VICReg (Bardes et al., 2021), and MSN (Assran et al., 2022)."
        },
        "is_compared": {
          "value": 1,
          "justification": "SimCLR is compared to other models like MSN and VICReg in the experimental section.",
          "quote": "One strategy, termed class-balanced sampling, constructs the mini-batches in each iteration by first randomly selecting 960 classes out of the 1000 ImageNet-1K classes, and then sampling an equal number of images from each class. Another strategy, termed class-imbalanced sampling, constructs the mini-batches in each iteration by first randomly selecting 2 classes out of the 1000 ImageNet-1K classes, and then sampling an equal number of images from each class. We compare the performance of those models to instance-based methods such as MAE (He et al., 2021) and data2vec (Baevski et al., 2022), which do not employ volume maximization regularizers."
        },
        "referenced_paper_title": {
          "value": "A Simple Framework for Contrastive Learning of Visual Representations",
          "justification": "The referenced paper provides the original definition and implementation of SimCLR.",
          "quote": "SimCLR (Chen et al., 2020b)"
        }
      },
      {
        "name": {
          "value": "VICReg",
          "justification": "VICReg is used for comparing the effectiveness of the proposed method against existing methods.",
          "quote": "Second, we empirically validate that joint-embedding methods employing volume maximization regularizers such as VICReg (Bardes et al., 2021), SwAV (Caron et al., 2020), MSN (Assran et al., 2022) and SimCLR (Chen et al., 2020b)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "VICReg is not introduced by this paper.",
          "quote": "VICReg (Bardes et al., 2021)"
        },
        "is_executed": {
          "value": 1,
          "justification": "VICReg is executed as part of the empirical validations.",
          "quote": "Additionally, we compare performance with instance-based methods such as MAE (He et al., 2021) and data2vec (Baevski et al., 2022), which do not employ volume maximization regularizers."
        },
        "is_compared": {
          "value": 1,
          "justification": "VICReg is compared to other models like MSN and SimCLR in the experimental section.",
          "quote": "We show that current methods with volume maximization regularizers such as VICReg (Bardes et al., 2021), SwAV (Caron et al., 2020), MSN (Assran et al., 2022) and SimCLR (Chen et al., 2020b)"
        },
        "referenced_paper_title": {
          "value": "VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning",
          "justification": "The referenced paper provides the original definition and implementation of VICReg.",
          "quote": "VICReg (Bardes et al., 2021)"
        }
      },
      {
        "name": {
          "value": "Prior Matching for Siamese Networks (PMSN)",
          "justification": "PMSN is introduced as a new method in this paper to handle class-imbalanced data in self-supervised learning.",
          "quote": "In particular, we extend Masked Siamese Networks (MSN) of Assran et al. (2022) to support the use of arbitrary features priors, and refer to this extension as Prior Matching for Siamese Networks (PMSN)."
        },
        "aliases": [
          "PMSN"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "PMSN is introduced and proposed as a solution in this paper.",
          "quote": "We introduce Prior Matching for Siamese Networks (PMSN), which extends MSN to support the use of arbitrary feature priors."
        },
        "is_executed": {
          "value": 1,
          "justification": "PMSN is executed as part of the empirical validations.",
          "quote": "To demonstrate this, we develop an extension of the Masked Siamese Networks (MSN) method to support the use of arbitrary features priors."
        },
        "is_compared": {
          "value": 1,
          "justification": "PMSN is compared to other self-supervised models in the experimental section.",
          "quote": "Second, we empirically validate that joint-embedding methods employing volume maximization regularizers are sensitive to the mini-batch class distributions."
        },
        "referenced_paper_title": {
          "value": "None",
          "justification": "PMSN is introduced in this paper for the first time.",
          "quote": "In particular, we extend Masked Siamese Networks (MSN) to support the use of arbitrary features priors, and refer to this extension as Prior Matching for Siamese Networks (PMSN)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is used in the empirical validations to showcase the efficacy of the proposed method.",
          "quote": "When pretrained on the ImageNet dataset (Russakovsky et al., 2015), these methods have been shown to produce representations that encode highly semantic features"
        },
        "aliases": [
          "IN1K",
          "ImageNet-1K"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "The referenced paper provides the details about the ImageNet dataset.",
          "quote": "When pretrained on the ImageNet dataset (Russakovsky et al., 2015)"
        }
      },
      {
        "name": {
          "value": "iNaturalist 2018",
          "justification": "iNaturalist 2018 is used for evaluating the effectiveness of the proposed PMSN method in handling class-imbalanced data.",
          "quote": "When pretraining on the iNaturalist 2018 dataset (Van Horn et al., 2018), which is naturally long-tailed"
        },
        "aliases": [
          "iNat18"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The iNaturalist Species Classification and Detection Dataset",
          "justification": "The referenced paper provides the details about the iNaturalist dataset.",
          "quote": "When pretraining on the iNaturalist 2018 dataset (Van Horn et al., 2018)"
        }
      },
      {
        "name": {
          "value": "CIFAR100",
          "justification": "CIFAR100 is used as one of the downstream tasks to evaluate the learned representations.",
          "quote": "After pretraining all models using the various sampling strategies, we evaluate performance on a wide range of downstream tasks requiring different levels of abstraction, i.e., classification with CIFAR100."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The referenced paper provides the details about the CIFAR100 dataset.",
          "quote": "classification with CIFAR100 (Krizhevsky et al., 2009)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "VISSL",
          "justification": "VISSL is used for the evaluation of different models on downstream tasks in the study.",
          "quote": "For evaluation, we use the publicly available VISSL codebase (Goyal et al., 2021); specific evaluation configurations are provided in Appendix D.2."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "VISSL",
          "justification": "The reference is to the same library, VISSL.",
          "quote": "For evaluation, we use the publicly available VISSL codebase (Goyal et al., 2021); specific evaluation configurations are provided in Appendix D.2."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2895,
    "prompt_tokens": 25192,
    "total_tokens": 28087
  }
}