{
  "paper": "PvLnIaJbt9.txt",
  "words": 10070,
  "extractions": {
    "title": {
      "value": "Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics",
      "justification": "This is the title of the paper provided by the user.",
      "quote": "Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics"
    },
    "description": "The paper presents Metadata Archaeology, specifically focusing on leveraging training dynamics to uncover latent metadata within datasets. It introduces a method called Metadata Archaeology via Probe Dynamics (MAP-D), which uses differences in learning dynamics to infer metadata features and perform tasks like auditing datasets, correcting mislabeled examples, and identifying minority-group samples.",
    "type": {
      "value": "Empirical",
      "justification": "The paper provides empirical results from multiple datasets and models to validate its approach.",
      "quote": "We present consistent results across six image classification datasets, CIFAR-10/CIFAR-100 (Krizhevsky et al., 2009), ImageNet (Deng et al., 2009), Waterbirds (Sagawa et al., 2020), CelebA (Liu et al., 2015) , Clothing1M (Xiao et al., 2015) and two models from the ResNet family (He et al., 2016)."
    },
    "primary_research_field": {
      "name": {
        "value": "Data Quality and Metadata Inference",
        "justification": "The paper focuses on improving data quality by identifying and inferring metadata within datasets.",
        "quote": "We introduce the problem of Metadata Archaeology as the task of surfacing and inferring metadata of different examples in a dataset."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The methods proposed in the paper are applied to image classification datasets.",
          "quote": "We present consistent results across six image classification datasets."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet",
          "justification": "The paper evaluates its methods using models from the ResNet family.",
          "quote": "We present consistent results across six image classification datasets... and two models from the ResNet family (He et al., 2016)."
        },
        "aliases": [
          "ResNet-50",
          "ResNet-18"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The ResNet models were used for evaluation and not contributed as part of this work.",
          "quote": ""
        },
        "is_executed": {
          "value": 1,
          "justification": "The models were used for running experiments.",
          "quote": "Training Details and Architectures: All our experiments are based on ResNet-50 (He et al., 2016), except label correction experiments which are based on ResNet-18 following Arazo et al. (2019)."
        },
        "is_compared": {
          "value": 1,
          "justification": "The ResNet models were used to compare the effectiveness of MAP-D across different datasets and tasks.",
          "quote": "We compare different noise correction methods under the presence of label noise. MAP-D is competitive with most other methods."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "The referenced paper for the ResNet models.",
          "quote": "We present consistent results across six image classification datasets... and two models from the ResNet family (He et al., 2016)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The CIFAR-10 dataset was used for experiments in this paper.",
          "quote": "We present consistent results across six image classification datasets, CIFAR-10/CIFAR-100 (Krizhevsky et al., 2009)"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The paper referenced for the CIFAR-10 dataset.",
          "quote": "We present consistent results across six image classification datasets, CIFAR-10/CIFAR-100 (Krizhevsky et al., 2009)"
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "The CIFAR-100 dataset was used for experiments in this paper.",
          "quote": "We present consistent results across six image classification datasets, CIFAR-10/CIFAR-100 (Krizhevsky et al., 2009)"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The paper referenced for the CIFAR-100 dataset.",
          "quote": "We present consistent results across six image classification datasets, CIFAR-10/CIFAR-100 (Krizhevsky et al., 2009)"
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset was used for experiments in this paper.",
          "quote": "We present consistent results across six image classification datasets... ImageNet (Deng et al., 2009)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "The paper referenced for the ImageNet dataset.",
          "quote": "We present consistent results across six image classification datasets... ImageNet (Deng et al., 2009)."
        }
      },
      {
        "name": {
          "value": "Waterbirds",
          "justification": "The Waterbirds dataset was used for experiments in this paper.",
          "quote": "We present consistent results across six image classification datasets... Waterbirds (Sagawa et al., 2020)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "An investigation of why overparameterization exacerbates spurious correlations",
          "justification": "The paper referenced for the Waterbirds dataset.",
          "quote": "We present consistent results across six image classification datasets... Waterbirds (Sagawa et al., 2020)."
        }
      },
      {
        "name": {
          "value": "CelebA",
          "justification": "The CelebA dataset was used for experiments in this paper.",
          "quote": "We present consistent results across six image classification datasets... CelebA (Liu et al., 2015)"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deep Learning Face Attributes in the Wild",
          "justification": "The paper referenced for the CelebA dataset.",
          "quote": "We present consistent results across six image classification datasets... CelebA (Liu et al., 2015)"
        }
      },
      {
        "name": {
          "value": "Clothing1M",
          "justification": "The Clothing1M dataset was used for experiments in this paper.",
          "quote": "We present consistent results across six image classification datasets... Clothing1M (Xiao et al., 2015)"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning from massive noisy labeled data for image classification",
          "justification": "The paper referenced for the Clothing1M dataset.",
          "quote": "We present consistent results across six image classification datasets... Clothing1M (Xiao et al., 2015)"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 3251,
    "prompt_tokens": 35287,
    "total_tokens": 38538
  }
}