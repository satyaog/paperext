{
  "paper": "2201.11231.txt",
  "words": 24089,
  "extractions": {
    "title": {
      "value": "Gap Minimization for Knowledge Sharing and Transfer",
      "justification": "The full title of the paper as mentioned on the document.",
      "quote": "Gap Minimization for Knowledge Sharing and Transfer"
    },
    "description": "This paper introduces the notion of performance gap and proposes methods to minimize it for better knowledge sharing and transfer in learning tasks. It presents two algorithms, gapBoost and gapMTNN, and evaluates them on multiple datasets.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper proposes new algorithms and evaluates them extensively on various datasets.",
      "quote": "Our extensive evaluation on both transfer learning and multitask learning benchmark data sets shows that our methods outperform existing baselines."
    },
    "primary_research_field": {
      "name": {
        "value": "Transfer Learning",
        "justification": "The primary focus of the paper is on improving knowledge transfer between tasks through gap minimization.",
        "quote": "Learning from multiple related tasks by knowledge sharing and transfer has become increasingly relevant over the last two decades."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Multitask Learning",
          "justification": "The paper also addresses multitask learning scenarios, with algorithms that apply to both transfer learning and multitask learning.",
          "quote": "Gap minimization is, to the best of our knowledge, the first unified principle that accommodates both transfer and multitask learning with the presence of labeled data."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "gapBoost",
          "justification": "This is one of the algorithms proposed in the paper for minimizing the performance gap in transfer learning tasks.",
          "quote": "We instantiate this principle with two algorithms: 1. gapBoost, a novel and principled boosting algorithm that explicitly minimizes the performance gap between source and target domains for transfer learning."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The algorithm is introduced as a contribution in this paper.",
          "quote": "We instantiate this principle with two algorithms: 1. gapBoost, a novel and principled boosting algorithm that explicitly minimizes the performance gap between source and target domains for transfer learning."
        },
        "is_executed": {
          "value": 1,
          "justification": "The algorithm was trained and tested during the experiments.",
          "quote": "Logistic regression is used as the base learner for all methods, and the number of boosting iterations is set to 20."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of gapBoost is compared with other baseline algorithms.",
          "quote": "We evaluated gapBoost against four baseline algorithms: AdaBoostT trained only on target data, AdaBoostT &S trained on both source and target data, TrAdaBoost, and TransferBoost."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Not applicable as this is a new algorithm introduced by the authors.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "gapMTNN",
          "justification": "This is one of the algorithms proposed in the paper, intended for multitask learning scenarios.",
          "quote": "We instantiate this principle with two algorithms:... and 2. gapMTNN, a representation learning algorithm that reformulates gap minimization as semantic conditional matching for multitask learning."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The algorithm is introduced as a contribution in this paper.",
          "quote": "We instantiate this principle with two algorithms:... and 2. gapMTNN, a representation learning algorithm that reformulates gap minimization as semantic conditional matching for multitask learning."
        },
        "is_executed": {
          "value": 1,
          "justification": "The algorithm was trained and tested during the experiments.",
          "quote": "In order to minimize the gap term ∇j , we note that for the task weighting approach, if we ignore the regularization term in VjΦ (h), performance gap minimization is equivalent to conditional distribution alignment."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of gapMTNN is compared with other baseline algorithms.",
          "quote": "gapMTNN outperforms all baselines in most cases. In particular, compared with AMTNN, which only aligns marginal distributions, gapMTNN has a large margin of improvement especially when there are few labeled instances."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Not applicable as this is a new algorithm introduced by the authors.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "20 Newsgroups",
          "justification": "The 20 Newsgroups dataset is used for evaluating the performance of the proposed gapBoost algorithm.",
          "quote": "The first data set we consider is 20 Newsgroups, which contains approximately 20,000 documents, grouped by seven top categories and 20 subcategories."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper mentioned for this dataset.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Office-Caltech",
          "justification": "The Office-Caltech dataset is used for evaluating the performance of the proposed gapBoost algorithm.",
          "quote": "The second data set we use is Office-Caltech, which contains approximately 2,500 images from four distinct domains: Amazon (A), DSLR (D), Webcam (W), and Caltech (C), which enabled us to construct 12 transfer problems by alternately selecting each possible source-target pair."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper mentioned for this dataset.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Digits",
          "justification": "The Digits dataset is used for evaluating the performance of the proposed gapMTNN algorithm.",
          "quote": "We evaluate the algorithm on Digits, PACS, Office-31 and Office-Home data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper mentioned for this dataset.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "PACS",
          "justification": "The PACS dataset is used for evaluating the performance of the proposed gapMTNN algorithm.",
          "quote": "We evaluate the algorithm on Digits, PACS, Office-31 and Office-Home data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper mentioned for this dataset.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Office-31",
          "justification": "The Office-31 dataset is used for evaluating the performance of the proposed gapMTNN algorithm.",
          "quote": "We evaluate the algorithm on Digits, PACS, Office-31 and Office-Home data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper mentioned for this dataset.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Office-Home",
          "justification": "The Office-Home dataset is used for evaluating the performance of the proposed gapMTNN algorithm.",
          "quote": "We evaluate the algorithm on Digits, PACS, Office-31 and Office-Home data sets."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper mentioned for this dataset.",
          "quote": "N/A"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1471,
    "prompt_tokens": 45663,
    "total_tokens": 47134
  }
}