{
  "paper": "97b96aea8ae0675ec7a92dad37b4256f.txt",
  "words": 7717,
  "extractions": {
    "title": {
      "value": "MOT: a Multi-Omics Transformer for multiclass classification tumour types predictions",
      "justification": "The title is clearly stated at the beginning of the paper.",
      "quote": "MOT: a Multi-Omics Transformer for multiclass classification tumour types predictions"
    },
    "description": "The paper introduces MOT (Multi-Omic Transformer), a deep learning model based on the transformer architecture, designed for multiclass classification of tumour types using multi-omics data. The model integrates five omics data types and achieves high F1-scores in cancer type prediction tasks, even in the presence of missing data.",
    "type": {
      "value": "Empirical Study",
      "justification": "The study involves experiments, performance evaluations, and comparisons with existing models using multiple datasets.",
      "quote": "The MOT model is trained and evaluated on three partitions: a training set (70% of the dataset), a validation set (10% of the dataset) and a testing set (20% of the dataset)."
    },
    "primary_research_field": {
      "name": {
        "value": "Bioinformatics and Computational Biology",
        "justification": "The paper focuses on integrating multi-omics data and applying deep learning models for biological data analysis, specifically in cancer classification.",
        "quote": "Breakthroughs in high-throughput technologies and machine learning methods have enabled the shift towards multi-omics modelling as the preferred means to understand the mechanisms underlying biological processes."
      },
      "aliases": [
        "Bioinformatics"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Medical Imaging and Diagnostics",
          "justification": "The focus on tumour type prediction and cancer classification relates directly to diagnostics within medical imaging and diagnostics.",
          "quote": "MOT (Multi-Omic Transformer), a deep learning based model using the transformer architecture, that discriminates complex phenotypes (herein cancer types) based on five omics data types."
        },
        "aliases": [
          "Diagnostics"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Multi-Omic Transformer (MOT)",
          "justification": "The primary model introduced and evaluated in the paper is MOT, which is specifically designed for multiclass classification of tumour types using multi-omics data.",
          "quote": "We proposed MOT (Multi-Omic Transformer), a deep learning based model using the transformer architecture."
        },
        "aliases": [
          "MOT"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The MOT model is introduced and used as the main contribution of the research to integrate multiple omics data for tumour classification.",
          "quote": "We proposed MOT (Multi-Omic Transformer), a deep learning based model using the transformer architecture."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper details the execution and evaluation of MOT on various datasets, including the training, validation, and testing phases.",
          "quote": "The MOT model is trained and evaluated on three partitions: a training set (70% of the dataset), a validation set (10% of the dataset) and a testing set (20% of the dataset)."
        },
        "is_compared": {
          "value": 1,
          "justification": "MOT is compared to multiple baseline algorithms and other models like OmiVAE, GeneTransformer, etc.",
          "quote": "We compared the MOT performance to some baselines algorithms."
        },
        "referenced_paper_title": {
          "value": "Attention is all you need",
          "justification": "The referenced paper for the transformer model architecture is 'Attention is all you need' by Vaswani et al.",
          "quote": "Figure 1 illustrates the MOT model which is the original model introduced by Vaswani et al. (29)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "TCGA Pan-Cancer Dataset",
          "justification": "The dataset used in the study for training and evaluating the MOT model is the TCGA pan-cancer dataset.",
          "quote": "The TCGA pan-cancer dataset is available on the UCSC Xena data portal. There are 33 tumour types in the dataset."
        },
        "aliases": [
          "TCGA"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Cancer Genome Atlas: an immeasurable source of knowledge",
          "justification": "The TCGA dataset is well-known and widely referenced in cancer research studies.",
          "quote": "The TCGA pan-cancer dataset is available on the UCSC Xena data portal."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "scikit-learn",
          "justification": "The scikit-learn library is used in the preprocessing and feature selection steps of the study.",
          "quote": "regarding the CNVs dataset, it contains categorical values [(-2, -1, 0, 1, 2)]. Thus, another feature selection method was applied, the mutual_info_classif, available on scikit-learn (34)."
        },
        "aliases": [
          "sklearn"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "API design for machine learning software: experiences from the scikit-learn project",
          "justification": "The scikit-learn library is widely referenced and used for machine learning tasks.",
          "quote": "Thus, another feature selection method was applied, the mutual_info_classif, available on scikit-learn (34)."
        }
      },
      {
        "name": {
          "value": "Optuna",
          "justification": "Optuna is used for hyper-parameter optimization in the study.",
          "quote": "The hyper-parameter optimization, a crucial step in machine learning problems, was done with Optuna (38), an open-source hyper-parameter optimization framework to automate hyper-parameter search."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Optuna: A next-generation hyperparameter optimization framework",
          "justification": "Optuna is explicitly mentioned as a tool used for hyper-parameter optimization.",
          "quote": "The hyper-parameter optimization, a crucial step in machine learning problems, was done with Optuna (38), an open-source hyper-parameter optimization framework to automate hyper-parameter search."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1154,
    "prompt_tokens": 15192,
    "total_tokens": 16346
  }
}