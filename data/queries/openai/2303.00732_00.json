{
  "paper": "2303.00732.txt",
  "words": 29537,
  "extractions": {
    "title": {
      "value": "R-U-SURE? Uncertainty-Aware Code Suggestions By Maximizing Utility Across Random User Intents",
      "justification": "This is the clear, full title given at the top of the research paper.",
      "quote": "R-U-SURE? Uncertainty-Aware Code Suggestions By Maximizing Utility Across Random User Intents"
    },
    "description": "This paper proposes R-U-SURE, an approach for generating uncertainty-aware code suggestions using a decision-theoretic model of goal-conditioned utility with samples from a generative model acting as proxies for the user's intent. The method combines minimum-Bayes-risk decoding, dual decomposition, and decision diagrams to efficiently provide structured uncertainty summaries for code suggestions. It is implemented as an open-source library and demonstrated on several developer assistance tasks.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper contains experiments and demonstrations of the proposed method on real-world developer assistance tasks, indicating it is an empirical study rather than purely theoretical.",
      "quote": "We demonstrate R-U-SURE on three developer-assistance tasks, and show that it can be applied different user interaction patterns without retraining the model and leads to more accurate uncertainty estimates than token-probability baselines."
    },
    "primary_research_field": {
      "name": {
        "value": "Software Engineering",
        "justification": "The primary focus of the paper is on generating and evaluating code suggestions to assist software developers, which falls under the broad field of Software Engineering.",
        "quote": "Large language models show impressive results at predicting structured text such as code, but also commonly introduce errors and hallucinations in their output. When used to assist software developers..."
      },
      "aliases": [
        "SE"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Learning for Code (ML4Code)",
          "justification": "The paper leverages machine learning, specifically large language models, to generate code suggestions. This aligns with the subfield of ML4Code.",
          "quote": "Our key insight is that, since language models of code are trained to predict file contents from context, we can reinterpret the samples from a well-trained language model as plausible goal states for the user."
        },
        "aliases": [
          "Machine Learning for Programming",
          "ML for Programming",
          "ML Code Generation"
        ]
      },
      {
        "name": {
          "value": "Uncertainty Quantification",
          "justification": "The core contribution of the paper is to introduce mechanisms for capturing and utilizing uncertainty in code suggestions generated by machine learning models.",
          "quote": "We propose Randomized Utility-driven Synthesis of Uncertain REgions (R-U-SURE), an approach for building uncertainty-aware suggestions based on a decision-theoretic model of goal-conditioned utility, using random samples from a generative model as a proxy for the unobserved possible intents of the end user."
        },
        "aliases": [
          "Uncertainty Estimation",
          "Uncertainty Modeling"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "R-U-SURE",
          "justification": "R-U-SURE is explicitly mentioned as the central model proposed in the paper which aids in generating uncertainty-aware code suggestions.",
          "quote": "We propose Randomized Utility-driven Synthesis of Uncertain REgions (R-U-SURE), an approach for building uncertainty-aware suggestions..."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "R-U-SURE is the primary contribution introduced and developed in the paper.",
          "quote": "We propose Randomized Utility-driven Synthesis of Uncertain REgions (R-U-SURE)..."
        },
        "is_executed": {
          "value": 0,
          "justification": "The model is discussed in the context of being used within an experimental setup for code completion tasks, but the paper does not explicitly talk about its execution environment (CPU/GPU).",
          "quote": "We demonstrate R-U-SURE on three developer-assistance tasks..."
        },
        "is_compared": {
          "value": 1,
          "justification": "R-U-SURE's performance is evaluated and compared with other baselines in the experiments.",
          "quote": "We compare our approach to a number of task-specific baselines..."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "R-U-SURE is a new model proposed in this paper and doesn't reference any prior specific model paper by title.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Mostly Basic Python Problems",
          "justification": "The MBPP dataset is explicitly mentioned as used for experiments in the paper.",
          "quote": "For the example in the Mostly Basic Python Problems benchmark dataset..."
        },
        "aliases": [
          "MBPP"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Program Synthesis with Large Language Models",
          "justification": "The cited reference for the MBPP dataset is the paper 'Program Synthesis with Large Language Models' by Jacob Austin et al.",
          "quote": "Austin, J., Odena, A., Nye, M., Bosma, M., Michalewski, H., Dohan, D., Jiang, E., Cai, C. J., Terry, M., Le, Q. V., and Sutton, C. Program synthesis with large language models."
        }
      },
      {
        "name": {
          "value": "GitHub Scientific Computing Dataset",
          "justification": "The paper mentions the use of a dataset created from permissively licensed code from scientific computing repositories hosted on GitHub.",
          "quote": "We use permissively licensed code from scientific computing repositories hosted on GitHub."
        },
        "aliases": [
          "GitHub Repos"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "This dataset is constructed specifically for the purpose of this study and doesn’t reference any prior paper by title.",
          "quote": "N/A"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Numba",
          "justification": "Numba is mentioned as part of the implementation details for the R-U-SURE system, specifically for CPU optimization.",
          "quote": "Our current implementation of R-U-SURE runs on the CPU using Numba..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Numba: A LLVM-based Python JIT Compiler",
          "justification": "The cited reference for Numba is the paper 'Numba: A LLVM-based Python JIT Compiler' by Lam et al.",
          "quote": "Lam, S. K., Pitrou, A., and Seibert, S. Numba: a llvm-based python jit compiler. In LLVM ’15, 2015."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1254,
    "prompt_tokens": 56501,
    "total_tokens": 57755
  }
}