{
  "paper": "0k_DN90uWF.txt",
  "words": 7892,
  "extractions": {
    "title": {
      "value": "Sample Boosting Algorithm (SamBA) - An Interpretable Greedy Ensemble Classifier Based On Local Expertise For Fat Data",
      "justification": "This is the exact title of the research paper.",
      "quote": "Sample Boosting Algorithm (SamBA) - An Interpretable Greedy Ensemble Classifier Based On Local Expertise For Fat Data"
    },
    "description": "The paper introduces SamBA, a supervised binary classification framework designed to handle fat datasets, characterized by a large number of dimensions but few samples. SamBA combines local classifiers using a similarity function and optimizes for data extraction efficiency. The paper provides theoretical analysis, convergence, and generalization guarantees, as well as empirical validation against state-of-the-art methods.",
    "type": {
      "value": "theoretical",
      "justification": "The paper proposes a new algorithm, provides a theoretical analysis of its convergence and generalization properties, and validates the approach with experiments.",
      "quote": "We provide a theoretical analysis of SamBA, yielding convergence and generalization guarantees. In addition, we highlight SamBA’s empirical behavior in an extensive experimental analysis on both real biological and generated datasets, comparing it to state-of-the-art ensemble methods and similarity-based approaches."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper focuses on proposing and analyzing a new machine learning algorithm specifically for supervised classification tasks.",
        "quote": "In machine learning, ensemble methods combine base estimators into a more robust model relying on several combination methods such as logical or linear combinations, stacking [Wolpert, 1992] or cascading [Gama and Brazdil, 2000] estimators."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Ensemble Learning",
          "justification": "The paper discusses various ensemble methods and proposes an ensemble classifier, SamBA.",
          "quote": "In this paper, we propose a supervised binary classification framework that propagates the local knowledge acquired during the boosting iterations to the prediction function. Based on this general framework, we introduce SamBA, an interpretable greedy ensemble method designed for fat datasets."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Boosting Algorithms",
          "justification": "The proposed SamBA algorithm is a variation of the Adaboost boosting algorithm.",
          "quote": "In addition, we consider H to be a set of decision stumps on the features of X . This allows for the final decision function to rely on a small subset of the features of X and implies some sparsity and interpretability of the decision process."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Interpretable Machine Learning",
          "justification": "The paper emphasizes the importance of interpretability in the SamBA algorithm, especially for biomedical applications.",
          "quote": "Numerous fat datasets are derived from biological tasks, in which algorithm interpretability—the ability for a non-expert to understand the decision function of a model [Rudin et al., 2021]—is central for the results to be endorsed by the users."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Sample Boosting Algorithm (SamBA)",
          "justification": "SamBA is the primary model introduced and discussed throughout the paper.",
          "quote": "we introduce SamBA, an interpretable greedy ensemble method designed for fat datasets, with a large number of dimensions and a small number of samples."
        },
        "aliases": [
          "SamBA"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "SamBA is a new model proposed by the authors of the paper.",
          "quote": "In this paper, we propose a supervised binary classification framework that propagates the local knowledge acquired during the boosting iterations to the prediction function."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed in experiments on both real biological and generated datasets.",
          "quote": "We present extensive experiments that highlight several assets of the algorithm, including its resource efficiency. We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers."
        },
        "is_compared": {
          "value": 1,
          "justification": "SamBA is empirically compared to other state-of-the-art ensemble methods and similarity-based approaches.",
          "quote": "In addition, we highlight SamBA’s empirical behavior in an extensive experimental analysis on both real biological and generated datasets, comparing it to state-of-the-art ensemble methods and similarity-based approaches."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no referenced paper title for SamBA as it is a new model introduced by the authors.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Adaboost",
          "justification": "Adaboost is one of the boosting algorithms that SamBA is derived from and compared against.",
          "quote": "One of the most commonly used is boosting, with the prominent Adaboost."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "Adaboost is not a model contributed by this paper. It is mentioned and used for comparison.",
          "quote": "Adaboost relies on greedily learning base classifiers that rectify the error from previous iterations."
        },
        "is_executed": {
          "value": 1,
          "justification": "Adaboost was executed in experiments for comparison purposes.",
          "quote": "We provide extensive experiments that highlight several assets of the algorithm, including its resource efficiency. We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers."
        },
        "is_compared": {
          "value": 1,
          "justification": "Adaboost is numerically compared to SamBA in the experiments.",
          "quote": "We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers."
        },
        "referenced_paper_title": {
          "value": "A decision-theoretic generalization of on-line learning and an application to boosting.",
          "justification": "This is the title of the reference paper for Adaboost as mentioned in the citations.",
          "quote": "[Freund and Schapire, 1997, Bauvin et al., 2020]"
        }
      },
      {
        "name": {
          "value": "Random Forest",
          "justification": "Random Forest is one of the state-of-the-art ensemble methods mentioned and used for comparison in the paper.",
          "quote": "This advantage is central in biomedical applications, such as biomarker discovery [Kothari et al., 2020], in which interpretable models are used as a means to extract new causes of the studied problem [Osseni et al., 2021]."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "Random Forest is not a model contributed by this paper. It is mentioned and used for comparison.",
          "quote": "Not to mention the celebrated Random Forest [Breiman, 2001] and Adaboost [Schapire and Freund, 2012] majority vote learners."
        },
        "is_executed": {
          "value": 1,
          "justification": "Random Forest was executed in experiments for comparison purposes.",
          "quote": "We present extensive experiments that highlight several assets of the algorithm, including its resource efficiency. We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers."
        },
        "is_compared": {
          "value": 1,
          "justification": "Random Forest is numerically compared to SamBA in the experiments.",
          "quote": "We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers."
        },
        "referenced_paper_title": {
          "value": "Random forests.",
          "justification": "This is the title of the reference paper for Random Forest as mentioned in the citations.",
          "quote": "[Breiman, 2001]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "real biological dataset",
          "justification": "The paper mentions the use of a real biological dataset in its experiments.",
          "quote": "We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers. We study their accuracy and sparsity on synthetic and real life datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "No specific title for the referenced paper for the real biological dataset is provided.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "synthetic datasets",
          "justification": "The paper mentions the use of synthetic datasets in its experiments.",
          "quote": "We also compare it to state-of-the-art implementations of several ensemble methods and similarity-based classifiers. We study their accuracy and sparsity on synthetic and real life datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "No specific title for the referenced paper for the synthetic datasets is provided.",
          "quote": ""
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2074,
    "prompt_tokens": 14597,
    "total_tokens": 16671
  }
}