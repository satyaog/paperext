{
  "paper": "2308.08938.txt",
  "words": 11678,
  "extractions": {
    "title": {
      "value": "Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces",
      "justification": "This is the title of the research paper.",
      "quote": "Causal Adversarial Perturbations for Individual Fairness and Robustness in Heterogeneous Data Spaces"
    },
    "description": "The paper proposes a framework to integrate individual fairness, adversarial robustness, and causal structures using causal adversarial perturbations (CAP), applied through adversarial training to achieve a fair and robust classifier. The method is evaluated on both real-world and synthetic datasets.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes empirical evaluations on both real-world and synthetic datasets.",
      "quote": "Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The study focuses on advancing machine learning models to ensure fairness, robustness, and causality.",
        "quote": "As responsible AI gains importance in machine learning algorithms, properties such as fairness, adversarial robustness, and causality have received considerable attention in recent years."
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Adversarial Learning",
          "justification": "The study introduces the concept of adversarial training and perturbations to enhance the robustness and fairness of machine learning models.",
          "quote": "By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier."
        },
        "aliases": [
          "Adversarial Training"
        ]
      },
      {
        "name": {
          "value": "Fairness in Machine Learning",
          "justification": "The paper is centered on achieving individual fairness within the framework of machine learning.",
          "quote": "Our contributions are as follows: • Causal Fair Metric (§ 3.1) .... • CAPI Fairness (§ 3.3)"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Causal Adversarial Perturbation",
          "justification": "The concept of Causal Adversarial Perturbation is a key contribution of the paper that combines fairness, robustness, and causality.",
          "quote": "By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier."
        },
        "aliases": [
          "CAP"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The model is introduced as a novel approach in the paper.",
          "quote": "To the best of our knowledge, this work is the first work that simultaneously addresses adversarial robustness, individual fairness, and causal structures in training a machine learning model."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is evaluated on real-world and synthetic datasets, implying its execution.",
          "quote": "Our method is evaluated on both real-world and synthetic datasets, demonstrating its effectiveness in achieving an accurate classifier that simultaneously exhibits fairness, adversarial robustness, and causal awareness."
        },
        "is_compared": {
          "value": 1,
          "justification": "The effectiveness of the CAP model is compared against other models in the evaluation section.",
          "quote": "We validate the efficacy of our approach through extensive evaluations on both real-world and synthetic datasets. These evaluations demonstrate the effectiveness of our proposed framework to simultaneously embody individual fairness, adversarial robustness, and causal awareness."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "The Causal Adversarial Perturbation model is proposed by the authors of the current paper and is not referenced from another source.",
          "quote": "By introducing a novel causal adversarial perturbation and applying adversarial training, we create a new regularizer that combines individual fairness, causality, and robustness in the classifier."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Adult",
          "justification": "The Adult dataset is explicitly mentioned as part of the empirical evaluation in the paper.",
          "quote": "For the Adult dataset, we incorporate features such as sex, age, native-country, marital-status, education-num, hours-per-week, and consider gender as a sensitive attribute."
        },
        "aliases": [
          "Census Income Dataset"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "UCI Adult Data Set",
          "justification": "The Adult dataset is a well-known dataset from the UCI repository, which the paper utilizes for evaluating the proposed methods.",
          "quote": "Kohavi, R.; and Becker, B. 1996. Uci adult data set. UCI Meachine Learning Repository, 5."
        }
      },
      {
        "name": {
          "value": "COMPAS",
          "justification": "The COMPAS dataset is explicitly mentioned as part of the empirical evaluation in the paper.",
          "quote": "For the COMPAS dataset, the utilized features comprise age, race, sex, and priors count, which function as variables. Additionally, sex is considered a sensitive attribute."
        },
        "aliases": [
          "Correctional Offender Management Profiling for Alternative Sanctions"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "How to Argue with an Algorithm: Lessons from the COMPAS-ProPublica debate",
          "justification": "The paper cites the COMPAS dataset, which has been the subject of several fairness studies.",
          "quote": "Washington, A. L. 2018. How to argue with an algorithm: Lessons from the COMPAS-ProPublica debate. Colo. Tech. LJ, 17: 131."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1094,
    "prompt_tokens": 21668,
    "total_tokens": 22762
  }
}