{
  "paper": "1910.13249.txt",
  "words": 8469,
  "extractions": {
    "title": {
      "value": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and Experiments",
      "justification": "This is the exact title as stated at the beginning of the paper.",
      "quote": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and Experiments"
    },
    "description": "The paper addresses the challenge of creating a navigation assistant for blind and visually-impaired (BVI) individuals. It introduces SEVN, a sidewalk simulation environment, and explores the performance of a neural network-based navigation agent trained using reinforcement learning algorithms.",
    "type": {
      "value": "empirical study",
      "justification": "The paper involves the creation of a simulation environment and conducts experiments to evaluate the performance of reinforcement learning algorithms for navigation tasks.",
      "quote": "This work introduces SEVN, a sidewalk simulation environment and a neural network-based approach to creating a navigation agent. SEVN contains panoramic images with labels for house numbers, doors, and street name signs, and formulations for several navigation tasks. We study the performance of an RL algorithm (PPO) in this setting."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper employs neural network-based models and reinforcement learning algorithms to solve the navigation task.",
        "quote": "This work introduces SEVN, a sidewalk simulation environment and a neural network-based approach to creating a navigation agent. [...] We study the performance of an RL algorithm (PPO) in this setting."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The paper focuses on using reinforcement learning algorithms, specifically Proximal Policy Optimization (PPO), to train navigation agents.",
          "quote": "Our experiments focus on learning navigation policies that assume access to ground truth text labels, and in this setting our multimodal fusion model demonstrates strong performance on a street segment navigation task. [...] trained with Proximal Policy Optimization (PPO) to fuse images, GPS, and scene text for navigation."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Proximal Policy Optimization",
          "justification": "The PPO algorithm was used to train the navigation agent within the SEVN environment.",
          "quote": "We study the performance of an RL algorithm (PPO) in this setting. [...] Our experiments focus on learning navigation policies [...] trained with Proximal Policy Optimization (PPO)."
        },
        "aliases": [
          "PPO"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Multi-Modal Fusion Model",
          "justification": "A novel model that fuses images, GPS, and scene text for navigation, trained using the PPO algorithm.",
          "quote": "Our policy model fuses multi-modal observations in the form of variable resolution images, visible text, and simulated GPS data to navigate to a goal door."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "SEVN",
          "justification": "SEVN is the novel sidewalk simulation environment introduced in this work, containing panoramic images with annotated labels.",
          "quote": "This work introduces SEVN, a sidewalk simulation environment [...] SEVN contains 4, 988 high resolution panoramas with 3, 259 labels on house numbers, doors, and street signs."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenAI Gym",
          "justification": "The SEVN simulator is based on the OpenAI Gym environment.",
          "quote": "The SEVN Simulator is based on the OpenAI Gym environment."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "NetworkX",
          "justification": "NetworkX was used to implement the panorama graph.",
          "quote": "Our panorama graph is implemented in NetworkX."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1006,
    "prompt_tokens": 12991,
    "total_tokens": 13997
  }
}