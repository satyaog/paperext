{
  "paper": "2310.17800.txt",
  "words": 13270,
  "extractions": {
    "title": {
      "value": "Interacting Diffusion Processes for Event Sequence Forecasting",
      "justification": "This is the title of the research paper as mentioned at the top.",
      "quote": "Interacting Diffusion Processes for Event Sequence Forecasting"
    },
    "description": "The paper presents a novel approach for forecasting event sequences using interacting diffusion processes. It aims to enhance long-horizon forecasting by modeling the sequences with coupled generative diffusion models that capture joint probability distributions of event types and inter-arrival times.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper primarily focuses on demonstrating the empirical performance of the proposed model against state-of-the-art baselines through experimental evaluations.",
      "quote": "We demonstrate that our proposal outperforms state-of-the-art baselines for long-horizon forecasting of TPP."
    },
    "primary_research_field": {
      "name": {
        "value": "Sequence Prediction",
        "justification": "The primary focus of the paper is to predict sequences of events using a novel diffusion model.",
        "quote": "Our proposal is to tackle the multi-event forecasting problem by directly modelling a complete sequence of N events."
      },
      "aliases": [
        "Sequence Forecasting",
        "Event Sequence Prediction"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper introduces a novel generative model for predicting event sequences.",
          "quote": "We build on recent advances in generative models, exploiting their impressive high-dimensionality modeling capabilities."
        },
        "aliases": [
          "Generative Modeling"
        ]
      },
      {
        "name": {
          "value": "Temporal Point Processes",
          "justification": "The research leverages the framework of Temporal Point Processes for event sequence prediction.",
          "quote": "Neural Temporal Point Processes (TPPs) have emerged as the primary framework for predicting sequences of events that occur at irregular time intervals."
        },
        "aliases": [
          "TPPs",
          "Temporal Modeling"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "CDiff",
          "justification": "CDiff is the proposed model in the paper which utilizes interacting diffusion processes for event sequence forecasting.",
          "quote": "We introduce our Cross-Diffusion (CDiff) model, which comprises two interacting diffusion processes."
        },
        "aliases": [
          "Cross-Diffusion Model"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "CDiff is introduced and thoroughly evaluated as the main contribution of the paper.",
          "quote": "We introduce our Cross-Diffusion (CDiff) model, which comprises two interacting diffusion processes."
        },
        "is_executed": {
          "value": 1,
          "justification": "CDiff is evaluated using extensive experimental setups, which typically involve executing the model.",
          "quote": "We train for a maximum of 500 epochs and report the best trained model based on the result of the validation set."
        },
        "is_compared": {
          "value": 1,
          "justification": "CDiff is compared with multiple state-of-the-art baselines in terms of forecasting accuracy and other metrics.",
          "quote": "We compare our CDiff model with 4 state-of-the-art baselines for event sequence modeling."
        },
        "referenced_paper_title": {
          "value": "Denoising Diffusion Probabilistic Models",
          "justification": "The foundational concept of diffusion processes for generative modeling, which is extended in CDiff, is described in this paper.",
          "quote": "Following the conventional diffusion model setup (Ho et al., 2020), this marginalization can be approximated as: ..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "StackOverflow",
          "justification": "StackOverflow dataset is used in the paper for evaluations.",
          "quote": "Figure 1: Visualization of the cross-diffusion generating process for 15 examples sequences of the Stackoverflow dataset."
        },
        "aliases": [
          "Stack Overflow"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "SNAP Datasets: Stanford large network dataset collection",
          "justification": "It is a well-known dataset compilation referenced by the authors.",
          "quote": "Leskovec, J. and Krevl, A. (2014). SNAP Datasets: Stanford large network dataset collection."
        }
      },
      {
        "name": {
          "value": "Retweet",
          "justification": "Retweet dataset is used in the paper for evaluations.",
          "quote": "We use four real-world datasets: Taobao (Alibaba, 2018), which tracks user clicks made on a website; Taxi (Whong, 2014), which contains trips to neighborhood made by taxi drivers; StackOverflow (Leskovec and Krevl, 2014), which tracks the history of a post on stackoverflow; and Retweet (Zhou et al., 2013), which tracks the user interactions on social media posts."
        },
        "aliases": [
          "Twitter Retweet"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning triggering kernels for multi-dimensional hawkes processes",
          "justification": "The dataset citation is from the original paper referenced.",
          "quote": "Zhou, K., Zha, H., and Song, L. (2013). Learning triggering kernels for multi-dimensional hawkes processes."
        }
      },
      {
        "name": {
          "value": "Taxi",
          "justification": "Taxi dataset is used in the paper for evaluations.",
          "quote": "We use four real-world datasets: Taobao (Alibaba, 2018), which tracks user clicks made on a website; Taxi (Whong, 2014), which contains trips to neighborhood made by taxi drivers; StackOverflow (Leskovec and Krevl, 2014), which tracks the history of a post on stackoverflow; and Retweet (Zhou et al., 2013), which tracks the user interactions on social media posts."
        },
        "aliases": [
          "NYC Taxi"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Foiling nyc’s taxi trip data",
          "justification": "The dataset citation is from the original paper referenced.",
          "quote": "Whong, C. (2014). Foiling nyc’s taxi trip data."
        }
      },
      {
        "name": {
          "value": "Taobao",
          "justification": "Taobao dataset used in the paper for evaluations.",
          "quote": "We use four real-world datasets: Taobao (Alibaba, 2018), which tracks user clicks made on a website; Taxi (Whong, 2014), which contains trips to neighborhood made by taxi drivers; StackOverflow (Leskovec and Krevl, 2014), which tracks the history of a post on stackoverflow; and Retweet (Zhou et al., 2013), which tracks the user interactions on social media posts."
        },
        "aliases": [
          "Taobao User Behavior"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "User behavior data from taobao for recommendation",
          "justification": "The dataset citation is from the original paper referenced.",
          "quote": "Alibaba (2018). User behavior data from taobao for recommendation."
        }
      },
      {
        "name": {
          "value": "Synthetic Multivariate Hawkes Dataset",
          "justification": "The paper uses a synthetic dataset generated from a multivariate Hawkes process for experimentation.",
          "quote": "Our synthetic dataset is generated from a Hawkes model."
        },
        "aliases": [
          "Generated Hawkes Data"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "tick: a python library for statistical learning, with an emphasis on hawkes processes and time-dependent models",
          "justification": "The dataset is generated using the tick library as referenced.",
          "quote": "Bacry, E., Bompaire, M., Deegan, P., Gaı̈ffas, S., and Poulsen, S. V. (2018). tick: a python library for statistical learning, with an emphasis on hawkes processes and time-dependent models."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The PyTorch library is used to implement the transformer-based components in their model.",
          "quote": "For the two diffusion denoising functions ϵθ (·), ϕθ (·), we adopt the PyTorch built-in transformer block (Paszke et al., 2019)."
        },
        "aliases": [
          "PyTorch Library"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Pytorch: An imperative style, high-performance deep learning library",
          "justification": "The authors referenced the original PyTorch paper.",
          "quote": "Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S. (2019). Pytorch: An imperative style, high-performance deep learning library."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1722,
    "prompt_tokens": 29197,
    "total_tokens": 30919
  }
}