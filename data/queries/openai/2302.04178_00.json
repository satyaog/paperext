{
  "paper": "2302.04178.txt",
  "words": 11234,
  "extractions": {
    "title": {
      "value": "DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets",
      "justification": "This is the title of the paper as indicated at the beginning of the document.",
      "quote": "DynGFN: Towards Bayesian Inference of Gene Regulatory Networks with GFlowNets"
    },
    "description": "The paper introduces DynGFN, a novel framework leveraging Generative Flow Networks (GFlowNets) for Bayesian inference of Gene Regulatory Networks (GRNs) particularly focusing on modelling uncertainty in cyclic gene regulation structures from noisy observational data.",
    "type": {
      "value": "empirical study",
      "justification": "The paper involves empirical evaluations and experiments on synthetic and real biological data to validate the proposed DynGFN framework.",
      "quote": "We showcase the use of DynGFN on a real biological system using single-cell RNA-velocity data for learning posteriors of GRNs."
    },
    "primary_research_field": {
      "name": {
        "value": "Computational Biology",
        "justification": "The primary research field is Computational Biology, as the paper's main focus is on inferring gene regulatory networks using machine learning techniques.",
        "quote": "One of the grand challenges of cell biology is inferring the gene regulatory network (GRN)..."
      },
      "aliases": [
        "CompBio",
        "Bioinformatics"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Bayesian Inference",
          "justification": "Part of the research involves developing a Bayesian inference framework to capture the uncertainty in GRN structures.",
          "quote": "We develop a novel framework for Bayesian structure learning under the lens of dynamical system identification for modelling complex posteriors over cyclic graphs."
        },
        "aliases": [
          "Bayesian Learning",
          "Probabilistic Inference"
        ]
      },
      {
        "name": {
          "value": "Gene Regulatory Network Inference",
          "justification": "The main application of the proposed framework is the inference of gene regulatory networks.",
          "quote": "We showcase the use of DynGFN on a real biological system using single-cell RNA-velocity data for learning posteriors of GRNs."
        },
        "aliases": [
          "GRN Inference"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "DynGFN",
          "justification": "The main model proposed in the paper is DynGFN, tailored for Bayesian dynamic structure learning.",
          "quote": "We design a novel GFlowNet architecture, Dynamic GFlowNet (DynGFN), tailored for modelling posteriors over cyclic structures."
        },
        "aliases": [
          "Dynamic GFlowNet"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "DynGFN is the primary contribution introduced by the authors.",
          "quote": "We design a novel GFlowNet architecture, Dynamic GFlowNet (DynGFN), tailored for modelling posteriors over cyclic structures."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was implemented and tested in the experiments described in the paper.",
          "quote": "We empirically evaluated DynGFN on synthetic dynamic data designed to induce highly multimodal posteriors over graphs."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of DynGFN was compared with baseline models in the empirical studies.",
          "quote": "We find that â„“-DynGFN and h-DynGFN yield low KL and moderate Bayes-SHD."
        },
        "referenced_paper_title": {
          "value": "not applicable",
          "justification": "The model was introduced in this paper and is not based on a previous work.",
          "quote": "We design a novel GFlowNet architecture, Dynamic GFlowNet (DynGFN), tailored for modelling posteriors over cyclic structures."
        }
      },
      {
        "name": {
          "value": "BCD-Nets",
          "justification": "BCD-Nets is one of the baseline models compared against DynGFN in the experiments.",
          "quote": "We apply versions of DiBS and BCD-Nets such that they are applicable in our Bayesian dynamic structure learning framework."
        },
        "aliases": [
          "Bayesian Causal Discovery Networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "BCD-Nets is an existing model used for comparison purposes in the paper.",
          "quote": "We apply versions of DiBS and BCD-Nets such that they are applicable in our Bayesian dynamic structure learning framework."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experimental comparisons with DynGFN.",
          "quote": "We compare to Bayesian methods that can also accomplish this task, i.e. versions of BCD-Nets [11] and DiBS [32]."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of BCD-Nets was compared with DynGFN in the empirical studies.",
          "quote": "Since our primary objective is to learn Bayesian posteriors over discrete structure G, we compare to Bayesian methods that can also accomplish this task, i.e. versions of BCD-Nets [11] and DiBS [32]."
        },
        "referenced_paper_title": {
          "value": "BCD Nets: Scalable Variational Approaches for Bayesian Causal Discovery",
          "justification": "This is the title of the original paper where BCD-Nets was introduced.",
          "quote": "BCD-Nets [11]"
        }
      },
      {
        "name": {
          "value": "DiBS",
          "justification": "DiBS is one of the baseline models compared against DynGFN in the experiments.",
          "quote": "We apply versions of DiBS and BCD-Nets such that they are applicable in our Bayesian dynamic structure learning framework."
        },
        "aliases": [
          "Differentiable Bayesian Structure Learning"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "DiBS is an existing model used for comparison purposes in the paper.",
          "quote": "We apply versions of DiBS and BCD-Nets such that they are applicable in our Bayesian dynamic structure learning framework."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experimental comparisons with DynGFN.",
          "quote": "We compare to Bayesian methods that can also accomplish this task, i.e. versions of BCD-Nets [11] and DiBS [32]."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of DiBS was compared with DynGFN in the empirical studies.",
          "quote": "Since our primary objective is to learn Bayesian posteriors over discrete structure G, we compare to Bayesian methods that can also accomplish this task, i.e. versions of BCD-Nets [11] and DiBS [32]."
        },
        "referenced_paper_title": {
          "value": "DiBS: Differentiable Bayesian Structure Learning",
          "justification": "This is the title of the original paper where DiBS was introduced.",
          "quote": "DiBS [32]"
        }
      },
      {
        "name": {
          "value": "NeuralODEs",
          "justification": "NeuralODEs is mentioned as a model in related work for structure learning from dynamics.",
          "quote": "Recent works in this direction based on NeuralODEs [10] propose a single explanatory structure [50, 6, 1, 2]."
        },
        "aliases": [
          "Neural Ordinary Differential Equations"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "NeuralODEs is an existing model mentioned in the related work, not a focus of this paper.",
          "quote": "Recent works in this direction based on NeuralODEs [10] propose a single explanatory structure [50, 6, 1, 2]."
        },
        "is_executed": {
          "value": 0,
          "justification": "NeuralODEs were referenced but not executed as part of this paper's experiments.",
          "quote": "Recent works in this direction based on NeuralODEs [10] propose a single explanatory structure [50, 6, 1, 2]."
        },
        "is_compared": {
          "value": 0,
          "justification": "NeuralODEs is referenced in the context of related work, but its performance is not empirically compared with DynGFN.",
          "quote": "Recent works in this direction based on NeuralODEs [10] propose a single explanatory structure [50, 6, 1, 2]."
        },
        "referenced_paper_title": {
          "value": "Neural Ordinary Differential Equations",
          "justification": "This is the title of the original paper where NeuralODEs were introduced.",
          "quote": "Neural Ordinary Differential Equations."
        }
      },
      {
        "name": {
          "value": "NOTEARS",
          "justification": "NOTEARS is mentioned as a model for learning acyclic dependencies from observational data.",
          "quote": "NOTEARS is a score-based approach that uses time-series to learn structure [40]."
        },
        "aliases": [
          "Non-Deterministic Efficient Acyclic Regions"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "NOTEARS is an existing model mentioned in the context of related work.",
          "quote": "NOTEARS is a score-based approach that uses time-series to learn structure [40]."
        },
        "is_executed": {
          "value": 1,
          "justification": "NOTEARS was executed as part of the toy example comparisons.",
          "quote": "In this example we compare NOTEARS and DynGFN for learning acyclic and cyclic dependencies from observational data."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of NOTEARS was compared with DynGFN in the toy example.",
          "quote": "In this example we compare NOTEARS and DynGFN for learning acyclic and cyclic dependencies from observational data."
        },
        "referenced_paper_title": {
          "value": "DAGs with NO TEARS: Continuous Optimization for Structure Learning",
          "justification": "This is the title of the original paper where NOTEARS was introduced.",
          "quote": "NOTEARS: Continuous Optimization for Structure Learning"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Single-cell RNA-velocity",
          "justification": "Single-cell RNA-velocity data was used in the experiments to showcase DynGFN's application to real biological systems.",
          "quote": "We showcase the use of DynGFN on a real biological system using single-cell RNA-velocity data for learning posteriors of GRNs."
        },
        "aliases": [
          "scRNA-velocity"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "RNA velocity of single cells. Nature, 560, 2018.",
          "justification": "This is the referenced paper where RNA velocity methods for single cells were discussed.",
          "quote": "We leverage the fact that we can estimate the rate of change of a geneâ€™s expression (velocity) with RNA velocity methods [9]."
        }
      },
      {
        "name": {
          "value": "Cell cycle dataset of human Fibroblasts",
          "justification": "Dataset used in the experiments to evaluate DynGFN on real biological data.",
          "quote": "We showcase the use of DynGFN on a real biological system using single-cell RNA-velocity data for learning posteriors of GRNs."
        },
        "aliases": [
          "Fibroblast cell cycle data"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Cell cycle gene regulation dynamics revealed by RNA velocity and deep-learning.",
          "justification": "This is the referenced paper where the cell cycle dataset of human Fibroblasts was used.",
          "quote": "We showcase the use of DynGFN on a real biological system using single-cell RNA-velocity data for learning posteriors of GRNs."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Pytorch",
          "justification": "Pytorch was used for the implementation of the models in this paper.",
          "quote": "Our model is implemented in Pytorch and Pytorch Lightning..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no specific referenced paper for Pytorch within the document.",
          "quote": "Our model is implemented in Pytorch and Pytorch Lightning and is available at..."
        }
      },
      {
        "name": {
          "value": "Pytorch Lightning",
          "justification": "Pytorch Lightning was used to implement the models in this paper.",
          "quote": "Our model is implemented in Pytorch and Pytorch Lightning..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no specific referenced paper for Pytorch Lightning within the document.",
          "quote": "Our model is implemented in Pytorch and Pytorch Lightning and is available at..."
        }
      },
      {
        "name": {
          "value": "CausalNex",
          "justification": "CausalNex was used to implement the NOTEARS model.",
          "quote": "NOTEARS is implemented using the CausalNex [5] library."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no specific referenced paper for CausalNex within the document.",
          "quote": "NOTEARS is implemented using the CausalNex [5] library."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 5653,
    "prompt_tokens": 42046,
    "total_tokens": 47699
  }
}