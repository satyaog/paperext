{
  "paper": "2102.08649.txt",
  "words": 41178,
  "extractions": {
    "title": {
      "value": "A General Framework for the Practical Disintegration of PAC-Bayesian Bounds",
      "justification": "The title accurately represents the content and aim of the research presented in the paper.",
      "quote": "A General Framework for the Practical Disintegration of PAC-Bayesian Bounds"
    },
    "description": "This paper introduces a new framework for deriving PAC-Bayesian generalization bounds without requiring a derandomization step for deterministic models such as neural networks. The authors provide easily optimizable PAC-Bayesian bounds applicable to one single hypothesis. They also demonstrate significant practical improvements on neural networks compared to existing methods.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents experimental results and comparisons with existing methods, which is characteristic of empirical research.",
      "quote": "We illustrate this behavior on neural networks, and we show a significant practical improvement over the state-of-the-art framework."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning Theory",
        "justification": "The paper mainly contributes to PAC-Bayesian theory and its applications in machine learning.",
        "quote": "In statistical learning theory, PAC-Bayesian theory provides a powerful framework for analyzing the generalization ability of machine learning models."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Neural Networks",
          "justification": "The paper applies PAC-Bayesian bounds to neural networks and discusses improvements in their practical applications.",
          "quote": "We illustrate this behavior on neural networks, and we show a significant practical improvement over the state-of-the-art framework."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Generalization Bounds",
          "justification": "The focus of the research is on developing and deriving new generalization bounds within the PAC-Bayesian framework.",
          "quote": "We derive new tight and usable disintegrated PAC-Bayesian bounds (i) that directly derandomize any classifiers without any other additional step and with almost no impact on the guarantee."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Neural Networks",
          "justification": "The paper discusses the evaluation of the proposed PAC-Bayesian framework on neural networks.",
          "quote": "We illustrate the practical usefulness of this disintegration on deterministic neural networks."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The paper contributes a new framework that can be applied to train and evaluate neural networks more efficiently.",
          "quote": "We introduce new PAC-Bayesian generalization bounds that have the originality to provide disintegrated bounds."
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments on neural networks would have utilized computational resources such as GPUs or CPUs for model training and evaluation.",
          "quote": "We performed our experimental study on three datasets: MNIST, Fashion-MNIST, and CIFAR-10."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the proposed method with existing state-of-the-art frameworks for practical improvements.",
          "quote": "We illustrate the practical usefulness of this disintegration on deterministic neural networks in Section 5."
        },
        "referenced_paper_title": {
          "value": "Not Provided",
          "justification": "The paper does not specify a particular reference paper for the neural network model used.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is one of the datasets used to evaluate the proposed PAC-Bayesian framework.",
          "quote": "We perform our experimental study on three datasets: MNIST, Fashion-MNIST, and CIFAR-10."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The MNIST dataset of handwritten digits",
          "justification": "This is the standard reference for the MNIST dataset.",
          "quote": "LeCun, Y., Cortes, C., & Burges, C. (1998). The MNIST dataset of handwritten digits."
        }
      },
      {
        "name": {
          "value": "Fashion-MNIST",
          "justification": "Fashion-MNIST is another dataset utilized for the experimental evaluation.",
          "quote": "We perform our experimental study on three datasets: MNIST, Fashion-MNIST, and CIFAR-10."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms",
          "justification": "This is the standard reference for the Fashion-MNIST dataset.",
          "quote": "Xiao, H., Rasul, K., & Vollgraf, R. (2017). Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms."
        }
      },
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is the third dataset used for evaluating the proposed methods.",
          "quote": "We perform our experimental study on three datasets: MNIST, Fashion-MNIST, and CIFAR-10."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "This is the standard reference for the CIFAR-10 dataset.",
          "quote": "Krizhevsky, A. (2009). Learning multiple layers of features from tiny images."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1289,
    "prompt_tokens": 89289,
    "total_tokens": 90578
  }
}