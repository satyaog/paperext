{
  "paper": "BTOBu7y2ZD.txt",
  "words": 3738,
  "extractions": {
    "title": {
      "value": "Channel Selection for Test-Time Adaptation Under Distribution Shift",
      "justification": "The information comes directly from the provided research paper.",
      "quote": "Channel Selection for Test-Time Adaptation Under Distribution Shift"
    },
    "description": "The paper discusses techniques to address the problem of label distribution shift in test-time adaptation (TTA), particularly with the use of batch normalization. The authors propose a method that selectively adapts channels in the network to improve model robustness.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes experiments and results demonstrating the performance of the proposed method on benchmark datasets.",
      "quote": "We use two popular benchmarks datasets in our evaluations: CIFAR-10-C and ImageNet-1K-C."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The research focuses on improving robustness and generalization of deep learning models through test-time adaptation techniques.",
        "quote": "To ensure robustness and generalization to real-world scenarios, test-time adaptation has been recently studied as an approach to adjust models to a new data distribution during inference."
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The paper evaluates the proposed method on benchmark datasets that are commonly used in Computer Vision research.",
          "quote": "We use two popular benchmarks datasets in our evaluations: CIFAR-10-C and ImageNet-1K-C."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Resnet-26",
          "justification": "The paper specifically mentions training a Resnet-26 model for experiments.",
          "quote": "On CIFAR-10 we train a Resnet-26 model as defined in [23]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Resnet-26 is not introduced as a new model in this paper; it is used for evaluation purposes.",
          "quote": "On CIFAR-10 we train a Resnet-26 model as defined in [23]."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was trained and executed as part of the experiments mentioned in the paper.",
          "quote": "On CIFAR-10 we train a Resnet-26 model as defined in [23]."
        },
        "is_compared": {
          "value": true,
          "justification": "The model's performance is compared with other models and baselines in the scope of the paper.",
          "quote": "Adapted models significantly improve the performance compared to the baseline models and counteract unknown label shifts."
        },
        "referenced_paper_title": {
          "value": "Deep residual learning for image recognition",
          "justification": "The referenced paper by Kaiming He et al., which introduced ResNet, is quoted in the research paper.",
          "quote": "Resnet-26 model as defined in [23]"
        }
      },
      {
        "name": {
          "value": "Resnet-18",
          "justification": "The paper mentions using a pre-trained Resnet-18 model for experiments.",
          "quote": "For ImageNet-1K we use a pre-trained Resnet18 model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Resnet-18 is not a new contribution; it is an existing model used in their experiments.",
          "quote": "For ImageNet-1K we use a pre-trained Resnet18 model."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed as part of the experiments described in the paper.",
          "quote": "For ImageNet-1K we use a pre-trained Resnet18 model."
        },
        "is_compared": {
          "value": true,
          "justification": "The model's performance is compared with other models and baselines in the scope of the paper.",
          "quote": "Adapted models significantly improve the performance compared to the baseline models and counteract unknown label shifts."
        },
        "referenced_paper_title": {
          "value": "Deep residual learning for image recognition",
          "justification": "The referenced paper by Kaiming He et al., which introduced ResNet, is quoted in the research paper.",
          "quote": "Resnet-26 model as defined in [23]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The research paper explicitly mentions the use of the CIFAR-10 dataset for its experiments.",
          "quote": "We use the CIFAR-10 [20] dataset along with CIFAR-10-C."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper by Alex Krizhevsky et al., which introduced CIFAR-10, is quoted in the research paper.",
          "quote": "We use the CIFAR-10 [20] dataset along with CIFAR-10-C."
        }
      },
      {
        "name": {
          "value": "CIFAR-10-C",
          "justification": "The research paper explicitly mentions the use of the CIFAR-10-C dataset for its experiments.",
          "quote": "We use the CIFAR-10 [20] dataset along with CIFAR-10-C."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking neural network robustness to common corruptions and perturbations",
          "justification": "The referenced paper by Dan Hendrycks and Thomas Dietterich, which introduced CIFAR-10-C, is quoted in the research paper.",
          "quote": "We use the CIFAR-10 [20] dataset along with CIFAR-10-C."
        }
      },
      {
        "name": {
          "value": "ImageNet-1K",
          "justification": "The research paper explicitly mentions the use of the ImageNet-1K dataset for its experiments.",
          "quote": "We use the ImageNet-1K [22] dataset along with ImageNet-1K-C."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "The referenced paper by Jia Deng et al., which introduced ImageNet, is quoted in the research paper.",
          "quote": "We use the ImageNet-1K [22] dataset along with ImageNet-1K-C."
        }
      },
      {
        "name": {
          "value": "ImageNet-1K-C",
          "justification": "The research paper explicitly mentions the use of the ImageNet-1K-C dataset for its experiments.",
          "quote": "We use the ImageNet-1K [22] dataset along with ImageNet-1K-C."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking neural network robustness to common corruptions and perturbations",
          "justification": "The referenced paper by Dan Hendrycks and Thomas Dietterich, which introduced ImageNet-1K-C, is quoted in the research paper.",
          "quote": "We use the ImageNet-1K [22] dataset along with ImageNet-1K-C."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2698,
    "prompt_tokens": 18521,
    "total_tokens": 21219
  }
}