{
  "paper": "beHp3L9KXc.txt",
  "words": 8296,
  "extractions": {
    "title": {
      "value": "Better Training of GFlowNets with Local Credit and Incomplete Trajectories",
      "justification": "This is the title as stated at the beginning of the paper and in the footer on every page.",
      "quote": "Better Training of GFlowNets with Local Credit and Incomplete Trajectories"
    },
    "description": "The paper proposes and investigates a new methodology for training Generative Flow Networks (GFlowNets) called Forward-looking GFlowNets (FL-GFN). It focuses on improving the training efficiency and credit assignment by utilizing a per-state or per-transition energy function, enabling learning from incomplete trajectories and boosting convergence speed.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts extensive experiments including set generation, bit sequence generation, and molecule discovery to demonstrate the effectiveness of the proposed methodology, thus making it empirical.",
      "quote": "We conducted extensive experiments to demonstrate the effectiveness of FL-GFN, which can scale to complex and challenging tasks, such as molecular graph generation."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The research centers around Generative Flow Networks (GFlowNets), which are variants of reinforcement learning methods.",
        "quote": "Generative Flow Networks (GFlowNets) (Bengio et al., 2021a;b) are variants of reinforcement learning (RL) methods (Sutton & Barto, 2018)..."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "GFlowNets are related to generative models as they learn to represent and sample from a distribution.",
          "quote": "They are also related to generative models (Kingma & Welling, 2013; Goodfellow et al., 2014; 2016; Ho et al., 2020) as they learn to represent and sample from a distribution..."
        },
        "aliases": [
          "Generative Modeling"
        ]
      },
      {
        "name": {
          "value": "Monte-Carlo Methods",
          "justification": "GFlowNets have relationships to Monte-Carlo Markov chain methods because they sample from a distribution specified by an energy function.",
          "quote": "GFlowNets are related to MCMC methods (Metropolis et al., 1953; Hastings, 1970; Andrieu et al., 2003) that approximately sample from a distribution associated with a given energy function..."
        },
        "aliases": [
          "MCMC"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Forward-Looking GFlowNets (FL-GFN)",
          "justification": "Forward-Looking GFlowNets (FL-GFN) is the new model proposed and investigated in this paper.",
          "quote": "We propose Forward-Looking GFlowNets (FL-GFN), a novel formulation that exploits the ability to compute an energy value (even if incomplete) for intermediate states..."
        },
        "aliases": [
          "FL-GFN"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "FL-GFN is introduced and developed within this paper.",
          "quote": "We propose Forward-Looking GFlowNets (FL-GFN), a novel formulation..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is executed as part of the extensive experiments conducted in the paper, including tests on set generation, bit sequence generation, and molecule discovery.",
          "quote": "We conducted extensive experiments to demonstrate the effectiveness of FL-GFN, which can scale to complex and challenging tasks."
        },
        "is_compared": {
          "value": 1,
          "justification": "FL-GFN is compared numerically against DB (Detailed Balance), TB (Trajectory Balance), and SubTB (Sub-trajectory Balance) models in various experimental setups.",
          "quote": "The first column in Figure 2 demonstrates the quality of generated sets in the set generation task with different problem sizes including small, medium, and large in each row. As shown, the forward-looking approach significantly outperforms previous baselines including DB, TB, and SubTB in training efficiency and quality of the solutions..."
        },
        "referenced_paper_title": {
          "value": "GFlowNet foundations",
          "justification": "The concept is based on the GFlowNet framework, foundations of which are detailed in 'GFlowNet foundations'",
          "quote": "GFlowNets... as noted by Malkin et al. (2022a), Madan et al. (2022) and the GFlowNet foundations by Bengio (2021b)."
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The implementation and training of the models likely involve PyTorch, given its extensive use in machine learning research and the advanced capabilities required for the experiments described.",
          "quote": "The model is trained based on the Adam (Kingma & Ba, 2015) optimizer with a learning rate of 0.001 for DB, SubTB, and FL-DB, where we use a larger learning rate of 0.1 for the learnable parameter Z for TB following (Malkin et al., 2022a)"
        },
        "aliases": [
          "torch",
          "pytorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A method for stochastic optimization",
          "justification": "The Adam Optimizer, central to the training process, is detailed in this referenced paper.",
          "quote": "The model is trained based on the Adam (Kingma & Ba, 2015) optimizer with a learning rate of 0.001 for DB, SubTB, and FL-DB, where we use a larger learning rate of 0.1 for the learnable parameter Z for TB following (Malkin et al., 2022a)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1337,
    "prompt_tokens": 14682,
    "total_tokens": 16019
  }
}