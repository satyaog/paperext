{
  "paper": "2212.06079.txt",
  "words": 11869,
  "extractions": {
    "title": {
      "value": "Robust Perception through Equivariance",
      "justification": "Based on the content and objectives described in the abstract and the detailed methodology of the paper.",
      "quote": "Robust Perception through Equivariance"
    },
    "description": "This paper proposes a framework that introduces dense intrinsic constraints in natural images during inference to shift the burden of robustness from training to testing. The method leverages equivariance to enhance the robustness of models against adversarial examples by restoring feature equivariance during inference.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes empirical experiments to test the proposed framework's effectiveness against adversarial attacks, as well as theoretical analysis to support their claims.",
      "quote": "Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper focuses on improving robustness in visual models, specifically in tasks like image recognition, semantic segmentation, and instance segmentation.",
        "quote": "state-of-the-art systems are not reliable when evaluated in open-world settings (Geirhos et al., 2019; Hendrycks et al., 2021; Szegedy et al., 2013; Hendrycks \\, Dietterich, 2019; Croce \\ Hein, 2020; Carlini \\ Wagner, 2017)."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Adversarial Robustness",
          "justification": "The paper concentrates on increasing the robustness of models against adversarial attacks through the concept of equivariance at inference time.",
          "quote": "By introducing constraints at inference time, we can shift the burden of robustness from training to testing, thereby allowing the model to dynamically adjust to each individual imageâ€™s unique and potentially novel characteristics at inference time."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet50",
          "justification": "The ResNet50 model is mentioned as part of the study's context on the strong performance of deep networks on computer vision benchmarks.",
          "quote": "Despite the strong performance of deep networks on computer vision benchmarks (He et al., 2016)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DRN-22-d",
          "justification": "The DRN-22-d model is explicitly mentioned as being used for semantic segmentation in the Cityscapes dataset.",
          "quote": "We adversarially train a segmentation model and evaluate it in Table 1, which is measured with mean Intersection over Union (mIoU) for semantic segmentation."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Mask R-CNN",
          "justification": "Mask R-CNN is explicitly mentioned as used for semantic and instance segmentation tasks on the COCO dataset.",
          "quote": "We use pretrained DeeplabV3 and MaskRCNN for semantic segmentation and instance segmentation, respectively."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is mentioned as one of the datasets used for evaluating the proposed framework.",
          "quote": "Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Cityscapes",
          "justification": "Cityscapes is explicitly mentioned as one of the datasets used for semantic segmentation tasks.",
          "quote": "Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "PASCAL VOC",
          "justification": "PASCAL VOC is another dataset mentioned as used for semantic segmentation tasks in the evaluation.",
          "quote": "Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "MS-COCO",
          "justification": "MS-COCO is explicitly mentioned as used for both semantic and instance segmentation tasks in the evaluation.",
          "quote": "Our empirical experiments show that restoring feature equivariance at inference time defends against worst-case adversarial perturbations. The method obtains improved adversarial robustness on four datasets (ImageNet, Cityscapes, PASCAL VOC, and MS-COCO) on image recognition, semantic segmentation, and instance segmentation tasks."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "SimCLR",
          "justification": "SimCLR is mentioned as part of the contrastive invariance baseline in the empirical evaluation.",
          "quote": "Contrastive defense (Mao et al., 2021) restores the intrinsic structure of the image using SimCLR (Chen et al., 2020) objective at inference time, which achieves state-of-the-art adversarial robustness on image recognition tasks."
        },
        "aliases": [],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1255,
    "prompt_tokens": 20521,
    "total_tokens": 21776
  }
}