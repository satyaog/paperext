{
  "paper": "2106.05410.txt",
  "words": 9456,
  "extractions": {
    "title": {
      "value": "DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection",
      "justification": "This is the title mentioned at the beginning of the paper.",
      "quote": "DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection"
    },
    "description": "The paper proposes DASVDD, a novel one-class anomaly detection method that combines deep autoencoders with support vector data descriptors to improve robustness and prevent the hypersphere collapse problem commonly found in similar methods. The performance of DASVDD is evaluated on various benchmark datasets, showing its superiority over several state-of-the-art algorithms.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts an extensive experimental evaluation of the DASVDD method on several datasets to demonstrate its performance.",
      "quote": "We present extensive experiments of DASVDD on the benchmark datasets and compare its performance against state-of-the-art algorithms."
    },
    "primary_research_field": {
      "name": {
        "value": "Anomaly Detection",
        "justification": "The main focus of the paper is on proposing a novel method for anomaly detection and evaluating its performance.",
        "quote": "Anomaly detection (AD) is the task of identifying samples of a dataset that deviate from the ”normal” pattern."
      },
      "aliases": [
        "AD"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The proposed method DASVDD leverages deep learning techniques, particularly autoencoders, to perform anomaly detection.",
          "quote": "In this paper, we propose a novel anomaly detection algorithm inspired by DSVDD and Autoencoders."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Support Vector Data Descriptor",
          "justification": "The DASVDD method introduces a combination of deep autoencoders and Support Vector Data Descriptor (SVDD) techniques to enhance anomaly detection capabilities.",
          "quote": "We propose a method, DASVDD, that jointly learns the parameters of an autoencoder while minimizing the volume of an enclosing hypersphere on its latent representation."
        },
        "aliases": [
          "SVDD"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "DASVDD",
          "justification": "DASVDD is the novel model introduced in this paper to address anomaly detection.",
          "quote": "In this paper, we propose a novel anomaly detection algorithm inspired by DSVDD and Autoencoders. Our method, deep autoencoding support vector data descriptor (DASVDD), trains an autoencoder instead of a vanilla neural network by simultaneously minimizing the volume of the enclosing hypersphere in the learned latent representation of the encoder and the reconstruction error of the decoder’s output."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The paper introduces DASVDD as the new method for anomaly detection.",
          "quote": "In this paper, we propose a novel anomaly detection algorithm inspired by DSVDD and Autoencoders. Our method, deep autoencoding support vector data descriptor (DASVDD)..."
        },
        "is_executed": {
          "value": true,
          "justification": "The experimental evaluation of DASVDD included implementations executed on computational resources indicating the use of GPUs.",
          "quote": "All experiments were implemented in Python using the PyTorch framework. All codes are run on Google Colaboratory GPU (Tesla K80) with 12GB"
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares DASVDD with several state-of-the-art anomaly detection models, demonstrating its superiority.",
          "quote": "The effective performance of DASVDD on these datasets shows the robustness of the proposed method across a wide variety of anomaly detection applications."
        },
        "referenced_paper_title": {
          "value": "Deep autoencoding support vector data descriptor (DASVDD)",
          "justification": "This model is a novel contribution of the current paper and is not referenced from a different paper.",
          "quote": "Deep autoencoding support vector data descriptor (DASVDD), trains an autoencoder..."
        }
      },
      {
        "name": {
          "value": "OCSVM",
          "justification": "OCSVM is mentioned as one of the baseline comparison models in the evaluation section.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, i.e. one class SVM (OCSVM) [10]..."
        },
        "aliases": [
          "One-Class SVM"
        ],
        "is_contributed": {
          "value": false,
          "justification": "OCSVM is used as a baseline for comparison, not as a contribution of this paper.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, i.e. one class SVM (OCSVM) [10]..."
        },
        "is_executed": {
          "value": false,
          "justification": "OCSVM is referenced as a baseline algorithm, and it's not directly executed within the scope of the paper.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, i.e. one class SVM (OCSVM) [10]..."
        },
        "is_compared": {
          "value": true,
          "justification": "OCSVM is used for performance comparison with DASVDD.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, i.e. one class SVM (OCSVM) [10]..."
        },
        "referenced_paper_title": {
          "value": "Support vector method for novelty detection",
          "justification": "This title corresponds to the main reference paper associated with One-class SVM (OCSVM).",
          "quote": "B. Schölkopf, R. Williamson, A. Smola, J. Shawe-Taylor, and J. Platt, Support vector method for novelty detection..."
        }
      },
      {
        "name": {
          "value": "DAGMM",
          "justification": "DAGMM is mentioned as one of the state-of-the-art deep anomaly detection algorithms used for comparison.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, ... as well as eight state-of-the-art deep anomaly detection algorithms, i.e. deep autoencoder (AE) [13], deep variational autoencoder (VAE) [25], deep autoencoding Gaussian mixture model (DAGMM) [48], ..."
        },
        "aliases": [
          "Deep Autoencoding Gaussian Mixture Model"
        ],
        "is_contributed": {
          "value": false,
          "justification": "DAGMM is used as a baseline for comparison, not as a contribution of this paper.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, ... as well as eight state-of-the-art deep anomaly detection algorithms, i.e. deep autoencoder (AE) [13], deep variational autoencoder (VAE) [25], deep autoencoding Gaussian mixture model (DAGMM) [48], ..."
        },
        "is_executed": {
          "value": false,
          "justification": "DAGMM is referenced as a baseline algorithm, and it's not directly executed within the scope of the paper.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, ... as well as eight state-of-the-art deep anomaly detection algorithms, i.e. deep autoencoder (AE) [13], deep variational autoencoder (VAE) [25], deep autoencoding Gaussian mixture model (DAGMM) [48], ..."
        },
        "is_compared": {
          "value": true,
          "justification": "DAGMM is used for performance comparison with DASVDD.",
          "quote": "We compare performance of DASVDD against three commonly-used traditional baselines, ... as well as eight state-of-the-art deep anomaly detection algorithms, i.e. deep autoencoder (AE) [13], deep variational autoencoder (VAE) [25], deep autoencoding Gaussian mixture model (DAGMM) [48], ..."
        },
        "referenced_paper_title": {
          "value": "Deep autoencoding Gaussian mixture model for unsupervised anomaly detection",
          "justification": "This title corresponds to the main reference paper associated with DAGMM.",
          "quote": "B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and H. Chen, `Deep autoencoding Gaussian mixture model for unsupervised anomaly detection'..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is one of the benchmark datasets used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include three computer vision datasets... (1) MNIST [42] which consists of 70,000 28×28 handwritten digits monochrome images."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "MNIST handwritten digit database",
          "justification": "Refers to the creator and main repository of the MNIST dataset.",
          "quote": "Y. LeCun and C. Cortes, `MNIST handwritten digit database,' Online, 2010."
        }
      },
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is one of the benchmark datasets used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include... four datasets from other domains, including ... speech, ... (2) CIFAR10 [43] which consists of 60,000 color images of size 32 × 32 from 10 different objects."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "CIFAR-10 (Canadian Institute for Advanced Research)",
          "justification": "Refers to the main repository and description of the CIFAR-10 dataset.",
          "quote": "A. Krizhevsky, V. Nair, and G. Hinton, `CIFAR-10 (Canadian Institute for Advanced Research),' Online, 2009."
        }
      },
      {
        "name": {
          "value": "Fashion MNIST (FMNIST)",
          "justification": "Fashion-MNIST is one of the benchmark datasets used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include three computer vision datasets... (3) Fashion MNIST (FMNIST) [44] which has 70,000 grey scale images of size 28 × 28 from 10 fashion products."
        },
        "aliases": [
          "FMNIST"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms",
          "justification": "Refers to the original paper introducing the Fashion-MNIST dataset.",
          "quote": "H. Xiao, K. Rasul, and R. Vollgraf, `Fashion-MNIST: A novel image dataset for benchmarking machine learning algorithms,' arXiv preprint arXiv:1708.07747, 2017."
        }
      },
      {
        "name": {
          "value": "ODDS Speech",
          "justification": "ODDS Speech is one of the benchmark datasets used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include... (4) ODDS Speech [45] which contains 3,686 segments of English speech spoken with different accents where segments are represented by a 400-dimensional feature vector called I-vector."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning outlier ensembles: The best of both worlds - supervised and unsupervised",
          "justification": "This title corresponds to the main reference paper associated with the ODDS Speech dataset.",
          "quote": "B. Micenková, B. McWilliams, and I. Assent, `Learning outlier ensembles: The best of both worlds - supervised and unsupervised,' arXiv preprint arXiv:1403.0192, 2014."
        }
      },
      {
        "name": {
          "value": "PIMA",
          "justification": "PIMA (a subset of the Pima Indians diabetes dataset) is one of the benchmark datasets used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include... (5) PIMA [46], which is included in the ODDS repository and is a subset of the 'Pima Indians diabetes dataset' of the UCI repository."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "UCI Machine Learning Repository",
          "justification": "Refers to the main repository containing the PIMA dataset.",
          "quote": "A. Asunción and D. Newman, 'UCI Machine Learning Repository,' UCI Repository, 2007."
        }
      },
      {
        "name": {
          "value": "AWID 3",
          "justification": "AWID 3 is one of the benchmark datasets used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include... an intrusion detection dataset (AWID 3) [39], which concentrates on WPA2-Enterprise and Protected Management Frames (PMF)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Empirical evaluation of attacks against IEEE 802.11 enterprise networks: The AWID3 dataset",
          "justification": "Refers to the paper describing the AWID 3 dataset.",
          "quote": "E. Chatzoglou, G. Kambourakis, and C. Kolias, 'Empirical evaluation of attacks against IEEE 802.11 enterprise networks: The AWID3 dataset,' IEEE Access, vol. 9, pp. 34 188–34 205, 2021."
        }
      },
      {
        "name": {
          "value": "MIMII",
          "justification": "MIMII dataset containing actual acoustic samples is used to evaluate the performance of DASVDD.",
          "quote": "The benchmark datasets include... (7) MIMII [40] comprises actual acoustic samples that are utilized for identifying faulty industrial equipment."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "MIMII dataset: Sound dataset for malfunctioning industrial machine investigation and inspection",
          "justification": "Refers to the main reference paper describing the MIMII dataset.",
          "quote": "H. Purohit, R. Tanabe, T. Ichige, et al., 'MIMII dataset: Sound dataset for malfunctioning industrial machine investigation and inspection,' in Proceedings of the Detection and Classification of Acoustic Scenes and Events 2019 Workshop (DCASE2019), New York University, NY, USA, October 2019, pp. 209–213."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The implementation of DASVDD and its evaluations are conducted using the PyTorch framework.",
          "quote": "All algorithms were implemented in Python using the PyTorch framework."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "The paper does not reference a specific publication for the PyTorch library.",
          "quote": "All algorithms were implemented in Python using the PyTorch framework."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3516,
    "prompt_tokens": 17650,
    "total_tokens": 21166
  }
}