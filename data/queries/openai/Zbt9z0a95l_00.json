{
  "paper": "Zbt9z0a95l.txt",
  "words": 12787,
  "extractions": {
    "title": {
      "value": "Piecewise Linear Parametrization of Policies for Interpretable Deep Reinforcement Learning",
      "justification": "This is the exact title as given in the provided research paper, which clearly states the main focus of the study on Deep Reinforcement Learning.",
      "quote": "Piecewise Linear Parametrization of Policies for Interpretable Deep Reinforcement Learning"
    },
    "description": "This paper proposes a novel interpretable neural network architecture for deep reinforcement learning named HyperCombinator (HC). It introduces piecewise linear policies to retain interpretability while maintaining competitive performance compared to traditional neural network models. The paper includes both theoretical justifications and empirical evaluations across various control and navigation tasks.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper provides empirical evaluations of the proposed HyperCombinator model on multiple control and navigation tasks, quantifying performance and interpretability trade-offs.",
      "quote": "We evaluate HC policies in control and navigation experiments, visualize the improved interpretability of the agent and highlight its trade-off with performance."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Reinforcement Learning",
        "justification": "The main focus of the paper is on reinforcement learning, specifically employing piecewise-linear policies for improved interpretability in deep reinforcement learning tasks.",
        "quote": "Deep reinforcement learning (DRL) is a particularly interesting domain in which to study interpretability."
      },
      "aliases": [
        "DRL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Interpretable Machine Learning",
          "justification": "The paper emphasizes enhancing interpretability in machine learning models, specifically in the context of deep reinforcement learning.",
          "quote": "Learning inherently interpretable policies is a central challenge in the path to developing autonomous agents that humans can trust."
        },
        "aliases": [
          "Explainable AI",
          "XAI"
        ]
      },
      {
        "name": {
          "value": "Control Systems",
          "justification": "The empirical evaluation includes tests on control tasks, which fall under the field of control systems.",
          "quote": "We evaluate HC policies in control and navigation experiments, visualize the improved interpretability of the agent and highlight its trade-off with performance."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Navigation",
          "justification": "The paper also evaluates the proposed models on navigation tasks, thus contributing to the field of navigation in robotics.",
          "quote": "We further evaluate the model on control and navigation tasks and observe a sustained performance of the model despite its greatly reduced expressivity."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "HyperCombinator",
          "justification": "HyperCombinator (HC) is explicitly introduced and evaluated as a novel neural network architecture in this paper.",
          "quote": "In particular, we propose the HyperCombinator (HC), a piecewise-linear neural architecture expressing a policy with a controllably small number of sub-policies."
        },
        "aliases": [
          "HC"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The HyperCombinator is the main contribution of this paper.",
          "quote": "In particular, we propose the HyperCombinator (HC), a piecewise-linear neural architecture expressing a policy with a controllably small number of sub-policies."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper evaluates the HyperCombinator in various tasks, implying its execution.",
          "quote": "We evaluate HC policies in control and navigation experiments, visualize the improved interpretability of the agent and highlight its trade-off with performance."
        },
        "is_compared": {
          "value": 1,
          "justification": "HyperCombinator is compared to baselines in the experiments, including SAC.",
          "quote": "HC policies approach or match the performance of SAC in most environments."
        },
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "The HyperCombinator is introduced in this paper itself, so no external reference is applicable.",
          "quote": "We propose the HyperCombinator (HC), a piecewise-linear neural architecture."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "DeepMind Control Suite",
          "justification": "The DeepMind Control Suite is prominently used in the control tasks evaluated in this paper.",
          "quote": "We evaluate how well HC policies can control proprioceptive variables such as the joints of a robot through the DeepMind Control Suite benchmark."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deepmind control suite",
          "justification": "This is the referenced paper for the DeepMind Control Suite benchmark used in evaluating HC.",
          "quote": "We evaluate how well HC policies can control proprioceptive variables such as the joints of a robot through the DeepMind Control Suite benchmark [22]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is implicitly used for implementing and training the neural network models, including the HyperCombinator.",
          "quote": "We ran all the experiments on an internal cluster. All the GPUs were NVIDIA Tesla V100, with 16GB memory available."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "No specific reference paper is provided for PyTorch, as it is a commonly known library.",
          "quote": "We ran all the experiments on an internal cluster. All the GPUs were NVIDIA Tesla V100, with 16GB memory available."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1030,
    "prompt_tokens": 21150,
    "total_tokens": 22180
  }
}