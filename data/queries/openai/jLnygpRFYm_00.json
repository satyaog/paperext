{
  "paper": "jLnygpRFYm.txt",
  "words": 6663,
  "extractions": {
    "title": {
      "value": "Predicting Masked Tokens in Stochastic Locations Improves Masked Image Modeling",
      "justification": "This is the title of the paper mentioned at the beginning",
      "quote": "P REDICTING MASKED TOKENS IN STOCHASTIC LOCA TIONS IMPROVES MASKED IMAGE MODELING"
    },
    "description": "This paper proposes the use of Stochastic Positional embeddings (StoP) in Masked Image Modeling (MIM) to address the issue of location uncertainty. By incorporating StoP, the model learns features that are more robust to location uncertainties, leading to improved performance on various downstream tasks.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents empirical results showing the improved performance of the proposed method on various downstream tasks.",
      "quote": "Quantitatively, using StoP improves downstream MIM performance on a variety of downstream tasks. For example, linear probing on ImageNet using ViT-B is improved by +1.7%, and by 2.5% for ViT-H using 1% of the data."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper deals with Masked Image Modeling, which is a sub-field of Computer Vision.",
        "quote": "Masked Image Modeling (MIM) enables learning from unlabeled images by reconstructing masked parts of the image given the rest of the image as context."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper focuses on Masked Image Modeling, a self-supervised learning approach.",
          "quote": "Masked Image Modeling (MIM) is a promising self-supervised learning approach that enables learning from unlabeled images."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "StoP (Stochastic Positional Embeddings)",
          "justification": "The proposed model is called Stochastic Positional embeddings (StoP).",
          "quote": "First, we propose the idea of Stochastic Positional embeddings (StoP) and apply it to MIM to address the location uncertainty in MIM."
        },
        "aliases": [
          "StoP"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "This model is proposed in the paper.",
          "quote": "First, we propose the idea of Stochastic Positional embeddings (StoP) and apply it to MIM to address the location uncertainty in MIM."
        },
        "is_executed": {
          "value": 1,
          "justification": "Execution details and performance metrics are provided in the paper indicating it was executed.",
          "quote": "We show that using StoP reduces overfitting to location features and guides the model toward learning features that are more robust to location uncertainties."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance is compared with existing Masked Image Modeling methods like MAE and I-JEPA.",
          "quote": "In this work, we propose to incorporate location uncertainty to MIM by using stochastic positional embeddings (StoP). Specifically, we condition the model on stochastic masked token positions drawn from a gaussian distribution."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "This model is proposed in the current paper.",
          "quote": "In this work, we propose to incorporate location uncertainty to MIM by using stochastic positional embeddings (StoP)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet (IN-1k)",
          "justification": "The dataset ImageNet (IN-1k) is used for linear probing to evaluate the performance of the proposed model.",
          "quote": "For image classification, we evaluated the StoP model linear probing performance on multiple datasets, including ImageNet (IN-1k) (Russakovsky et al., 2015)"
        },
        "aliases": [
          "IN-1k"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet large scale visual recognition challenge",
          "justification": "This is the referenced paper for the ImageNet dataset.",
          "quote": "For image classification, we evaluated the StoP model linear probing performance on multiple datasets, including ImageNet (IN-1k) (Russakovsky et al., 2015)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The library used for implementation is mentioned in the context of the VISSL framework, which is based on PyTorch.",
          "quote": "Our models are implemented in the VISSL library (Goyal et al., 2021), based on PyTorch"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Vissl",
          "justification": "PyTorch is mentioned in the context of the VISSL framework.",
          "quote": "Our models are implemented in the VISSL library (Goyal et al., 2021), based on PyTorch"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1840,
    "prompt_tokens": 26501,
    "total_tokens": 28341
  }
}