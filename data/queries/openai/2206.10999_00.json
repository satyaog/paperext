{
  "paper": "2206.10999.txt",
  "words": 11367,
  "extractions": {
    "title": {
      "value": "Neural Networks as Paths of Representations Through the Space",
      "justification": "The title of the paper is clearly indicated at the beginning.",
      "quote": "NEURAL NETWORKS AS PATHS OF REPRESENTATIONS THROUGH THE SPACE"
    },
    "description": "This paper presents a geometric framework for interpreting the layer-by-layer operations of deep neural networks as spatial paths through high-dimensional representation space. The authors extend existing representational distance methods to compute geodesics, angles, and projections of representations. They use this framework to visualize and compare the paths taken by ResNet and VGG architectures on the CIFAR-10 dataset and discuss the implications for understanding network training and model comparisons.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes experiments, visualizations, and empirical comparisons between different neural network architectures.",
      "quote": "We then demonstrate these tools by visualizing and comparing the paths taken by ResNet and VGG architectures on CIFAR-10."
    },
    "primary_research_field": {
      "name": {
        "value": "Neural Network Interpretability",
        "justification": "The primary focus of the paper is on interpreting neural networks using a geometric framework.",
        "quote": "We consider a simple hypothesis for interpreting the layer-by-layer construction of useful representations."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Metric Learning",
          "justification": "The paper extends existing representational distance methods and introduces new metrics for understanding neural networks.",
          "quote": "We extend existing representational distance methods by computing geodesics, angles, and projections of representations."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Visualization",
          "justification": "The paper provides visualizations of representational paths and geometric properties of neural networks.",
          "quote": "We create novel visualizations of how representations are transformed through the layers of deep networks."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Neural Network Architectures",
          "justification": "The paper compares different neural network architectures (ResNet and VGG) using the proposed geometric framework.",
          "quote": "We apply these techniques to compare paths taken by wide and deep residual networks, as well as four VGG architectures, all trained on CIFAR-10."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet",
          "justification": "The paper includes experiments and visualizations using the ResNet architecture.",
          "quote": "We then demonstrate these tools by visualizing and comparing the paths taken by ResNet and VGG architectures on CIFAR-10."
        },
        "aliases": [
          "Residual Network"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ResNet is not introduced by this paper but is used for experiments.",
          "quote": "We then demonstrate these tools by visualizing and comparing the paths taken by ResNet and VGG architectures on CIFAR-10."
        },
        "is_executed": {
          "value": 1,
          "justification": "The ResNet models are executed as part of the experiments.",
          "quote": "We visualize and compare the paths taken by ResNet on CIFAR-10."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares ResNet to VGG and analyzes differences.",
          "quote": "We compare paths taken by wide and deep residual networks, as well as four VGG architectures, all trained on CIFAR-10."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "The referenced paper for ResNet is commonly known to be He et al., 2016.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "VGG",
          "justification": "The paper includes experiments and visualizations using the VGG architecture.",
          "quote": "We then demonstrate these tools by visualizing and comparing the paths taken by ResNet and VGG architectures on CIFAR-10."
        },
        "aliases": [
          "Very Deep Convolutional Networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "VGG is not introduced by this paper but is used for experiments.",
          "quote": "We then demonstrate these tools by visualizing and comparing the paths taken by ResNet and VGG architectures on CIFAR-10."
        },
        "is_executed": {
          "value": 1,
          "justification": "The VGG models are executed as part of the experiments.",
          "quote": "We visualize and compare the paths taken by VGG on CIFAR-10."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares VGG to ResNet and analyzes differences.",
          "quote": "We compare paths taken by wide and deep residual networks, as well as four VGG architectures, all trained on CIFAR-10."
        },
        "referenced_paper_title": {
          "value": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
          "justification": "The referenced paper for VGG is commonly known to be Simonyan and Zisserman, 2014.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The dataset used in the experiments is explicitly stated.",
          "quote": "We demonstrate these tools by visualizing and comparing the paths taken by ResNet and VGG architectures on CIFAR-10."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper for CIFAR-10 is commonly known to be Krizhevsky, 2009.",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The experiments are mentioned to be conducted using PyTorch.",
          "quote": "We trained a collection of convolutional networks... using PyTorch"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "This is the commonly referenced paper for PyTorch.",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2564,
    "prompt_tokens": 41417,
    "total_tokens": 43981
  }
}