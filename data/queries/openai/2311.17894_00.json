{
  "paper": "2311.17894.txt",
  "words": 7041,
  "extractions": {
    "title": {
      "value": "Learning and Controlling Silicon Dopant Transitions in Graphene using Scanning Transmission Electron Microscopy",
      "justification": "Title as extracted from the document",
      "quote": "Learning and Controlling Silicon Dopant\nTransitions in Graphene using Scanning\nTransmission Electron Microscopy"
    },
    "description": "This paper introduces a machine learning approach to determine the transition dynamics of silicon atoms on a single layer of carbon atoms when stimulated by the electron beam of a scanning transmission electron microscope (STEM). The method uses data-centric techniques to predict transition probabilities and automates the manipulation of silicon atoms.",
    "type": {
      "value": "Empirical study",
      "justification": "The study provides empirical analyses to demonstrate the efficacy and generality of the machine learning approach.",
      "quote": "We present empirical analyses that demonstrate the efficacy and generality of our approach."
    },
    "primary_research_field": {
      "name": {
        "value": "Nano-Technology",
        "justification": "The primary research field focuses on the manipulation of atoms using electron microscopy, which is a subfield of nanotechnology.",
        "quote": "Microscopy, Machine Learning"
      },
      "aliases": [
        "Nanotechnology"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Learning",
          "justification": "The study introduces a machine learning approach for predicting the transition dynamics of silicon atoms.",
          "quote": "Our work is a robust first step for determining transition probabilities via machine learning"
        },
        "aliases": [
          "ML"
        ]
      },
      {
        "name": {
          "value": "Electron Microscopy",
          "justification": "The research involves the use of Scanning Transmission Electron Microscopy (STEM) for atomic transitions.",
          "quote": "electron beam induced effects (with a STEM) have been studied"
        },
        "aliases": [
          "Microscopy"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Deep Ensemble Neural Networks",
          "justification": "The model used for identifying atomic species and positions quickly and reliably.",
          "quote": "Given this, atomic coordinates must be known with high confidence in as close to real time as possible, and flexible control of the beam position is needed. This last\nconsideration is addressed by using deep ensemble neural networks to identify the atomic species and positions both quickly and reliably (Ghosh et al, 2021)."
        },
        "aliases": [
          "Ensemble Neural Networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The model was not contributed by the paper but was used for the research.",
          "quote": "deep ensemble neural networks to identify the atomic species and positions both quickly and reliably (Ghosh et al, 2021)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the research to identify atomic positions in real-time.",
          "quote": "atomic coordinates must be known with high confidence in as close to real time as possible"
        },
        "is_compared": {
          "value": 0,
          "justification": "The model was used as-is, and its performance was not compared to other models in this paper.",
          "quote": "This last\nconsideration is addressed by using deep ensemble neural networks to identify the atomic species and positions both quickly and reliably (Ghosh et al, 2021)."
        },
        "referenced_paper_title": {
          "value": "Ensemble learning-iterative training machine learning for uncertainty quantification and automated experiment in atom- resolved microscopy",
          "justification": "Referenced paper for the deep ensemble neural networks used in this study.",
          "quote": "(Ghosh et al, 2021)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Silicon Dopant Transition Dataset",
          "justification": "The dataset is specifically collected for training the model to predict silicon dopant transitions under electron beam stimulation.",
          "quote": "we discard transitions where: (1) There is no recorded beam position (793 examples); (2) There is not exactly one (1) detected dopant atom before and after the transition (4 examples); (3) The dopant does not have the expected number of neighbors (3)\nbefore and after the transition, either because they are absent, indicating non-pristine\ngraphene, or were not detected (3, 593 examples); and (4) the neighbors after the\ntransition did not approximately align with the neighbors before the transition"
        },
        "aliases": [
          "Dopant Transition Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "No referenced paper for the dataset.",
          "quote": "our data collection approach is as follows"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The library used for training the neural network models.",
          "quote": "Given a stack of image observations (o1 , ..., on ), the network is trained to\npredict the drift dn between on−1 and on , as a two-dimensional vector....We parameterized the network as six convolutional layers followed by downsampling, followed\nby a single fully-connected layer."
        },
        "aliases": [
          "Torch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "No specific reference provided for the library.",
          "quote": "Given a stack of image observations (o1 , ..., on ), the network is trained to\npredict the drift dn between on−1 and on , as a two-dimensional vector....We parameterized the network as six convolutional layers followed by downsampling, followed\nby a single fully-connected layer."
        }
      },
      {
        "name": {
          "value": "Adam",
          "justification": "The optimizer used during the training of the neural network models.",
          "quote": "Given the above loss function, we trained a three-layer neural network using Adam\nwith weight decay (Kingma and Ba, 2015) and ReLU hidden layer nonlinearities"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A method for stochastic optimization",
          "justification": "Referenced paper for the Adam optimizer.",
          "quote": "Given the above loss function, we trained a three-layer neural network using Adam\nwith weight decay (Kingma and Ba, 2015)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1175,
    "prompt_tokens": 11895,
    "total_tokens": 13070
  }
}