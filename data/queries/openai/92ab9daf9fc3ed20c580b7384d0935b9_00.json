{
  "paper": "92ab9daf9fc3ed20c580b7384d0935b9.txt",
  "words": 10604,
  "extractions": {
    "title": {
      "value": "PhAST: Physics-Aware, Scalable, and Task-Specific GNNs for Accelerated Catalyst Design",
      "justification": "The title of the research paper is mentioned at the beginning of the document, right after the list of authors and affiliations.",
      "quote": "PhAST: Physics-Aware, Scalable, and Task-Specific GNNs for\nAccelerated Catalyst Design"
    },
    "description": "This paper presents PhAST, a framework of improvements for graph neural networks (GNNs) applied to catalyst discovery. The proposed innovations focus on enhancing computational efficiency and accuracy during the graph creation phase, atom representation, energy prediction, and force prediction, specifically for electrocatalyst design. The work is validated on the OC20 dataset, achieving better performance and increased scalability compared to existing models.",
    "type": {
      "value": "empirical",
      "justification": "The paper provides detailed evaluations and improvements of GNNs on a real-world dataset (OC20) and presents empirical results that demonstrate enhanced performance and scalability of their proposed method, PhAST.",
      "quote": "We provide a broad evaluation of these contributions on OC20 and a thorough ablation study."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper is focused on developing machine learning models (specifically, graph neural networks) for accelerated catalyst design.",
        "quote": "Machine learning (ML) holds the potential to efficiently model materials properties from large amounts of data, accelerating electrocatalyst design."
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Graph Neural Networks",
          "justification": "The research involves innovations in the pipeline of graph neural networks to make them more suitable for catalyst design.",
          "quote": "we propose multiple model improvements to increase the accuracy and scalability of generic GNNs applied to catalyst discovery."
        },
        "aliases": [
          "GNNs"
        ]
      },
      {
        "name": {
          "value": "Catalyst Design",
          "justification": "A significant portion of the paper discusses methods for improving catalysts through machine learning, indicating it as a subfield.",
          "quote": "To reduce the energy spent on such activities, we must quickly discover more efficient catalysts to drive electrochemical reactions."
        },
        "aliases": [
          "Electrocatalyst Design"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GemNet",
          "justification": "GemNet is a model discussed in the context of incorporating PhAST improvements.",
          "quote": "GemNet (Gasteiger et al., 2021) builds on top of DimeNet++, but additionally incorporates torsion information between quadruplets of atoms."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GemNet is not a new model contributed by this paper, but rather an existing model on which PhAST is applied.",
          "quote": "GemNet (Gasteiger et al., 2021) builds on top of DimeNet++."
        },
        "is_executed": {
          "value": true,
          "justification": "GemNet is executed as part of the PhAST framework evaluation on the OC20 dataset.",
          "quote": "We study the enhancements brought by the PhAST components to five key GNN architectures for material modeling: ... GemNet ..."
        },
        "is_compared": {
          "value": true,
          "justification": "GemNet is used as a baseline for comparison with PhAST-enhanced models.",
          "quote": "We study the enhancements brought by the PhAST components to five key GNN architectures for material modeling: ... GemNet ..."
        },
        "referenced_paper_title": {
          "value": "Gemnet: Universal directional graph neural networks for molecules.",
          "justification": "The original paper is cited in reference to describing the GemNet model.",
          "quote": "GemNet (Gasteiger et al., 2021) builds on top of DimeNet++."
        }
      },
      {
        "name": {
          "value": "SchNet",
          "justification": "SchNet is one of the baseline models discussed for applying PhAST improvements.",
          "quote": "SchNet (Schütt et al., 2017) is a simple message passing architecture."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "SchNet is not a new model contributed by this paper but is a known model used for testing the PhAST improvements.",
          "quote": "SchNet (Schütt et al., 2017) is a simple message passing architecture that leverages relative distances to update atom representations."
        },
        "is_executed": {
          "value": true,
          "justification": "SchNet is executed as part of the PhAST framework evaluation on the OC20 dataset.",
          "quote": "We target five well-known GNN baselines to study the impact of our contributions, including ... SchNet ..."
        },
        "is_compared": {
          "value": true,
          "justification": "SchNet is used as a baseline for comparison with PhAST-enhanced models.",
          "quote": "We target five well-known GNN baselines to study the impact of our contributions, including ... SchNet ..."
        },
        "referenced_paper_title": {
          "value": "Schnet: A continuous-filter convolutional neural network for modeling quantum interactions.",
          "justification": "The original paper is cited when describing the baseline model SchNet.",
          "quote": "SchNet (Schütt et al., 2017) is a simple message passing architecture ... leveraging a continuous filter."
        }
      },
      {
        "name": {
          "value": "ForceNet",
          "justification": "ForceNet is one of the GNN models used as a baseline to apply the PhAST improvements.",
          "quote": "ForceNet (Hu et al., 2021) is a scalable force-centric GNN that does not impose explicit physical constraints."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ForceNet is not a new model proposed by this paper; it is used as a pre-existing model for experimentation.",
          "quote": "ForceNet (Hu et al., 2021) is a scalable force-centric GNN."
        },
        "is_executed": {
          "value": true,
          "justification": "ForceNet is executed in the context of evaluating PhAST improvements.",
          "quote": "ForceNet is one of the models evaluated with the PhAST framework for performance improvements."
        },
        "is_compared": {
          "value": true,
          "justification": "ForceNet serves as a baseline model for performance comparison against PhAST-improved models.",
          "quote": "We target five well-known GNN baselines to study the impact of our contributions, including ... ForceNet ..."
        },
        "referenced_paper_title": {
          "value": "Forcenet: A graph neural network for large-scale quantum calculations.",
          "justification": "The paper where ForceNet is originally introduced is cited in relation to its description as a baseline model.",
          "quote": "ForceNet (Hu et al., 2021) is a scalable force-centric GNN that does not impose explicit physical constraints ..."
        }
      },
      {
        "name": {
          "value": "DimeNet++",
          "justification": "DimeNet++ is involved in the study and implementation of PhAST improvements, as it is one of the baselines compared against PhAST models.",
          "quote": "DimeNet++ (Klicpera et al., 2020a) is an optimised version of DimeNet, which proposes a directional message passing."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "DimeNet++ is an existing model on which PhAST enhancements are applied for testing and comparison.",
          "quote": "DimeNet++ (Klicpera et al., 2020a) is an optimised version of DimeNet."
        },
        "is_executed": {
          "value": true,
          "justification": "DimeNet++ is executed as part of the baseline evaluation to assess the efficacy of PhAST.",
          "quote": "We target five well-known GNN baselines to study the impact of our contributions, including ... DimeNet++ ..."
        },
        "is_compared": {
          "value": true,
          "justification": "DimeNet++ is used as a baseline for comparing its performance with PhAST-enhanced models.",
          "quote": "We target five well-known GNN baselines to study the impact of our contributions, including ... DimeNet++ ..."
        },
        "referenced_paper_title": {
          "value": "Fast and uncertainty-aware directional message passing for non-equilibrium molecules.",
          "justification": "The referenced paper provides further details on the DimeNet++ model, explaining its components.",
          "quote": "DimeNet++ (Klicpera et al., 2020a) is an optimised version of DimeNet."
        }
      },
      {
        "name": {
          "value": "GemNet-OC",
          "justification": "GemNet-OC is an improved version of GemNet that is evaluated after applying PhAST improvements.",
          "quote": "GemNet-OC (Gasteiger et al., 2022) is an improved version of GemNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GemNet-OC is an existing model variant used for evaluation and not a new contribution by the paper.",
          "quote": "GemNet-OC is an improved version of GemNet."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not explicitly mention executing GemNet-OC within its experiments, rather it is mentioned as a reference point.",
          "quote": "GemNet-OC is an improved version of GemNet."
        },
        "is_compared": {
          "value": true,
          "justification": "GemNet-OC is referenced as a benchmark or baseline model for comparison purposes.",
          "quote": "GemNet-OC (Gasteiger et al., 2022) is an improved version of GemNet."
        },
        "referenced_paper_title": {
          "value": "GemNet-OC: Developing Graph Neural Networks for Large and Diverse Molecular Simulation Datasets.",
          "justification": "The GemNet-OC model is discussed concerning its improvements over GemNet and cited from its original publication.",
          "quote": "GemNet-OC (Gasteiger et al., 2022) is an improved version of GemNet."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Open Catalyst Project OC20",
          "justification": "The OC20 dataset is used extensively in evaluating the different improvements proposed in PhAST.",
          "quote": "The Open Catalyst Project OC20 dataset was constructed to that end."
        },
        "aliases": [
          "OC20"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Open Catalyst 2020 (OC20) Dataset and Community Challenges",
          "justification": "The dataset is derived from the Open Catalyst Project and the paper articulates its coverage and scope.",
          "quote": "The Open Catalyst Project released OC20 (Chanussot et al., 2021), a large data set of pairs of catalyst and target molecule ..."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Deep Graph Library (DGL)",
          "justification": "The paper mentions using the Deep Graph Library (DGL) as a platform for running GNNs during CPU training experiments.",
          "quote": "Additionally, Miret et al. (2022) utilize the Deep Graph Library (DGL) as the platform for GNN development, which provides an additional proofpoint given that all prior experiments were performed using PyTorch Geometric."
        },
        "aliases": [
          "DGL"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Open Matsci ML Toolkit: A Flexible Framework for Machine Learning in Materials Science",
          "justification": "The paper referenced here discusses the use and application context of the Deep Graph Library (DGL), as utilized in the PhAST paper.",
          "quote": "utilize the Deep Graph Library (DGL) as the platform for GNN development, which provides an additional proofpoint ..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2270,
    "prompt_tokens": 19220,
    "total_tokens": 21490,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}