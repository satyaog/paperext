{
  "paper": "bd491181b04e106ccd17a7529739d3ec.txt",
  "words": 8415,
  "extractions": {
    "title": {
      "value": "Cache-Efﬁcient Dynamic Programming MDP Solver",
      "justification": "This is the title of the paper as stated at the beginning.",
      "quote": "Cache-Efﬁcient Dynamic Programming MDP Solver"
    },
    "description": "The paper proposes two state-reordering techniques for the Topological Value Iteration (TVI) algorithm to improve the cache efficiency of dynamic programming MDP solvers, resulting in new algorithms named eTVI and eiTVI. The empirical results show that these new methods can run several times faster than traditional techniques.",
    "type": {
      "value": "Empirical",
      "justification": "The paper conducts empirical research by proposing new techniques and comparing them through experiments.",
      "quote": "We present our empirical evaluation study in Section 5, where we analyze the cache performance of existing MDP algorithms and show that our novel methods are capable of outperforming them in almost all considered instances."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The research applies machine learning approaches to improve MDP solvers' performance.",
        "quote": "We argue that modifying existing MDP solvers to harness these features could yield substantial performance boosts, mirroring those observed in High-Performance Computing (HPC) [9, 17, 11]. In recent times, Machine Learning (ML) algorithms have seen dramatic performance improvements (across multiple orders of magnitude) by taking into account low-level computer architecture components."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The paper focuses on improving MDP solvers, which are central to reinforcement learning.",
          "quote": "The agent’s decisions are guided by a probabilistic model deﬁning potential outcomes of these actions, which can either be known a priori in the context of automated planning [18], or learned through real-world or simulated experiments in the context of (Model-Based) Reinforcement Learning (RL) [23]."
        },
        "aliases": [
          "RL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Value Iteration",
          "justification": "Value Iteration is used as a baseline method in the paper.",
          "quote": "In general SSP-MDP problems, VI takes a polynomial time on the number of states (it is P-Complete [18])."
        },
        "aliases": [
          "VI"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Value Iteration is an existing method used for comparison.",
          "quote": "In general SSP-MDP problems, VI takes a polynomial time on the number of states (it is P-Complete [18])."
        },
        "is_executed": {
          "value": 1,
          "justification": "Value Iteration is executed and compared with other methods in the empirical evaluation.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "Value Iteration's performance is compared to other models mentioned in the paper.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "referenced_paper_title": {
          "value": "Dynamic Programming and Markov Processes",
          "justification": "This is the reference for the original Value Iteration algorithm.",
          "quote": "Value Iteration (VI) [1]"
        }
      },
      {
        "name": {
          "value": "Labeled Real-Time Dynamic-Programming",
          "justification": "LRTDP is used as one of the baseline methods for empirical comparison.",
          "quote": "Labeled Real-Time Dynamic-Programming (LRTDP) [3]"
        },
        "aliases": [
          "LRTDP"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "LRTDP is an existing method used for comparison.",
          "quote": "Labeled Real-Time Dynamic-Programming (LRTDP) [3]"
        },
        "is_executed": {
          "value": 1,
          "justification": "LRTDP is executed as part of the empirical evaluation.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "LRTDP's performance is compared to other models mentioned in the paper.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "referenced_paper_title": {
          "value": "Labeled RTDP: Improving the Convergence of Real-time Dynamic Programming",
          "justification": "This is the reference for the original LRTDP algorithm.",
          "quote": "Labeled Real-Time Dynamic-Programming (LRTDP) [3]"
        }
      },
      {
        "name": {
          "value": "Improved Learning Algorithm for Optimized Operations",
          "justification": "ILAO* is used as one of the baseline methods for empirical comparison.",
          "quote": "Labeled Real-Time Dynamic-Programming (LRTDP) [3] and LAO* [12]"
        },
        "aliases": [
          "ILAO*"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ILAO* is an existing method used for comparison.",
          "quote": "Labeled Real-Time Dynamic-Programming (LRTDP) [3] and LAO* [12]"
        },
        "is_executed": {
          "value": 1,
          "justification": "ILAO* is executed and benchmarked in the study.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "ILAO*'s performance is compared to other models mentioned in the paper.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "referenced_paper_title": {
          "value": "LAO*: A Heuristic Search Algorithm that Finds Solutions with Loops",
          "justification": "This is the reference for the original ILAO* algorithm.",
          "quote": "LAO* [12]"
        }
      },
      {
        "name": {
          "value": "Topological Value Iteration",
          "justification": "TVI is used as a baseline method and is compared with the new proposed algorithms.",
          "quote": "We propose two state-reordering techniques for the Topological Value Iteration (TVI) algorithm."
        },
        "aliases": [
          "TVI"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "TVI is an existing method used as a reference point.",
          "quote": "We propose two state-reordering techniques for the Topological Value Iteration (TVI) algorithm."
        },
        "is_executed": {
          "value": 1,
          "justification": "TVI is executed as part of the empirical evaluation.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "TVI's performance is directly compared to the new models eTVI and eiTVI.",
          "quote": "Finally, we would need to add multiple new metrics to our study. Since we were limited by the paper length, we decided to present our results using the number of Bellman backups, which might be of greater interest to the AI community and allows us to measure indirectly the cache performance. This way, we can use two criteria (running time and number ..."
        },
        "referenced_paper_title": {
          "value": "Topological Value Iteration Algorithms",
          "justification": "This is the reference for the original TVI algorithm.",
          "quote": "the Topological Value Iteration (TVI) algorithm [8]"
        }
      },
      {
        "name": {
          "value": "Extra-Topological Value Iteration",
          "justification": "eTVI is one of the new algorithms proposed in the paper to improve cache efficiency.",
          "quote": "Our new algorithms, called eTVI and eiTVI, run several times faster than traditional VI, TVI, LRTDP and ILAO* techniques."
        },
        "aliases": [
          "eTVI"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "This algorithm is newly proposed in this paper",
          "quote": "Our new algorithms, called eTVI and eiTVI, run several times faster than traditional VI, TVI, LRTDP and ILAO* techniques."
        },
        "is_executed": {
          "value": 1,
          "justification": "eTVI is executed as part of the empirical evaluation.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "eTVI is compared to the other methods, such as TVI, VI, and LRTDP.",
          "quote": "Finally, we would need to add multiple new metrics to our study. Since we were limited by the paper length, we decided to present our results using the number of Bellman backups, which might be of greater interest to the AI community and allows us to measure indirectly the cache performance. This way, we can use two criteria (running time and number ..."
        },
        "referenced_paper_title": {
          "value": "Cache-Efﬁcient Dynamic Programming MDP Solver",
          "justification": "This is the paper where eTVI was introduced.",
          "quote": "In this paper, we show that state-of-the-art MDP solvers can run orders of magnitude faster if they exploit the memory hierarchy of modern computers."
        }
      },
      {
        "name": {
          "value": "Extra-Intra-Topological Value Iteration",
          "justification": "eiTVI is one of the new algorithms proposed in the paper to improve cache efficiency.",
          "quote": "Our new algorithms, called eTVI and eiTVI, run several times faster than traditional VI, TVI, LRTDP and ILAO* techniques."
        },
        "aliases": [
          "eiTVI"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "This algorithm is newly proposed in this paper",
          "quote": "Our new algorithms, called eTVI and eiTVI, run several times faster than traditional VI, TVI, LRTDP and ILAO* techniques."
        },
        "is_executed": {
          "value": 1,
          "justification": "eiTVI is executed as part of the empirical evaluation.",
          "quote": "Figure 1 illustrates the results of the six competing algorithms on the tested domains."
        },
        "is_compared": {
          "value": 1,
          "justification": "eiTVI is compared to the other methods, such as TVI, VI, and LRTDP.",
          "quote": "Finally, we would need to add multiple new metrics to our study. Since we were limited by the paper length, we decided to present our results using the number of Bellman backups, which might be of greater interest to the AI community and allows us to measure indirectly the cache performance. This way, we can use two criteria (running time and number ..."
        },
        "referenced_paper_title": {
          "value": "Cache-Efﬁcient Dynamic Programming MDP Solver",
          "justification": "This is the paper where eiTVI was introduced.",
          "quote": "In this paper, we show that state-of-the-art MDP solvers can run orders of magnitude faster if they exploit the memory hierarchy of modern computers."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2641,
    "prompt_tokens": 15499,
    "total_tokens": 18140
  }
}