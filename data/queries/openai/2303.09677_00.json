{
  "paper": "2303.09677.txt",
  "words": 12186,
  "extractions": {
    "title": {
      "value": "Instance-Conditioned GAN Data Augmentation for Representation Learning",
      "justification": "Title extracted from the paper",
      "quote": "Instance-Conditioned GAN Data Augmentation for Representation Learning"
    },
    "description": "The paper introduces DAIC-GAN, a data augmentation module that leverages instance-conditioned GAN generations and can be used with state-of-the-art training recipes. The effectiveness of DAIC-GAN is demonstrated on supervised and self-supervised training of ResNet and DeiT models on the ImageNet dataset. The results show accuracy improvements and robust representations.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents experimental results on the impact of DAIC-GAN using supervised and self-supervised training on ImageNet dataset, including improvements in accuracy and robustness.",
      "quote": "We showcase the benefits of DAIC-GAN by plugging it out-of-the-box into the supervised training of ResNets and DeiT models on the ImageNet dataset, and achieving accuracy boosts up to between 1%p and 2%p with the highest capacity models."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper focuses on visual representation learning and data augmentation for image classification models.",
        "quote": "Data augmentation has become a crucial component to train state-of-the-art visual representation models."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Data Augmentation",
          "justification": "The paper explores using instance-conditioned GAN models for data augmentation in training visual representation models.",
          "quote": "In this paper, we introduce a data augmentation module, called DAIC-GAN , which leverages instance-conditioned GAN generations and can be used off-the-shelf in conjunction with most state-of-the-art training recipes."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Generative Adversarial Networks",
          "justification": "The paper uses instance-conditioned GAN models to generate augmented data for training.",
          "quote": "In this paper, we study the use of Instance-Conditioned GAN (IC-GAN) (Casanova et al., 2021), a generative model that, conditioned on an image, generates samples that are semantically similar to the conditioning image."
        },
        "aliases": [
          "GAN"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "DAIC-GAN",
          "justification": "DAIC-GAN is explicitly introduced as a new data augmentation module in the paper.",
          "quote": "In this paper, we introduce a data augmentation module, called DAIC-GAN, which leverages instance-conditioned GAN generations and can be used off-the-shelf in conjunction with most state-of-the-art training recipes."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "DAIC-GAN is a newly introduced module by the authors of the paper.",
          "quote": "In this paper, we introduce a data augmentation module, called DAIC-GAN."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is executed to evaluate its impact on visual representation learning.",
          "quote": "We validate the proposed approach by training supervised image classification models of increasing capacity on the ImageNet dataset and evaluating them in distribution and out-of-distribution."
        },
        "is_compared": {
          "value": 1,
          "justification": "DAIC-GAN is compared to baseline models, showing improvements in accuracy and robustness.",
          "quote": "Our results highlight the benefits of leveraging DAIC-GAN, by outperforming strong baselines when considering high-capacity models, and by achieving robust representations exhibiting increased invariance to viewpoint and instance."
        },
        "referenced_paper_title": {
          "value": "Instance-Conditioned GAN",
          "justification": "Reference to the foundational model IC-GAN which DAIC-GAN builds upon.",
          "quote": "we study the use of Instance-Conditioned GAN (IC-GAN) (Casanova et al., 2021), a generative model that, conditioned on an image, generates samples that are semantically similar to the conditioning image."
        }
      },
      {
        "name": {
          "value": "IC-GAN",
          "justification": "IC-GAN is utilized as the base generative model for creating instance-conditioned samples.",
          "quote": "we study the use of Instance-Conditioned GAN (IC-GAN) (Casanova et al., 2021), a generative model that, conditioned on an image, generates samples that are semantically similar to the conditioning image."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "IC-GAN is a pre-existing model referenced and used in this work.",
          "quote": "Instance-Conditioned GAN (IC-GAN) (Casanova et al., 2021)"
        },
        "is_executed": {
          "value": 1,
          "justification": "IC-GAN is executed to generate instance-conditioned samples for data augmentation.",
          "quote": "we propose to leverage IC-GAN to generate plausible augmentations of each available datapoint"
        },
        "is_compared": {
          "value": 0,
          "justification": "IC-GAN is not compared numerically in this paper; it is used to build DAIC-GAN.",
          "quote": "we propose to leverage IC-GAN to generate plausible augmentations of each available datapoint"
        },
        "referenced_paper_title": {
          "value": "Instance-Conditioned GAN",
          "justification": "Reference to the original IC-GAN paper.",
          "quote": "Instance-Conditioned GAN (IC-GAN) (Casanova et al., 2021)"
        }
      },
      {
        "name": {
          "value": "CC-IC-GAN",
          "justification": "CC-IC-GAN is another version of the instance-conditioned GAN model, conditioning on class labels in addition to instance representation.",
          "quote": "a class-conditional version of IC-GAN, referred to as CC-IC-GAN, a class label y is used as an extra input conditioning for the generator, such that x̃ = Gψ (z, h, y)"
        },
        "aliases": [
          "Class-Conditional IC-GAN"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "CC-IC-GAN is a pre-existing model referenced and used in this work.",
          "quote": "a class-conditional version of IC-GAN, referred to as CC-IC-GAN"
        },
        "is_executed": {
          "value": 1,
          "justification": "CC-IC-GAN is executed to generate class-conditional instance-conditioned samples.",
          "quote": "CC-IC-GAN conditions the generation process on both the instance representation obtained with a ResNet-50 trained for classification and a class label."
        },
        "is_compared": {
          "value": 0,
          "justification": "CC-IC-GAN is not numerically compared in this paper, it is used to build DAIC-GAN.",
          "quote": "CC-IC-GAN conditions the generation process on both the instance representation obtained with a ResNet-50 trained for classification and a class label."
        },
        "referenced_paper_title": {
          "value": "Instance-Conditioned GAN",
          "justification": "Reference to the original IC-GAN paper, which introduced both IC-GAN and CC-IC-GAN models.",
          "quote": "a class-conditional version of IC-GAN, referred to as CC-IC-GAN"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is used for training and evaluating the performance of the models.",
          "quote": "We showcase the benefits of DAIC-GAN by plugging it out-of-the-box into the supervised training of ResNets and DeiT models on the ImageNet dataset"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "Reference to the foundational paper of the ImageNet dataset.",
          "quote": "ImageNet (Deng et al., 2009)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "VISSL",
          "justification": "VISSL library is used for data augmentation and model training.",
          "quote": "We used the VISSL library (Goyal et al., 2021) which relies on Torchvision transformations"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "VISSL",
          "justification": "Referencing the VISSL library which the authors used for their experiments.",
          "quote": "We used the VISSL library (Goyal et al., 2021)"
        }
      },
      {
        "name": {
          "value": "Torchvision",
          "justification": "Torchvision is used within the VISSL library for image transformations and augmentations.",
          "quote": "We used the VISSL library (Goyal et al., 2021) which relies on Torchvision transformations"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Torchvision: The machine learning library for PyTorch",
          "justification": "Referencing the Torchvision library used for image transformations and augmentations.",
          "quote": "Torchvision transformations"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 5834,
    "prompt_tokens": 46538,
    "total_tokens": 52372
  }
}