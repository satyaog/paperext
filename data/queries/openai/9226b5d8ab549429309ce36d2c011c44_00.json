{
  "paper": "9226b5d8ab549429309ce36d2c011c44.txt",
  "words": 5661,
  "extractions": {
    "title": {
      "value": "Who Controlled the Evidence? Question Answering for Disclosure Information Extraction",
      "justification": "The title is explicit in the text.",
      "quote": "Who Controlled the Evidence? Question Answering for Disclosure Information Extraction"
    },
    "description": "The paper introduces a novel task of identifying relationships between sponsoring entities and the research studies they sponsor from the disclosure statements. It proposes a Question Answering-based method for this task, constructs a new annotated dataset, and demonstrates the robustness of the method in handling diverse relationship patterns.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves the creation of a dataset, application of machine learning models, and empirical evaluation of their performance.",
      "quote": "To overcome these challenges, in this paper, we also constructed a new annotated dataset and proposed a Question Answering-based method to recognize entities and extract relationships."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on text extraction and question answering tasks, which fall under Natural Language Processing (NLP).",
        "quote": "we propose a novel method called Question Answering for Conflict of Interest Extraction (QA4COI) for the COIRelationExt task that is based on a Question Answering (QA) approach."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Information Extraction",
          "justification": "This sub-field is justified because the task involves extracting information from unstructured text.",
          "quote": "we introduce a novel task to identify relationships between sponsoring entities and the research studies they sponsor from the disclosure statement."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Question Answering",
          "justification": "The proposed method to solve the task is a QA-based approach.",
          "quote": "we propose a novel method called Question Answering for Conflict of Interest Extraction (QA4COI) for the COIRelationExt task that is based on a Question Answering (QA) approach."
        },
        "aliases": [
          "QA"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "QA4COI",
          "justification": "The QA4COI model is introduced in the paper as the primary methodology for the task.",
          "quote": "we propose a novel method called Question Answering for Conflict of Interest Extraction (QA4COI) for the COIRelationExt task..."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The model is introduced in this paper.",
          "quote": "we propose a novel method called Question Answering for Conflict of Interest Extraction (QA4COI) for the COIRelationExt task..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model's performance is evaluated in the experiments section.",
          "quote": "For our model, we use pre-trained Flan-T5... We train our model using the Flan-T5 base model, running the training process three times with different random seeds."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model is compared with baseline models like Spacy NER.",
          "quote": "To understand the results difference in Table 3, we look into the performance of both models..."
        },
        "referenced_paper_title": {
          "value": "Exploring the limits of transfer learning with a unified text-to-text transformer",
          "justification": "Flan-T5, utilized as a base model, references this paper, reflecting the foundational work of text-to-text transformers.",
          "quote": "For our model, we use pre-trained Flan-T5 (Chung et al., 2022) which is an extended T5 model (Raffel et al., 2020)..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "COIRelationExt Dataset",
          "justification": "The paper introduces this new dataset for its novel task.",
          "quote": "To accompany the COIRelationExt task, we created a new dataset where we collect disclosure statements from various journals and then employ expert annotators to annotate the sponsoring relationships to the study."
        },
        "aliases": [],
        "role": "Contributed",
        "referenced_paper_title": {
          "value": "ICMJE recommendations",
          "justification": "The dataset creation references ICMJE recommendations to define the relationships and conflicts of interest.",
          "quote": "These labels are created based on the ICMJE recommendations and the AMA styles."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Flan-T5",
          "justification": "Flan-T5 is explicitly used as the base model in the paper.",
          "quote": "For our model, we use pre-trained Flan-T5 (Chung et al., 2022) which is an extended T5 model (Raffel et al., 2020) that is further fine-tuned on hundreds of downstream tasks including QA tasks."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Scaling instruction-finetuned language models",
          "justification": "Flan-T5 is based on a paper that discusses fine-tuning language models for various tasks, which is relevant here.",
          "quote": "For our model, we use pre-trained Flan-T5 (Chung et al., 2022)..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2044,
    "prompt_tokens": 21296,
    "total_tokens": 23340
  }
}