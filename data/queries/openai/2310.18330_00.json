{
  "paper": "2310.18330.txt",
  "words": 7675,
  "extractions": {
    "title": {
      "value": "Towards Detecting Contextual Real-Time Toxicity for In-Game Chat",
      "justification": "This is the title of the paper provided by the user.",
      "quote": "Towards Detecting Contextual Real-Time Toxicity for In-Game Chat"
    },
    "description": "This paper introduces ToxBuster, a real-time toxicity detection model for in-game chat that leverages chat history and metadata. ToxBuster is evaluated on several datasets, including popular multiplayer games and comment threads of news articles, demonstrating its effectiveness and transferability.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes experiments and evaluations of the ToxBuster model on various datasets and baseline comparisons.",
      "quote": "We conduct an ablation study to assess the importance of each model component and explore ToxBusterâ€™s transferability across the datasets."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper deals with toxicity detection in textual data, which falls under Natural Language Processing (NLP).",
        "quote": "We leverage recent advancements in large language models to create accurate and transferable models for effective content moderation."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Toxicity Detection",
          "justification": "The research specifically focuses on detecting toxic speech in online environments.",
          "quote": "Toxicity detection research has gained increasing attention due to the challenges it poses."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Real-Time Systems",
          "justification": "The model introduced is designed for real-time toxicity detection in in-game chat.",
          "quote": "We present ToxBuster, the first real-time in-game chat toxicity detection model capable of integrating chat history and metadata."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Transfer Learning",
          "justification": "The paper discusses the transferability of the ToxBuster model across different datasets and domains.",
          "quote": "We show that the proposed model can transfer across different games and domains."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ToxBuster",
          "justification": "ToxBuster is the main model introduced and evaluated in the paper.",
          "quote": "We introduce ToxBuster, a simple and scalable model that reliably detects toxic content in real-time for a line of chat by including chat history and metadata."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "ToxBuster is the main contribution of the paper.",
          "quote": "We present ToxBuster, a real-time toxicity detection model for in-game chat that outperforms current available solutions by leveraging chat history and metadata."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper mentions performing experiments and evaluations, which implies the model was executed.",
          "quote": "In our experiments, we employed a 60-20-20 train-validation-test split using 5 different random seeds."
        },
        "is_compared": {
          "value": 1,
          "justification": "ToxBuster is compared to several baseline models in the paper.",
          "quote": "In terms of precision, Perspective API generally outperforms Cleanspeak, while Detoxifyunbiased excells in recall and F1 score. Cleanspeak ranks the lowest."
        },
        "referenced_paper_title": {
          "value": "None",
          "justification": "The paper does not reference another paper for the ToxBuster model.",
          "quote": "None"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Rainbow Six Siege (R6S)",
          "justification": "R6S dataset is one of the datasets used in the paper.",
          "quote": "We collected and curated datasets from three multiplayer games representing different genres: Rainbow Six Siege (R6S), For Honor (FH), and Defense of the Ancients 2 (DOTA 2)"
        },
        "aliases": [
          "R6S"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "The paper does not reference another paper for the Rainbow Six Siege dataset.",
          "quote": "We collected and curated datasets from three multiplayer games representing different genres: Rainbow Six Siege (R6S), For Honor (FH), and Defense of the Ancients 2 (DOTA 2)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "BERT",
          "justification": "The paper references using BERT as a foundational model for ToxBuster.",
          "quote": "Contextual language embeddings, like BERT (Devlin et al., 2018), serve as the foundation for many state-of-the-art toxic speech detection models."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
          "justification": "The paper explicitly cites BERT as foundational.",
          "quote": "Contextual language embeddings, like BERT (Devlin et al., 2018), serve as the foundation for many state-of-the-art toxic speech detection models."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 975,
    "prompt_tokens": 14379,
    "total_tokens": 15354
  }
}