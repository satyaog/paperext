{
  "paper": "94f6a1ca883e56bd4860fd1c31bc290f.txt",
  "words": 11340,
  "extractions": {
    "title": {
      "value": "Learning few-shot imitation as cultural transmission",
      "justification": "The title is clearly stated at the beginning of the paper.",
      "quote": "Learning few-shot imitation as cultural transmission"
    },
    "description": "This paper presents a method for generating cultural transmission in AI agents, specifically through few-shot imitation. The agents can imitate humans in real-time in novel contexts without any pre-collected human data. The researchers introduce a new reinforcement learning environment (GoalCycle3D) and identify key components necessary for cultural transmission to emerge. They demonstrate their method’s effectiveness through various experiments and rigorous evaluations.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper involves empirical experiments and evaluations to demonstrate the effectiveness of the proposed method.",
      "quote": "We provide a method for generating cultural transmission in artiﬁcially intelligent agents, in the form of few-shot imitation. ... We identify a surprisingly simple set of ingredients sufﬁcient for generating cultural transmission and develop an evaluation methodology for rigorously assessing it."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The primary method used in this study is deep reinforcement learning.",
        "quote": "Our artiﬁcial agent is parameterised by a neural network and we use deep reinforcement learning (RL) to train the weights."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Imitation Learning",
          "justification": "The focus is on imitation learning as a method for cultural transmission.",
          "quote": "We focus on a particular form of cultural transmission, known in the psychology and neuroscience literature as observational learning or (few-shot) imitation."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Meta-Learning",
          "justification": "The authors describe their approach as memory-based meta-learning to enable the agent to generalize across tasks.",
          "quote": "We can characterise our approach to generating cultural transmission as memory-based meta-learning."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "MEDAL-ADR",
          "justification": "The model described in the paper for generating cultural transmission is referred to as MEDAL-ADR.",
          "quote": "Via careful ablations, we identify a minimal sufﬁcient “starter kit” of training ingredients required for cultural transmission to emerge in GoalCycle3D, namely function approximation, memory (M), the presence of an expert co-player (E), expert dropout (D), attentional bias towards the expert (AL), and automatic domain randomisation (ADR). We refer to this collection by the acronym MEDAL-ADR."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The model is introduced and developed as part of this research.",
          "quote": "We refer to this collection by the acronym MEDAL-ADR."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is executed within the paper's experimental framework.",
          "quote": "Figure 4b shows an example expansion of the randomisation ranges for all parameters for the duration of an experiment."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model is compared with ablated versions and other methods.",
          "quote": "To understand the importance of ADR for generating cultural transmission in complex worlds, we ablate the automatic (A) and domain randomisation (DR) components of MEDAL-ADR."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no external reference paper specific to this model, as it is introduced in this paper.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "GoalCycle3D",
          "justification": "The dataset/environment introduced for evaluating the agent's performance is called GoalCycle3D.",
          "quote": "The central novelty in this work is the application of agent-environment co-adaptation to generate an agent capable of robust real-time cultural transmission. To this end, we introduce a new open-ended reinforcement learning environment, GoalCycle3D."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "The GoalCycle3D environment is introduced and described within this paper.",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Unity",
          "justification": "Unity is mentioned as the platform used to build the 3D physical simulated task space.",
          "quote": "We introduce GoalCycle3D, a 3D physical simulated task space built in Unity."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Juliani, A. et al. Unity: a general platform for intelligent agents. arXiv https://arxiv.org/abs/1809.02627 (2018).",
          "justification": "This reference provides the details of the Unity platform used.",
          "quote": "Juliani, A. et al. Unity: a general platform for intelligent agents. arXiv https://arxiv.org/abs/1809.02627 (2018)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 966,
    "prompt_tokens": 19113,
    "total_tokens": 20079
  }
}