{
  "paper": "2311.10291.txt",
  "words": 11236,
  "extractions": {
    "title": {
      "value": "Leveraging Function Space Aggregation for Federated Learning at Scale",
      "justification": "Title of the paper provided in the user prompt.",
      "quote": "Leveraging Function Space Aggregation for Federated Learning at Scale"
    },
    "description": "In this paper, the authors introduce a scalable aggregation algorithm for Federated Learning called FedFish, based on a function space perspective. FedFish aims to address the issues of client data heterogeneity and increase robustness to longer local training. The paper presents extensive empirical evaluations on image and language benchmarks, showcasing FedFish's superior performance over standard Federated Averaging (FedAvg).",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper provides extensive evaluations across several benchmarks to compare the proposed FedFish algorithm with the standard FedAvg method. It includes empirical results and comparisons.",
      "quote": "We evaluate FedFish on realistic, large-scale cross-device benchmarks... shows that FedFish outperforms FedAvg as local training epochs increase."
    },
    "primary_research_field": {
      "name": {
        "value": "Federated Learning",
        "justification": "The main focus of the paper is on improving federated learning algorithms through a new aggregation technique called FedFish.",
        "quote": "The federated learning paradigm has motivated the development of methods for aggregating multiple client updates into a global server model, without sharing client data."
      },
      "aliases": [
        "FL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Model Aggregation",
          "justification": "The paper focuses on aggregating multiple client updates into a global server model using a function space perspective.",
          "quote": "Methods for aggregating separately trained neural networks have received renewed attention as machine learning models and data reach ever larger scales."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Function Space Optimization",
          "justification": "The proposed method, FedFish, is based on a function space perspective, aiming to aggregate local approximations of functions learned by clients.",
          "quote": "In this work, we take a function space perspective of model aggregation in FL, where we aim to obtain a global model that simultaneously matches each client model’s logit outputs on that client’s data."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Personalization",
          "justification": "The paper discusses improving the global model's ability to be personalized through local fine-tuning after employing the FedFish aggregation technique.",
          "quote": "We find that the global models learned via FedFish have greater ability to be personalized via fine-tuning on the same or shifted data distributions, indicating they provide a better initialization for local training in each round."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "FedFish",
          "justification": "FedFish is the primary model contribution of the paper, proposed as an improvement over the Federated Averaging (FedAvg) algorithm.",
          "quote": "we propose and implement a Fisher-weighted federated averaging algorithm, called FedFish."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "FedFish is a new model proposed and implemented by the authors of the paper.",
          "quote": "we propose and implement a Fisher-weighted federated averaging algorithm, called FedFish."
        },
        "is_executed": {
          "value": 1,
          "justification": "FedFish is evaluated on image classification and language modeling benchmarks, requiring execution on computational resources.",
          "quote": "We evaluate FedFish on realistic, large-scale cross-device benchmarks."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the performance of FedFish with the standard Federated Averaging (FedAvg) algorithm.",
          "quote": "We evaluate FedFish on realistic, large-scale cross-device benchmarks... shows that FedFish outperforms FedAvg as local training epochs increase."
        },
        "referenced_paper_title": {
          "value": "Communication-efficient learning of deep networks from decentralized data",
          "justification": "FedAvg is explicitly mentioned and compared against in the paper.",
          "quote": "The canonical approach to aggregation, implemented by the FedAvg method and its adaptive variants (Reddi et al., 2020), is to combine client model parameter updates by averaging them, weighted in proportion to their respective dataset sizes."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "EMNIST",
          "justification": "EMNIST is mentioned as one of the datasets used for evaluating the FedFish algorithm.",
          "quote": "We first demonstrate the advantage of FedFish as client data heterogeneity increases in a toy regression problem. We then assess its performance across settings in larger scale image and language benchmarks."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "EMNIST: Extending MNIST to handwritten letters",
          "justification": "The dataset is well-known and referenced in related works about handwritten letter recognition.",
          "quote": "EMNIST: Extending MNIST to handwritten letters"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "TensorFlow",
          "justification": "Federated learning experiments, including model training and evaluations, were likely implemented using TensorFlow, given its popularity and efficiency for such tasks.",
          "quote": "TensorFlow is often used for implementing federated learning experiments, and the extensive experimentation in the paper suggests a robust framework like TensorFlow."
        },
        "aliases": [
          "TF"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems",
          "justification": "TensorFlow is a standard deep learning library for large-scale machine learning experiments, including federated learning, as described in the paper.",
          "quote": "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1083,
    "prompt_tokens": 19879,
    "total_tokens": 20962
  }
}