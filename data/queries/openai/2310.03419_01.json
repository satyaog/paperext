{
  "paper": "2310.03419.txt",
  "words": 10200,
  "extractions": {
    "title": {
      "value": "Pre-Training and Fine-Tuning Generative Flow Networks",
      "justification": "Title found at the beginning of the paper.",
      "quote": "Pre-Training and Fine-Tuning Generative Flow Networks"
    },
    "description": "This paper introduces a novel method for the reward-free pre-training of Generative Flow Networks (GFlowNets) called the outcome-conditioned GFlowNet (OC-GFN). The authors demonstrate how these pre-trained models can be efficiently fine-tuned for diverse downstream tasks with new reward functions. Experimental results validate the efficacy and efficiency of this approach across various domains including GridWorld and biological sequence design tasks.",
    "type": {
      "value": "theoretical",
      "justification": "The paper proposes a novel theoretical approach to GFlowNet training and fine-tuning, although there are extensive empirical validations.",
      "quote": "In this paper, we propose a novel method for reward-free unsupervised pre-training of GFlowNets. We formulate the problem of pre-training GFlowNets as a self-supervised problem of learning an outcome-conditioned GFlowNet (OC-GFN) which learns to reach any outcome (goal)\nas a functional understanding of the environment (akin to goal-conditioned RL (Chebotar et al.,\n2021))."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research focuses on Generative Flow Networks, which is a subfield within deep learning.",
        "quote": "In this paper, we propose a novel method for reward-free unsupervised pre-training of GFlowNets."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper discusses Generative Flow Networks (GFlowNets) which are used to generate diverse sets of high-reward objects.",
          "quote": "Generative Flow Networks (GFlowNets) are amortized samplers that learn stochastic policies to sequentially generate compositional objects from a given unnormalized reward distribution."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Outcome-Conditioned Generative Flow Network",
          "justification": "Specifically mentioned as the key model introduced in the paper.",
          "quote": "We propose a novel method for reward-free unsupervised pre-training of GFlowNets. We formulate the problem of pre-training GFlowNets as a self-supervised problem of learning an outcome-conditioned GFlowNet (OC-GFN)."
        },
        "aliases": [
          "OC-GFN"
        ],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "Contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "Trained"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "GridWorld",
          "justification": "The dataset is used for evaluating the proposed pre-training and fine-tuning strategy.",
          "quote": "Extensive experimental results validate the efficacy of our approach, demonstrating the effectiveness of pre-training the OC-GFN... on the GridWorld domain."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "TF Bind",
          "justification": "TF Bind is utilized to show the applicability of OC-GFN in biological sequence design.",
          "quote": "Through extensive experiments on the GridWorld domain, we empirically validate the efficacy of the proposed pre-training and fine-tuning paradigm. We also demonstrate its scalability to larger-scale and challenging biological sequence design tasks, which achieves consistent and substantial improvements over strong baselines, especially in terms of diversity of the generated samples."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "RNA Sequence",
          "justification": "RNA Sequence dataset is used to illustrate the effectiveness in generating RNA sequences for binding targets.",
          "quote": "A GFlowNet can be trained to generate candidate RNA sequences."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Adam",
          "justification": "The Adam optimizer is mentioned as part of the training setup for the models.",
          "quote": "We train all models with the Adam (Kingma and Ba, 2015) optimizer (learning rate is 0.001) based on samples from a parallel of 16 rollouts in the environment."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 854,
    "prompt_tokens": 17977,
    "total_tokens": 18831
  }
}