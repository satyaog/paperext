{
  "paper": "2210.03535.txt",
  "words": 15098,
  "extractions": {
    "title": {
      "value": "From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML",
      "justification": "Provided title in the given research paper",
      "quote": "From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML"
    },
    "description": "This paper addresses the social and ethical risks associated with the inappropriate design and deployment of Machine Learning (ML) systems. Through interviews with industry practitioners, it investigates current risk management practices and examines how safety engineering frameworks like System Theoretic Process Analysis (STPA) and Failure Mode and Effects Analysis (FMEA) can be adapted to improve these practices. The findings call for strengthening existing frameworks and integrating them into the ML industry to mitigate risks effectively.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper involves interviews with 30 industry practitioners and collects empirical data on their current social and ethical risk management practices.",
      "quote": "We interviewed 30 industry practitioners on their current social and ethical risk management practices, and collected their first reactions on adapting safety engineering frameworks into their practice."
    },
    "primary_research_field": {
      "name": {
        "value": "Human-Centered Computing",
        "justification": "The research focuses on the social and ethical implications for users and society, a central theme in Human-Centered Computing.",
        "quote": "CCS Concepts: • Social and professional topics → Computing / technology policy; • General and reference → Evaluation; Surveys and overviews."
      },
      "aliases": [
        "HCC"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Safety Engineering for ML",
          "justification": "The paper examines how safety engineering frameworks can be applied to manage the risks of ML systems.",
          "quote": "We chose two of the most successful safety engineering frameworks used in other sociotechnical domains [19, 93, 117]: Failure Mode and Effect Analysis (FMEA) [21] and System Theoretic Process Analysis (STPA) [67, 91], which we describe in detail in Section 2."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Responsible AI",
          "justification": "Deals with managing social and ethical risks, central aspects of the responsible development and deployment of AI.",
          "quote": "We contribute to the emerging research on managing social and ethical risk of ML systems in human-computing scholarship and responsible ML communities by offering: (...) insights on how FMEA and STPA could inform existing practices along with their perceived advantages and disadvantages;"
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 594,
    "prompt_tokens": 25055,
    "total_tokens": 25649
  }
}