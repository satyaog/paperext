{
  "paper": "2306.07179.txt",
  "words": 45669,
  "extractions": {
    "title": {
      "value": "Benchmarking Neural Network Training Algorithms",
      "justification": "This is the exact title mentioned at the beginning of the paper.",
      "quote": "Benchmarking Neural Network Training Algorithms"
    },
    "description": "This paper introduces the AlgoPerf benchmark for systematically comparing neural network training algorithms. The benchmark addresses key challenges in empirical comparisons and provides a competitive, time-to-result evaluation on multiple workloads running on fixed hardware.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts concrete experiments to demonstrate challenges and evaluate training algorithms.",
      "quote": "In this work, using concrete experiments, we argue that real progress in speeding up training requires new benchmarks that resolve three basic challenges faced by empirical comparisons of training algorithms"
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper focuses on improving the efficiency and benchmarking the performance of deep learning training algorithms.",
        "quote": "Training algorithms, broadly construed, are an essential part of every deep learning pipeline."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Optimization and Training",
          "justification": "The paper specifically addresses training algorithms and techniques to optimize the training process of neural networks.",
          "quote": "This paper describes the working group’s first attempt to benchmark training algorithms for neural networks"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-50",
          "justification": "It is used as one of the models for evaluating training algorithms on the ImageNet dataset.",
          "quote": "We use the ResNet-50 defined in He et al. (2016a, Section 4.1)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "ViT",
          "justification": "It is one of the models utilized for benchmarking training algorithms on image data.",
          "quote": "For all experiments, we use the S/16 variant of the Vision Transformer (ViT)."
        },
        "aliases": [
          "Vision Transformer"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "U-Net",
          "justification": "It is used in the fastMRI workload for MRI image reconstruction.",
          "quote": "We train a U-Net model similar to the one described in Ronneberger et al. (2015)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DLRM",
          "justification": "DLRM is used on the Criteo 1TB dataset for click-through rate prediction.",
          "quote": "We train a standard ads recommender model, DLRM (Naumov et al., 2019) to predict the CTR."
        },
        "aliases": [
          "Deep Learning Recommendation Model"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Conformer",
          "justification": "It is used for training on the LibriSpeech dataset for speech recognition.",
          "quote": "Conformer (Gulati et al., 2020) is an architecture combing attention and convolution layers to capture both global and local relationships in input audio."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DeepSpeech",
          "justification": "It is utilized in the LibriSpeech workload for speech recognition tasks.",
          "quote": "A variant of the DeepSpeech (Amodei et al., 2016) model with residual connections, dropout..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Transformer",
          "justification": "It is used as an example of a transformer model for machine translation tasks.",
          "quote": "We use the Transformer-big architecture from Vaswani et al. (2017) with some modifications."
        },
        "aliases": [
          "Big"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "training"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "Used to benchmark image classification models like ResNet-50 and ViT.",
          "quote": "We use the ILSVRC 2012 training and validation sets as the training and validation splits."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "fastMRI",
          "justification": "Used for the U-Net model in MRI image reconstruction tasks.",
          "quote": "We use fastMRI’s single-coil knee data..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Criteo 1TB",
          "justification": "Employed in click-through rate prediction with the DLRM model.",
          "quote": "Criteo 1TB Click Logs dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "LibriSpeech",
          "justification": "Used for the Conformer and DeepSpeech models in speech recognition tasks.",
          "quote": "The LibriSpeech dataset (Panayotov et al., 2015) consists of 960 hours of audio..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "OGBG-MOLPCBA",
          "justification": "Used for the GNN model in the molecular property prediction task.",
          "quote": "We use the OGBG-MOLPCBA dataset (Hu et al., 2020) containing molecular graphs and 128 molecular properties."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "WMT 2017",
          "justification": "Used in the Transformer model for machine translation tasks.",
          "quote": "We use the Transformer-big architecture from Vaswani et al. (2017) with some modifications."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "JAX",
          "justification": "JAX is one of the libraries used to implement the models and workloads in the benchmark.",
          "quote": "The JAX implementations of the workloads used in the benchmark."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is another library used to implement the models and workloads in the benchmark.",
          "quote": "The PyTorch implementations of the workloads used in the benchmark."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1418,
    "prompt_tokens": 70409,
    "total_tokens": 71827
  }
}