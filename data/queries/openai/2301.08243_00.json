{
  "paper": "2301.08243.txt",
  "words": 10761,
  "extractions": {
    "title": {
      "value": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture",
      "justification": "The information is extracted from the title and content of the paper.",
      "quote": "Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture"
    },
    "description": "This paper introduces the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative method for self-supervised learning from images aimed at producing semantic image representations. The proposed method uses a single context block to predict the representations of target blocks in the same image. The authors explore this approach using Vision Transformers and test it across various tasks, including image classification, object counting, and depth prediction.",
    "type": {
      "value": "Empirical",
      "justification": "The paper provides empirical evaluations of the proposed I-JEPA method across multiple tasks and includes experimentation details such as GPU hours, epochs, and specific performance metrics.",
      "quote": "Through an extensive empirical evaluation, we demonstrate that: â€¢ I-JEPA learns strong off-the-shelf representations without the use of hand-crafted view augmentations"
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The focus of the paper is on self-supervised learning methods for image representations, which is a major area under Computer Vision.",
        "quote": "In computer vision, there are two common families of approaches for self-supervised learning from images: invariance-based methods and generative methods."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper proposes a new self-supervised learning architecture and compares it to existing self-supervised methods.",
          "quote": "We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images."
        },
        "aliases": [
          "SSL"
        ]
      },
      {
        "name": {
          "value": "Visual Representation Learning",
          "justification": "The primary aim of the proposed method is to learn semantic image representations.",
          "quote": "This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations."
        },
        "aliases": [
          "Image Representation Learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "I-JEPA",
          "justification": "This new model architecture is the main focus of the paper and is introduced as a contribution to the research field.",
          "quote": "To that end, we introduce a joint-embedding predictive architecture [48] for images (I-JEPA)."
        },
        "aliases": [
          "Image-based Joint-Embedding Predictive Architecture"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The paper introduces I-JEPA as a novel contribution for self-supervised learning from images.",
          "quote": "To that end, we introduce a joint-embedding predictive architecture for images (I-JEPA)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper discusses various experiments involving the execution of I-JEPA on GPUs.",
          "quote": "For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares I-JEPA's performance against multiple existing methods such as MAE, DINO, and iBOT.",
          "quote": "For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The I-JEPA model is newly introduced in this paper, and thus no reference paper exists.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet-1K",
          "justification": "This dataset is explicitly mentioned as being used for training and evaluation in the paper.",
          "quote": "For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks."
        },
        "aliases": [
          "ImageNet"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet large scale visual recognition challenge",
          "justification": "ImageNet's full title is provided for clarity and completeness.",
          "quote": "For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper uses PyTorch for implementation, as indicated in various experimental details and methodology sections.",
          "quote": "The mask-sampler is efficiently implemented in only a few lines of code in PyTorch using a batch-collator function, which runs in the data loader processes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "PyTorch's full title is provided for clarity and completeness.",
          "quote": "The mask-sampler is efficiently implemented in only a few lines of code in PyTorch using a batch-collator function, which runs in the data loader processes."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1034,
    "prompt_tokens": 20313,
    "total_tokens": 21347
  }
}