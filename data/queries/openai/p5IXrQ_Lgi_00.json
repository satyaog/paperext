{
  "paper": "p5IXrQ_Lgi.txt",
  "words": 7507,
  "extractions": {
    "title": {
      "value": "MixupE: Understanding and Improving Mixup from Directional Derivative Perspective",
      "justification": "This is the title of the research paper.",
      "quote": "MixupE: Understanding and Improving Mixup from Directional Derivative Perspective"
    },
    "description": "The paper introduces MixupE, an enhancement to the Mixup data augmentation technique. The authors analyze Mixup from a directional derivative perspective and propose MixupE, which theoretically and empirically improves generalization performance across various datasets and architectures.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper proposes a new method (MixupE) and demonstrates its effectiveness through various experiments on multiple datasets and architectures.",
      "quote": "To demonstrate the effectiveness of the proposed method, we conduct experiments across various domains such as images, tabular data, speech, and graphs."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The primary research field of the paper is Machine Learning, focusing on improvements to the Mixup data augmentation technique for better generalization in neural networks.",
        "quote": "Mixup is a popular data augmentation technique for training deep neural networks where additional samples are generated by linearly interpolating pairs of inputs and their labels."
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Data Augmentation",
          "justification": "The paper focuses on improving the Mixup data augmentation technique by proposing an enhanced version called MixupE.",
          "quote": "Mixup is a popular data augmentation technique for training deep neural networks where additional samples are generated by linearly interpolating pairs of inputs and their labels."
        },
        "aliases": [
          "Data Aug"
        ]
      },
      {
        "name": {
          "value": "Regularization Techniques",
          "justification": "The proposed MixupE is designed to enhance the implicit regularization effects of Mixup, making it a study of regularization techniques as well.",
          "quote": "In this paper, we show that Mixup is equivalent to implicitly adding infinitely many regularization terms on the directional derivatives of all orders instead of a complex second-order form."
        },
        "aliases": [
          "Regularization"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "MixupE",
          "justification": "MixupE is the main model proposed and contributed by this paper. It is an enhancement of the Mixup technique.",
          "quote": "Based on this novel insight, this paper proposes to explicitly enhance the implicit regularization effect of Mixup on the directional derivatives. Instead of computing all infinite regularization terms, we efficiently approximate the dominant term using accessible results during each forward propagation, ensuring computational efficiency. We name this method as MixupE (Mixup Enhanced)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "MixupE is a new method introduced by the authors as an improvement over the existing Mixup technique.",
          "quote": "Based on this novel insight, this paper proposes to explicitly enhance the implicit regularization effect of Mixup on the directional derivatives. Instead of computing all infinite regularization terms, we efficiently approximate the dominant term using accessible results during each forward propagation, ensuring computational efficiency. We name this method as MixupE (Mixup Enhanced)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments demonstrating the implementation and effectiveness of MixupE across various datasets and architectures.",
          "quote": "To demonstrate the effectiveness of the proposed method, we conduct experiments across various domains such as images, tabular data, speech, and graphs."
        },
        "is_compared": {
          "value": 1,
          "justification": "MixupE is compared with other models such as ERM and Mixup in various experiments to demonstrate improvement in performance.",
          "quote": "Empirically, MixupE outperforms Mixup on several datasets, such as image, tabular, and speech datasets, trained with various networks. The improvement in test error is more significant for networks with larger capacities."
        },
        "referenced_paper_title": {
          "value": "mixup: Beyond empirical risk minimization",
          "justification": "The Mixup technique, which MixupE aims to improve, is originally proposed and detailed in the paper titled 'mixup: Beyond empirical risk minimization'.",
          "quote": "To address this limitation of ERM, Mixup [Zhang et al., 2018] has recently been proposed as an alternative training principle."
        }
      },
      {
        "name": {
          "value": "Mixup",
          "justification": "Mixup is a baseline model that the proposed MixupE aims to improve upon. It is referenced and used for comparison in this paper.",
          "quote": "To address this limitation of ERM, Mixup [Zhang et al., 2018] has recently been proposed as an alternative training principle."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "Mixup is not contributed by this paper; it is an existing technique that the authors aim to improve.",
          "quote": "Mixup [Zhang et al., 2018] creates synthetic training samples by linear interpolation in the input vectors and their corresponding labels."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments that execute the Mixup model for comparison with the proposed MixupE.",
          "quote": "To validate that the method is not overly sensitive to the newly introduced hyperparameter η, we conducted experiments for MixupE with the value of η ∈ {0.0001, 0.001, 0.01, 0.1} with Preactresnet50 architecture and the CIFAR-100 dataset."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the performance of Mixup with MixupE through various experiments to highlight improvements.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets. We see that MixupE consistently outperforms baseline methods ERM and Mixup across all the datasets and architectures."
        },
        "referenced_paper_title": {
          "value": "mixup: Beyond empirical risk minimization",
          "justification": "The Mixup technique is originally proposed in the paper titled 'mixup: Beyond empirical risk minimization'.",
          "quote": "Mixup [Zhang et al., 2018] creates synthetic training samples by linear interpolation in the input vectors and their corresponding labels."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The CIFAR-10 dataset is used for evaluating the performance of the proposed MixupE method.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-10 dataset is originally described in the paper 'Learning Multiple Layers of Features from Tiny Images'.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "The CIFAR-100 dataset is also used for performance evaluation of MixupE in the experiments.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-100 dataset is originally detailed in the paper 'Learning Multiple Layers of Features from Tiny Images'.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        }
      },
      {
        "name": {
          "value": "SVHN",
          "justification": "The SVHN dataset is used to test and validate the effectiveness of the proposed MixupE method.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Reading Digits in Natural Images with Unsupervised Feature Learning",
          "justification": "The SVHN dataset is originally described in the paper 'Reading Digits in Natural Images with Unsupervised Feature Learning'.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        }
      },
      {
        "name": {
          "value": "Tiny-ImageNet",
          "justification": "The Tiny-ImageNet dataset is utilized for evaluating the performance of MixupE in the experiments.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "The Tiny-ImageNet dataset is part of the larger ImageNet dataset detailed in 'ImageNet: A Large-Scale Hierarchical Image Database'.",
          "quote": "We show results for the CIFAR-10 (Table 1a), CIFAR-100 (Table 1b), SVHN (Table 2a), and Tiny-ImageNet (Table 2b) datasets."
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset is used for large-scale image classification experiments to benchmark MixupE.",
          "quote": "For a large-scale image classification dataset, we consider ImageNet [Deng et al., 2009]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "The ImageNet dataset is described in the paper 'ImageNet: A Large-Scale Hierarchical Image Database'.",
          "quote": "For a large-scale image classification dataset, we consider ImageNet [Deng et al., 2009]."
        }
      },
      {
        "name": {
          "value": "Google Speech Commands Dataset",
          "justification": "The Google Speech Commands Dataset is used for speech data experiments to evaluate the effectiveness of MixupE.",
          "quote": "similar to their work for the speech dataset, we use the Google commands dataset [Warden, 2018]."
        },
        "aliases": [
          "Google Commands"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition",
          "justification": "The Google Speech Commands Dataset is introduced in the paper 'Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition'.",
          "quote": "similar to their work for the speech dataset, we use the Google commands dataset [Warden, 2018]."
        }
      },
      {
        "name": {
          "value": "MUTAG",
          "justification": "The MUTAG dataset is used in the experiments to test MixupE on graph data.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Chemical Applications of Graph Theory",
          "justification": "The MUTAG dataset is originally used in the paper 'Chemical Applications of Graph Theory'.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        }
      },
      {
        "name": {
          "value": "NCI1",
          "justification": "The NCI1 dataset is used in the experiments to test the performance of MixupE on graph data.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The NCI Database Substructure Search Program",
          "justification": "The NCI1 dataset is originally described in the paper 'The NCI Database Substructure Search Program'.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        }
      },
      {
        "name": {
          "value": "PTC",
          "justification": "The PTC dataset is another graph dataset used to validate the performance of MixupE.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Predictive Toxicology Challenge",
          "justification": "The PTC dataset is used in the Predictive Toxicology Challenge (PTC) for validating the model.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        }
      },
      {
        "name": {
          "value": "PROTEINS",
          "justification": "The PROTEINS dataset is used for experiments to evaluate the performance of MixupE on graph data.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Predictive Toxicology Evaluation Challenge",
          "justification": "The PROTEINS dataset is detailed in 'The Predictive Toxicology Evaluation Challenge'.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        }
      },
      {
        "name": {
          "value": "IMDB-BINARY",
          "justification": "The IMDB-BINARY dataset is used to test the effectiveness of MixupE on graph data.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        },
        "aliases": [
          "IMDB-B"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "An Analysis of the Overlap of Actors in Movies for the IMDB Network",
          "justification": "The IMDB-BINARY dataset is detailed in 'An Analysis of the Overlap of Actors in Movies for the IMDB Network'.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        }
      },
      {
        "name": {
          "value": "IMDB-MULTI",
          "justification": "The IMDB-MULTI dataset is used for graph data experiments to benchmark the performance of MixupE.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        },
        "aliases": [
          "IMDB-M"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "An Analysis of the Overlap of Actors in Movies for the IMDB Network",
          "justification": "The IMDB-MULTI dataset is detailed in 'An Analysis of the Overlap of Actors in Movies for the IMDB Network'.",
          "quote": "For graph classification, we consider the MUTAG, NCI1, PTC, PROTEINS, IMDB-BINARY and IMDB-MULTI datasets"
        }
      },
      {
        "name": {
          "value": "UCI Datasets",
          "justification": "The UCI datasets are used for the evaluation of MixupE in experiments involving tabular data.",
          "quote": "For small-scale image datasets, we consider the CIFAR-10, CIFAR-100, SVHN, and Tiny-ImageNet. We run our experiments using a variety of architectures, including PreActResNet18, PreActResNet34, PreActResNet50, PreActResNet101 [He et al., 2016], and Wide-Resnet-28-10 [Zagoruyko and Komodakis, 2016]."
        },
        "aliases": [
          "UCI"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "UCI Machine Learning Repository",
          "justification": "The UCI datasets are hosted in the 'UCI Machine Learning Repository'.",
          "quote": "We consider a number of tabular environments drawn from the UCI dataset [Lichman et al., 2013], namely Arrhythmia, Letter, Balance-scale, Mfeat-factors, Mfeat-fourier, Mfeat-karhunen, Mfeat-morphological, Mfeat-zernike, CMC, Optdigits, Pendigits, Iris, Mnist_784, Abalone and Volkert."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Pytorch",
          "justification": "Pytorch is mentioned as the implementation framework for running the experiments in the discussed domains.",
          "quote": "The code is available at https://github.com/oneHuster/MixupE."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic Differentiation in PyTorch",
          "justification": "Pytorch library is detailed in the paper 'Automatic Differentiation in PyTorch'.",
          "quote": "The code is available at https://github.com/oneHuster/MixupE."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3602,
    "prompt_tokens": 15040,
    "total_tokens": 18642
  }
}