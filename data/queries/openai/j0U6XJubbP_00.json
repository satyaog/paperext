{
  "paper": "j0U6XJubbP.txt",
  "words": 8058,
  "extractions": {
    "title": {
      "value": "Versatile Energy-Based Probabilistic Models for High Energy Physics",
      "justification": "This is the exact title of the paper.",
      "quote": "Versatile Energy-Based Probabilistic Models for High Energy Physics"
    },
    "description": "The paper builds and explores a multi-purpose energy-based probabilistic model for High Energy Physics (HEP) events, leveraging the properties of energy-based models (EBMs) to describe the interactions of elementary particles at the LHC. It also discusses the use of EBMs for tasks such as event generation, signal detection, and event classification in HEP.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper introduces and evaluates an energy-based probabilistic model for HEP events with experiments and results, indicating an empirical approach.",
      "quote": "As summarized in Table 1, we build a multi-tasking framework for High Energy Physics. To that end, we construct an energy-based model of the fundamental interactions of elementary particles to simulate the resulting radiation patterns."
    },
    "primary_research_field": {
      "name": {
        "value": "High Energy Physics",
        "justification": "The primary focus of the paper is exploring energy-based probabilistic models for High Energy Physics (HEP) events at the Large Hadron Collider.",
        "quote": "Motivated by the flexibility in the architecture and the compatibility with different tasks, we explore the potential of EBMs in modeling radiation patterns of elementary particles at high energy."
      },
      "aliases": [
        "HEP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper discusses the use of energy-based models for generative modeling in high energy physics.",
          "quote": "As one important practical application, neural net-based unsupervised learning of physics events have been explored in the usual generative modeling methods including Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs)."
        },
        "aliases": [
          "Generative Modeling"
        ]
      },
      {
        "name": {
          "value": "Anomaly Detection",
          "justification": "The paper explores the use of EBMs for anomaly detection tasks in HEP.",
          "quote": "At the same time, EBMs can serve as generic signal detectors, since out-of-distribution (OOD) detection comes naturally in the form of energy comparison."
        },
        "aliases": [
          "Out-of-Distribution Detection"
        ]
      },
      {
        "name": {
          "value": "Hybrid Modeling",
          "justification": "The paper includes discussions on hybrid modeling combining both generative and discriminative models using EBMs.",
          "quote": "The task of classifying/identifying different Standard Model jet types and the task of searching for beyond the Standard Model signals actually can be unified in a single approach with neural classifiers distinguishing different Standard Model particle types."
        },
        "aliases": [
          "Hybrid Models"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Transformer-based Energy Model",
          "justification": "The paper describes a transformer-based energy model used for describing jets and their inner structures.",
          "quote": "We leverage the self-attention-based transformer to approximate the energy function, which takes into account the higher-order interactions between the component particles."
        },
        "aliases": [
          "Transformer EBM"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The Transformer-based Energy Model is a central focus and contribution of this paper.",
          "quote": "We build a multi-purpose energy-based probabilistic model for High Energy Physics events at the Large Hadron Collider. This framework builds on a powerful generative model and describes higher-order inter-particle interactions."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model's computation would largely benefit from GPU usage, particularly for training large transformer architectures and running MCMC simulations.",
          "quote": "To accelerate training, we employ a relatively small number of MCMC steps."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model is compared to β-VAE and other baselines for performance evaluation.",
          "quote": "In Table 2, we present the Jensen-Shannon Divergence of the high-level observables pT and M distributions between real data and model generation, as the quantitative measure of the generation performance."
        },
        "referenced_paper_title": {
          "value": "Attention is all you need",
          "justification": "The model uses a transformer architecture, which is originally proposed in 'Attention is all you need.'",
          "quote": "We leverage the self-attention-based transformer to approximate the energy function."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Simulated QCD Jets",
          "justification": "The paper uses simulated QCD jets for training and experimentation.",
          "quote": "The training set consists of 300,000 QCD jets."
        },
        "aliases": [
          "QCD Jets"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Qcd jet samples with particle flow constituents",
          "justification": "The dataset referred to is used for different HEP tasks.",
          "quote": "QCD jets are extracted from QCD di-jet events that are generated with MadGraph for LHC 13 TeV, followed by Pythia8 and Delphes for parton shower and fast detector simulation. All jets are clustered using the anti-kT algorithm with cone size R = 1.0 and a selection cut in the jet transverse momentum pT > 450 GeV. We use the particle flow objects for jet clustering."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Adam",
          "justification": "The Adam optimizer is used for optimization during model training.",
          "quote": "We use Adam for optimization, with the momenta β1 = 0.0 and β2 = 0.999."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A method for stochastic optimization",
          "justification": "The paper explicitly mentions using the Adam optimizer, which is a well-known optimization algorithm.",
          "quote": "We use Adam for optimization, with the momenta β1 = 0.0 and β2 = 0.999."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1156,
    "prompt_tokens": 14592,
    "total_tokens": 15748
  }
}