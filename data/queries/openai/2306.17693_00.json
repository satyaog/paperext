{
  "paper": "2306.17693.txt",
  "words": 5543,
  "extractions": {
    "title": {
      "value": "Thompson Sampling for Improved Exploration in GFlowNets",
      "justification": "This is the title of the paper.",
      "quote": "Thompson Sampling for Improved Exploration in GFlowNets"
    },
    "description": "This paper proposes and evaluates an algorithm based on Thompson sampling to improve exploration in Generative Flow Networks (GFlowNets). The algorithm, termed Thompson sampling GFlowNets (TS-GFN), maintains an approximate posterior distribution over policies and samples trajectories from this posterior for training. The paper demonstrates that TS-GFN allows for improved exploration and faster convergence to the target distribution compared to previous exploration strategies used in GFlowNets.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper describes experiments to validate the proposed Thompson sampling method in GFlowNets.",
      "quote": "We validate our method on a grid-world and sequence generation task."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The primary focus of the paper is on enhancing exploration strategies in GFlowNets, which are related to reinforcement learning concepts.",
        "quote": "GFlowNets are typically trained by either sampling trajectories on-policy from the learned sampling policy or off-policy from a mix of the learned policy and random noise."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper discusses Generative Flow Networks (GFlowNets), which are a type of generative model.",
          "quote": "Generative flow networks (GFlowNets; Bengio et al., 2021) are generative models which sequentially construct objects from a space X by taking a series of actions sampled from a learned policy PF."
        },
        "aliases": [
          "GFlowNets"
        ]
      },
      {
        "name": {
          "value": "Bayesian Methods",
          "justification": "The paper employs Bayesian techniques for improving exploration in GFlowNets.",
          "quote": "We view the choice of trajectories for training as an active learning problem and approach it using Bayesian techniques inspired by methods for multi-armed bandits."
        },
        "aliases": [
          "Bayesian Techniques"
        ]
      },
      {
        "name": {
          "value": "Optimization",
          "justification": "The focus of improving the exploration strategy in GFlowNets pertains to optimizing the process of learning the target distribution.",
          "quote": "Thompson sampling (TS; Thompson, 1933) is a method which provably manages the exploration/exploitation problem in settings from multi-armed bandits to reinforcement learning (Agrawal & Jia, 2017; Agrawal & Goyal, 2017) and has been employed to much success across a variety of deep reinforcement learning tasks (Osband et al., 2016a; 2018; 2019)."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Thompson Sampling GFlowNets (TS-GFN)",
          "justification": "TS-GFN is the proposed algorithm in the paper for improved exploration in GFlowNets.",
          "quote": "The proposed algorithm, Thompson sampling GFlowNets (TS-GFN), maintains an approximate posterior distribution over policies and samples trajectories from this posterior for training."
        },
        "aliases": [
          "TS-GFN"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "This model was introduced in the paper.",
          "quote": "The proposed algorithm, Thompson sampling GFlowNets (TS-GFN), maintains an approximate posterior distribution over policies and samples trajectories from this posterior for training."
        },
        "is_executed": {
          "value": 1,
          "justification": "Experiments show the application of TS-GFN.",
          "quote": "Our algorithm is computationally efficient and highly parallelizable, only taking ∼ 15% more computation time than prior approaches."
        },
        "is_compared": {
          "value": 1,
          "justification": "TS-GFN was compared with other models such as on-policy, tempering, and ϵ-noisy in their experiments.",
          "quote": "Models trained with trajectories sampled by TS-GFN converge faster and with very little variance over random seeds to the true distribution than all other exploration strategies."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The referenced paper title is not given as TS-GFN is the main contribution of this paper.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "GFlowNets",
          "justification": "The paper discusses utilizing GFlowNets for generative tasks.",
          "quote": "Generative flow networks (GFlowNets; Bengio et al., 2021) are generative models which sequentially construct objects from a space X by taking a series of actions sampled from a learned policy PF."
        },
        "aliases": [
          "Generative Flow Networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "GFlowNets were introduced in prior research.",
          "quote": "Generative flow networks (GFlowNets; Bengio et al., 2021) are generative models which sequentially construct objects from a space X by taking a series of actions sampled from a learned policy PF."
        },
        "is_executed": {
          "value": 1,
          "justification": "Experiments in the paper utilized GFlowNets.",
          "quote": "Generative flow networks (GFlowNets; Bengio et al., 2021)... A GFlowNet’s policy PF is trained such that, at convergence, the probability of obtaining some object x ∈ X as the result of sampling a sequence of actions from PF is proportional to a reward R(x)."
        },
        "is_compared": {
          "value": 1,
          "justification": "GFlowNets are compared to TS-GFN in the experiments.",
          "quote": "We develop an exploration method for GFlowNets which provides improved convergence to the target distribution even when the reward R(x) is not sparse."
        },
        "referenced_paper_title": {
          "value": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation",
          "justification": "The main referenced paper for GFlowNets is by Bengio et al., 2021.",
          "quote": "Generative flow networks (GFlowNets; Bengio et al., 2021) are generative models which sequentially construct objects from a space X by taking a series of actions sampled from a learned policy PF."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Grid Environment Dataset",
          "justification": "This dataset was used for training and evaluating the TS-GFN algorithm.",
          "quote": "We study a modified version of the grid environment from (Bengio et al., 2021)."
        },
        "aliases": [
          "grid-world",
          "grid environment"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation",
          "justification": "The grid environment is based on the environment described in Bengio et al., 2021.",
          "quote": "We study a modified version of the grid environment from (Bengio et al., 2021)."
        }
      },
      {
        "name": {
          "value": "Synthetic Bit Sequence Dataset",
          "justification": "This dataset was used for evaluating the TS-GFN algorithm.",
          "quote": "We consider the synthetic sequence generation setting from Malkin et al. (2022), where the goal is to generate sequences of bits of fixed length n = 120, resulting in a search space X of size 2^120."
        },
        "aliases": [
          "sequence generation task"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Trajectory Balance: Improved Credit Assignment in GFlowNets",
          "justification": "The sequence generation task references Malkin et al., 2022.",
          "quote": "We consider the synthetic sequence generation setting from Malkin et al. (2022), where the goal is to generate sequences of bits of fixed length n = 120, resulting in a search space X of size 2^120."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Optuna",
          "justification": "Optuna is mentioned as a tool for hyperparameter tuning in the experiments.",
          "quote": "Hyperparameters were tuned using the Optuna Bayesian optimization framework from project Ray (Akiba et al., 2019; Moritz et al., 2018)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Optuna: A Next-generation Hyperparameter Optimization Framework",
          "justification": "The reference for Optuna is Akiba et al., 2019.",
          "quote": "Hyperparameters were tuned using the Optuna Bayesian optimization framework from project Ray (Akiba et al., 2019;"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1682,
    "prompt_tokens": 10583,
    "total_tokens": 12265
  }
}