{
  "paper": "xxfHMqNcum.txt",
  "words": 8178,
  "extractions": {
    "title": {
      "value": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network",
      "justification": "Title of the paper is 'Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network'.",
      "quote": "Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network"
    },
    "description": "This paper introduces a hybrid-grained feature interaction selection approach for deep sparse networks, targeting both feature field and feature value levels. The authors propose a decomposed space and a selection algorithm named OptFeature, which efficiently selects feature interactions from both levels. The method is validated on three large real-world benchmark datasets, demonstrating improvements in terms of accuracy, efficiency, and feasibility.",
    "type": {
      "value": "Empirical",
      "justification": "The paper presents a new method, 'OptFeature', and validates it through extensive experiments on three benchmark datasets.",
      "quote": "\"To explore such expansive space, we propose a decomposed space which is calculated on the fly. We then develop a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously. Results from experiments on three large real-world benchmark datasets demonstrate that OptFeature performs well in terms of accuracy and efficiency.\""
    },
    "primary_research_field": {
      "name": {
        "value": "Recommendation Systems",
        "justification": "The study focuses on deep sparse networks applied in areas like advertisement recommendation and other prediction tasks with high-dimensional sparse features.",
        "quote": "Deep Sparse Networks (DSNs) are commonly utilized neural network architectures for prediction tasks, designed to handle sparse and high-dimensional categorical features as inputs. These networks find widespread application in real-world scenarios such as advertisement recommendation, fraud detection, and more."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Neural Architecture Search",
          "justification": "The paper discusses the use of neural architecture search for feature interaction selection in deep sparse networks.",
          "quote": "Neural architecture search(NAS) [12] has been introduced as a powerful approach for feature interaction selection in DSNs for both efficiency and effectiveness [11, 7, 15]."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Sparse Representations",
          "justification": "The focus on sparse networks and their optimization through feature interaction selection aligns with the field of sparse representations.",
          "quote": "In this work, we propose extending the selection granularity of feature interactions from the field to the value level ... leading to an increase in exploration time and memory usage."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "OptFeature",
          "justification": "The model proposed in the paper is called OptFeature.",
          "quote": "We then develop a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "OptFeature is introduced and developed by the authors of this paper.",
          "quote": "\"we propose a decomposed space which is calculated on the fly. We then develop a selection algorithm called OptFeature\""
        },
        "is_executed": {
          "value": 1,
          "justification": "Experiments were conducted using OptFeature.",
          "quote": "We conduct experiments over three large-scale real-world benchmarks and compare accuracy and efficiency with state-of-the-art models."
        },
        "is_compared": {
          "value": 1,
          "justification": "OptFeature is compared with state-of-the-art models in experiments.",
          "quote": "we conduct experiments over three large-scale real-world benchmarks and compare accuracy and efficiency with state-of-the-art models."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "OptFeature is proposed in the current paper and hence does not reference any previous paper specifically for its introduction.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "DeepFM",
          "justification": "DeepFM is one of the models used for comparison.",
          "quote": "To eliminate the need for human expertise, DeepFM [8] models all second-order feature interactions by utilizing a factorization machine [21] and adopts a multi-layer perceptron (MLP) as a predictor."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model was used for experimental comparison and was not introduced by this paper.",
          "quote": "To eliminate the need for human expertise, DeepFM [8] models all second-order feature interactions by utilizing a factorization machine [21] and adopts a multi-layer perceptron (MLP) as a predictor."
        },
        "is_executed": {
          "value": 1,
          "justification": "DeepFM was used and executed in the experiments.",
          "quote": "We then developed a selection algorithm named OptFeature (short for Optimizing Feature Interaction Selection), which efficiently selects the feature interaction concurrently from both feature fields and feature values .. We conduct experiments over three large-scale real-world benchmarks and compare accuracy and efficiency with state-of-the-art models."
        },
        "is_compared": {
          "value": 1,
          "justification": "DeepFM was compared with OptFeature in the experiments.",
          "quote": "Experiments conducted on three real-world benchmark datasets validate the effectiveness and efficiency of our method."
        },
        "referenced_paper_title": {
          "value": "Deepfm: A factorization-machine based neural network for ctr prediction.",
          "justification": "The referenced paper for DeepFM is provided in the citations.",
          "quote": "\"Deepfm: A factorization-machine based neural network for ctr prediction. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, pages 1725â€“1731, Melbourne, Australia, 2017. ijcai.org.\""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Criteo",
          "justification": "Criteo is mentioned multiple times as one of the datasets used for experiments.",
          "quote": "We conduct experiments over three large-scale real-world benchmarks and compare accuracy and efficiency with state-of-the-art models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Criteo dataset is publicly available and commonly used in CTR prediction tasks.",
          "quote": "https://www.kaggle.com/c/criteo-display-ad-challenge"
        }
      },
      {
        "name": {
          "value": "Avazu",
          "justification": "Avazu is used in the experiments for validating the proposed model.",
          "quote": "We conduct experiments over three large-scale real-world benchmarks and compare accuracy and efficiency with state-of-the-art models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Avazu dataset is publicly available and commonly used in CTR prediction tasks.",
          "quote": "http://www.kaggle.com/c/avazu-ctr-prediction"
        }
      },
      {
        "name": {
          "value": "KDD12",
          "justification": "KDD12 is explicitly mentioned as one of the datasets used for experiments.",
          "quote": "We conduct experiments over three large-scale real-world benchmarks and compare accuracy and efficiency with state-of-the-art models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "KDD12 dataset is publicly available and commonly used in CTR prediction tasks.",
          "quote": "http://www.kddcup2012.org/c/kddcup2012-track2/data"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1760,
    "prompt_tokens": 14746,
    "total_tokens": 16506
  }
}