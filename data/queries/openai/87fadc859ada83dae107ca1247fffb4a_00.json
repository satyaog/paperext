{
  "paper": "87fadc859ada83dae107ca1247fffb4a.txt",
  "words": 1674,
  "extractions": {
    "title": {
      "value": "Latent Space Evolution under Incremental Learning with Concept Drift (Student Abstract)",
      "justification": "The title is explicitly provided at the top of the research paper.",
      "quote": "Latent Space Evolution under Incremental Learning with Concept Drift (Student Abstract)"
    },
    "description": "This work investigates the evolution of latent space when deep learning models are trained incrementally in non-stationary environments caused by virtual concept drift. The paper proposes a methodology for visualizing changes in latent representations and demonstrates how classes not targeted by concept drift can be negatively affected.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves experiments and qualitative analysis to support its findings, indicating an empirical study.",
      "quote": "In the following section, we investigate the performance impact of incrementally learning from an environment which undergoes virtual concept drift. Using the well-known MNIST dataset ... We first show that in a non-stationary environment, ... These results are supported by our final qualitative analysis of the latent representation evolution."
    },
    "primary_research_field": {
      "name": {
        "value": "Incremental Learning",
        "justification": "The primary focus of the paper is on incremental learning in non-stationary environments.",
        "quote": "Incremental Learning consists in pursuing the training of a model on new data without accessing previous data."
      },
      "aliases": [
        "Sequential Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Concept Drift",
          "justification": "The study specifically addresses issues related to concept drift and its impact on incremental learning.",
          "quote": "This work investigates the evolution of latent space when deep learning models are trained incrementally in non-stationary environments that stem from concept drift."
        },
        "aliases": [
          "Virtual Concept Drift"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Multi-Layer Perceptron",
          "justification": "The paper uses a multi-layer perceptron with two hidden layers as the deep neural network for the experiments.",
          "quote": "We use a multi-layer perceptron with two hidden layers of width 20, optimized over a cross entropy loss using SGD and learning rate of 0.05."
        },
        "aliases": [
          "MLP"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The multi-layer perceptron is a well-known model and is not contributed by the authors.",
          "quote": "We use a multi-layer perceptron with two hidden layers of width 20, optimized over a cross entropy loss using SGD and learning rate of 0.05."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is executed as part of the experiments conducted by the authors.",
          "quote": "We use a multi-layer perceptron with two hidden layers of width 20, optimized over a cross entropy loss using SGD and learning rate of 0.05."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not compare the multi-layer perceptron with other models.",
          "quote": "Table 1 shows the results of the incremental learning experiments. We observe that the overall performance appears to remain stable, while the accuracy of the under-represented class decreases drastically."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There is no specific reference paper for the multi-layer perceptron model used in this study.",
          "quote": "We use a multi-layer perceptron with two hidden layers of width 20, optimized over a cross entropy loss using SGD and learning rate of 0.05."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "The MNIST dataset is used in the experiments to create a virtual concept drift problem.",
          "quote": "Using the well-known MNIST dataset (Lecun et al. 1998), we artificially create a virtual concept drift problem."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Gradient-based learning applied to document recognition",
          "justification": "The referenced paper is cited to credit the original source of the MNIST dataset.",
          "quote": "Using the well-known MNIST dataset (Lecun et al. 1998), we artificially create a virtual concept drift problem."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 819,
    "prompt_tokens": 3907,
    "total_tokens": 4726
  }
}