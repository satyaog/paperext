{
  "paper": "2310.14001.txt",
  "words": 12674,
  "extractions": {
    "title": {
      "value": "Toward Stronger Textual Attack Detectors",
      "justification": "The title is explicitly mentioned at the top of the paper.",
      "quote": "Toward Stronger Textual Attack Detectors"
    },
    "description": "This paper introduces LAROUSSE, a new framework to detect textual adversarial attacks, and STAKEOUT, a new benchmark consisting of nine attack methods, three datasets, and two pre-trained models. It aims to enhance the detection of textual adversarial attacks in NLP systems.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves the empirical evaluation of the proposed methods (LAROUSSE and STAKEOUT) using numerical experiments and benchmark comparisons.",
      "quote": "We conduct extensive numerical experiments which demonstrate that LAROUSSE outperforms previous methods, and which allows to identify interesting factors of detection rate variations."
    },
    "primary_research_field": {
      "name": {
        "value": "Adversarial Attacks in Natural Language Processing",
        "justification": "The main focus of the paper is on detecting adversarial attacks in natural language processing models.",
        "quote": "The landscape of available textual adversarial attacks keeps growing, posing severe threats and raising concerns regarding the deep NLP systemâ€™s integrity."
      },
      "aliases": [
        "Adversarial NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Textual Adversarial Attack Detection",
          "justification": "The paper specifically aims at detecting adversarial attacks on text data in NLP systems.",
          "quote": "This paper makes two important contributions in this line of search: (i) we introduce LAROUSSE, a new framework to detect textual adversarial attacks."
        },
        "aliases": [
          "Adversarial Text Detection"
        ]
      },
      {
        "name": {
          "value": "NLP Benchmarking",
          "justification": "The paper introduces a new benchmark STAKEOUT for evaluating adversarial attack detection methods in NLP.",
          "quote": "we introduce STAKEOUT, a new benchmark composed of nine popular attack methods, three datasets, and two pre-trained models."
        },
        "aliases": [
          "NLP Benchmarks"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "LAROUSSE",
          "justification": "LAROUSSE is the main model introduced in the paper for detecting textual adversarial attacks.",
          "quote": "we introduce LAROUSSE, a new framework to detect textual adversarial attacks."
        },
        "aliases": [
          "textuaL AdversaRial detectOr Using halfSpace maSs dEpth"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "LAROUSSE is a direct contribution of this paper.",
          "quote": "we introduce LAROUSSE, a new framework to detect textual adversarial attacks."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper mentions that numerical experiments were conducted using LAROUSSE, which implies it was executed.",
          "quote": "we conduct extensive numerical experiments which demonstrate that LAROUSSE outperforms previous methods."
        },
        "is_compared": {
          "value": 1,
          "justification": "LAROUSSE is compared with other methods in terms of performance in the experimental section.",
          "quote": "we conduct extensive numerical experiments which demonstrate that LAROUSSE outperforms previous methods."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "LAROUSSE is presented as a new framework in this paper; it does not have a reference paper.",
          "quote": "we introduce LAROUSSE, a new framework to detect textual adversarial attacks."
        }
      },
      {
        "name": {
          "value": "BERT",
          "justification": "BERT is one of the pre-trained models used in the benchmark experiments in the paper.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "aliases": [
          "BERT-base"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "BERT is not a contribution of this paper, but it is used for the evaluations.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper mentions that BERT was used in the STAKEOUT benchmark experiments.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "is_compared": {
          "value": 1,
          "justification": "BERT's performance is compared with other models in the experiments.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "referenced_paper_title": {
          "value": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
          "justification": "The referenced paper for BERT is 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding'.",
          "quote": "In order to ensure that our conclusions are not model specific, we work with classifiers that are based on two types of pre-trained encoders: BERT [Devlin et al., 2019] and ROBERTA (ROB) [Liu et al., 2019]."
        }
      },
      {
        "name": {
          "value": "ROBERTA",
          "justification": "ROBERTA is one of the pre-trained models used in the benchmark experiments in the paper.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "aliases": [
          "ROB"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ROBERTA is not a contribution of this paper, but it is used for the evaluations.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "is_executed": {
          "value": 1,
          "justification": "ROBERTA was used in the STAKEOUT benchmark experiments.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "is_compared": {
          "value": 1,
          "justification": "ROBERTA's performance is compared with other models in the experiments.",
          "quote": "We work with classifiers that are based on two types of pre-trained encoders: BERT and ROBERTA."
        },
        "referenced_paper_title": {
          "value": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
          "justification": "The referenced paper for ROBERTA is 'RoBERTa: A Robustly Optimized BERT Pretraining Approach'.",
          "quote": "In order to ensure that our conclusions are not model specific, we work with classifiers that are based on two types of pre-trained encoders: BERT [Devlin et al., 2019] and ROBERTA (ROB) [Liu et al., 2019]."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "SST2",
          "justification": "SST2 is one of the datasets used for the benchmark in this paper.",
          "quote": "We choose to work on sentiment analysis, using SST2 [Socher et al., 2013] and IMDB [Maas et al., 2011], and topic classification, relying on ag-news [Joachims, 1996]."
        },
        "aliases": [
          "Sentiment Treebank"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank",
          "justification": "The referenced paper for SST2 is 'Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank'.",
          "quote": "We choose to work on sentiment analysis, using SST2 [Socher et al., 2013] and IMDB [Maas et al., 2011], and topic classification, relying on ag-news [Joachims, 1996]."
        }
      },
      {
        "name": {
          "value": "IMDB",
          "justification": "IMDB is one of the datasets used for the benchmark in this paper.",
          "quote": "We choose to work on sentiment analysis, using SST2 [Socher et al., 2013] and IMDB [Maas et al., 2011], and topic classification, relying on ag-news [Joachims, 1996]."
        },
        "aliases": [
          "Internet Movie Database"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Word Vectors for Sentiment Analysis",
          "justification": "The referenced paper for IMDB is 'Learning Word Vectors for Sentiment Analysis'.",
          "quote": "We choose to work on sentiment analysis, using SST2 [Socher et al., 2013] and IMDB [Maas et al., 2011], and topic classification, relying on ag-news [Joachims, 1996]."
        }
      },
      {
        "name": {
          "value": "ag-news",
          "justification": "ag-news is one of the datasets used for the benchmark in this paper.",
          "quote": "We choose to work on sentiment analysis, using SST2 [Socher et al., 2013] and IMDB [Maas et al., 2011], and topic classification, relying on ag-news [Joachims, 1996]."
        },
        "aliases": [
          "AG News Corpus"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization",
          "justification": "The referenced paper for ag-news is 'A Probabilistic Analysis of the Rocchio Algorithm with TFIDF for Text Categorization'.",
          "quote": "We choose to work on sentiment analysis, using SST2 [Socher et al., 2013] and IMDB [Maas et al., 2011], and topic classification, relying on ag-news [Joachims, 1996]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is mentioned as one of the deep learning libraries used for implementing the models.",
          "quote": "All our models and detectors are implemented with PyTorch."
        },
        "aliases": [
          "pytorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic Differentiation in PyTorch",
          "justification": "The referenced paper for PyTorch is 'Automatic Differentiation in PyTorch'.",
          "quote": "All our models and detectors are implemented with PyTorch."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2018,
    "prompt_tokens": 26757,
    "total_tokens": 28775
  }
}