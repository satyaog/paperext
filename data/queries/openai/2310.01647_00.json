{
  "paper": "2310.01647.txt",
  "words": 8737,
  "extractions": {
    "title": {
      "value": "Equivariant Adaptation of Large Pretrained Models",
      "justification": "It's the title of the paper mentioned in the provided text.",
      "quote": "Equivariant Adaptation of Large Pretrained Models"
    },
    "description": "This paper focuses on making large pretrained neural network models equivariant to certain transformations, such as rotations, by using a canonicalization network to transform input data to a canonical form before feeding it to the prediction network. The proposed method improves the robustness of pretrained models to these transformations without compromising performance.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper demonstrates empirical results and improvements in robustness through various experiments and datasets.",
      "quote": "Our extensive experimental results using different pretrained models, datasets, and modalities give insight into this subtle issue and demonstrate the viability of our proposed solution."
    },
    "primary_research_field": {
      "name": {
        "value": "Equivariant Deep Learning",
        "justification": "The paper's main contribution is introducing a method to adapt large pretrained models to be equivariant to certain transformations.",
        "quote": "Our proposed equivariant adaptation of large pretrained models can help their domain-specific applications with known symmetry priors."
      },
      "aliases": [
        "Equivariance in Deep Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The paper extensively discusses applications and improvements in computer vision tasks, like classification and segmentation in datasets like CIFAR10 and COCO.",
          "quote": "As such, they have emerged as a promising solution to a wide range of computer vision and point cloud processing tasks [7, 9, 10, 15–20], including classification, object recognition, and segmentation, among others."
        },
        "aliases": [
          "CV"
        ]
      },
      {
        "name": {
          "value": "Point Cloud Processing",
          "justification": "The methods are also applied to point cloud processing tasks, as evidenced by the experiments with datasets like ModelNet40 and ShapeNet.",
          "quote": "As such, they have emerged as a promising solution to a wide range of computer vision and point cloud processing tasks [7, 9, 10, 15–20], including classification, object recognition, and segmentation, among others."
        },
        "aliases": [
          "PCL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Segment Anything Model (SAM)",
          "justification": "The Segment Anything Model (SAM) is explicitly mentioned in the experiment section and figures as a large pretrained model adapted using the proposed method.",
          "quote": "Figure 1: Predicted masks from the Segment Anything Model (SAM) [21], showcasing both the original model and our proposed equivariant adaptation for 90◦ counter-clockwise rotated input images taken from the COCO 2017 dataset [22]."
        },
        "aliases": [
          "SAM"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "SAM is referenced as an existing model, not introduced by this paper.",
          "quote": "Segment Anything Model (SAM) [21]"
        },
        "is_executed": {
          "value": 1,
          "justification": "SAM was used in the experiments to showcase the effectiveness of the proposed method.",
          "quote": "Figure 1: Predicted masks from the Segment Anything Model (SAM) [21], showcasing both the original model and our proposed equivariant adaptation."
        },
        "is_compared": {
          "value": 1,
          "justification": "SAM's performance was compared before and after applying the proposed method, both in the original and transformed dataset.",
          "quote": "Our method makes SAM equivariant to the group of 90◦ rotations while only requiring 0.3% extra parameters and modestly increasing the inference time by 7.3%."
        },
        "referenced_paper_title": {
          "value": "Segment Anything",
          "justification": "[21] in the paper refers to SAM, confirming its title as 'Segment Anything'.",
          "quote": "Segment Anything Model (SAM) [21]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "COCO 2017",
          "justification": "COCO 2017 is explicitly mentioned in relation to the experiments conducted with SAM and Mask R-CNN, involving the proposed equivariant adaptation method.",
          "quote": "Predicted masks from the Segment Anything Model (SAM) [21], showcasing both the original model and our proposed equivariant adaptation for 90◦ counter-clockwise rotated input images taken from the COCO 2017 dataset [22]."
        },
        "aliases": [
          "Common Objects in Context 2017"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Microsoft COCO: Common Objects in Context",
          "justification": "[22] in the paper refers to the dataset COCO, confirming its title as 'Microsoft COCO: Common Objects in Context'.",
          "quote": "COCO 2017 dataset [22]"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "ES-CNN",
          "justification": "The paper mentions using the ES-CNN library to design equivariant convolutional architectures for the canonicalization network.",
          "quote": "We extensively use escnn library [15, 50] to design equivariant convolutional architectures."
        },
        "aliases": [
          "e2cnn"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "A program to build E(N)-equivariant CNNs",
          "justification": "[15, 50] in the paper refers to the ES-CNN library, confirming its title as 'A program to build E(N)-equivariant CNNs'.",
          "quote": "We extensively use escnn library [15, 50] to design equivariant convolutional architectures."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1080,
    "prompt_tokens": 15540,
    "total_tokens": 16620
  }
}