{
  "paper": "2312.10725.txt",
  "words": 8424,
  "extractions": {
    "title": {
      "value": "Addressing Sample Inefficiency in Multi-View Representation Learning",
      "justification": "This is the title of the paper as mentioned at the beginning of the text.",
      "quote": "Addressing Sample Inefficiency in Multi-View Representation Learning"
    },
    "description": "The paper provides theoretical insights into the implicit bias of non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins and VICReg. It challenges existing heuristics, demonstrates empirical findings that support sample efficiency improvements, and offers practical pretraining recommendations.",
    "type": {
      "value": "theoretical study",
      "justification": "The paper provides theoretical insights and analyses into the implicit bias of NC-SSL methods and supports these with empirical findings.",
      "quote": "we provide theoretical insights on the implicit bias of the BarlowTwins and VICReg loss that can explain these heuristics and guide the development of more principled recommendations."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper focuses on representation learning techniques in computer vision using self-supervised methods.",
        "quote": "Non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins and VICReg have shown great promise for label-free representation learning in computer vision."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper specifically addresses self-supervised learning methods and their sample inefficiency.",
          "quote": "Modern approaches, grouped under the self-supervised learning (SSL) umbrella, build on the core insight that similar images should map to nearby points in the learned feature space."
        },
        "aliases": [
          "SSL"
        ]
      },
      {
        "name": {
          "value": "Contrastive and Non-Contrastive Learning",
          "justification": "The paper categorizes existing self-supervised learning methods into contrastive and non-contrastive algorithms and focuses on non-contrastive methods.",
          "quote": "Current SSL methods can be broadly categorized into contrastive and non-contrastive algorithms."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "BarlowTwins",
          "justification": "BarlowTwins is one of the NC-SSL methods analyzed and discussed in the paper.",
          "quote": "Non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins and VICReg have shown great promise for label-free representation learning in computer vision."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model is not proposed as a contribution by the authors of this paper but is studied within the context of the research.",
          "quote": "Non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins and VICReg have shown great promise for label-free representation learning in computer vision."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes empirical findings and results using the BarlowTwins model.",
          "quote": "Based on this, we empirically demonstrate that low-dimensional projector heads are sufficient with appropriate regularization, contrary to the existing heuristic."
        },
        "is_compared": {
          "value": 1,
          "justification": "BarlowTwins is compared with other models like VICReg in the scope of the paper.",
          "quote": "Based on this, we empirically demonstrate that low-dimensional projector heads are sufficient with appropriate regularization, contrary to the existing heuristic."
        },
        "referenced_paper_title": {
          "value": "Barlow twins: Self-supervised learning via redundancy reduction",
          "justification": "This is the reference paper title for the BarlowTwins model, as mentioned in the citations.",
          "quote": "BarlowTwins [ZJM+ 21]"
        }
      },
      {
        "name": {
          "value": "VICReg",
          "justification": "VICReg is another NC-SSL method analyzed and discussed in the paper.",
          "quote": "Non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins and VICReg have shown great promise for label-free representation learning in computer vision."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model is not proposed as a contribution by the authors of this paper but is studied within the context of the research.",
          "quote": "Non-contrastive self-supervised learning (NC-SSL) methods like BarlowTwins and VICReg have shown great promise for label-free representation learning in computer vision."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes empirical findings and results using the VICReg model.",
          "quote": "Based on this, we empirically demonstrate that low-dimensional projector heads are sufficient with appropriate regularization, contrary to the existing heuristic."
        },
        "is_compared": {
          "value": 1,
          "justification": "VICReg is compared with other models like BarlowTwins in the scope of the paper.",
          "quote": "Based on this, we empirically demonstrate that low-dimensional projector heads are sufficient with appropriate regularization, contrary to the existing heuristic."
        },
        "referenced_paper_title": {
          "value": "VICReg: Variance-invariance-covariance regularization for self-supervised learning",
          "justification": "This is the reference paper title for the VICReg model, as mentioned in the citations.",
          "quote": "VICReg [BPL21]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The CIFAR-10 dataset is used for empirical evaluations in the paper.",
          "quote": "Combining these insights, we present practical pretraining recommendations that improve wall-clock time by 2x and improve performance on CIFAR-10/STL-10 datasets using a ResNet-50 backbone."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "This is the reference paper title for the CIFAR-10 dataset, as mentioned in the citations.",
          "quote": "CIFAR-10 [KH09]"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1172,
    "prompt_tokens": 15174,
    "total_tokens": 16346
  }
}