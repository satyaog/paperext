{
  "paper": "2403.19421.txt",
  "words": 8478,
  "extractions": {
    "title": {
      "value": "Scaling up ridge regression for brain encoding in a massive individual fMRI dataset",
      "justification": "The title clearly states the core focus of the paper: improving the scalability of ridge regression models for brain encoding using a large fMRI dataset.",
      "quote": "Scaling up ridge regression for brain encoding in a massive individual fMRI dataset"
    },
    "description": "This paper evaluates various parallelization techniques to enhance the efficiency of training ridge regression models for brain encoding tasks using fMRI data from the CNeuroMod Friends dataset. The study benchmarks different multi-threading and distributed approaches to reduce the computational time of training these models with high-dimensional data, utilizing libraries such as Intel MKL, OpenBLAS, and Dask.",
    "type": {
      "value": "empirical study",
      "justification": "The paper is empirical as it evaluates the efficiency of different parallelization techniques by performing experiments on the CNeuroMod Friends dataset.",
      "quote": "This paper evaluates different parallelization techniques to reduce the training time of brain encoding with ridge regression on the CNeuroMod Friends dataset"
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research revolves around improving machine learning models and techniques, specifically within the realm of deep learning for brain encoding tasks.",
        "quote": "Brain encoding with neuroimaging data is an established analysis aimed at predicting human brain activity directly from complex stimuli features such as movie frames. Typically, these features are the latent space representation from an artificial neural network..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Neuroimaging and Brain Encoding",
          "justification": "The specific application area of deep learning in this paper is neuroimaging and brain encoding, focusing on predicting brain activity from visual stimuli using complex machine learning models.",
          "quote": "For brain encoding of visual tasks, ridge regression is often applied to the activations produced by various neural networks architectures in response to visual stimuli, such as convolutional neural networks (CNN) and transformers"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "VGG16",
          "justification": "The paper uses a pretrained VGG16 model to extract visual features from movie frames for predicting brain activity.",
          "quote": "In this work, we used the approach of [12, 37], and applied a VGG16 model [38] pretrained for image classification to extract visual features from the movie frames."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CNeuroMod Friends dataset",
          "justification": "The CNeuroMod Friends dataset was used as the primary source of fMRI data to train the brain encoding models in this study.",
          "quote": "We used the 2020-alpha2 release of the Friends fMRI dataset collected by the Courtois project on neuronal modeling, CNeuroMod [30]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Intel Math Kernel Library",
          "justification": "The Intel Math Kernel Library (MKL) was used to optimize multi-threaded linear algebra operations for ridge regression.",
          "quote": "With multi-threading, our results show that the Intel Math Kernel Library (MKL) significantly outperforms the OpenBLAS library, being 1.9 times faster using 32 threads on a single machine."
        },
        "aliases": [
          "MKL"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "OpenBLAS",
          "justification": "OpenBLAS was used as another option for multi-threaded linear algebra operations in the benchmark experiments.",
          "quote": "With multi-threading, our results show that the Intel Math Kernel Library (MKL) significantly outperforms the OpenBLAS library, being 1.9 times faster using 32 threads on a single machine."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "scikit-learn",
          "justification": "Scikit-learn was the primary machine learning library used for implementing ridge regression and performing benchmarks.",
          "quote": "We used the scikit-learn library [26] for brain encoding, that provides efficient implementations of various machine-learning models, including ridge regression."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Dask",
          "justification": "Dask was employed for distributed parallelism, dividing computation across multiple compute nodes to accelerate training.",
          "quote": "Moreover, scikit-learn models rely on the Joblib library to interface with various parallelization backends including Dask [29], which can be used to distribute computations across multiple compute nodes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 945,
    "prompt_tokens": 14106,
    "total_tokens": 15051
  }
}