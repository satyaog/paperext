{
  "paper": "d79e11dbb374dd07cdfa32e0424c88fa.txt",
  "words": 13840,
  "extractions": {
    "title": {
      "value": "On Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes",
      "justification": "This is the exact title of the given paper.",
      "quote": "On Dynamic Programming Decompositions of Static Risk Measures in Markov Decision Processes"
    },
    "description": "This paper investigates the optimization of static risk-averse objectives in Markov decision processes (MDPs), highlighting the suboptimality of popular dynamic programming decompositions for Conditional-Value-at-Risk (CVaR) and Entropic-Value-at-Risk (EVaR). It also proposes a correct decomposition for Value-at-Risk (VaR).",
    "type": {
      "value": "theoretical study",
      "justification": "The paper primarily focuses on theoretical aspects such as the correctness of dynamic programming decompositions for different risk measures in MDPs.",
      "quote": "Our findings are significant because risk-averse algorithms are used in high-stakes environments, making their correctness much more critical."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper discusses dynamic programming decompositions in the context of Markov decision processes, which are central topics in reinforcement learning.",
        "quote": "Dynamic programming, the linchpin of most RL algorithms, cannot be used directly to optimize a risk measure like VaR or CVaR in MDPs."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Risk-Averse Reinforcement Learning",
          "justification": "The paper focuses on optimizing risk-averse objectives in MDPs, discussing CVaR, EVaR, and VaR in the context of reinforcement learning.",
          "quote": "Risk-averse reinforcement learning (RL) seeks to provide a risk-averse policy for high-stakes real-world decision problems."
        },
        "aliases": [
          "Risk-Averse RL",
          "RARL"
        ]
      }
    ],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 374,
    "prompt_tokens": 26858,
    "total_tokens": 27232
  }
}