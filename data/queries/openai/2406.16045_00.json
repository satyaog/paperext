{
  "paper": "2406.16045.txt",
  "words": 11561,
  "extractions": {
    "title": {
      "value": "Combine and Conquer: A Meta-Analysis on Data Shift and Out-of-Distribution Detection",
      "justification": "This is the complete title of the paper extracted from the provided text.",
      "quote": "Combine and Conquer: A Meta-Analysis on Data Shift and Out-of-Distribution Detection"
    },
    "description": "This paper introduces a universal approach to combine out-of-distribution (OOD) detection scores through quantile normalization and meta-analysis tools, resulting in a robust OOD detector. The paper investigates performance across different types of data shifts, showcasing the framework's superiority in robustness and flexibility.",
    "type": {
      "value": "empirical study",
      "justification": "The paper includes empirical investigations to validate its contributions.",
      "quote": "Through empirical investigation, we explore different types of shifts, each exerting varying degrees of impact on data."
    },
    "primary_research_field": {
      "name": {
        "value": "Out-of-Distribution Detection",
        "justification": "The paper primarily deals with out-of-distribution detection methods and their combination for better robustness.",
        "quote": "A Meta-Analysis on Data Shift and Out-of-Distribution Detection"
      },
      "aliases": [
        "OOD Detection"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Data Shift",
          "justification": "The paper investigates methodologies for detecting and managing data distribution shifts in deep learning models.",
          "quote": "One of the most pressing issues is preventing and reacting to data distribution shift"
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Machine Learning Model Evaluation",
          "justification": "The paper deals with the evaluation of machine learning models under data shift and OOD scenarios.",
          "quote": "This paper explores ways to improve the detection of performance-degrading shifts"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-50",
          "justification": "ResNet-50 is used as a classifier in the empirical evaluations for OOD detection benchmarking.",
          "quote": "Table 2 displays the experimental result on classic OOD detection for a ResNet-50 model on the setup described in Section 5.1"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "ResNet-50 is a standard model used for evaluations and is not contributed by this paper.",
          "quote": "the setup described in Section 5.1"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is executed to benchmark the OOD detection scores.",
          "quote": "ResNet-50 model on the setup described in Section 5.1"
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares ResNet-50 with other models in benchmark scenarios.",
          "quote": "Table 2 displays the experimental result on classic OOD detection for a ResNet-50 model"
        },
        "referenced_paper_title": {
          "value": "Deep residual learning for image recognition",
          "justification": "ResNet-50 originated from the paper titled 'Deep residual learning for image recognition'.",
          "quote": "He et al. 2016"
        }
      },
      {
        "name": {
          "value": "Vision Transformer (ViT-L-16)",
          "justification": "ViT-L-16 is used for evaluating OOD detection in the benchmarks provided in the study.",
          "quote": "Similar experiments were ran for ViT-L-16 as shown in Figure 11"
        },
        "aliases": [
          "ViT-L-16"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ViT-L-16 is another model used for evaluations and is not contributed by this paper.",
          "quote": "Vision Transformers (Dosovitskiy et al., 2021)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is executed in multiple benchmark scenarios.",
          "quote": "Figure 11 shows the covariate shift detection performance for ViT-L-16"
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper involves comparisons of ViT-L-16 with other models.",
          "quote": "Figure 11 shows the covariate shift detection performance for ViT-L-16"
        },
        "referenced_paper_title": {
          "value": "An image is worth 16x16 words: Transformers for image recognition at scale",
          "justification": "ViT-L-16 is derived from the paper titled 'An image is worth 16x16 words: Transformers for image recognition at scale'.",
          "quote": "Dosovitskiy et al., 2021"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet-1K",
          "justification": "ImageNet-1K is used as the in-distribution dataset in OOD detection experiments.",
          "quote": "For all our main experiments, we set as in-distribution dataset ImageNet-1K"
        },
        "aliases": [
          "ILSVRC2012"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "ImageNet-1K is originally from 'ImageNet: A Large-Scale Hierarchical Image Database'.",
          "quote": "Deng et al., 2009"
        }
      },
      {
        "name": {
          "value": "OpenImage-O",
          "justification": "OpenImage-O is utilized for out-of-distribution detection validation.",
          "quote": "from the OpenImage-O (OI-O) (Wang et al., 2022) dataset"
        },
        "aliases": [
          "OI-O"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "OpenImages: A public dataset for large-scale multi-label and multi-class image classification",
          "justification": "OpenImage-O is a subset of OpenImages dataset addressed in 'OpenImages: A public dataset for large-scale multi-label and multi-class image classification'.",
          "quote": "OpenImage-O (OI-O) (Wang et al., 2022)"
        }
      },
      {
        "name": {
          "value": "ImageNet-R",
          "justification": "ImageNet-R is used for covariate shift simulations in evaluation.",
          "quote": "To simulate a covariate shift at test time, we ran experiments with the ImageNet-R (IN-R) (Hendrycks et al., 2021) dataset"
        },
        "aliases": [
          "IN-R"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The many faces of robustness: A critical analysis of out-of-distribution generalization",
          "justification": "ImageNet-R is referenced in the paper 'The many faces of robustness: A critical analysis of out-of-distribution generalization'.",
          "quote": "Hendrycks et al., 2021"
        }
      },
      {
        "name": {
          "value": "ImageNet-C",
          "justification": "ImageNet-C is referenced for sequential drift detection tasks in evaluation.",
          "quote": "To simulate a progressive sequential drift in a data stream, we ran experiments with the corrupted ImageNet (IN-C) (Hendrycks & Dietterich, 2019) dataset."
        },
        "aliases": [
          "IN-C"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking neural network robustness to common corruptions and perturbations",
          "justification": "ImageNet-C is derived from the paper 'Benchmarking neural network robustness to common corruptions and perturbations'.",
          "quote": "Hendrycks & Dietterich, 2019"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 3119,
    "prompt_tokens": 47090,
    "total_tokens": 50209
  }
}