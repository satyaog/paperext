{
  "paper": "2310.19391.txt",
  "words": 11709,
  "extractions": {
    "title": {
      "value": "Bridging Causality, Individual Fairness, and Adversarial Robustness in the Absence of Structural Causal Model",
      "justification": "The title is the header of the paper.",
      "quote": "B RIDGING C AUSALITY, I NDIVIDUAL FAIRNESS , AND A DVERSARIAL ROBUSTNESS IN THE A BSENCE OF S TRUCTURAL C AUSAL M ODEL"
    },
    "description": "This paper aims to address the intersection of causality, fairness, and robustness in machine learning models. It introduces a causal fair metric that incorporates sensitive attributes and protected causal perturbation, deploying these metrics in real-world scenarios without the requirement of structural causal models (SCMs). The work also covers metric learning to empirically derive these metrics, enhancing classifier effectiveness in terms of fairness and adversarial robustness.",
    "type": {
      "value": "Empirical Study",
      "justification": "Multiple empirical evaluations and experiments, such as on synthetic and real-world datasets, are conducted to validate the proposed metrics and methods.",
      "quote": "Empirical evaluation of real-world and synthetic datasets illustrates the effectiveness of our proposed metric in achieving an accurate classifier with fairness, resilience to adversarial perturbations, and a nuanced understanding of causal relationships."
    },
    "primary_research_field": {
      "name": {
        "value": "Fairness in AI",
        "justification": "The primary focus is the intersection of fairness, causal inference, and adversarial robustness within AI systems.",
        "quote": "Despite the essential need for comprehensive considerations in responsible AI, factors like robustness, fairness, and causality are often studied in isolation."
      },
      "aliases": [
        "Responsible AI",
        "AI Fairness"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Adversarial Robustness",
          "justification": "A significant component involves enhancing adversarial robustness using the proposed causal fair metrics.",
          "quote": "We use our proposed causal fair metric to generate adversarial perturbation within causal structures while addressing fairness concerns."
        },
        "aliases": [
          "Robustness in AI"
        ]
      },
      {
        "name": {
          "value": "Causal Inference",
          "justification": "The paper develops metrics and methods that consider underlying causal structures.",
          "quote": "we introduce a definition for a causal fair metric applicable to any SCM, effectively addressing both causality and the protection of sensitive attributes."
        },
        "aliases": [
          "Causal ML",
          "Causality in Machine Learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Siamese Network",
          "justification": "The Siamese Network is used as a baseline model for various scenarios within metric learning, crucial for deriving and validating the proposed causal fair metric.",
          "quote": "We regard the Siamese metric learning method as our baseline across various scenarios."
        },
        "aliases": [
          "Siamese Network Baseline"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The Siamese Network is used as a baseline model, not a novel contribution of this paper.",
          "quote": "We regard the Siamese metric learning method as our baseline across various scenarios."
        },
        "is_executed": {
          "value": 1,
          "justification": "The Siamese Network was executed as part of the experiments conducted in the paper.",
          "quote": "We regard the Siamese metric learning method as our baseline across various scenarios."
        },
        "is_compared": {
          "value": 1,
          "justification": "The effectiveness of the Siamese Network is compared against the proposed metrics and alternative methods.",
          "quote": "We regard the Siamese metric learning method as our baseline across various scenarios."
        },
        "referenced_paper_title": {
          "value": "Siamese Neural Networks: An Overview",
          "justification": "The referenced paper provides an overview and context of Siamese Network applications, validating its use and comparison in this study.",
          "quote": "Siamese neural networks: An overview. Artificial neural networks, pages 73â€“94, 2021."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Adult Dataset",
          "justification": "The Adult Dataset is used in empirical evaluations to validate the proposed causal fair metric and classifier.",
          "quote": "For real-world datasets like Adult Kohavi and Becker (1996)..."
        },
        "aliases": [
          "Census Income Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "UCI Adult Data Set",
          "justification": "It provides the paper and context in which the Adult dataset was introduced.",
          "quote": "Kohavi and Becker. Uci adult data set. UCI Meachine Learning Repository, 5, 1996."
        }
      },
      {
        "name": {
          "value": "COMPAS Dataset",
          "justification": "The COMPAS Dataset is used as another real-world dataset for evaluating the effectiveness of the proposed methods.",
          "quote": "For real-world datasets like... COMPAS Washington (2018)..."
        },
        "aliases": [
          "Correctional Offender Management Profiling for Alternative Sanctions"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "How to Argue with an Algorithm: Lessons from the COMPAS-ProPublica Debate",
          "justification": "This referenced paper discusses the COMPAS dataset and its implications in fairness studies.",
          "quote": "Washington. How to argue with an algorithm: Lessons from the compas-propublica debate. Colo. Tech. LJ, 17: 131, 2018."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Pytorch",
          "justification": "Pytorch is likely used for implementing and executing the deep learning models like the Siamese Networks, as referenced.",
          "quote": "We train decision-making classifiers, denoted as h(x), using various training objectives"
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "Pytorch provides the implementation framework mentioned in the experimental setups.",
          "quote": "Pytorch: An imperative style, high-performance deep learning library. Advances in neural information processing systems, 32, 2019."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1146,
    "prompt_tokens": 20872,
    "total_tokens": 22018
  }
}