{
  "paper": "2211.00519.txt",
  "words": 6179,
  "extractions": {
    "title": {
      "value": "Learning Neural Implicit Representations with Surface Signal Parameterizations",
      "justification": "This is the given title of the paper.",
      "quote": "Learning Neural Implicit Representations with Surface Signal Parameterizations\nYanran Guana,∗, Andrei Chubaraub,c , Ruby Raoc , Derek Nowrouzezahraib"
    },
    "description": "The paper presents a novel neural network architecture that implicitly encodes underlying surface parameterization suitable for appearance data, enabling texture mapping and various common applications of texture mapping on neural implicit surfaces.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents and evaluates a specific machine learning architecture and its applications, comparing it against other models and measuring its performance on specific tasks.",
      "quote": "Our method outperforms reasonable baselines and state-of-the-art alternatives."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The primary focus of the paper is on neural implicit representations and texture mapping, which falls under the domain of computer vision.",
        "quote": "Keywords: Neural implicit surfaces, Surface parameterization, Overfit digital content"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "3D Modeling and Reconstruction",
          "justification": "The paper focuses on encoding 3D surfaces and enabling texture mapping on these surfaces.",
          "quote": "We briefly review the relevant literature, including neural implicit surface and appearance, surface parameterization, and overfit neural representations."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "OverfitSDF",
          "justification": "The model represents the surface geometry using an overfitted neural network.",
          "quote": "To represent objects’ geometry, we train for each object a model by Davies et al. [3], which we call OverfitSDF for brevity."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model OverfitSDF is based on the work by Davies et al. [3].",
          "quote": "To represent objects’ geometry, we train for each object a model by Davies et al. [3], which we call OverfitSDF for brevity."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is implemented and executed on a GPU to represent objects' geometry.",
          "quote": "Training our model requires an average of 1.1 h per object, roughly twice the time needed to train the geometry-only OverfitSDF model...We trained our neural networks on an NVIDIA GeForce RTX 2070 SUPER GPU with 8 GB of memory and CUDA version 10.1."
        },
        "is_compared": {
          "value": 1,
          "justification": "The OverfitSDF model is used as a baseline for comparison in texture mapping performance.",
          "quote": "To benchmark the utility and fidelity of diffuse texture mapping using our neural surface parameterization, we train an OverfitSDF-style baseline model to represent the surface color of objects as a continuous function in the 3D space — i.e., directly mapping 3D locations to RGB colors using an MLP network."
        },
        "referenced_paper_title": {
          "value": "On the effectiveness of weight-encoded neural implicit 3D shapes",
          "justification": "This is the title of the reference paper by Davies et al., from which the OverfitSDF model is derived.",
          "quote": "To represent objects’ geometry, we train for each object a model by Davies et al. [3], which we call OverfitSDF for brevity."
        }
      },
      {
        "name": {
          "value": "point2component",
          "justification": "One stage of the neural network architecture proposed in the paper.",
          "quote": "We use one MLP network, termed point2component, to predict the component label to which the input point belongs"
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "It is part of the two-stage network architecture proposed by the authors.",
          "quote": "We design a two-stage network architecture that handles both component predictions and UV coordinate predictions at the same time; see Figure 4 for the designed architecture of our model. We use one MLP network, termed point2component, to predict the component label to which the input point belongs."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is implemented and trained for the specific task of component prediction.",
          "quote": "To improve the reconstruction quality of the MLP, we pre-process the input layer of the network with a Fourier positional encoding [5, 12] and implement the hidden layers as sinusoidal representation network (SIREN) layers [11]."
        },
        "is_compared": {
          "value": 0,
          "justification": "The model is not directly compared against other models but is part of the proposed network architecture.",
          "quote": "We design a two-stage network architecture that handles both component predictions and UV coordinate predictions at the same time"
        },
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "There is no specific reference paper for the point2component model as it is a novel contribution of this paper.",
          "quote": "Not applicable"
        }
      },
      {
        "name": {
          "value": "point2UV",
          "justification": "One stage of the neural network architecture proposed in the paper.",
          "quote": "We use another MLP network, termed point2UV, to predict the UV coordinate associated with the input point"
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "It is part of the two-stage network architecture proposed by the authors.",
          "quote": "We use another MLP network, termed point2UV, to predict the UV coordinate associated with the input point"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is implemented and trained for the specific task of UV coordinate prediction.",
          "quote": "To improve the reconstruction quality of the MLP, we pre-process the input layer of the network with a Fourier positional encoding [5, 12] and implement the hidden layers as sinusoidal representation network (SIREN) layers [11]."
        },
        "is_compared": {
          "value": 0,
          "justification": "The model is not directly compared against other models but is part of the proposed network architecture.",
          "quote": "We design a two-stage network architecture that handles both component predictions and UV coordinate predictions at the same time"
        },
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "There is no specific reference paper for the point2UV model as it is a novel contribution of this paper.",
          "quote": "Not applicable"
        }
      },
      {
        "name": {
          "value": "OverfitColor",
          "justification": "The model is a baseline used for comparison in texture mapping performance.",
          "quote": "We train an OverfitSDF-style baseline model to represent the surface color of objects as a continuous function in the 3D space — i.e., directly mapping 3D locations to RGB colors using an MLP network. We call this baseline model OverfitColor."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model OverfitColor is based on an existing model (OverfitSDF) and is used as a baseline.",
          "quote": "We train an OverfitSDF-style baseline model to represent the surface color of objects as a continuous function in the 3D space — i.e., directly mapping 3D locations to RGB colors using an MLP network. We call this baseline model OverfitColor."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is implemented and executed on a GPU to represent objects' surface colors.",
          "quote": "Training our model requires an average of 1.1 h per object, roughly twice the time needed to train the geometry-only OverfitSDF model...We trained our neural networks on an NVIDIA GeForce RTX 2070 SUPER GPU with 8 GB of memory and CUDA version 10.1."
        },
        "is_compared": {
          "value": 1,
          "justification": "The OverfitColor model is used as a baseline for comparison in texture mapping performance.",
          "quote": "To benchmark the utility and fidelity of diffuse texture mapping using our neural surface parameterization, we train an OverfitSDF-style baseline model to represent the surface color of objects as a continuous function in the 3D space — i.e., directly mapping 3D locations to RGB colors using an MLP network. We call this baseline model OverfitColor."
        },
        "referenced_paper_title": {
          "value": "On the effectiveness of weight-encoded neural implicit 3D shapes",
          "justification": "This is the title of the reference paper by Davies et al., from which the OverfitSDF model is derived.",
          "quote": "To benchmark the utility and fidelity of diffuse texture mapping using our neural surface parameterization, we train an OverfitSDF-style baseline model to represent the surface color of objects as a continuous function in the 3D space — i.e., directly mapping 3D locations to RGB colors using an MLP network. We call this baseline model OverfitColor."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2153,
    "prompt_tokens": 11207,
    "total_tokens": 13360
  }
}