{
  "paper": "2302.11349.txt",
  "words": 9213,
  "extractions": {
    "title": {
      "value": "STEERABLE EQUIVARIANT REPRESENTATION LEARNING",
      "justification": "The title of the paper is stated at the top of the text provided.",
      "quote": "STEERABLE EQUIVARIANT REPRESENTATION LEARNING"
    },
    "description": "This paper proposes a method for learning representations that are equivariant to data augmentations through the use of steerable representations. It achieves equivariance by using learned linear maps to directly manipulate representations in the embedding space. The method is demonstrated to improve performance on tasks like transfer learning, robustness, and image retrieval.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper conducts various experiments and provides quantitative results showcasing the performance improvements of the proposed method.",
      "quote": "We demonstrate that our resulting steerable and equivariant representations lead to better performance on transfer learning and robustness: e.g. we improve linear probe top-1 accuracy by between 1% to 3% for transfer; and ImageNet-C accuracy by upto 3.4%."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper deals primarily with image embeddings and tasks like classification, retrieval, and object detection, all of which are core problems in the field of Computer Vision.",
        "quote": "Pre-trained deep image representations are useful for post-training tasks such as classification through transfer learning, image retrieval, and object detection."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Transfer Learning",
          "justification": "One of the key contributions of the paper is to show improved performance on transfer learning tasks due to the proposed steerable and equivariant representations.",
          "quote": "We demonstrate that our resulting steerable and equivariant representations lead to better performance on transfer learning and robustness."
        },
        "aliases": [
          "Transfer"
        ]
      },
      {
        "name": {
          "value": "Robustness",
          "justification": "The paper addresses robustness and provides empirical results showing improved robustness on datasets like ImageNet-C.",
          "quote": "We further show that the steerability of our representations provides significant speedup (nearly 50×) for test-time augmentations; by applying a large number of augmentations for out-of-distribution detection, we significantly improve OOD AUC on the ImageNet-C dataset over an invariant representation."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Image Retrieval",
          "justification": "The paper evaluates the proposed method on image retrieval tasks and demonstrates performance improvements.",
          "quote": "A common use-case for pre-trained embeddings is their use in image retrieval."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-50",
          "justification": "The paper uses the ResNet-50 architecture as part of its experiments and evaluation.",
          "quote": "Our models are trained on the ImageNet dataset (Deng et al., 2009), on the ResNet-50 architecture (He et al., 2016)."
        },
        "aliases": [
          "ResNet"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The ResNet-50 model is used for the experiments but is not a contribution of this paper.",
          "quote": "Our models are trained on the ImageNet dataset (Deng et al., 2009), on the ResNet-50 architecture (He et al., 2016)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The ResNet-50 model was executed as part of the experiments to demonstrate the proposed method.",
          "quote": "The equivariant/steerable model is trained with the loss in Eqn. 5 with the same learning rate schedule, number of epochs and batch size as the invariant model, with hyperparameters α=0.1 and β=0.1."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of the ResNet-50 model is compared to other model configurations to highlight the improvements due to the proposed method.",
          "quote": "We demonstrate that our resulting steerable and equivariant representations lead to better performance on transfer learning and robustness: e.g. we improve linear probe top-1 accuracy by between 1% to 3% for transfer; and ImageNet-C accuracy by upto 3.4%."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "This is the original paper by He et al. (2016) that introduced the ResNet-50 architecture used in this study.",
          "quote": "on the ResNet-50 architecture (He et al., 2016)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset is used to pre-train the models and conduct experiments in the paper.",
          "quote": "Our models are trained on the ImageNet dataset (Deng et al., 2009)"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "This is the original paper introducing the ImageNet dataset by Deng et al. (2009).",
          "quote": "ImageNet dataset (Deng et al., 2009)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "SGD",
          "justification": "The experiments utilized the SGD optimizer for training the models as stated in the paper.",
          "quote": "SGD optimizer with 0.9 nesterov momentum, 0.1 learning rate with cosine decay warmed up over 12 epochs"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1097,
    "prompt_tokens": 18673,
    "total_tokens": 19770
  }
}