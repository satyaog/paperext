{
  "paper": "2210.13583.txt",
  "words": 9668,
  "extractions": {
    "title": {
      "value": "LEARNING LATENT STRUCTURAL CAUSAL MODELS",
      "justification": "This is the title of the paper as presented: 'LEARNING LATENT STRUCTURAL CAUSAL MODELS'.",
      "quote": "LEARNING LATENT STRUCTURAL CAUSAL MODELS"
    },
    "description": "This paper addresses the problem of learning latent Structural Causal Models (SCMs) from low-level data through Bayesian inference. The authors propose a tractable approximate inference method for linear Gaussian additive noise SCMs, demonstrating its effectiveness on synthetic datasets and a causally generated image dataset. The work also validates the method's ability to generalize to unseen interventions.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes experimental results and evaluations on synthetic and real-world datasets, indicating it is primarily empirical.",
      "quote": "Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach."
    },
    "primary_research_field": {
      "name": {
        "value": "Causal Learning",
        "justification": "The main focus of the study is on learning latent causal models and structures from low-level data.",
        "quote": "Causal learning has long concerned itself with the accurate recovery of underlying causal mechanisms."
      },
      "aliases": [
        "Causal Discovery"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Representation Learning",
          "justification": "The paper discusses issues and methodologies related to learning causal variables and their representations from data.",
          "quote": "In causal machine learning and representation learning, however, these causal variables may no longer be observable."
        },
        "aliases": [
          "Representation Learning"
        ]
      },
      {
        "name": {
          "value": "Bayesian Inference",
          "justification": "Bayesian inference is used as the main technique for learning the latent SCMs.",
          "quote": "We treat this problem as Bayesian inference of the latent SCM, given low-level data."
        },
        "aliases": [
          "Bayesian Methods"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Bayesian Latent Causal Model",
          "justification": "The authors propose using a Bayesian latent causal model to infer the causal structure and variables from the observed data.",
          "quote": "We propose a general algorithm for Bayesian causal discovery in the latent space of a generative model, learning a distribution over causal variables, structure and parameters in linear Gaussian latent SCMs with random, known interventions."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The model is proposed and implemented as part of the research presented in this paper.",
          "quote": "We propose a general algorithm for Bayesian causal discovery in the latent space of a generative model."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed in the experiments performed, which include learning and sampling tasks.",
          "quote": "The model was trained for... iterations to reach convergence."
        },
        "is_compared": {
          "value": 1,
          "justification": "The proposed model is compared with baseline models such as VAE and GraphVAE.",
          "quote": "We compare our approach against two baselines: (i) Against VAE that has a marginal independence assumption... and (ii) against GraphVAE... which learns a structure between latent variables."
        },
        "referenced_paper_title": {
          "value": "Towards efficient representation identification in supervised learning",
          "justification": "One of the baselines used for comparison is VAE.",
          "quote": "We compare our approach against two baselines: (i) Against VAE that has a marginal independence assumption."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "synthetic datasets",
          "justification": "The paper mentions the use of synthetic datasets to evaluate the proposed model.",
          "quote": "Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "The synthetic datasets appear to be generated for the purpose of this study and do not reference an external paper.",
          "quote": "Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach."
        }
      },
      {
        "name": {
          "value": "causally generated image dataset",
          "justification": "The paper uses a causally generated image dataset for experiments.",
          "quote": "Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Towards efficient representation identification in supervised learning",
          "justification": "The causally generated image dataset appears to be related to prior works on representation learning.",
          "quote": "Experiments are performed on synthetic datasets and a causally generated image dataset to demonstrate the efficacy of our approach."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "JAX",
          "justification": "The experiments are implemented using JAX.",
          "quote": "All our implementations are in JAX (Bradbury et al., 2018)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "JAX: composable transformations of Python+ NumPy programs",
          "justification": "The library is referenced with the citation 'Bradbury et al., 2018'.",
          "quote": "All our implementations are in JAX (Bradbury et al., 2018)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1297,
    "prompt_tokens": 18929,
    "total_tokens": 20226
  }
}