{
  "paper": "2206.15331.txt",
  "words": 20243,
  "extractions": {
    "title": {
      "value": "GitHub Copilot AI pair programmer: Asset or Liability?",
      "justification": "The title is taken from the header of the paper.",
      "quote": "GitHub Copilot AI pair programmer: Asset or Liability?"
    },
    "description": "This paper empirically evaluates the performance and potential of GitHub Copilot, an AI-powered code completion tool developed by OpenAI and Microsoft. It compares Copilot’s generated solutions with human solutions on programming tasks and fundamental algorithmic problems, assessing aspects like correctness, reproducibility, code quality, and repair cost of buggy solutions.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts experiments to empirically evaluate the performance, capabilities, and limitations of GitHub Copilot by comparing it to human-generated solutions over various programming tasks.",
      "quote": "We present an empirical study on the performance and functionality of Copilot’s suggestions for fundamental algorithmic problems."
    },
    "primary_research_field": {
      "name": {
        "value": "Software Engineering",
        "justification": "The paper's primary focus is on evaluating an AI-based tool designed to aid in software development and program synthesis, which falls under the domain of Software Engineering.",
        "quote": "Automatic program synthesis is a long-lasting dream in software engineering."
      },
      "aliases": [
        "SE"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Learning",
          "justification": "GitHub Copilot utilizes a large language model trained using deep learning techniques, indicating its relevance to the Machine Learning field.",
          "quote": "Recently, a promising Deep Learning (DL) based solution, called Copilot, has been proposed by OpenAI and Microsoft as an industrial product."
        },
        "aliases": [
          "ML"
        ]
      },
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The model underlying Copilot processes natural language prompts to generate code, highlighting its connection to Natural Language Processing.",
          "quote": "Novel Large Language Models (LLMs) with the transformer architecture recently achieved good performance in automatic program synthesis."
        },
        "aliases": [
          "NLP"
        ]
      },
      {
        "name": {
          "value": "Program Synthesis",
          "justification": "The paper evaluates Copilot's capability in automatic code generation and program synthesis, placing it well within this subfield.",
          "quote": "Program synthesis is useful for different purposes such as teaching, programmer assistance, or the discovery of new algorithmic solutions for a problem."
        },
        "aliases": [
          "PS"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Copilot",
          "justification": "The primary focus of the paper is on the GitHub Copilot model, which provides code suggestions based on user prompts.",
          "quote": "the capabilities of Copilot in two different programming tasks: (i) generating (and reproducing) correct and efficient solutions for fundamental algorithmic problems, and (ii) comparing Copilot’s proposed solutions with those of human programmers on a set of programming tasks."
        },
        "aliases": [
          "GitHub Copilot"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Copilot is evaluated but not contributed by the authors.",
          "quote": "Although some studies evaluate the correctness of Copilot solutions and report its issues, more empirical evaluations are necessary to understand how developers can benefit from it effectively."
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments involve actually using Copilot to generate code, implying execution.",
          "quote": "To generate solutions with Copilot, we feed the description of each algorithmic problem, call it prompt, to Copilot."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper explicitly compares Copilot's outputs with those of human programmers.",
          "quote": "We empirically compare Copilot’s solutions with human solutions on a dataset of Python programming problems."
        },
        "referenced_paper_title": {
          "value": "Evaluating large language models trained on code",
          "justification": "The model underlying Copilot is based on Codex, which is detailed in the referenced paper.",
          "quote": "One such model is Codex; a GPT-3 based language model with up to 12 billion parameters."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "HumanEval",
          "justification": "HumanEval is mentioned in the context of evaluating Codex, the underlying model for Copilot.",
          "quote": "Codex shows a good performance in solving a set of hand-written programming problems (i.e., not in the training dataset) using Python, named HumanEval dataset."
        },
        "aliases": [
          "HumanEval Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Evaluating large language models trained on code",
          "justification": "The HumanEval dataset is cited in the context of evaluating the Codex model.",
          "quote": "Codex shows a good performance in solving a set of hand-written programming problems (i.e., not in the training dataset) using Python, named HumanEval dataset."
        }
      },
      {
        "name": {
          "value": "Python Programming Course Dataset",
          "justification": "The paper uses a dataset from a Python programming course to evaluate Copilot's performance compared to human students.",
          "quote": "This dataset includes 2442 'Correct' and 1783 'Buggy' student submissions for 5 Python programming assignments in a Python course."
        },
        "aliases": [
          "Python Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Re-factoring based program repair applied to programming assignments",
          "justification": "The reference paper discusses the dataset used to evaluate Copilot against human-written code.",
          "quote": "To address RQ2, as we already discussed in Subsection 3.1, we require a dataset of programming problems that Copilot can solve so that we can conduct further investigations on Copilot’s suggestions."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "AST",
          "justification": "The AST (Abstract Syntax Tree) library is used to measure the similarity between code snippets.",
          "quote": "To identify the correct solutions that are reproduced and measure their similarity, we have used the Abstract Syntax Trees (AST) similarity method described."
        },
        "aliases": [
          "Abstract Syntax Tree"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Comparing Python programs using abstract syntax trees",
          "justification": "The AST similarity method used in this paper is based on the referenced work.",
          "quote": "To identify the correct solutions that are reproduced and measure their similarity, we have used the Abstract Syntax Trees (AST) similarity method described in [44]."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1229,
    "prompt_tokens": 30802,
    "total_tokens": 32031
  }
}