{
  "paper": "2304.09012.txt",
  "words": 6245,
  "extractions": {
    "title": {
      "value": "GUILGET: GUI Layout GEneration with Transformer",
      "justification": "Title is directly stated at the beginning of the paper",
      "quote": "GUILGET: GUI Layout GEneration with Transformer"
    },
    "description": "The paper presents GUILGET, a method based on transformers to automatically generate GUI layouts from positional constraints represented as GUI arrangement graphs. It aims to assist designers by producing realistic and diverse GUI layouts, improving the efficiency of the GUI design process.",
    "type": {
      "value": "Empirical",
      "justification": "The paper includes experiments and evaluations to demonstrate the effectiveness of the method.",
      "quote": "Our experiments, which are conducted on the CLAY dataset, reveal that our model has the best understanding of relationships from GUI-AG and has the best performances in most of evaluation metrics."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper focuses on generating graphical user interface layouts which is a task in the computer vision domain.",
        "quote": "GUI generation is an emerging but yet under-explored computer vision application."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The method proposed in the paper is a generative model used to create GUI layouts.",
          "quote": "...we propose a transformer-based generative model that generates GUI layout from a given GUI-AG."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Graphical User Interfaces",
          "justification": "The entire paper is about generating and designing graphical user interfaces (GUIs).",
          "quote": "GUI generation is an emerging but yet under-explored computer vision application, especially for GUI generation based on GUI-AGs."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GUILGET",
          "justification": "GUILGET is the novel method proposed and developed in this paper for generating GUI layouts.",
          "quote": "We developed a method named GUILGET to automatically generate GUI layouts from positional constraints represented as GUI arrangement graphs (GUI-AGs)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "GUILGET is the primary contribution of this paper.",
          "quote": "We developed a method named GUILGET..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed and tested, as mentioned in the experiments.",
          "quote": "Our experiments, which are conducted on the CLAY dataset, reveal that our model has the best understanding of relationships from GUI-AG and has the best performances in most of evaluation metrics."
        },
        "is_compared": {
          "value": 1,
          "justification": "GUILGET was compared against other models such as SG2IM and LayoutTransformer in the experiments.",
          "quote": "Table 1 gives the results of our method compared to SG2IM and to LayoutTransformer."
        },
        "referenced_paper_title": {
          "value": "n/a",
          "justification": "GUILGET is a new model introduced in this paper, hence it does not reference any previous paper specifically for this model.",
          "quote": "n/a"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CLAY dataset",
          "justification": "The CLAY dataset is explicitly used in the experiments to validate the proposed method GUILGET.",
          "quote": "Our experiments, which are conducted on the CLAY dataset, reveal that our model has the best understanding of relationships from GUI-AG and has the best performances in most of evaluation metrics."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning to Denoise Raw Mobile UI Layouts for Improving Datasets at Scale",
          "justification": "The referenced paper for the CLAY dataset is provided in the references section.",
          "quote": "G. Li, G. Baechler, M. Tragut, and Y. Li. “Learning to Denoise Raw Mobile UI Layouts for Improving Datasets at Scale”. In: CHI Conference on Human Factors in Computing Systems. 2022, pp. 1–13."
        }
      },
      {
        "name": {
          "value": "RICO dataset",
          "justification": "The RICO dataset is mentioned as a source for GUI layouts and screenshots that were later refined in the CLAY dataset.",
          "quote": "UI layouts in RICO dataset [4] are often noisy and have visual mismatches hence CLAY is a dataset that improves RICO by denoising UI layouts."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Rico: A mobile app dataset for building data-driven design applications",
          "justification": "The referenced paper for the RICO dataset is provided in the references section.",
          "quote": "B. Deka, Z. Huang, C. Franzen, J. Hibschman, D. Afergan, Y. Li, J. Nichols, and R. Kumar. “Rico: A mobile app dataset for building data-driven design applications”. In: Proceedings of the 30th annual ACM symposium on user interface software and technology. 2017, pp. 845–854."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Transformers",
          "justification": "The method proposed in the paper is based on transformer models, and the architecture relies heavily on this library.",
          "quote": "A transformer-based approach for generating GUI layouts from GUI-AGs."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Attention is all you need",
          "justification": "The referenced paper for Transformer models is provided in the references section.",
          "quote": "A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin. “Attention is all you need”. In: Advances in neural information processing systems 30 (2017)."
        }
      },
      {
        "name": {
          "value": "BERT",
          "justification": "The object/relation predictor in the proposed model uses techniques from BERT.",
          "quote": "In order to capture conceptually diverse embedding and exploiting the co-occurrence among objects, predicates and parents, we follow the technique used in BERT and mask randomly words from the input that must be predicted by the object/relation predictor."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Bert: Pre-training of deep bidirectional transformers for language understanding",
          "justification": "The referenced paper for BERT is provided in the references section.",
          "quote": "J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. “Bert: Pre-training of deep bidirectional transformers for language understanding”. In: arXiv preprint arXiv:1810.04805 (2018)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1333,
    "prompt_tokens": 10296,
    "total_tokens": 11629
  }
}