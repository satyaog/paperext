{
  "paper": "e2jDr8NdJm.txt",
  "words": 16334,
  "extractions": {
    "title": {
      "value": "CAUSAL REPRESENTATION LEARNING IN TEMPORAL DATA VIA SINGLE-PARENT DECODING",
      "justification": "It's the exact title of the paper.",
      "quote": "CAUSAL REPRESENTATION LEARNING IN TEMPORAL DATA VIA SINGLE-PARENT DECODING"
    },
    "description": "This paper introduces a method that combines causal representation learning with a sparsity assumption called Single-Parent Decoding for temporal models. The method, Causal Discovery with Single-parent Decoding (CDSD), ensures the identification of causal relationships by assuming that each observed low-level variable is only affected by a single latent variable. This approach is validated both theoretically and empirically in simulated and real-world data from climate science.",
    "type": {
      "value": "Empirical",
      "justification": "The paper includes experimental validation on both synthetic and real-world datasets.",
      "quote": "We prove these identifiability results theoretically, and verify empirically that they hold in simulated data. Furthermore, we demonstrate the practical relevance of our method and assumptions via an application to a real-world climate science task."
    },
    "primary_research_field": {
      "name": {
        "value": "Causal Representation Learning",
        "justification": "The paper's primary focus is on learning causal relationships from data, explicitly aiming at identifying causally-relevant latent variables.",
        "quote": "Thus, scientific discovery requires causal representation learning: the coupled tasks of learning latent variables that represent semantically meaningful abstractions of the observed measurements and the quantification of causal relationships among these latents."
      },
      "aliases": [
        "CRL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Causal Discovery",
          "justification": "The method proposed is validated by discovering causal relationships in data.",
          "quote": "A BSTRACT Scientific research often seeks to understand the causal structure underlying high-level variables in a system."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Time-Series Data",
          "justification": "The paper focuses on models handling temporal observations.",
          "quote": "In this paper, we introduce a causal representation learning method for temporal observations."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Causal Discovery with Single-parent Decoding",
          "justification": "This is the primary model introduced and used in the paper.",
          "quote": "In this work, we consider a temporal model with a sparsity assumption, namely single-parent decoding. We demonstrate the identifiability of the resulting model and propose a differentiable method, Causal Discovery with Single-parent Decoding (CDSD), that simultaneously learns the underlying latents and a causal graph over them."
        },
        "aliases": [
          "CDSD"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The method is a novel contribution of this paper.",
          "quote": "We propose a differentiable causal discovery approach that simultaneously learns both latent variables and a causal graph over the latents, based on time-series data."
        },
        "is_executed": {
          "value": true,
          "justification": "The method was implemented and validated through various experiments.",
          "quote": "We evaluate our method both on synthetic data and a real-world climate science dataset in which relevant latents must be uncovered from measurements of sea-level pressure."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares CDSD to other methods like Varimax-PCMCI.",
          "quote": "First, we compare CDSD to Varimax-PCMCI (87), an alternate method that has a closely similar application."
        },
        "referenced_paper_title": {
          "value": "Differentiable causal discovery from interventional data",
          "justification": "The model was inspired by techniques from various referenced works.",
          "quote": "To learn the graphs G via continuous optimization, we use a similar approach to Ke et al. (36); Brouillard et al. (9); Ng et al. (59)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "NOAA's Reanalysis 1 mean sea-level pressure (MSLP) dataset",
          "justification": "This dataset was used in the empirical validation of the method.",
          "quote": "To test the capabilities of CDSD in real-world settings, we apply it to the National Oceanic and Atmospheric Administration’s (NOAA) Reanalysis 1 mean sea-level pressure (MSLP) dataset (35)."
        },
        "aliases": [
          "NOAA MSLP dataset"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "The NCEP/NCAR 40-Year Reanalysis Project",
          "justification": "This title matches the full name and description of the dataset mentioned.",
          "quote": "To test the capabilities of CDSD in real-world settings, we apply it to the National Oceanic and Atmospheric Administration’s (NOAA) Reanalysis 1 mean sea-level pressure (MSLP) dataset (35)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The implementation details suggest the use of neural networks, commonly implemented with PyTorch.",
          "quote": "We use the optimizer RMSProp (22) with a learning rate of 1e − 3 and batch size of 64."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Neural networks for machine learning lecture 6a overview of mini-batch gradient descent.",
          "justification": "The cited reference corresponds to the description of the RMSProp optimizer, typically part of the PyTorch library.",
          "quote": "We use the optimizer RMSProp (22) with a learning rate of 1e − 3 and batch size of 64."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1309,
    "prompt_tokens": 28109,
    "total_tokens": 29418
  }
}