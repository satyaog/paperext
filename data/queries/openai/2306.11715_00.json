{
  "paper": "2306.11715.txt",
  "words": 11478,
  "extractions": {
    "title": {
      "value": "Multi-Fidelity Active Learning with GFlowNets",
      "justification": "The title provided by the user within the input text.",
      "quote": "Multi-Fidelity Active Learning with GFlowNets"
    },
    "description": "This paper proposes the use of Generative Flow Networks (GFlowNets) for multi-fidelity active learning, where multiple approximations of a costly black-box function are available at various fidelities and costs. The authors present an algorithm for their proposed method and demonstrate its efficiency in accelerating scientific discovery and engineering design through experiments on synthetic benchmark tasks and practical applications in molecular discovery.",
    "type": {
      "value": "Empirical",
      "justification": "The paper presents an algorithm and evaluates its performance on synthetic tasks and practical applications, which indicates empirical research.",
      "quote": "Here, we describe our algorithm for multi-fidelity active learning with GFlowNets and evaluate its performance in both well-studied synthetic tasks and practically relevant applications of molecular discovery."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The primary research field is machine learning, focusing on improving active learning techniques using GFlowNets.",
        "quote": "In this paper, we propose the use of GFlowNets for multi-fidelity active learning, where multiple approximations of the black-box function are available at lower fidelity and cost."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Active Learning",
          "justification": "The paper contributes to active learning by proposing a novel multi-fidelity approach using GFlowNets.",
          "quote": "Our work can be framed within the broad field of active learning (AL), a class of machine learning methods whose goal is to learn an efficient data sampling scheme to accelerate training."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Probabilistic Inference",
          "justification": "The use of GFlowNets is closely tied with probabilistic inference, aiming to sample from distributions proportionally to a reward function.",
          "quote": "GFlowNets are recently proposed methods for amortised probabilistic inference that have proven efficient for exploring large, high-dimensional spaces and can hence be practical in the multi-fidelity setting too."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Bayesian Optimization",
          "justification": "Part of the work involves comparisons and improvements over Bayesian optimization approaches, particularly in multi-fidelity settings.",
          "quote": "The past decade has seen significant progress in multi-fidelity Bayesian optimisation (BO) [22, 59], including methods that leverage the potential of deep neural networks [41]."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GFlowNet",
          "justification": "The paper revolves around the use of GFlowNets for multi-fidelity active learning.",
          "quote": "In this paper, we propose the use of GFlowNets for multi-fidelity active learning."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The use of GFlowNets in the context of multi-fidelity active learning is a novel contribution of the paper.",
          "quote": "we propose the use of GFlowNets for multi-fidelity active learning"
        },
        "is_executed": {
          "value": 0,
          "justification": "The paper does not specify that the GFlowNet model was executed on GPU or CPU.",
          "quote": ""
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of the proposed method using GFlowNets is evaluated and compared with other methods in the paper.",
          "quote": "As a main result, we demonstrate that multi-fidelity active learning with GFlowNets discovers diverse, high-scoring samples when multiple oracles with different fidelities and costs are available, with lower computational cost than its single-fidelity counterpart."
        },
        "referenced_paper_title": {
          "value": "Flow network based generative models for non-iterative diverse candidate generation",
          "justification": "The concept of GFlowNets is based on the work titled 'Flow network based generative models for non-iterative diverse candidate generation.'",
          "quote": "Generative Flow Networks [GFlowNets; 6, 7] are amortised samplers designed for sampling from discrete high-dimensional distributions."
        }
      },
      {
        "name": {
          "value": "Deep Neural Networks (DNN)",
          "justification": "The paper mentions leveraging deep neural networks within the context of Bayesian optimization.",
          "quote": "The past decade has seen significant progress in multi-fidelity Bayesian optimisation (BO) [22, 59], including methods that leverage the potential of deep neural networks [41]."
        },
        "aliases": [
          "DNN"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Deep neural networks are mentioned but not a contribution of this paper.",
          "quote": "including methods that leverage the potential of deep neural networks [41]"
        },
        "is_executed": {
          "value": 0,
          "justification": "There is no explicit execution of DNNs described in the paper.",
          "quote": ""
        },
        "is_compared": {
          "value": 0,
          "justification": "DNNs are not compared or evaluated within this paper.",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "Multi-fidelity Bayesian optimization via deep neural networks",
          "justification": "The paper mentions the use of deep neural networks in the context of Bayesian Optimization, referencing this work.",
          "quote": "including methods that leverage the potential of deep neural networks [41]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "DNA aptamers dataset",
          "justification": "The dataset is mentioned in the context of evaluating the method for DNA sequence design.",
          "quote": "The main results on the DNA aptamers task are presented in Fig. 3a."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DBAASP",
          "justification": "The dataset is used for experiments related to antimicrobial peptides.",
          "quote": "We use data from DBAASP [51] containing antimicrobial activity labels, which is split into two sets â€“ one used for training the oracle and one as the initial data set in the active learning loop, following [26]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "DBAASP v3: database of antimicrobial/cytotoxic activity and structure of peptides as a resource for development of new therapeutics",
          "justification": "The paper references DBAASP database version 3, which is relevant for the antimicrobial activity labels used in the paper.",
          "quote": "We use data from DBAASP [51] containing antimicrobial activity labels, which is split into two sets"
        }
      },
      {
        "name": {
          "value": "Randomly sampled sequences dataset",
          "justification": "This dataset is used for training a transformer model as a lower fidelity oracle in DNA sequence design.",
          "quote": "To construct a lower fidelity oracle, we train a transformer with 8 layers, 1024 hidden units per layer and 16 heads. We sampled 1 million random sequences for the training set."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1752,
    "prompt_tokens": 20110,
    "total_tokens": 21862
  }
}