{
  "paper": "2308.05741.txt",
  "words": 7824,
  "extractions": {
    "title": {
      "value": "Neural Progressive Meshes",
      "justification": "The title is derived from the beginning of the research paper.",
      "quote": "Neural Progressive Meshes YUN-CHUN CHEN, University of Toronto, Canada VLADIMIR G. KIM, Adobe Research, USA NOAM AIGERMAN, Adobe Research, USA ALEC JACOBSON, Adobe Research, University of Toronto, Canada"
    },
    "description": "The paper introduces Neural Progressive Meshes, a framework leveraging a neural network-based encoder-decoder architecture that derives a progressive compressed representation of 3D meshes for efficient transmission.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents experiments, evaluations, and comparisons with baselines to demonstrate the effectiveness of their proposed method.",
      "quote": "We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper addresses problems related to the efficient transmission and reconstruction of 3D meshes, which is a topic within the computer vision research field.",
        "quote": "arXiv:2308.05741v1 [cs.CV] 10 Aug 2023"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "3D Vision",
          "justification": "The work focuses on the processing, compression, and reconstruction of 3D meshes, fitting within the sub-research field of 3D Vision.",
          "quote": "We present a framework that learns a progressive compressed representation of meshes for transmission purposes."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Neural Progressive Mesh",
          "justification": "This is the model introduced and developed in the paper.",
          "quote": "Fig. 1. Neural Progressive Meshes. We present a framework that learns a progressive compressed representation of meshes for transmission purposes."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "SubdivNet",
          "justification": "SubdivNet is used within the neural network framework described.",
          "quote": "The server first uses TetWild [Hu et al. 2018] to preprocess it and then uses a subdivision-based encoder adapted from SubdivNet [Hu et al. 2022] to map geometric details of the original mesh."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Neural Subdivision",
          "justification": "Neural Subdivision, a pre-existing model, is adapted for the decoder in the framework.",
          "quote": "The client uses a subdivision-based decoder adapted from Neural Subdivision [Liu et al. 2020] to reconstruct a high-resolution mesh."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Thingi10K",
          "justification": "This dataset is used to evaluate the proposed method.",
          "quote": "We evaluate our network on the Thingi10K [Zhou and Jacobson 2016] dataset, split into the training, validation, and test sets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is used for training the neural networks involved in the study.",
          "quote": "We train our network using the ADAM [Kingma and Ba 2014] optimizer in PyTorch [Paszke et al. 2019]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "TetWild",
          "justification": "TetWild is utilized to preprocess the mesh inputs.",
          "quote": "Given an input mesh, we use TetWild [Hu et al. 2018] to preprocess it."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "QSlim",
          "justification": "QSlim is employed for decimating the input meshes to obtain coarse representations.",
          "quote": "To derive our LoD M0â€¦M L representation used in the encoder, we first decimate the input mesh M via QSlim [Garland and Heckbert 1997] to obtain a coarse mesh."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1215,
    "prompt_tokens": 14203,
    "total_tokens": 15418
  }
}