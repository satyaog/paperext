{
  "paper": "2312.00231.txt",
  "words": 3120,
  "extractions": {
    "title": {
      "value": "LEARNING DOMAIN-INVARIANT CLASSIFIERS FOR INFANT CRY SOUNDS",
      "justification": "The title of the paper is explicitly given at the beginning of the provided text.",
      "quote": "LEARNING DOMAIN-INVARIANT CLASSIFIERS FOR INFANT CRY SOUNDS"
    },
    "description": "This paper studies domain shift in a clinical database of infant cry sounds and explores methods for domain adaptation to improve the accuracy of neural networks in diagnosing neurological injuries from infant cries across different hospitals. The authors propose a new approach, Target Noise Injection (TNI), for unsupervised domain adaptation, which doesn't require labels or training data from the target domain.",
    "type": {
      "value": "empirical",
      "justification": "The focus of the study is on experiments conducted with different domain adaptation methods and the evaluation of their performance on clinical data, which is characteristic of empirical research.",
      "quote": "Here, we are interested in domain adaptation in the context of identifying signs of neurological injury from audio recordings of infant cries. Over a span of 3 years, the Ubenwa clinical study [12] collected cry recordings across hospitals in 3 countries (Brazil, Canada, and Nigeria) for this problem."
    },
    "primary_research_field": {
      "name": {
        "value": "Audio Classification",
        "justification": "The research is primarily concerned with classifying audio recordings of infant cries to detect neurological injuries, which falls under the domain of Audio Classification.",
        "quote": "Through insights generated in this study, we propose a new unsupervised domain adaptation technique that requires neither training examples nor training labels in the target domain â€“ only noise recordings."
      },
      "aliases": [
        "Audio Classification"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Domain Adaptation",
          "justification": "The paper focuses on overcoming domain shift and proposes multiple domain adaptation methods to improve model performance across different target domains.",
          "quote": "In this work, we identify and study patterns of domain shift using this international database of infant cry recordings and explore methods for domain adaptation."
        },
        "aliases": [
          "DA"
        ]
      },
      {
        "name": {
          "value": "Healthcare",
          "justification": "The application domain is healthcare, specifically detecting neurological injuries in newborns using cry sounds.",
          "quote": "We explore methodologies for mitigating the impact of domain shift in a model for identifying neurological injury from cry sounds."
        },
        "aliases": [
          "Healthcare"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "CNN14",
          "justification": "CNN14 is explicitly named as the model used in the experiments for cross-hospital generalization and is also the backbone encoder for the proposed methods.",
          "quote": "Here we train a classifier (CNN14 [16]) on the source hospital data and test it on the target. If there is no domain shift between hospitals, the model should generalize to the target domain."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model CNN14 was not introduced in this paper. Instead, it was referenced as a pre-existing architecture used within their experiments.",
          "quote": "Here we train a classifier (CNN14 [16]) on the source hospital data and test it on the target."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was trained and executed within the experiments of the paper.",
          "quote": "All models were trained using the Adam optimizer with a batch size of 32."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of CNN14 is compared with various domain adaptation methods.",
          "quote": "Here we train a classifier (CNN14 [16]) on the source hospital data and test it on the target."
        },
        "referenced_paper_title": {
          "value": "PANNs: Large-Scale Pretrained Audio Neural Networks for Audio Pattern Recognition",
          "justification": "The referenced paper title provides the details of the source where CNN14 was initially proposed.",
          "quote": "Here we train a classifier (CNN14 [16]) on the source hospital data and test it on the target."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Ubenwa newborn cry database",
          "justification": "The Ubenwa newborn cry database is the primary dataset used for the experiments described in the paper.",
          "quote": "This study uses a subset of the Ubenwa newborn cry database collected from hospitals in Brazil, Canada, and Nigeria."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Self-supervised learning for infant cry analysis",
          "justification": "The paper references a previous study where the Ubenwa newborn cry database was used, indicating its ongoing use in related research.",
          "quote": "This study uses a subset of the Ubenwa newborn cry database collected from hospitals in Brazil, Canada, and Nigeria. Each cry recording is annotated as either healthy or neurological injury based on clinical exams conducted by doctors."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Adam",
          "justification": "The Adam optimizer is specified as the library used for training the models in the experiments.",
          "quote": "All models were trained using the Adam optimizer with a batch size of 32."
        },
        "aliases": [
          "Adam Optimizer"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A Method for Stochastic Optimization",
          "justification": "The referenced paper for Adam provides the details of this optimization method which is commonly used in deep learning.",
          "quote": "All models were trained using the Adam optimizer with a batch size of 32."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1055,
    "prompt_tokens": 6140,
    "total_tokens": 7195
  }
}