{
  "paper": "2303.04143.txt",
  "words": 13595,
  "extractions": {
    "title": {
      "value": "Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?",
      "justification": "This is the title of the paper provided by the user.",
      "quote": "Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?"
    },
    "description": "This paper presents the development and evaluation of Graph HyperNetworks (GHNs), specifically GHN-3, which are designed to predict parameters for various deep learning models. The GHN-3 aims to democratize the pretraining of neural networks by efficiently predicting parameters that can initialize other networks, thereby reducing training time and computational costs. The authors evaluate GHN-3 on large-scale datasets like ImageNet and showcase its superior performance over previous versions and traditional initialization methods.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves the training and evaluation of models on datasets, making it empirical in nature.",
      "quote": "To do so, we follow recent works where one network (HyperNetwork) parameterized by θ is trained to predict good parameters wpred for unseen network architectures."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper primarily deals with improving the training of diverse ImageNet models, which is a key area in Computer Vision.",
        "quote": "We focus in this paper on generalization to new architectures f in a large-scale ImageNet setting so that the HyperNetwork HD is used as:"
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Model Initialization",
          "justification": "The primary focus of the paper is on initializing models using predicted parameters to enhance their training efficiency.",
          "quote": "Using trained GHNs we first predict ImageNet parameters for all 900 + 74 evaluation architectures in DEEPNETS-1M and PYTORCH and evaluate their ImageNet classification accuracy (top-1) by propagating validation images."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Transfer Learning",
          "justification": "The paper evaluates the transferability of the predicted parameters from ImageNet to few-shot learning tasks, indicating a focus on transfer learning.",
          "quote": "We explore if the parameters predicted by our GHNs for ImageNet can be transferred to other tasks."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GHN-3",
          "justification": "GHN-3 is the model introduced in the paper and evaluated against various benchmarks.",
          "quote": "3. We evaluate GHNs by predicting parameters for around 1000 unseen ImageNet models, including all models available in the official PyTorch framework (Paszke et al., 2019)."
        },
        "aliases": [
          "Graph HyperNetwork 3"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "GHN-3 is the main contribution of this paper.",
          "quote": "Scaling up GHNs leads to consistent improvements in the quality of predicted parameters when used as initialization on ImageNet."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed using GPUs, as evidenced by the training descriptions and time evaluations.",
          "quote": "Training GHN-3. We train the GHNs on the ILSVRC-2012 ImageNet dataset (Russakovsky et al., 2015) with 1.28M training and 50K validation images of the 1k classes. All GHNs are trained for 75 epochs using AdamW (Loshchilov & Hutter, 2017), initial learning rate 4e-4 decayed using cosine scheduling, weight decay λ=1e-2, predicted parameter regularization γ=3e-5 (Eq. 10), batch size b=128 and automatic mixed precision in PyTorch (Paszke et al., 2019). We train the GHNs on the same training split of 1 million architectures, DEEPNETS-1M, used to train GHN-2 (Knyazev et al., 2021)."
        },
        "is_compared": {
          "value": 1,
          "justification": "GHN-3 is numerically compared to other initialization methods and previous GHNs versions in the paper.",
          "quote": "We evaluate if neural networks initialized with the parameters wpred predicted by GHNs obtain high performance without any training (Eq. 2) and after fine-tuning (Eq. 3)."
        },
        "referenced_paper_title": {
          "value": "Parameter prediction for unseen deep architectures",
          "justification": "The referenced paper for GHN-3 is the previous work on GHNs by Knyazev et al., 2021.",
          "quote": "Our proposed GHN-3 closely resembles GHN-2 and uses the same training dataset. However, GHN-3 is > 100× larger, which we show is important to increase the performance on ImageNet."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is the primary dataset used for training and evaluating the GHN-3 models.",
          "quote": "We train the GHNs on the ILSVRC-2012 ImageNet dataset (Russakovsky et al., 2015) with 1.28M training and 50K validation images of the 1k classes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "The referenced paper for ImageNet is by Russakovsky et al., 2015.",
          "quote": "Novel neural architectures, e.g. Vision Transformer (Dosovitskiy et al., 2020), are usually first pretrained by Eq. (1) on some large D such as ImageNet (Russakovsky et al., 2015) or, some in-house data such as JFT-300M, and then transferred to other downstream tasks (Kornblith et al., 2019; Zhai et al., 2019; Dosovitskiy et al., 2020)."
        }
      },
      {
        "name": {
          "value": "DeepNets-1M",
          "justification": "DeepNets-1M is used for training the GHN models and is extensively referenced in the paper.",
          "quote": "Training architectures are sampled from DeepNets-1M - a dataset of 1 million architectures (Knyazev et al., 2021)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Parameter prediction for unseen deep architectures",
          "justification": "The referenced paper for DeepNets-1M is the previous work on GHNs by Knyazev et al., 2021.",
          "quote": "We train the GHNs on the same training split of 1 million architectures, DeepNets-1M, used to train GHN-2 (Knyazev et al., 2021)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is used for implementing and training the GHN models.",
          "quote": "All GHNs are trained for 75 epochs using AdamW (Loshchilov & Hutter, 2017)... and mixed precision in PyTorch (Paszke et al., 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The referenced paper for PyTorch is by Paszke et al., 2019.",
          "quote": "All GHNs are trained for 75 epochs using AdamW (Loshchilov & Hutter, 2017)... and mixed precision in PyTorch (Paszke et al., 2019)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1528,
    "prompt_tokens": 33533,
    "total_tokens": 35061
  }
}