{
  "paper": "2312.06795.txt",
  "words": 7628,
  "extractions": {
    "title": {
      "value": "Model Breadcrumbs: Scaling Multi-Task Model Merging with Sparse Masks",
      "justification": "This is the title of the paper as stated at the beginning of the document.",
      "quote": "Model Breadcrumbs: Scaling Multi-Task Model Merging with Sparse Masks"
    },
    "description": "This paper introduces a method called Model Breadcrumbs for effectively merging multiple fine-tunings of a foundational model across various tasks. The approach aims to address scalability, noise reduction, and hyperparameter generalization in multi-task model merging without additional training or access to the original training data. It accomplishes this by creating sparse masks based on weight differences from fine-tuned models, thus enabling efficient and robust model merging.",
    "type": {
      "value": "empirical",
      "justification": "The paper focuses on empirical evaluations to demonstrate the effectiveness of their proposed method using various models, tasks, and datasets.",
      "quote": "Through extensive experimentation involving various models, tasks, and modalities we establish that integrating Model Breadcrumbs offers a simple, efficient, and highly effective approach for constructing multi-task models and facilitating updates to foundation models."
    },
    "primary_research_field": {
      "name": {
        "value": "Multi-Task Learning",
        "justification": "The primary focus of the paper is on merging models to perform multiple tasks simultaneously.",
        "quote": "We introduce a new simple method, Model Breadcrumbs, which consists of a sparsely defined set of weights that carve out a trajectory within the weight space of a pre-trained model, enhancing task performance when traversed."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Model Merging",
          "justification": "The core method introduced in the paper deals with merging models created from various fine-tuning tasks.",
          "quote": "Model Breadcrumbs constructs multi-task models from pre-existing fine-tuned models..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Scalability in Deep Learning",
          "justification": "The paper addresses challenges related to scaling model merging to handle numerous tasks efficiently.",
          "quote": "To address the challenges of scalability, practical constraints, and unlock the untapped potential of the growing pool of publicly available fine-tuned models, recent developments in neural network weight averaging techniques have gained attention..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Hyperparameter Generalization",
          "justification": "One of the contributions of the paper is showing the robustness of the Model Breadcrumbs method to hyperparameter variations as the number of merged tasks increases.",
          "quote": "We empirically show the robustness of our approach to hyperparameter variations and its ability to generalize with the increasing number of tasks."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Model Breadcrumbs",
          "justification": "The paper introduces Model Breadcrumbs as the primary method for merging multiple fine-tuned models into a single multi-task model.",
          "quote": "To address these challenges and to capitalize on the untapped resources within the field, our paper introduces Model Breadcrumbs, a simple solution designed to tackle scalability, noise reduction in merging tasks, and hyperparameter generalization issues."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Model Breadcrumbs is introduced as the main contribution of the paper.",
          "quote": "Our method is shown to be more efficient and unlike previous proposals does not require hyperparameter tuning for each new task added."
        },
        "is_executed": {
          "value": true,
          "justification": "The method is implemented and evaluated using GPU resources. The references to specific models like CLIP also imply the use of GPU.",
          "quote": "Following a procedure akin to Ilharco et al. [21], our fine-tuning comprises 2000 iterations with a batch size of 128, a learning rate set to 1e-5, and a cosine annealing learning rate schedule with 200 warm-up steps. The AdamW optimizer [32] with a weight decay of 0.1 is employed for optimization."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of Model Breadcrumbs is compared with other model merging methods such as Task Vectors and Fisher Merging.",
          "quote": "Table 1 presents a comparison between Model Breadcrumbs with 85% sparsity, the recently proposed Task Vectors [20], and Fisher Merging [35] across 8 tasks, using ViT-B-32 model. Model Breadcrumbs outperforms all considered methods by a substantial margin."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Model Breadcrumbs is introduced in this paper, hence there is no external reference paper for it.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Cars dataset",
          "justification": "The Cars dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "3d object representations for fine-grained categorization",
          "justification": "The Cars dataset is referred to in the context of a previous paper on fine-grained categorization.",
          "quote": "Jonathan Krause, Michael Stark, Jia Deng, and Li Fei- Fei. 3d object representations for fine-grained categorization. In Proceedings of the IEEE international conference on computer vision workshops, pages 554–561, 2013."
        }
      },
      {
        "name": {
          "value": "DTD dataset",
          "justification": "The DTD dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Describing textures in the wild",
          "justification": "The DTD dataset is referred to in the context of a previous paper on texture description.",
          "quote": "M. Cimpoi, S. Maji, I. Kokkinos, S. Mohamed, , and A. Vedaldi. Describing textures in the wild. In Proceedings of the IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), 2014."
        }
      },
      {
        "name": {
          "value": "EuroSAT dataset",
          "justification": "The EuroSAT dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification",
          "justification": "The EuroSAT dataset is referred to in the context of a previous paper on land use and land cover classification.",
          "quote": "Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth. Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019."
        }
      },
      {
        "name": {
          "value": "GTSRB dataset",
          "justification": "The GTSRB dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [
          "German Traffic Sign Detection Benchmark"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Detection of traffic signs in real-world images: The German Traffic Sign Detection Benchmark",
          "justification": "The GTSRB dataset is referred to in the context of a previous paper on traffic sign detection.",
          "quote": "Sebastian Houben, Johannes Stallkamp, Jan Salmen, Marc Schlipsing, and Christian Igel. Detection of traffic signs in real-world images: The German Traffic Sign Detection Benchmark. In International Joint Conference on Neural Networks, 2013."
        }
      },
      {
        "name": {
          "value": "MNIST dataset",
          "justification": "The MNIST dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Mnist handwritten digit database",
          "justification": "The MNIST dataset is referred to in the context of a previous paper on handwritten digit recognition.",
          "quote": "Yann LeCun, Corinna Cortes, and CJ Burges. Mnist handwritten digit database. ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, 2, 2010."
        }
      },
      {
        "name": {
          "value": "RESISC45 dataset",
          "justification": "The RESISC45 dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Remote sensing image scene classification: Benchmark and state of the art",
          "justification": "The RESISC45 dataset is referred to in the context of a previous paper on remote sensing image scene classification.",
          "quote": "Gong Cheng, Junwei Han, and Xiaoqiang Lu. Remote sensing image scene classification: Benchmark and state of the art. Proceedings of the IEEE, 105: 1865–1883, 2017."
        }
      },
      {
        "name": {
          "value": "SUN397 dataset",
          "justification": "The SUN397 dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Sun database: Large-scale scene recognition from abbey to zoo",
          "justification": "The SUN397 dataset is referred to in the context of a previous paper on large-scale scene recognition.",
          "quote": "J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba. Sun database: Large-scale scene recognition from abbey to zoo. In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 3485–3492, 2010."
        }
      },
      {
        "name": {
          "value": "SVHN dataset",
          "justification": "The SVHN dataset is used in the experiments for model fine-tuning and evaluation.",
          "quote": "In Section 4.2, 4.3, 4.4, and 4.6, we assess our findings using an extensive set of 8 datasets: Cars, DTD, EuroSAT, GTSRB, MNIST, RESISC45, SUN397, and SVHN."
        },
        "aliases": [
          "Street View House Numbers"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Reading digits in natural images with unsupervised feature learning",
          "justification": "The SVHN dataset is referred to in the context of a previous paper on digit recognition in natural images.",
          "quote": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. Advances in Neural Information Processing Systems (NIPS), 2011."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2526,
    "prompt_tokens": 14671,
    "total_tokens": 17197
  }
}