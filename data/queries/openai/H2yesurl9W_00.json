{
  "paper": "H2yesurl9W.txt",
  "words": 4900,
  "extractions": {
    "title": {
      "value": "Preventing Dimensional Collapse in Contrastive Local Learning with Subsampling",
      "justification": "This is the title of the paper as stated at the beginning.",
      "quote": "Preventing Dimensional Collapse in Contrastive Local Learning with Subsampling"
    },
    "description": "This paper presents an investigation of the challenges of training Deep Neural Networks (DNNs) via self-supervised objectives, using local learning as a parallelizable alternative to traditional backpropagation. The authors divide DNNs into distinct blocks, each updated independently with gradients from small local auxiliary NNs. They identify a layer-wise dimensional collapse as a major factor in performance degradation and propose a feature-similarity-based sampling method to counter this. Experiments on CIFAR-10, Fashion-MNIST, and STL-10 datasets validate their method.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes detailed numerical experiments and evaluations on image classification datasets like CIFAR-10, Fashion-MNIST, and STL-10, validating the proposed method.",
      "quote": "Our numerical experiments conducted on the CIFAR-10, Fashion-MNIST and STL-10 datasets validate the effectiveness of our method."
    },
    "primary_research_field": {
      "name": {
        "value": "Self-Supervised Learning",
        "justification": "The primary focus of the paper is on self-supervised learning, specifically contrastive learning methods within this domain.",
        "quote": "We focus on approaching the contrastive learning SimCLR framework (Chen et al., 2020), a leading contrastive learning method, through the lens of local learning."
      },
      "aliases": [
        "SSL",
        "Self-Supervised Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Contrastive Learning",
          "justification": "The paper is centered around contrastive learning, particularly the SimCLR framework, which is a key method in this area.",
          "quote": "We focus on approaching the contrastive learning SimCLR framework (Chen et al., 2020), a leading contrastive learning method, through the lens of local learning."
        },
        "aliases": [
          "Contrastive Learning"
        ]
      },
      {
        "name": {
          "value": "Local Learning",
          "justification": "The proposal and analyses are focused on local learning as an alternative to traditional backpropagation for training deep neural networks.",
          "quote": "We consider the challenge of dividing a NN trained via self-supervision into a larger split while maintaining competitive final accuracy. We focus on approaching the contrastive learning SimCLR framework... through the lens of local learning."
        },
        "aliases": [
          "Localized Learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "SimCLR",
          "justification": "The SimCLR framework is prominently discussed and used as the contrastive learning method for the study.",
          "quote": "We focus on approaching the contrastive learning SimCLR framework (Chen et al., 2020), a leading contrastive learning method, through the lens of local learning."
        },
        "aliases": [
          "SimCLR"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The authors build upon the existing SimCLR framework but do not claim it as a new contribution.",
          "quote": "We focus on approaching the contrastive learning SimCLR framework (Chen et al., 2020), a leading contrastive learning method, through the lens of local learning."
        },
        "is_executed": {
          "value": 1,
          "justification": "The method based on SimCLR was implemented and tested in the experiments.",
          "quote": "Our experiments conducted on the CIFAR-10, Fashion-MNIST and STL-10 datasets validate the effectiveness of our method."
        },
        "is_compared": {
          "value": 1,
          "justification": "The SimCLR framework is compared with the proposed method to validate their improvements.",
          "quote": "We compare our subsampling method against the standard SimCLR loss across multiple splits and datasets."
        },
        "referenced_paper_title": {
          "value": "A simple framework for contrastive learning of visual representations",
          "justification": "This is the reference paper for SimCLR cited by the authors.",
          "quote": "Chen, T., Kornblith, S., Norouzi, M., & Hinton, G. (2020). A simple framework for contrastive learning of visual representations."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is one of the datasets used for the experiments validating the proposed method.",
          "quote": "Our experiments conducted on the CIFAR-10, Fashion-MNIST and STL-10 datasets validate the effectiveness of our method."
        },
        "aliases": [
          "CIFAR-10"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Cifar-10 (Canadian Institute for Advanced Research)",
          "justification": "The authors mention CIFAR-10 as one of the datasets used in their experiments.",
          "quote": "Krizhevsky, A., Nair, V., & Hinton, G. (n.d.). Cifar-10 (Canadian Institute for Advanced Research)."
        }
      },
      {
        "name": {
          "value": "Fashion-MNIST",
          "justification": "Fashion-MNIST is one of the datasets used for the experiments validating the proposed method.",
          "quote": "Our experiments conducted on the CIFAR-10, Fashion-MNIST and STL-10 datasets validate the effectiveness of our method."
        },
        "aliases": [
          "Fashion-MNIST"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fashion-MNIST: a novel image dataset for benchmarking machine learning algorithms",
          "justification": "The authors mention Fashion-MNIST as one of the datasets used in their experiments.",
          "quote": "Xiao, H., Rasul, K., & Vollgraf, R. (2017). Fashionmnist: a novel image dataset for benchmarking machine learning algorithms."
        }
      },
      {
        "name": {
          "value": "STL-10",
          "justification": "STL-10 is one of the datasets used for the experiments validating the proposed method.",
          "quote": "Our experiments conducted on the CIFAR-10, Fashion-MNIST and STL-10 datasets validate the effectiveness of our method."
        },
        "aliases": [
          "STL-10"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "An analysis of single layer networks in unsupervised feature learning",
          "justification": "The authors mention STL-10 as one of the datasets used in their experiments.",
          "quote": "Coates, A., Lee, H., & Ng, A. Y. (2011). An analysis of single layer networks in unsupervised feature learning."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is likely used given its common use in implementing deep learning experiments, especially those involving the ResNet and SimCLR frameworks.",
          "quote": "We consider a ResNet-50... following Pytorch official implementation at https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py."
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "PyTorch is the deep learning library used for the experiments, as inferred from the provided implementation link.",
          "quote": "Paszke, A., Gross, S., Massa, F., et al. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1439,
    "prompt_tokens": 9379,
    "total_tokens": 10818
  }
}