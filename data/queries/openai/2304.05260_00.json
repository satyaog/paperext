{
  "paper": "2304.05260.txt",
  "words": 10538,
  "extractions": {
    "title": {
      "value": "Re-weighted Softmax Cross-entropy to Control Forgetting in Federated Learning",
      "justification": "Extracted from the research paper title",
      "quote": "R E-W EIGHTED S OFTMAX C ROSS -E NTROPY TO C ONTROL F ORGETTING IN F EDERATED L EARNING"
    },
    "description": "This paper discusses a method to reduce catastrophic forgetting in Federated Learning by re-weighting the softmax logits on a per-client basis before computing the loss. It aims to address the challenge of data heterogeneity across clients, which leads to different local objectives and client drift. The proposed method modifies the cross-entropy objective to alleviate client forgetting and improve the performance of federated learning algorithms.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper includes empirical results and experiments to demonstrate the effectiveness of the proposed method in Federated Learning scenarios.",
      "quote": "we empirically demonstrate it can alleviate client forgetting and provide consistent improvements to standard federated learning algorithms."
    },
    "primary_research_field": {
      "name": {
        "value": "Federated Learning",
        "justification": "The research specifically focuses on Federated Learning, addressing challenges such as client drift and data heterogeneity.",
        "quote": "In Federated Learning, a global model is learned by aggregating model updates computed at a set of independent client nodes"
      },
      "aliases": [
        "FL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Continual Learning",
          "justification": "The paper draws parallels between client drift in Federated Learning and catastrophic forgetting in Continual Learning, using strategies inspired by Continual Learning to address these challenges.",
          "quote": "We can draw a connection between the catastrophic forgetting problem in continual learning and the client drift problem in federated learning."
        },
        "aliases": [
          "CL"
        ]
      },
      {
        "name": {
          "value": "Supervised Learning",
          "justification": "The experiments and methods discussed, such as supervised multi-class classification, are indicative of supervised learning techniques.",
          "quote": "Under realistic settings, client data will often have non-i.i.d. distributions. For the case of supervised multi-class classification, users may frequently have no data whatsoever from one or several classes."
        },
        "aliases": [
          "SL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "FedAvg",
          "justification": "FedAvg is a mentioned baseline algorithm used for comparison in the experiments.",
          "quote": "Baseline algorithm FedAvg (McMahan et al., 2017)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "FedAvg was not contributed by the authors of this paper but is used for comparison.",
          "quote": "We apply the re-weighted softmax to baseline methods FedAvg (McMahan et al., 2017)..."
        },
        "is_executed": {
          "value": 1,
          "justification": "FedAvg was executed as part of the experiments.",
          "quote": "In our experiments, we observe that FedAvg often..."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of FedAvg is compared to other models in the paper.",
          "quote": "We also observe these improvements are not limited to FedAvg since we also observe significant performance increases when WSM is applied to SCAFFOLD and FedProx."
        },
        "referenced_paper_title": {
          "value": "Communication-Efficient Learning of Deep Networks from Decentralized Data",
          "justification": "FedAvg is introduced in this paper by McMahan et al.",
          "quote": "Baseline algorithm FedAvg (McMahan et al., 2017)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is listed as one of the datasets used in the experiments.",
          "quote": "We utilize CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and FEMNIST (Caldas et al., 2018) datasets in our experiments."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The dataset CIFAR-10 is introduced in this paper by Krizhevsky et al.",
          "quote": "We utilize CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and FEMNIST (Caldas et al., 2018) datasets in our experiments."
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is listed as one of the datasets used in the experiments.",
          "quote": "We utilize CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and FEMNIST (Caldas et al., 2018) datasets in our experiments."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The dataset CIFAR-100 is introduced in this paper by Krizhevsky et al.",
          "quote": "We utilize CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and FEMNIST (Caldas et al., 2018) datasets in our experiments."
        }
      },
      {
        "name": {
          "value": "FEMNIST",
          "justification": "FEMNIST is listed as one of the datasets used in the experiments.",
          "quote": "We utilize CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and FEMNIST (Caldas et al., 2018) datasets in our experiments."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "LEAF: A Benchmark for Federated Settings",
          "justification": "The dataset FEMNIST is introduced in this paper by Caldas et al.",
          "quote": "We utilize CIFAR-10, CIFAR-100 (Krizhevsky & Hinton, 2009) and FEMNIST (Caldas et al., 2018) datasets in our experiments."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1200,
    "prompt_tokens": 21252,
    "total_tokens": 22452
  }
}