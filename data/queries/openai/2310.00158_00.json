{
  "paper": "2310.00158.txt",
  "words": 10736,
  "extractions": {
    "title": {
      "value": "Feedback-Guided Data Synthesis for Imbalanced Classification",
      "justification": "The title of the paper is available at the top of the first page.",
      "quote": "Feedback-Guided Data Synthesis for Imbalanced Classification"
    },
    "description": "This paper introduces a framework for augmenting static datasets with useful synthetic samples based on feedback from the classifier to the generative model. The framework is designed to be effective in balanced class distribution for imbalanced scenarios by ensuring that the samples generated are close to the support of the real data and are sufficiently diverse. The approach is validated on imbalanced datasets ImageNet-LT and NICO++ and shows state-of-the-art improvements.",
    "type": {
      "value": "empirical",
      "justification": "The paper employs experiments and validations to show the effectiveness of its proposed framework, particularly on the ImageNet-LT and NICO++ datasets, showcasing empirical performance gains.",
      "quote": "In this work, we introduce a framework for augmenting static datasets with useful synthetic samples... We validate three feedback criteria on long-tailed dataset ImageNet-LT as well as group-imbalanced dataset NICO++."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The primary focus of the paper is on generating and augmenting images for the purpose of improving classification tasks, which falls under the domain of Computer Vision.",
        "quote": "leveraging state-of-the-art text-to-image models as data sources that can be queried to improve downstream applications."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper uses generative models to synthesize data aiming to augment static datasets effectively.",
          "quote": "With the recent advances in generative models, researchers have started augmenting these static datasets with synthetic data, reporting moderate performance improvements on classification tasks."
        },
        "aliases": [
          "Generative Adversarial Networks",
          "GANs"
        ]
      },
      {
        "name": {
          "value": "Imbalanced Classification",
          "justification": "The central theme of the paper is addressing class imbalance problems through synthetic data generation and classifier feedback.",
          "quote": "the goal is to create a balanced training set using synthetic data."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Data Augmentation",
          "justification": "The paper revolves around the augmentation of datasets using synthetic data to improve classifier performance.",
          "quote": "We hypothesize that these performance gains are limited by the lack of feedback from the classifier to the generative model, which would promote the usefulness of the generated samples to improve the classifierâ€™s performance."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Latent Diffusion Model (LDM) v2-1-unclip",
          "justification": "The Latent Diffusion Model (LDM) v2-1-unclip is extensively used as the generative model for creating synthetic data in the experiments conducted for the paper.",
          "quote": "We leverage the pre-trained state-of-the-art image-and-text conditional LDM v2-1-unclip (Rombach et al., 2022) to sample from."
        },
        "aliases": [
          "LDM v2-1-unclip"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The model is not newly introduced but used in the scope of the paper for synthetic data generation.",
          "quote": "We leverage the pre-trained state-of-the-art image-and-text conditional LDM v2-1-unclip (Rombach et al., 2022) to sample from."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is executed as part of the data synthesis process in the paper's experiments.",
          "quote": "We leverage the pre-trained state-of-the-art image-and-text conditional LDM v2-1-unclip (Rombach et al., 2022) to sample from."
        },
        "is_compared": {
          "value": true,
          "justification": "The performances of datasets augmented with synthetic data generated by LDM are compared against other methods in the paper.",
          "quote": "We report the results of our proposed framework for the three feedback guidance techniques introduced... by leveraging synthetic data from generative models, our framework surpasses the LDM baseline."
        },
        "referenced_paper_title": {
          "value": "High-Resolution Image Synthesis with Latent Diffusion Models",
          "justification": "This is the referenced paper where the used model 'LDM v2-1-unclip' was introduced.",
          "quote": "We leverage the pre-trained state-of-the-art image-and-text conditional LDM v2-1-unclip (Rombach et al., 2022) to sample from."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet-LT",
          "justification": "ImageNet-LT is one of the key datasets used to evaluate the performance of the proposed framework in the paper.",
          "quote": "More precisely, we conduct experiments on ImageNet Long-Tailed (ImageNet-LT) (Liu et al., 2019)"
        },
        "aliases": [
          "ImageNet Long-Tailed"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Large-Scale Long-Tailed Recognition in an Open World",
          "justification": "This is the referenced paper where the 'ImageNet-LT' dataset was introduced.",
          "quote": "More precisely, we conduct experiments on ImageNet Long-Tailed (ImageNet-LT) (Liu et al., 2019)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper mentions using PyTorch, particularly for experimenting with float16 datatype settings.",
          "quote": "we use the float16 datatype in PyTorch"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "This is the standard reference for the PyTorch library.",
          "quote": "we use the float16 datatype in PyTorch"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1154,
    "prompt_tokens": 19301,
    "total_tokens": 20455
  }
}