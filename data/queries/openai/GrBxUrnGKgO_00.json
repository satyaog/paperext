{
  "paper": "GrBxUrnGKgO.txt",
  "words": 4753,
  "extractions": {
    "title": {
      "value": "From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML",
      "justification": "This is the title of the paper mentioned at the beginning of the provided text.",
      "quote": "From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML"
    },
    "description": "This paper investigates how safety engineering frameworks, specifically Failure Mode and Effects Analysis (FMEA) and System Theoretic Process Analysis (STPA), can be adapted to manage social and ethical risks in machine learning (ML) systems. The study includes interviews with 30 industry practitioners to gather their insights and current practices in social and ethical risk management.",
    "type": {
      "value": "Empirical",
      "justification": "The paper is based on empirical research as it involves conducting 30 semi-structured in-depth interviews with industry practitioners to understand their current practices and gather their first reactions towards adapting safety engineering frameworks to ML.",
      "quote": "We conducted 30 semi-structured in-depth interviews with industry practitioners who shared their current practices used to assess and mitigate social and ethical risks."
    },
    "primary_research_field": {
      "name": {
        "value": "Responsible AI",
        "justification": "The primary research field of the paper is responsible AI as it focuses on assessing and managing social and ethical risks in machine learning systems.",
        "quote": "We interviewed 30 industry practitioners on their current social and ethical risk management practices, and collected their first reactions on adapting safety engineering frameworks into their practice."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "AI Safety",
          "justification": "The paper explores the adaptation of safety engineering frameworks to enhance the safety of AI systems.",
          "quote": "Safety practices in the ML community often focus on ML-centered areas, such as Robustness, Monitoring, Alignment and Systemic Safety."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 366,
    "prompt_tokens": 7921,
    "total_tokens": 8287
  }
}