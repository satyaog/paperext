{
  "paper": "2306.13761.txt",
  "words": 5087,
  "extractions": {
    "title": {
      "value": "CeBed: A Benchmark for Deep Data-Driven OFDM Channel Estimation",
      "justification": "This is the title as provided in the research paper.",
      "quote": "CeBed: A Benchmark for Deep Data-Driven OFDM Channel Estimation"
    },
    "description": "The paper presents CeBed, the first open benchmark for deep OFDM channel estimation. It aims to unify various deep OFDM estimators by introducing standardized scenarios and evaluation protocols. The benchmark includes a modular toolkit for adding new scenarios, models, and metrics, along with a comprehensive evaluation of ten baseline models.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper performs a multi-metric (accuracy, robustness, generalization) analysis of various models, implementing ten baselines and evaluating them on different scenarios.",
      "quote": "Second, we perform a multi-metric (accuracy, robustness, generalization) analysis of the performance of ten deep and traditional baselines."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning for Wireless Communications",
        "justification": "The paper focuses on deep learning techniques applied to channel estimation within wireless OFDM systems.",
        "quote": "Deep learning has been extensively adopted in channel estimation problems."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Channel Estimation",
          "justification": "The core application of the deep learning models discussed in this paper is channel estimation, which is extensively covered and evaluated.",
          "quote": "Deep learning has been extensively adopted in channel estimation problems."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "OFDM Systems",
          "justification": "The DL models and datasets are specifically designed to address issues in OFDM systems, which are central to the discussion.",
          "quote": "Orthogonal frequency division multiplexing (OFDM) is the core transmission technology in 5G and beyond thanks to its high data-rate transmissions and resilience to frequency selective fading."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ChannelNet",
          "justification": "ChannelNet is one of the deep learning models implemented and evaluated in the benchmark.",
          "quote": "ChannelNet [4]: is a pre-sampling SR method that uses SRCNN to upscale the low-resolution inputs and a denoising CNN to further refine the obtained channels."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "ChannelNet was implemented as part of the benchmark evaluation but is not an original contribution of this paper.",
          "quote": "ChannelNet [4]: is a pre-sampling SR method that uses SRCNN to upscale the low-resolution inputs and a denoising CNN [16] to further refine the obtained channels."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of ChannelNet.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "ChannelNet is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including ChannelNet and compare them."
        },
        "referenced_paper_title": {
          "value": "Deep learning-based channel estimation",
          "justification": "The referenced paper for ChannelNet is titled 'Deep learning-based channel estimation'.",
          "quote": "ChannelNet [4]: is a pre-sampling SR method that uses SRCNN to upscale the low-resolution inputs and a denoising CNN to further refine the obtained channels."
        }
      },
      {
        "name": {
          "value": "ReEsNet",
          "justification": "ReEsNet is another significant deep learning model evaluated in the benchmark.",
          "quote": "ReEsNet [5] uses a post-sampling residual SR network (as in ESDR) and a deconvolution layer as an upscaling layer."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "ReEsNet was incorporated as part of the benchmark evaluation, but it is not a novel contribution of this specific paper.",
          "quote": "ReEsNet [5] uses a post-sampling residual SR network (as in ESDR) and a deconvolution layer as an upscaling layer."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of ReEsNet.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "ReEsNet is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including ReEsNet and compare them."
        },
        "referenced_paper_title": {
          "value": "Deep residual learning meets OFDM channel estimation",
          "justification": "The referenced paper for ReEsNet is titled 'Deep residual learning meets OFDM channel estimation'.",
          "quote": "ReEsNet [5] uses a post-sampling residual SR network (as in ESDR) and a deconvolution layer as an upscaling layer."
        }
      },
      {
        "name": {
          "value": "InReEsNet",
          "justification": "InReEsNet is a prominent model mentioned in the paper.",
          "quote": "InReEsNet [6] is an extension of ReEsNet where the deconvolution layer is replaced by a bilinear interpolation."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "InReEsNet was implemented for the evaluation but is not an original contribution of this paper.",
          "quote": "InReEsNet [6] is an extension of ReEsNet where the deconvolution layer is replaced by a bilinear interpolation."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of InReEsNet.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "InReEsNet is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including InReEsNet and compare them."
        },
        "referenced_paper_title": {
          "value": "Low complexity channel estimation with neural network solutions",
          "justification": "The referenced paper for InReEsNet is titled 'Low complexity channel estimation with neural network solutions'.",
          "quote": "InReEsNet [6] is an extension of ReEsNet where the deconvolution layer is replaced by a bilinear interpolation."
        }
      },
      {
        "name": {
          "value": "MReEsNet",
          "justification": "MReEsNet is one of the models introduced in the paper for evaluation.",
          "quote": "MReEsNet is another extension of ReEsNet, that we introduce, where the low-resolution inputs are replaced by the masked LS estimates."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "MReEsNet is introduced in this paper as an extension of ReEsNet.",
          "quote": "MReEsNet is another extension of ReEsNet, that we introduce, where the low-resolution inputs are replaced by the masked LS estimates."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of MReEsNet.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "MReEsNet is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including MReEsNet and compare them."
        },
        "referenced_paper_title": {
          "value": "Not Applicable",
          "justification": "MReEsNet is introduced by the authors and hence does not have a reference paper.",
          "quote": "MReEsNet is another extension of ReEsNet, that we introduce, where the low-resolution inputs are replaced by the masked LS estimates."
        }
      },
      {
        "name": {
          "value": "DDAE",
          "justification": "DDAE is one of the models evaluated in the paper.",
          "quote": "DDAE [9] is a dense denoising autoencoder. It takes the masked LS estimates as inputs and simultaneously denoises the coefficients at the pilot positions and estimates the values at the masked data locations."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "DDAE is implemented for evaluation but is not an original contribution of this paper.",
          "quote": "DDAE [9] is a dense denoising autoencoder. It takes the masked LS estimates as inputs and simultaneously denoises the coefficients at the pilot positions and estimates the values at the masked data locations."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of DDAE.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "DDAE is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including DDAE and compare them."
        },
        "referenced_paper_title": {
          "value": "A denoising autoencoder based wireless channel transfer function estimator for OFDM communication system",
          "justification": "The referenced paper for DDAE is titled 'A denoising autoencoder based wireless channel transfer function estimator for OFDM communication system'.",
          "quote": "DDAE [9] is a dense denoising autoencoder. It takes the masked LS estimates as inputs and simultaneously denoises the coefficients at the pilot positions and estimates the values at the masked data locations."
        }
      },
      {
        "name": {
          "value": "MTRE",
          "justification": "MTRE is one of the deep learning models evaluated in the benchmark.",
          "quote": "MTRE [8] is an MIM approach. It embeds the masked LS estimates using a 1D convolution layer, and then applies a sequence of Transformer encoder blocks."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "MTRE was implemented as part of the benchmark evaluation but is not an original contribution of this paper.",
          "quote": "MTRE [8] is an MIM approach. It embeds the masked LS estimates using a 1D convolution layer, and then applies a sequence of Transformer encoder blocks."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of MTRE.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "MTRE is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including MTRE and compare them."
        },
        "referenced_paper_title": {
          "value": "Channel estimation method based on transformer in high dynamic environment",
          "justification": "The referenced paper for MTRE is titled 'Channel estimation method based on transformer in high dynamic environment'.",
          "quote": "MTRE [8] is an MIM approach. It embeds the masked LS estimates using a 1D convolution layer, and then applies a sequence of Transformer encoder blocks."
        }
      },
      {
        "name": {
          "value": "HA02",
          "justification": "HA02 is one of the deep learning models implemented and evaluated in the benchmark.",
          "quote": "HA02 [7] is a hybrid auto-encoder that uses a Transformer encoder and a residual decoder (as in ReEsNet) and an up-sampling module."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "HA02 was implemented as part of the benchmark evaluation but is not an original contribution of this paper.",
          "quote": "HA02 [7] is a hybrid auto-encoder that uses a Transformer encoder and a residual decoder (as in ReEsNet) and an up-sampling module."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes the implementation and evaluation of HA02.",
          "quote": "First, we define a new taxonomy of scenarios covering various wireless system configurations and select a set of scenarios to standardize the training and evaluation conditions."
        },
        "is_compared": {
          "value": 1,
          "justification": "HA02 is compared against other models in the conducted experiments.",
          "quote": "In this work, we implement 10 baselines including HA02 and compare them."
        },
        "referenced_paper_title": {
          "value": "Channelformer: Attention based Neural Solution for Wireless Channel Estimation and Effective Online Training",
          "justification": "The referenced paper for HA02 is titled 'Channelformer: Attention based Neural Solution for Wireless Channel Estimation and Effective Online Training'.",
          "quote": "HA02 [7] is a hybrid auto-encoder that uses a Transformer encoder and a residual decoder (as in ReEsNet) and an up-sampling module."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CeBed",
          "justification": "CeBed is the dataset introduced and utilized throughout the paper for standardizing the training and evaluation of deep channel estimators.",
          "quote": "To address these concerns, we present the first open benchmark for deep OFDM channel estimation, coined CeBed."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "Not Applicable",
          "justification": "CeBed is introduced in this paper and hence does not have a reference paper.",
          "quote": "To address these concerns, we present the first open benchmark for deep OFDM channel estimation, coined CeBed."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Sionna",
          "justification": "The paper mentions the use of the Sionna library for generating datasets.",
          "quote": "We use the open source link level simulator Sionna."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Sionna: An open-source library for next-generation physical layer research",
          "justification": "The referenced paper for Sionna is titled 'Sionna: An open-source library for next-generation physical layer research'.",
          "quote": "We use the open source link level simulator Sionna [17]."
        }
      },
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper mentions the use of the PyTorch library for training models.",
          "quote": "All the models are trained using Adam optimizer with an initial learning rate of 0.001."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A method for stochastic optimization",
          "justification": "Although the paper refers to the 'Adam' optimizer, it is common knowledge that it is implemented using the PyTorch library.",
          "quote": "All the models are trained using Adam optimizer with an initial learning rate of 0.001."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3656,
    "prompt_tokens": 9692,
    "total_tokens": 13348
  }
}