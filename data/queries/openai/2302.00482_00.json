{
  "paper": "2302.00482.txt",
  "words": 17428,
  "extractions": {
    "title": {
      "value": "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport",
      "justification": "The title of the paper is clearly stated in the provided text.",
      "quote": "Improving and Generalizing Flow-Based Generative Models\nwith Minibatch Optimal Transport"
    },
    "description": "This paper introduces the generalized conditional flow matching (CFM) technique for continuous normalizing flows (CNFs), which addresses limitations in CNF training and performance. It proposes a variant called optimal transport CFM (OT-CFM) that enhances training efficiency and inference speed. The paper also evaluates CFM and OT-CFM models in several generative tasks and releases a Python package for training these models.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper includes experimental evaluations of the proposed CFM and OT-CFM models on various tasks, as well as comparisons with existing methods.",
      "quote": "We evaluate CFM and OT-CFM in experiments on single-cell dynamics, image generation, unsupervised image translation, and energy-based models."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research is based on improving generative models, which are a core aspect of deep learning.",
        "quote": "Generative modeling considers the problem of approximating and sampling from a probability distribution.\nNormalizing flows, which have emerged as a competitive generative modeling method, construct an invertible\nand efficiently differentiable mapping between a fixed (e.g., standard normal) distribution and the data\ndistribution (Rezende & Mohamed, 2015)."
      },
      "aliases": [
        "Deep Learning",
        "DL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Generative Models",
          "justification": "The primary focus of the paper is on improving and generalizing flow-based generative models using the proposed CFM and OT-CFM techniques.",
          "quote": "Continuous normalizing flows (CNFs) are an attractive generative modeling technique... We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs."
        },
        "aliases": [
          "Generative Models",
          "Generative Modeling"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "OT-CFM",
          "justification": "OT-CFM is explicitly introduced as a novel model in the paper.",
          "quote": "We propose a variant of the \nCFM called optimal transport conditional flow matching (OT-CFM) that approximates dynamic OT via CNFs."
        },
        "aliases": [
          "OT-CFM"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "OT-CFM is a proposed variant introduced and evaluated within the paper.",
          "quote": "We propose a variant of the \nCFM called optimal transport conditional flow matching (OT-CFM)..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was evaluated using experiments, indicating it was executed.",
          "quote": "We evaluate CFM and OT-CFM in experiments on single-cell dynamics, image generation, unsupervised image translation, and energy-based models."
        },
        "is_compared": {
          "value": 1,
          "justification": "The OT-CFM model is compared against other models such as standard CFM, FM, etc.",
          "quote": "CFM and OT-CFM in experiments on single-cell dynamics, image generation, unsupervised image translation, and energy-based models..."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "OT-CFM is presented as a novel contribution of this paper, so no referenced paper title is applicable.",
          "quote": "We propose a variant of the \nCFM called optimal transport conditional flow matching (OT-CFM)..."
        }
      },
      {
        "name": {
          "value": "CFM",
          "justification": "Conditional Flow Matching (CFM) is a principal model introduced in the paper.",
          "quote": "We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs."
        },
        "aliases": [
          "CFM"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "CFM is described as a novel model introduced in the paper.",
          "quote": "We introduce the generalized conditional flow matching (CFM) technique..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was evaluated through experiments, indicating it was executed.",
          "quote": "We evaluate CFM and OT-CFM in experiments on single-cell dynamics, image generation, unsupervised image translation, and energy-based models."
        },
        "is_compared": {
          "value": 1,
          "justification": "CFM was compared against other models.",
          "quote": "CFM and OT-CFM in experiments on..."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "CFM is presented as a novel contribution from this paper, so no reference paper title is necessary.",
          "quote": "We introduce the generalized conditional flow matching (CFM) technique."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is mentioned as one of the evaluation benchmarks for high-dimensional image generation tasks.",
          "quote": "We perform an experiment on unconditional CIFAR-10 generation from a Gaussian source to examine how\nOT-CFM performs in the high-dimensional image setting."
        },
        "aliases": [
          "CIFAR-10"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The referenced paper provides the context for CIFAR-10 dataset which was used in the experiments.",
          "quote": "The CIFAR-10 dataset [48]"
        }
      },
      {
        "name": {
          "value": "CelebA",
          "justification": "CelebA dataset is used for the unsupervised image translation task.",
          "quote": "We show how CFM can be used to learn a mapping between two unpaired datasets in high-dimensional space using the CelebA dataset (Liu et al., 2015; Sun et al., 2014), which consists of âˆ¼200k images of faces together with 40 binary attribute annotations."
        },
        "aliases": [
          "CelebA"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Deep Learning Face Attributes in the Wild",
          "justification": "The referenced paper provides the foundational dataset description used in the experiments.",
          "quote": "The CelebA dataset (Liu et al., 2015; Sun et al., 2014)..."
        }
      },
      {
        "name": {
          "value": "Embryoid body dataset",
          "justification": "This dataset was used for single-cell trajectory interpolation tasks.",
          "quote": "For the Embryoid body dataset which consists of 5 timepoints collected over 30 days we train separate models leaving out times 1, 2, 3 in turn."
        },
        "aliases": [
          "EB dataset"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Optimal-Transport Analysis of Single-Cell Gene Expression Identifies Developmental Trajectories in Reprogramming",
          "justification": "The referenced paper provides context for the Embryoid body dataset which was utilized in the experiments.",
          "quote": "For the Embryoid body dataset which consists of 5 timepoints collected over 30 days..."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The code implementation specifies the use of PyTorch for developing and training models.",
          "quote": "The Python package for CFM is implemented in PyTorch."
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "The referenced paper is the foundational reference for PyTorch, the library used in this research.",
          "quote": "implemented in PyTorch..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1515,
    "prompt_tokens": 31648,
    "total_tokens": 33163
  }
}