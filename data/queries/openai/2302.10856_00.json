{
  "paper": "2302.10856.txt",
  "words": 12114,
  "extractions": {
    "title": {
      "value": "Overview of the TREC 1 2021 Fair Ranking Track",
      "justification": "The title is clearly mentioned on the first page of the paper.",
      "quote": "Overview of the TREC 2021 Fair Ranking Track"
    },
    "description": "The paper describes the goals, structure, data, and evaluation metrics of the TREC 2021 Fair Ranking Track, which aims to develop and evaluate retrieval algorithms that provide fair exposure to diverse demographics in Wikipedia articles.",
    "type": {
      "value": "Empirical",
      "justification": "The study involves empirical evaluations of different retrieval algorithms using specific datasets and well-defined tasks, as shown in sections describing tasks and evaluation metrics.",
      "quote": "The 2021 Fair Ranking Track adopted a resource allocation task... aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure."
    },
    "primary_research_field": {
      "name": {
        "value": "Information Retrieval",
        "justification": "The primary goal of the Fair Ranking Track is to develop and evaluate retrieval algorithms for fair ranking, fitting within the Information Retrieval field.",
        "quote": "The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Fairness in Machine Learning",
          "justification": "The primary focus on developing retrieval algorithms to ensure fair exposure to documents related to protected characteristics places this paper in the field of Fairness in Machine Learning.",
          "quote": "...aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "Subset of English Wikipedia",
          "justification": "The dataset used in the tasks is described as a subset of the English Wikipedia.",
          "quote": "Participants were provided with a corpus of documents (a subset of the English language Wikipedia) and a set of queries."
        },
        "aliases": [
          "English Wikipedia"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "The reference paper for the dataset is not provided in the document.",
          "quote": "Not applicable"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "BM25",
          "justification": "BM25 is mentioned as part of the ranking models used by participants.",
          "quote": "BM25 ranking from pyserini and re-ranked using MMR implicit diversification (without explicit fairness groups). Lambda varied between runs."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "The reference paper for BM25 is not provided in the document.",
          "quote": "Not applicable"
        }
      },
      {
        "name": {
          "value": "RoBERTa",
          "justification": "RoBERTa is mentioned as part of the ranking models used by participants.",
          "quote": "RoBERTa model to compute embeddings for text fields."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "The reference paper for RoBERTa is not provided in the document.",
          "quote": "Not applicable"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 601,
    "prompt_tokens": 31416,
    "total_tokens": 32017
  }
}