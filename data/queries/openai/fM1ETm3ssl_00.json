{
  "paper": "fM1ETm3ssl.txt",
  "words": 8495,
  "extractions": {
    "title": {
      "value": "Towards Meta-Models For Automated Interpretability",
      "justification": "Title is clearly stated at the beginning of the paper.",
      "quote": "TOWARDS META-MODELS FOR AUTOMATED INTERPRETABILITY"
    },
    "description": "This paper proposes a scalable meta-model architecture for automated interpretability of neural networks. The meta-models are neural networks that take another network’s parameters as input to perform interpretability tasks, such as detecting backdoors and translating transformer weights to human-readable code. The research aims to provide proof-of-concept for automated tools useful to interpretability researchers.",
    "type": {
      "value": "Empirical",
      "justification": "The paper presents empirical results from multiple experiments including predicting hyperparameters, detecting backdoors, and mapping transformer parameters to equivalent programs written in human-readable code.",
      "quote": "In this section we present empirical results on three main meta-modeling tasks: predicting data properties, detecting backdoors, and mapping transformer parameters to equivalent programs written in human-readable code."
    },
    "primary_research_field": {
      "name": {
        "value": "Interpretability of Neural Networks",
        "justification": "The primary focus of the paper is on interpretability of neural networks, specifically aiming to automate interpretability methods.",
        "quote": "The field of interpretability studies the workings of neural networks, with the goal of making the outputs and behaviour of neural networks more understandable to humans."
      },
      "aliases": [
        "Automated Interpretability",
        "Meta-Models for Interpretability"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Mechanistic Interpretability",
          "justification": "Mechanistic interpretability is one of the sub-problems focused on in this paper, aiming to understand the learned mechanisms implemented by a neural network.",
          "quote": "In the context of this work we occasionally focus on the sub-problem of mechanistic interpretability, which aims to understand the learned mechanisms implemented by a neural network."
        },
        "aliases": [
          "Explainable AI",
          "XAI"
        ]
      },
      {
        "name": {
          "value": "Automated Interpretability Methods",
          "justification": "The paper discusses multiple automated interpretability methods such as using LLMs to annotate neurons, automated circuit ablation, and verification of circuit behavior.",
          "quote": "There have been a number of proposed approaches to automated interpretability, including using LLMs to annotate neurons based on dataset examples, automated circuit ablation, and verification of circuit behavior."
        },
        "aliases": [
          "AI Transparency",
          "AI Explainability"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Meta-Model",
          "justification": "The paper introduces and focuses on the Meta-Model to take another network’s parameters as input for interpretability tasks.",
          "quote": "We propose to train a neural network to take the parameters of other neural networks as input in order to perform interpretability tasks. We refer to such models as meta-models."
        },
        "aliases": [
          "Meta-Neural Network",
          "Meta-Interpreter"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The meta-model is introduced as a new approach for interpretability tasks in this paper.",
          "quote": "We propose to train a neural network to take the parameters of other neural networks as input in order to perform interpretability tasks. We refer to such models as meta-models."
        },
        "is_executed": {
          "value": 1,
          "justification": "The meta-model is executed for multiple tasks such as detecting backdoors and translating transformer weights.",
          "quote": "The inputs are the weights of a base model (in our experiments either a CNN or transformer)."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of the meta-model is compared with previous methods in multiple tasks.",
          "quote": "We show our proposed architecture outperforms previous meta-model methods by Eilertsen et al. (2020) and Schürholt, Kostadinov, et al. (2021) for predicting hyperparameters directly from weights."
        },
        "referenced_paper_title": {
          "value": "Classifying the classifier: dissecting the weight space of neural networks",
          "justification": "The referenced paper is cited when comparing the performance of the proposed meta-model for predicting hyperparameters.",
          "quote": "We show our proposed architecture outperforms previous meta-model methods by Eilertsen et al. (2020) and Schürholt, Kostadinov, et al. (2021) for predicting hyperparameters directly from weights."
        }
      },
      {
        "name": {
          "value": "Base Model",
          "justification": "The paper uses the term 'base models' to describe the subject networks whose weights are interpreted by the meta-model.",
          "quote": "We refer to such models as meta-models and the networks they are trained on as base models."
        },
        "aliases": [
          "Subject Neural Network",
          "Primary Network"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Base models are the pre-existing neural networks that are being interpreted by the newly introduced meta-model.",
          "quote": "We refer to such models as meta-models and the networks they are trained on as base models."
        },
        "is_executed": {
          "value": 1,
          "justification": "Base models are used in the experiments with the meta-model to perform tasks like backdoor detection and hyperparameter prediction.",
          "quote": "Base Model Flattened weights Conv Chunks Conv Chunk Positional Encoding Meta-Model Transformer"
        },
        "is_compared": {
          "value": 0,
          "justification": "Base models are not compared but rather used as input for the meta-model.",
          "quote": "We refer to such models as meta-models and the networks they are trained on as base models."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "Base models are not specifically referenced from other papers but are inherent to the experiments conducted.",
          "quote": "We refer to such models as meta-models and the networks they are trained on as base models."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The CIFAR-10 dataset is used for training base models in the experiments for detecting backdoors.",
          "quote": "In this section we show we are able to beat state-of-the-art methods on a backdoor detection task. Base model dataset. We train base models on CIFAR-10 (Krizhevsky, Hinton, et al. 2009), using a simple CNN architecture with 70,000 parameters."
        },
        "aliases": [
          "CIFAR-10 dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The CIFAR-10 dataset is derived from the referenced paper by Krizhevsky, Hinton, et al. 2009.",
          "quote": "Base model dataset. We train base models on CIFAR-10 (Krizhevsky, Hinton, et al. 2009), using a simple CNN architecture with 70,000 parameters."
        }
      },
      {
        "name": {
          "value": "MNIST",
          "justification": "The MNIST dataset is mentioned as part of the replication for comparison with prior meta-model work.",
          "quote": "The setting of Schürholt, Kostadinov, et al. (2021) is similar. The base model dataset consists of classifiers trained on four datasets: MNIST, FashionMNIST, CIFAR-10, and SVHN."
        },
        "aliases": [
          "MNIST dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Gradient-Based Learning Applied to Document Recognition",
          "justification": "The MNIST dataset is referring to the referenced paper by Yann LeCun et al. 1998.",
          "quote": "The setting of Schürholt, Kostadinov, et al. (2021) is similar. The base model dataset consists of classifiers trained on four datasets: MNIST, FashionMNIST, CIFAR-10, and SVHN."
        }
      },
      {
        "name": {
          "value": "FashionMNIST",
          "justification": "The FashionMNIST dataset is mentioned as part of the replication for comparison with prior meta-model work.",
          "quote": "The base model dataset consists of classifiers trained on four datasets: MNIST, FashionMNIST, CIFAR-10, and SVHN."
        },
        "aliases": [
          "Fashion MNIST"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms",
          "justification": "The FashionMNIST dataset is referring to the referenced paper by Han Xiao et al. 2017.",
          "quote": "The setting of Schürholt, Kostadinov, et al. (2021) is similar. The base model dataset consists of classifiers trained on four datasets: MNIST, FashionMNIST, CIFAR-10, and SVHN."
        }
      },
      {
        "name": {
          "value": "SVHN",
          "justification": "The SVHN dataset is mentioned as part of the replication for comparison with prior meta-model work.",
          "quote": "The base model dataset consists of classifiers trained on four datasets: MNIST, FashionMNIST, CIFAR-10, and SVHN."
        },
        "aliases": [
          "Street View House Numbers"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Reading Digits in Natural Images with Unsupervised Feature Learning",
          "justification": "The SVHN dataset is referring to the referenced paper by Yuval Netzer et al. 2011.",
          "quote": "The setting of Schürholt, Kostadinov, et al. (2021) is similar. The base model dataset consists of classifiers trained on four datasets: MNIST, FashionMNIST, CIFAR-10, and SVHN."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "JAX",
          "justification": "JAX is mentioned as the library used for model implementation in one of the experiments.",
          "quote": "Using a simple CNN model in JAX framework for the backdoor detection experiment."
        },
        "aliases": [
          "JAX library"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "JAX: Autograd and XLA",
          "justification": "The JAX library refers to the referenced paper by Frostig, Roy, and Quick, 2018.",
          "quote": "Using a simple CNN model in JAX framework for the backdoor detection experiment."
        }
      },
      {
        "name": {
          "value": "Flax",
          "justification": "Flax is mentioned as the library used for defining neural network layers in one of the experiments.",
          "quote": "Using the Flax library to define layers of a simple CNN model for the backdoor detection experiment."
        },
        "aliases": [
          "Flax library"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Flax: A neural network library and ecosystem for JAX.",
          "justification": "The Flax library refers to the referenced paper by Heek et al., 2020.",
          "quote": "Using the Flax library to define layers of a simple CNN model for the backdoor detection experiment."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2116,
    "prompt_tokens": 15249,
    "total_tokens": 17365
  }
}