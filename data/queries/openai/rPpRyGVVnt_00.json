{
  "paper": "rPpRyGVVnt.txt",
  "words": 7794,
  "extractions": {
    "title": {
      "value": "LEARNING TO PLAY ATARI IN A WORLD OF TOKENS",
      "justification": "The title of the paper is clearly mentioned at the beginning of the document.",
      "quote": "LEARNING TO PLAY ATARI IN A WORLD OF TOKENS"
    },
    "description": "This paper introduces Discrete Abstract Representations for Transformer-based learning (DART), a model-based reinforcement learning method that utilizes discrete representations and transformers for both world modeling and policy learning. The paper demonstrates that DART achieves state-of-the-art results on the Atari 100k benchmark without using look-ahead search during inference.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts experiments and presents results on the Atari 100k benchmark, comparing the performance of the proposed model (DART) against other models.",
      "quote": "We evaluated our model alongside existing baselines using the Atari 100k benchmark (Kaiser et al., 2019),..."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper focuses on model-based reinforcement learning, utilizing transformers for world and policy modeling.",
        "quote": "In this work, we introduce discrete abstract representations for transformer-based learning (DART), a sample-efficient method utilizing discrete representations for modeling both the world and learning behavior."
      },
      "aliases": [
        "RL",
        "Model-Based Reinforcement Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Transformer Models",
          "justification": "The paper leverages transformers for both world and policy modeling, distinguishing it from other reinforcement learning models.",
          "quote": "We utilize a transformer-decoder architecture, akin to the generative pre-trained transformer (GPT) framework, to model the world, while adopting a transformer encoder, similar to the ViT architecture, to learn the policy"
        },
        "aliases": [
          "Transformers",
          "Attention Models"
        ]
      },
      {
        "name": {
          "value": "Discrete Representations",
          "justification": "The paper introduces the use of discrete representations for world modeling and policy learning in reinforcement learning.",
          "quote": "we introduce discrete abstract representations for transformer-based learning (DART), a novel approach that leverages transformers for learning both the world model and policy"
        },
        "aliases": [
          "Discrete Abstract Representations",
          "Discrete Tokens"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "DART",
          "justification": "DART (Discrete Abstract Representations for Transformer-based learning) is the primary model introduced and evaluated in the paper.",
          "quote": "In this work, we introduce discrete abstract representations for transformer-based learning (DART), a novel approach that leverages transformers for learning both the world model and policy."
        },
        "aliases": [
          "Discrete Abstract Representations for Transformer-based learning"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The paper introduces DART as a new approach for reinforcement learning.",
          "quote": "In this work, we introduce discrete abstract representations for transformer-based learning (DART), a novel approach that leverages transformers for learning both the world model and policy."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper evaluates DART's performance on the Atari 100k benchmark, implying that the model was executed.",
          "quote": "We evaluated our model alongside existing baselines using the Atari 100k benchmark (Kaiser et al., 2019),..."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of DART is compared to various baseline models such as DreamerV3, IRIS, SPR, etc.",
          "quote": "In Figure 2, we present the IQM and optimality gap scores, as well as the mean and median scores. These scores pertain to various models assessed on Atari 100k."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "DART is the primary contribution of the paper and does not reference any prior work for its definition.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Atari 100k benchmark",
          "justification": "The Atari 100k benchmark is the primary dataset used for evaluating the performance of the DART model in the paper.",
          "quote": "DART outperforms previous state-of-the-art methods that do not use look-ahead search on the Atari 100k sample efficiency benchmark with a median human-normalized score of 0.790 and beats humans in 9 out of 26 games."
        },
        "aliases": [
          "Atari 100k"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Model-based reinforcement learning for atari",
          "justification": "The Atari 100k benchmark is based on the work titled 'Model-based reinforcement learning for atari' by Kaiser et al., 2019.",
          "quote": "We evaluated our model alongside existing baselines using the Atari 100k benchmark (Kaiser et al., 2019),"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "TensorFlow",
          "justification": "TensorFlow is a common deep learning library used in many reinforcement learning and machine learning experiments.",
          "quote": "N/A"
        },
        "aliases": [
          "TF"
        ],
        "role": "Referenced",
        "referenced_paper_title": {
          "value": "Transformers: State-of-the-art natural language processing",
          "justification": "The paper refers to the work by Wolf et al., 2020, which makes extensive use of TensorFlow for implementing transformers.",
          "quote": "This motivates the need to use transformers (Vaswani et al., 2017; Lin et al., 2022), which have proven highly effective in capturing long-range dependencies in various natural language processing (NLP) tasks (Wolf et al., 2020)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1101,
    "prompt_tokens": 14706,
    "total_tokens": 15807
  }
}