{
  "paper": "2210.01742.txt",
  "words": 7436,
  "extractions": {
    "title": {
      "value": "CADet: Fully Self-Supervised Anomaly Detection With Contrastive Learning",
      "justification": "This is the title of the paper as provided by the user.",
      "quote": "CADet: Fully Self-Supervised Anomaly Detection With Contrastive Learning"
    },
    "description": "This paper presents CADet, a fully self-supervised method for anomaly detection using contrastive learning. The method is designed to detect out-of-distribution (OOD) samples and adversarial attacks without needing access to OOD samples during training.",
    "type": {
      "value": "Empirical",
      "justification": "The paper evaluates the empirical performance of the proposed CADet method across various benchmarks including CIFAR-10, CIFAR-10.1, ImageNet, ImageNet-O, and iNaturalist.",
      "quote": "Section 5 presents CADet and evaluates its empirical performance."
    },
    "primary_research_field": {
      "name": {
        "value": "Anomaly Detection",
        "justification": "The main focus of the paper is on detecting anomalies, specifically out-of-distribution samples and adversarial attacks.",
        "quote": "Motivated by this success, we introduce CADet (Contrastive Anomaly Detection), a novel method for OOD detection of single samples."
      },
      "aliases": [
        "OOD Detection",
        "Anomaly Detection"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The method utilizes self-supervised contrastive learning to perform anomaly detection.",
          "quote": "This work explores the use of self-supervised contrastive learning to the simultaneous detection of two types of OOD samples: unseen classes and adversarial perturbations."
        },
        "aliases": [
          "Self-Supervised Contrastive Learning"
        ]
      },
      {
        "name": {
          "value": "Adversarial Detection",
          "justification": "Part of the paper's focus is on detecting adversarial attacks.",
          "quote": "CADet outperforms existing adversarial detection methods in identifying adversarially perturbed samples on ImageNet."
        },
        "aliases": [
          "Adversarial Detection"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "SimCLRv2",
          "justification": "SimCLRv2 is used as part of the contrastive learning approach in the paper.",
          "quote": "Section 3 describes the self-supervised contrastive method based on SimCLRv2 [5] used in this work."
        },
        "aliases": [
          "SimCRL"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "SimCLRv2 is an existing model used in the study, not a novel contribution.",
          "quote": "Section 3 describes the self-supervised contrastive method based on SimCLRv2 [5] used in this work."
        },
        "is_executed": {
          "value": 1,
          "justification": "SimCLRv2 is used as a part of the proposed method for evaluation.",
          "quote": "We build our model on top of SimCLRv2 [5] for its simplicity and efficiency. It is composed of an encoder backbone network fθ as well as a 3-layer contrastive head hθ′."
        },
        "is_compared": {
          "value": 1,
          "justification": "The SimCLRv2-based method is compared with other anomaly detection methods.",
          "quote": "We compare our results with ODIN [33], which achieves good performances in Lee et al. [32] despite not being designed for adversarial detection, Feature Squeezing (FS) [66], Local Intrinsinc Dimensionality (LID) [40], and to Hu et al. [26]."
        },
        "referenced_paper_title": {
          "value": "Big self-supervised models are strong semi-supervised learners",
          "justification": "The SimCLRv2 method is described in the referenced paper.",
          "quote": "[5] T. Chen, S. Kornblith, K. Swersky, M. Norouzi, and G. Hinton. Big self-supervised models are strong semi-supervised learners. arXiv preprint arXiv:2006.10029, 2020."
        }
      },
      {
        "name": {
          "value": "ResNet50",
          "justification": "A ResNet50 model is used for both supervised and self-supervised learning in this work.",
          "quote": "For computational simplicity and comparison with previous work, we use a ResNet50 encoder architecture with final features of size 2048."
        },
        "aliases": [
          "ResNet-50"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ResNet50 is an existing model utilized as part of the experiment.",
          "quote": "For computational simplicity and comparison with previous work, we use a ResNet50 encoder architecture with final features of size 2048."
        },
        "is_executed": {
          "value": 1,
          "justification": "The ResNet50 is implemented and used extensively in both supervised and self-supervised paradigms within the paper.",
          "quote": "We use a ResNet50 encoder architecture with final features of size 2048. Following SimCLRv2, we use a three-layer fully connected contrastive head with hidden layers of width 2048 using ReLU activation and batchNorm and set the last layer projection to dimension 128."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares results between supervised and contrastive learning using ResNet50 as the backbone.",
          "quote": "Finally, applying CADet to a supervised network achieves state-of-the-art performances on iNaturalist with ResNet50 architecture, suggesting CADet can be a reasonable standalone detection method on some benchmarks, independently of contrastive learning."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "The ResNet50 model is described in the referenced paper.",
          "quote": "[31] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Conference on Computer Vision and Pattern Recognition, 2016."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is used for evaluating the MMD two-sample test.",
          "quote": "We demonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1 with higher confidence than previous work."
        },
        "aliases": [
          "CIFAR10"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-10 dataset is described in the referenced paper.",
          "quote": "[31] A. Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009."
        }
      },
      {
        "name": {
          "value": "CIFAR-10.1",
          "justification": "CIFAR-10.1 is used for evaluating the MMD two-sample test.",
          "quote": "We demonstrate its effectiveness by discriminating between CIFAR-10 and CIFAR-10.1 with higher confidence than previous work."
        },
        "aliases": [
          "CIFAR10.1"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Do ImageNet Classifiers Generalize to ImageNet?",
          "justification": "The CIFAR-10.1 dataset is described in the referenced paper.",
          "quote": "[50] B. Recht, R. Roelofs, L. Schmidt, and V. Shankar. Do imagenet classifiers generalize to imagenet? arXiv preprint arXiv:1902.10811, 2019."
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset is used to evaluate CADet's adversarial detection on various perturbations.",
          "quote": "We introduce CADet, a fully self-supervised method for OOD detection inspired by MMD, and show it outperforms current methods in adversarial detection tasks while performing well on label-based OOD detection."
        },
        "aliases": [
          "ImageNet-1k"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "The ImageNet dataset is described in the referenced paper.",
          "quote": "[31] O. Russakovsky, J. Deng, H. Su, et al. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision, 2015."
        }
      },
      {
        "name": {
          "value": "ImageNet-O",
          "justification": "The ImageNet-O dataset is used for label-based OOD detection evaluation.",
          "quote": "CADet draws inspiration from MMD, but leverages the similarity between contrastive transformations of a same sample. CADet outperforms existing adversarial detection methods in identifying adversarially perturbed samples on ImageNet and achieves comparable performance to unseen label detection methods on two challenging benchmarks: ImageNet-O and iNaturalist."
        },
        "aliases": [
          "ImageNet-Out-of-distribution"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Natural Adversarial Examples",
          "justification": "The ImageNet-O dataset is sourced and described in the referenced paper.",
          "quote": "[25] D. Hendrycks, K. Zhao, S. Basart, J. Steinhardt, and D. Song. Natural adversarial examples. arXiv preprint arXiv:1907.07174, 2021."
        }
      },
      {
        "name": {
          "value": "iNaturalist",
          "justification": "The iNaturalist dataset is used to evaluate the out-of-distribution detection of unknown classes.",
          "quote": "For all evaluations, we use the same transformations as SimCLRv2 except color jittering, Gaussian blur and grayscaling. We fix the random crop scale to 0.75. We use |{Xval}| = 2000 in-distribution samples, |{Xval}| = 300 separate samples to compute cross-similarities, and 50 transformations per sample. We pre-train a ResNet50 with ImageNet as in-distribution."
        },
        "aliases": [
          "iNat"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "MOS: Towards Scaling Out-of-Distribution Detection for Large Semantic Space",
          "justification": "The iNaturalist dataset used in their study is referenced in this paper.",
          "quote": "[27] R. Huang and Y. Li. Mos: Towards scaling out-of-distribution detection for large semantic space. arXiv preprint arXiv:2105.01879, 2021."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2455,
    "prompt_tokens": 14791,
    "total_tokens": 17246
  }
}