{
  "paper": "845230e4dca85cabdd027b2a8086008f.txt",
  "words": 10620,
  "extractions": {
    "title": {
      "value": "Pepid: a Highly Modifiable, Bioinformatics-Oriented Peptide Search Engine",
      "justification": "The paper introduces and discusses Pepid, a peptide search engine.",
      "quote": "Results We present pepid, a bioinformatics research-oriented peptide search engine...."
    },
    "description": "The paper presents Pepid, a flexible and modifiable peptide search engine designed for bioinformatics research.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes experimental comparisons with other engines and showcases performance data.",
      "quote": "Figure 1B summarizes the runtime performance of various engines on ProteomeTools so as to demonstrate Pepid viability in a realistic workload, while Figure 3 compares Pepid's scaling performance on our datasets..."
    },
    "primary_research_field": {
      "name": {
        "value": "Bioinformatics",
        "justification": "The paper focuses on a bioinformatics tool for peptide identification.",
        "quote": "Results We present pepid, a bioinformatics research-oriented peptide search engine."
      },
      "aliases": [
        "Bioinformatics"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Proteomics",
          "justification": "The primary application domain of Pepid is in proteomics for peptide identification.",
          "quote": "We believe that deep learning is already instrumental to achieving best-in-class performance in peptide identification, and that further research at the intersection of deep learning and proteomics is critical to next-generation peptide identification research."
        },
        "aliases": [
          "Proteomics"
        ]
      },
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The paper discusses the integration and importance of deep learning methods.",
          "quote": "We implement experimental deep learning methods with our source release to demonstrate how one might go about integrating such algorithms..."
        },
        "aliases": [
          "Deep Learning"
        ]
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "ProteomeTools",
          "justification": "ProteomeTools is mentioned multiple times as a dataset.",
          "quote": "The ProteomeTools spectra can be found in the PRIDE archive under accession ID PXD004732..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Building ProteomeTools based on a complete synthetic human proteome",
          "justification": "The referenced paper details the creation of the ProteomeTools dataset.",
          "quote": "Building ProteomeTools based on a complete synthetic human proteome. Nature Methods, 14(3):259-262, Jan. 2017."
        }
      },
      {
        "name": {
          "value": "One Hour Yeast Proteome",
          "justification": "One Hour Yeast Proteome is used for evaluation in the paper.",
          "quote": "We use the 'batched' dataset, which combines the result of all the hour-long runs."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The one hour yeast proteome",
          "justification": "The referenced paper details the One Hour Yeast Proteome dataset.",
          "quote": "The one hour yeast proteome. Molecular & Cellular Proteomics, 13(1):339-347, Jan. 2014"
        }
      },
      {
        "name": {
          "value": "Massive-KB",
          "justification": "Massive-KB is used for evaluation in the paper.",
          "quote": "The Massive-KB dataset contains spectra from real experiments and use a best-representative and consensus identification approach..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Assembling the community-scale discoverable human proteome",
          "justification": "The referenced paper discusses the Massive-KB dataset creation.",
          "quote": "Assembling the community-scale discoverable human proteome. Cell Systems, 7(4):412-421.e5, Oct. 2018."
        }
      },
      {
        "name": {
          "value": "selected yeast proteome",
          "justification": "The yeast proteome dataset is mentioned in the paper.",
          "quote": "The selected yeast proteome can be found on SwissProt with accession ID UP000002311..."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "UniProt: the universal protein knowledgebase in 2021",
          "justification": "The Uniprot database is often cited as a source for proteomic data.",
          "quote": "UniProt: The universal protein knowledgebase in 2021. Nucleic Acids Research, 49(D1):D480-489, Nov. 2020."
        }
      },
      {
        "name": {
          "value": "selected human proteome",
          "justification": "The human proteome dataset is mentioned in the paper.",
          "quote": "the human proteome's accession ID is UP0000005640."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "UniProt: the universal protein knowledgebase in 2021",
          "justification": "The Uniprot database is often cited as a source for proteomic data.",
          "quote": "UniProt: The universal protein knowledgebase in 2021. Nucleic Acids Research, 49(D1):D480-489, Nov. 2020."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "pytorch",
          "justification": "The paper mentions using PyTorch for both training and inference.",
          "quote": "For the experimental deep learning facilities, pytorch is used for both training and inference."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "No reference paper is provided for PyTorch.",
          "quote": "For the experimental deep learning facilities, pytorch is used for both training and inference."
        }
      },
      {
        "name": {
          "value": "SciPy",
          "justification": "The paper mentions using SciPy for compressing and storing spectra.",
          "quote": "store it using the compressed sparse row representation using the SciPy module, version 1.10.0"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python",
          "justification": "The paper refers to the SciPy library version using the title.",
          "quote": "SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17:261-272, 2020."
        }
      },
      {
        "name": {
          "value": "numba",
          "justification": "The paper mentions using Numba for accelerating scoring functions.",
          "quote": "The scoring functions are also accelerated using numba"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "No reference paper is provided for Numba.",
          "quote": "The scoring functions are also accelerated using numba"
        }
      },
      {
        "name": {
          "value": "numpy",
          "justification": "The paper mentions using NumPy for vectorization and speed advantages.",
          "quote": "extensive use of numpy and vectorization provides additional speed advantages."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "No reference paper is provided for NumPy.",
          "quote": "extensive use of numpy and vectorization provides additional speed advantages."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1770,
    "prompt_tokens": 19559,
    "total_tokens": 21329
  }
}