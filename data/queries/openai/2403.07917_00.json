{
  "paper": "2403.07917.txt",
  "words": 7632,
  "extractions": {
    "title": {
      "value": "A Neural-Evolutionary Algorithm for Autonomous Transit Network Design",
      "justification": "This is the title of the paper.",
      "quote": "A Neural-Evolutionary Algorithm for Autonomous Transit Network Design"
    },
    "description": "This paper presents a novel algorithm for planning autonomous bus route networks, integrating a graph neural network model trained via reinforcement learning into an evolutionary algorithm for improved performance. The approach is evaluated on standard benchmarks and demonstrates significant improvements over baseline methods.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents an empirical evaluation of the proposed neural-evolutionary algorithm on standard benchmarks.",
      "quote": "We evaluate this algorithm on a standard set of benchmarks for transit network design, and find that it outperforms the learned policy alone by up to 20% and a plain evolutionary algorithm approach by up to 53% on realistic benchmark instances."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The primary contribution of the paper involves training a graph neural network model via reinforcement learning to construct transit networks.",
        "quote": "To this end, we train a graph neural net (GNN) policy via reinforcement learning (RL) to construct transit networks for cities."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Graph Neural Networks",
          "justification": "The paper heavily utilizes graph neural networks as a core component of the proposed algorithm.",
          "quote": "Graph neural nets (GNNs) are neural net models that are designed to operate on graph-structured data."
        },
        "aliases": [
          "GNN"
        ]
      },
      {
        "name": {
          "value": "Evolutionary Algorithms",
          "justification": "The novel algorithm integrates evolutionary algorithms as a key part of the solution.",
          "quote": "We use this policy as one of several mutation operators in an evolutionary algorithm."
        },
        "aliases": [
          "EA"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Graph Neural Net Policy",
          "justification": "The model is referred to as a 'graph neural net policy' that is trained using reinforcement learning.",
          "quote": "To this end, we train a graph neural net (GNN) policy via reinforcement learning (RL) to construct transit networks for cities."
        },
        "aliases": [
          "GNN Policy",
          "Policy"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The Graph Neural Net Policy is a key contribution of this paper.",
          "quote": "To this end, we train a graph neural net (GNN) policy via reinforcement learning (RL) to construct transit networks for cities."
        },
        "is_executed": {
          "value": 1,
          "justification": "The Graph Neural Net Policy is executed as part of the experimental evaluation.",
          "quote": "To this end, we train a graph neural net (GNN) policy via reinforcement learning (RL) to construct transit networks for cities."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of the Graph Neural Net Policy is compared to other models in the paper.",
          "quote": "We compare our approach to the GNN model on its own and to the baseline evolutionary algorithm, and find that on realistically-sized problem instances, the hybrid algorithm performs best."
        },
        "referenced_paper_title": {
          "value": "Attention, learn to solve routing problems!",
          "justification": "The training of the GNN policy is influenced by methodologies in prior work.",
          "quote": "Following the work of [22], we train the policy net using the policy gradient method REINFORCE with baseline [59], setting Î³ = 1."
        }
      },
      {
        "name": {
          "value": "Pointer Network",
          "justification": "The paper references using a GNN model called a Pointer Network for related work in combinatorial optimization.",
          "quote": "[20] proposed a GNN model called a Pointer Network, and trained it by supervised learning to solve TSP instances."
        },
        "aliases": [
          "PointerNet"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Pointer Network is not a contribution of this paper but is referenced for its relevance in combinatorial optimization.",
          "quote": "[20] proposed a GNN model called a Pointer Network, and trained it by supervised learning to solve TSP instances."
        },
        "is_executed": {
          "value": 0,
          "justification": "The Pointer Network is not executed in the current paper but is referenced for background context.",
          "quote": "[20] proposed a GNN model called a Pointer Network, and trained it by supervised learning to solve TSP instances."
        },
        "is_compared": {
          "value": 0,
          "justification": "The Pointer Network is not directly compared in this paper but is mentioned for related prior work.",
          "quote": "[20] proposed a GNN model called a Pointer Network, and trained it by supervised learning to solve TSP instances."
        },
        "referenced_paper_title": {
          "value": "Pointer Networks",
          "justification": "The referenced paper title is 'Pointer Networks'.",
          "quote": "[20] proposed a GNN model called a Pointer Network, and trained it by supervised learning to solve TSP instances."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Mandl benchmark",
          "justification": "The Mandl benchmark is used for evaluating the proposed method.",
          "quote": "Both [52] and [53] use RL to design a network and schedule for the Mandl benchmark [54], a single small graph with just 15 nodes."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Evaluation and optimization of urban public transportation networks",
          "justification": "The referenced paper for the Mandl benchmark is 'Evaluation and optimization of urban public transportation networks'.",
          "quote": "Both [52] and [53] use RL to design a network and schedule for the Mandl benchmark [54], a single small graph with just 15 nodes."
        }
      },
      {
        "name": {
          "value": "Mumford benchmark",
          "justification": "The Mumford benchmark is used for evaluating the proposed method.",
          "quote": "All evaluations are performed on the Mandl [54] and Mumford [62] city datasets, two popular benchmarks for evaluating NDP algorithms."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Supplementary material for: New heuristic and evolutionary operators for the multi-objective urban transit routing problem, cec 2013",
          "justification": "The referenced paper for the Mumford benchmark is 'Supplementary material for: New heuristic and evolutionary operators for the multi-objective urban transit routing problem, cec 2013'.",
          "quote": "All evaluations are performed on the Mandl [54] and Mumford [62] city datasets, two popular benchmarks for evaluating NDP algorithms."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1596,
    "prompt_tokens": 14076,
    "total_tokens": 15672
  }
}