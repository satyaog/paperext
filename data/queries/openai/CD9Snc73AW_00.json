{
  "paper": "CD9Snc73AW.txt",
  "words": 17422,
  "extractions": {
    "title": {
      "value": "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport",
      "justification": "This is the title of the supplied research paper.",
      "quote": "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport"
    },
    "description": "The paper introduces a generalized conditional flow matching technique for continuous normalizing flows (CNFs) and proposes a variant called optimal transport conditional flow matching (OT-CFM) that approximates dynamic optimal transport, improving training stability and inference speed.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments to evaluate the proposed methods on various tasks including single-cell dynamics, image generation, and image translation.",
      "quote": "We show that OT-CFM not only improves the efficiency of training and inference, but also leads to more accurate OT flows than existing neural OT models..."
    },
    "primary_research_field": {
      "name": {
        "value": "Generative Modeling",
        "justification": "The paper focuses on improving generative models, specifically continuous normalizing flows (CNFs).",
        "quote": "Continuous normalizing flows (CNFs) are an attractive generative modeling technique..."
      },
      "aliases": [
        "CNF",
        "Flow-Based Generative Models"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Continuous Normalizing Flows",
          "justification": "A significant part of the paper focuses on continuous normalizing flows (CNFs) and their training dynamics.",
          "quote": "We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs."
        },
        "aliases": [
          "CNF"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Conditional Flow Matching",
          "justification": "The CFM model is introduced as a simulation-free training technique for continuous normalizing flows.",
          "quote": "We introduce the generalized conditional flow matching (CFM) technique, a family of simulation-free training objectives for CNFs."
        },
        "aliases": [
          "CFM"
        ],
        "is_contributed": {
          "value": true,
          "justification": "Conditional Flow Matching is a novel contribution of this paper.",
          "quote": "We introduce the generalized conditional flow matching (CFM) technique."
        },
        "is_executed": {
          "value": true,
          "justification": "CFM models are trained and evaluated in various experiments in the paper.",
          "quote": "We evaluate CFM and OT-CFM in experiments on single-cell dynamics, image generation, unsupervised image translation..."
        },
        "is_compared": {
          "value": true,
          "justification": "CFM is compared with other generative modeling approaches in the paper.",
          "quote": "We compare CFM...with other generative modeling techniques."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "CFM is newly introduced in this paper, so there won't be a reference paper for it.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Optimal Transport Conditional Flow Matching",
          "justification": "OT-CFM is introduced as a variant of CFM that incorporates optimal transport to improve training efficiency and inference speed.",
          "quote": "We propose a variant called optimal transport CFM (OT-CFM), which creates simpler flows that are more stable to train and lead to faster inference..."
        },
        "aliases": [
          "OT-CFM"
        ],
        "is_contributed": {
          "value": true,
          "justification": "OT-CFM is a novel contribution of this paper.",
          "quote": "We propose a variant called optimal transport CFM (OT-CFM)..."
        },
        "is_executed": {
          "value": true,
          "justification": "OT-CFM models are trained and evaluated in various experiments in the paper.",
          "quote": "We evaluate CFM and OT-CFM in experiments on single-cell dynamics, image generation, unsupervised image translation..."
        },
        "is_compared": {
          "value": true,
          "justification": "OT-CFM is compared with other generative modeling approaches in the paper.",
          "quote": "OT-CFM not only improves the efficiency of training and inference, but also leads to more accurate OT flows than existing neural OT models..."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "OT-CFM is newly introduced in this paper, so there won't be a reference paper for it.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Flow Matching",
          "justification": "Flow Matching is an objective to train CNFs, mentioned as a foundational concept leading to CFM.",
          "quote": "Lipman et al. (2023) showed that CNFs could also be trained using a regression of the ODE's drift similar to training of diffusion models, an objective called flow matching (FM)."
        },
        "aliases": [
          "FM"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Flow Matching was introduced by Lipman et al. (2023) and is utilized in the paper as background.",
          "quote": "Lipman et al. (2023) showed that CNFs could also be trained using a regression of the ODE's drift similar to training of diffusion models, an objective called flow matching (FM)."
        },
        "is_executed": {
          "value": true,
          "justification": "Flow Matching is executed in order to compare it with new techniques like CFM and OT-CFM.",
          "quote": "We compare CFM and OT-CFM with FM in various experiments..."
        },
        "is_compared": {
          "value": true,
          "justification": "Flow Matching is compared with CFM and OT-CFM in the paper.",
          "quote": "FM was shown to produce high-quality samples and stabilize CNF training, but made the assumption of a Gaussian source distribution..."
        },
        "referenced_paper_title": {
          "value": "Flow Matching for Generative Modeling",
          "justification": "The referenced paper by Lipman et al. is titled 'Flow Matching for Generative Modeling'.",
          "quote": "Lipman et al. (2023) showed that CNFs could also be trained using a regression of the ODE's drift similar to training of diffusion models, an objective called flow matching (FM)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CelebA",
          "justification": "CelebA is used to test the translation between different attributes of images.",
          "quote": "We show how CFM can be used to learn a mapping between two unpaired datasets in high-dimensional space using the CelebA dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deep learning face attributes in the wild",
          "justification": "CelebA is defined in the referenced paper 'Deep learning face attributes in the wild'.",
          "quote": "CelebA dataset (Liu et al., 2015; Sun et al., 2014)..."
        }
      },
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is used for training and testing generative models.",
          "quote": "We use the MNIST dataset to evaluate the performance of OT-CFM and other generative models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Gradient-Based Learning Applied to Document Recognition",
          "justification": "MNIST is defined in the referenced paper 'Gradient-Based Learning Applied to Document Recognition'.",
          "quote": "(LeCun et al., 1998)"
        }
      },
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is used to perform high-dimensional image generation experiments.",
          "quote": "We perform an experiment on unconditional CIFAR-10 generation from a Gaussian source to examine how OT-CFM performs in the high-dimensional image setting."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A learning system for generic object recognition in cluttered real-world scenes.",
          "justification": "'A learning system for generic object recognition in cluttered real-world scenes' is the title of the paper in which CIFAR-10 was introduced.",
          "quote": "(Krizhevsky, 2009)"
        }
      },
      {
        "name": {
          "value": "Embryoid body",
          "justification": "Embryoid body data is used to evaluate the performance of CFM and OT-CFM in modeling single-cell dynamics.",
          "quote": "We also include the Embryoid body data from Moon et al. (2019); Tong et al. (2020)."
        },
        "aliases": [
          "EB"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Visualizing structure and transitions in high-dimensional biological data",
          "justification": "This data is referenced in the paper 'Visualizing structure and transitions in high-dimensional biological data'.",
          "quote": "We also include the Embryoid body data from Moon et al. (2019); Tong et al. (2020)."
        }
      },
      {
        "name": {
          "value": "CITE-seq",
          "justification": "CITE-seq is used to demonstrate the model's capacity for single-cell trajectory interpolation.",
          "quote": "Following Huguet et al. (2022b), we repurpose the CITE-seq and Multiome datasets from a recent NeurIPS competition for this task (Burkhardt et al., 2022)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Multimodal single-cell integration across time, individuals, and batches",
          "justification": "This dataset is referenced in the NeurIPS competition paper titled 'Multimodal single-cell integration across time, individuals, and batches'.",
          "quote": "Following Huguet et al. (2022b), we repurpose the CITE-seq and Multiome datasets from a recent NeurIPS competition for this task (Burkhardt et al., 2022)."
        }
      },
      {
        "name": {
          "value": "Multiome",
          "justification": "Multiome is used to evaluate the capacity of the model for single-cell trajectory interpolation.",
          "quote": "Following Huguet et al. (2022b), we repurpose the CITE-seq and Multiome datasets from a recent NeurIPS competition for this task (Burkhardt et al., 2022)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Multimodal single-cell integration across time, individuals, and batches",
          "justification": "This dataset is mentioned in the NeurIPS competition paper titled 'Multimodal single-cell integration across time, individuals, and batches'.",
          "quote": "Following Huguet et al. (2022b), we repurpose the CITE-seq and Multiome datasets from a recent NeurIPS competition for this task (Burkhardt et al., 2022)."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 4616,
    "prompt_tokens": 64435,
    "total_tokens": 69051
  }
}