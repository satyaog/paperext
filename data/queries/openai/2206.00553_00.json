{
  "paper": "2206.00553.txt",
  "words": 9721,
  "extractions": {
    "title": {
      "value": "FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms for Neural Networks",
      "justification": "This is the title of the paper as presented by the user",
      "quote": "FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms for Neural Networks"
    },
    "description": "The paper introduces techniques to verify, train, and predict individual fairness in neural network models. It proposes a tool called FETA, which incorporates counterexample-guided methods to guarantee fairness constraints during prediction and training. The effectiveness of these techniques is demonstrated through empirical evaluations on real-world datasets.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper employs empirical evaluations on real-world datasets to demonstrate the effectiveness of the proposed techniques.",
      "quote": "Empirical evaluations on real-world benchmark datasets demonstrate the effectiveness of our solutions to train fair and accurate models, while provably guaranteeing fairness at the prediction time."
    },
    "primary_research_field": {
      "name": {
        "value": "Fairness in Machine Learning",
        "justification": "The primary focus of the paper is on ensuring fairness in machine learning models, particularly neural networks.",
        "quote": "In this paper, we study the problem of verifying, training and guaranteeing individual fairness of neural network models."
      },
      "aliases": [
        "Fair ML",
        "Fairness in AI"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Adversarial Machine Learning",
          "justification": "The paper includes methods that involve adversarial training to enforce fairness constraints.",
          "quote": "...we propose a novel counterexample-guided algorithm to incorporate fairness during training..."
        },
        "aliases": [
          "AML"
        ]
      },
      {
        "name": {
          "value": "Neural Network Verification",
          "justification": "The paper extensively discusses verifying fairness constraints using neural network verification methods.",
          "quote": "Our approach. This paper develops techniques to detect, incorporate and guarantee individual fairness constraints for all points in the input space to a standard ReLU neural network without imposing further restrictions on the hypothesis space..."
        },
        "aliases": [
          "NN Verification"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "FETA",
          "justification": "FETA is the proposed tool in the paper which incorporates the authors' techniques for fairness verification, training, and prediction.",
          "quote": "We have implemented our algorithms in a tool called “Fairness Enforced Verifying, Training, and Predicting Algorithm” (FETA)."
        },
        "aliases": [
          "Fairness Enforced Verifying, Training, and Predicting Algorithm",
          "FETA"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "FETA is the main contribution of the paper as it implements the proposed fairness verification, training, and prediction algorithms.",
          "quote": "We have implemented our algorithms in a tool called “Fairness Enforced Verifying, Training, and Predicting Algorithm” (FETA)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper mentions empirical evaluations, which implies that the model was executed to obtain results.",
          "quote": "Empirical evaluation on real-world datasets indicates that FETA is not only able to guarantee fairness on-the-fly at prediction time but also is able to train accurate models exhibiting a much higher degree of individual fairness."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares FETA to other models and approaches to demonstrate its effectiveness.",
          "quote": "Table 5 reports the accuracy and CE Rate of FETA compared to a recent method called LCIFR (Ruoss et al., 2020) that mitigates individual fairness using the same fairness definition as ours (i.e., Definition 3.1)."
        },
        "referenced_paper_title": {
          "value": "FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms for Neural Networks",
          "justification": "The reference paper for the model is the same as the paper being analyzed.",
          "quote": "We have implemented our algorithms in a tool called “Fairness Enforced Verifying, Training, and Predicting Algorithm” (FETA)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "German Credit Data",
          "justification": "This dataset is used in the empirical evaluation of the proposed methods.",
          "quote": "This dataset consists of 1k samples... The main task is binary classification of good or bad credit risks."
        },
        "aliases": [
          "German"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Statlog (German Credit Data) Data Set",
          "justification": "This dataset is well-known and referenced as Statlog (German Credit Data) Data Set.",
          "quote": "Hofmann, H. Statlog (german credit data) data set."
        }
      },
      {
        "name": {
          "value": "IPUMS Adult Dataset",
          "justification": "This dataset is used in the empirical evaluation of the proposed methods.",
          "quote": "The initial Adult dataset is used for binary classification of whether an individual’s salary is above or below $50k."
        },
        "aliases": [
          "Adult"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Retiring Adult: New Datasets for Fair Machine Learning",
          "justification": "The paper provides references for the reconstructed Adult dataset.",
          "quote": "Ding, F., Hardt, M., Miller, J., and Schmidt, L. Retiring adult: New datasets for fair machine learning."
        }
      },
      {
        "name": {
          "value": "Law School Dataset",
          "justification": "This dataset is used in the empirical evaluation of the proposed methods.",
          "quote": "This dataset, consisting of 86k samples, gathers law school admission records and is used for predicting if an individual would pass the bar exam."
        },
        "aliases": [
          "Law",
          "LS"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "LSAC National Longitudinal Bar Passage Study",
          "justification": "The dataset is referred to as the Law School dataset and is documented in the LSAC National Longitudinal Bar Passage Study.",
          "quote": "Wightman, L. S. LSAC National Longitudinal Bar Passage Study."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper mentions the use of PyTorch for implementing the experiments.",
          "quote": "Experiments are implemented in Python using Pytorch."
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "Used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "The referenced paper for PyTorch is provided as PyTorch: An Imperative Style, High-Performance Deep Learning Library.",
          "quote": "Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E. Z., Devito, Z., Raison, M., Tejani, A., Chilamkurthy, S., Steiner, B., Fang, L., Bai, J., and Chintala, S. Pytorch: An imperative style, high-performance deep learning library."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1388,
    "prompt_tokens": 17482,
    "total_tokens": 18870
  }
}