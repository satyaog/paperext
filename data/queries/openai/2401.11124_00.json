{
  "paper": "2401.11124.txt",
  "words": 6702,
  "extractions": {
    "title": {
      "value": "EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions",
      "justification": "This is the exact title of the paper provided.",
      "quote": "EMA-Net: Efficient Multitask Affinity Learning for Dense Scene Predictions"
    },
    "description": "This paper presents the Efficient Multitask Affinity Learning Network (EMA-Net), a framework designed to enhance the task refinement capabilities of multitask networks using the novel Cross-Task Affinity Learning (CTAL) module. The paper demonstrates that EMA-Net can adeptly capture local, global, and cross-task interactions using fewer model parameters without significant information loss. State-of-the-art multitask learning performance is achieved on CNN-based models, and the code is publicly available for further research.",
    "type": {
      "value": "Empirical",
      "justification": "The paper includes experimental results and comparisons to other methods, demonstrating the effectiveness of EMA-Net through empirical data.",
      "quote": "Our results show that we achieve state-of-the-art MTL performance for CNN-based decoder-focused models while using substantially fewer model parameters."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper's primary focus is on dense scene predictions, which is a key area within the field of Computer Vision.",
        "quote": "EMA-Net adeptly captures local, global, and cross-task interactions using our novel Cross-Task Affinity Learning (CTAL) module."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Multitask Learning",
          "justification": "The primary focus of the paper is on multitask learning, aiming to improve task refinement in multitask networks.",
          "quote": "Multitask learning (MTL) has gained prominence for its ability to jointly predict multiple tasks, achieving better per-task performance while using fewer per-task model parameters than single-task learning."
        },
        "aliases": [
          "MTL"
        ]
      },
      {
        "name": {
          "value": "Convolutional Neural Networks",
          "justification": "The proposed EMA-Net achieves state-of-the-art performance specifically on CNN-based decoder-focused models, emphasizing the use of Convolutional Neural Networks.",
          "quote": "Our results show that we achieve state-of-the-art MTL performance for CNN-based decoder-focused models while using substantially fewer model parameters."
        },
        "aliases": [
          "CNN"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "EMA-Net",
          "justification": "EMA-Net is the model introduced and evaluated in the paper.",
          "quote": "In this paper, we introduce the Efficient Multitask Affinity Learning Network (EMA-Net), which is a lightweight framework that enhances the task refinement capabilities of multitask networks."
        },
        "aliases": [
          "Efficient Multitask Affinity Learning Network"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "EMA-Net is the novel contribution of the paper.",
          "quote": "In this paper, we introduce the Efficient Multitask Affinity Learning Network (EMA-Net), which is a lightweight framework that enhances the task refinement capabilities of multitask networks."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes detailed experimental results and comparisons, indicating that EMA-Net was implemented and tested.",
          "quote": "Our results show that we achieve state-of-the-art MTL performance for CNN-based decoder-focused models while using substantially fewer model parameters."
        },
        "is_compared": {
          "value": 1,
          "justification": "EMA-Net is compared with various state-of-the-art models in the experiments section.",
          "quote": "Our results show that we achieve state-of-the-art MTL performance for CNN-based decoder-focused models while using substantially fewer model parameters."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "EMA-Net is introduced in this paper, hence there is no prior reference.",
          "quote": "In this paper, we introduce the Efficient Multitask Affinity Learning Network (EMA-Net), which is a lightweight framework that enhances the task refinement capabilities of multitask networks."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "NYUv2",
          "justification": "NYUv2 is one of the datasets used for the experiments in the paper.",
          "quote": "We perform our experiments on NYUv2 and Cityscapes datasets, which are both very popular for multitask learning."
        },
        "aliases": [
          "New York University Depth Dataset V2"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Indoor segmentation and support inference from rgbd images",
          "justification": "This is the reference paper for the NYUv2 dataset, as mentioned in the context.",
          "quote": "NYUv2 contains 1449 densely labelled RGB-depth images of indoor scenes. The raw dataset contains images with incomplete depth values; which are masked during training."
        }
      },
      {
        "name": {
          "value": "Cityscapes",
          "justification": "Cityscapes is one of the datasets used for the experiments in the paper.",
          "quote": "We perform our experiments on NYUv2 and Cityscapes datasets, which are both very popular for multitask learning."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The cityscapes dataset for semantic urban scene understanding",
          "justification": "This is the reference paper for the Cityscapes dataset, as mentioned in the context.",
          "quote": "Cityscapes is a larger dataset containing 3475 outdoor urban street scenes with fine annotations taken from 50 cities over several months of the year."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is likely used given its prominence in deep learning research, although it is not explicitly mentioned in the provided text.",
          "quote": "The implementation code for all baseline networks is taken from [Vandenhende et al., 2020], except for PAP-Net which we implemented ourselves."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "The exact reference paper for PyTorch is not mentioned.",
          "quote": "The implementation code for all baseline networks is taken from [Vandenhende et al., 2020], except for PAP-Net which we implemented ourselves."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1183,
    "prompt_tokens": 12141,
    "total_tokens": 13324
  }
}