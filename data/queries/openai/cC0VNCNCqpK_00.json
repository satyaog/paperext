{
  "paper": "cC0VNCNCqpK.txt",
  "words": 12904,
  "extractions": {
    "title": {
      "value": "DyG2Vec: Representation Learning for Dynamic Graphs with Self-Supervision",
      "justification": "The paper introduces a method called DyG2Vec for representation learning on dynamic graphs using self-supervision.",
      "quote": "To address these limitations, we present DyG2Vec, an SSL-compatible, efficient model for representation learning on dynamic graphs."
    },
    "description": "This paper presents DyG2Vec, a model designed for self-supervised representation learning on dynamic graphs. The model utilizes a window-based mechanism to generate task-agnostic node embeddings for forecasting future interactions. It aims to address the incompatibility of existing state-of-the-art models with the self-supervised learning paradigm and to improve the efficiency of training and inference.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments to validate the performance and efficiency of the DyG2Vec model on multiple benchmark datasets, comparing it with state-of-the-art baselines.",
      "quote": "Experimental results for 7 benchmark datasets indicate that DyG2Vec outperforms SoTA baselines on future link prediction and dynamic node classification in terms of performance and speed."
    },
    "primary_research_field": {
      "name": {
        "value": "Representation Learning",
        "justification": "The paper focuses on learning efficient and robust representations of nodes in dynamic graphs.",
        "quote": "To address these limitations, we present DyG2Vec, an SSL-compatible, efficient model for representation learning on dynamic graphs."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The primary method discussed and evaluated in the paper revolves around self-supervised learning (SSL) mechanisms.",
          "quote": "The novelty of our model lies in its compatibility with SoTA SSL approaches."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Dynamic Graphs",
          "justification": "The paper focuses on representation learning specifically for dynamic graphs, tackling challenges such as fine-grained temporal motifs and evolving graph structures.",
          "quote": "Our goal is to learn a model f that maps the input graph to a representation space. The model is a pre-trainable encoder-decoder architecture, f = (gθ , dγ ). The encoder gθ maps a dynamic graph to node embeddings H ∈ R N ×D ; the decoder dγ performs a task-specific prediction given the embeddings."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DyG2Vec",
          "justification": "DyG2Vec is the primary model proposed and evaluated in this paper for representation learning on dynamic graphs.",
          "quote": "To address these limitations, we present DyG2Vec, an SSL-compatible, efficient model for representation learning on dynamic graphs."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "DyG2Vec is the novel model introduced by the authors in this paper.",
          "quote": "In this work, we propose DyG2Vec, a novel encoder-decoder model for continuous-time dynamic graphs."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed during the experimental evaluation.",
          "quote": "Experimental results for 7 benchmark datasets indicate that DyG2Vec outperforms SoTA baselines on future link prediction and dynamic node classification in terms of performance and speed, particularly in medium- and long-range forecasting."
        },
        "is_compared": {
          "value": true,
          "justification": "DyG2Vec is compared to several state-of-the-art baseline models, such as DyRep, JODIE, TGAT, TGN, and CaW.",
          "quote": "Experimental results for 7 benchmark datasets indicate that DyG2Vec outperforms SoTA baselines on future link prediction and dynamic node classification in terms of performance and speed."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "This is the reference paper for the DyG2Vec model itself.",
          "quote": "To address these limitations, we present DyG2Vec, an SSL-compatible, efficient model for representation learning on dynamic graphs."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Reddit",
          "justification": "Reddit is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks",
          "justification": "This is the reference paper where the Reddit dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "Wikipedia",
          "justification": "Wikipedia is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks",
          "justification": "This is the reference paper where the Wikipedia dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "MOOC",
          "justification": "MOOC is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks",
          "justification": "This is the reference paper where the MOOC dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "LastFM",
          "justification": "LastFM is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Predicting Dynamic Embedding Trajectory in Temporal Interaction Networks",
          "justification": "This is the reference paper where the LastFM dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "SocialEvolution",
          "justification": "SocialEvolution is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Inductive representation learning in temporal networks via causal anonymous walks",
          "justification": "This is the reference paper where the SocialEvolution dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "Enron",
          "justification": "Enron is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Inductive representation learning in temporal networks via causal anonymous walks",
          "justification": "This is the reference paper where the Enron dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "UCI",
          "justification": "UCI is one of the benchmark datasets used to evaluate DyG2Vec's performance in the paper.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Inductive representation learning in temporal networks via causal anonymous walks",
          "justification": "This is the reference paper where the UCI dataset was initially presented and described.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Pytorch",
          "justification": "Pytorch was used as the primary deep learning framework for implementing DyG2Vec and conducting the experiments.",
          "quote": "We train our model using the Pytorch framework (Paszke et al., 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Pytorch: An imperative style, high-performance deep learning library",
          "justification": "To credit the main Pytorch library used in the research.",
          "quote": "We train our model using the Pytorch framework (Paszke et al., 2019)."
        }
      },
      {
        "name": {
          "value": "Pytorch Geometric",
          "justification": "Pytorch Geometric was used for dynamic graph data handling and implementing the GNN encoder architecture for DyG2Vec.",
          "quote": "The dynamic graph data and GNN encoder architecture are implemented using Pytorch Geometric (Fey & Lenssen, 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fast graph representation learning with PyTorch Geometric",
          "justification": "To credit the Pytorch Geometric library used in implementing the graph-based components of DyG2Vec.",
          "quote": "The dynamic graph data and GNN encoder architecture are implemented using Pytorch Geometric (Fey & Lenssen, 2019)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2371,
    "prompt_tokens": 24427,
    "total_tokens": 26798
  }
}