{
  "paper": "LfCzmmnH4L.txt",
  "words": 2696,
  "extractions": {
    "title": {
      "value": "Pretrained Language Models to Solve Graph Tasks in Natural Language",
      "justification": "The title is clearly stated at the beginning of the paper.",
      "quote": "Pretrained Language Models to Solve Graph Tasks in Natural Language"
    },
    "description": "This paper explores the application of pretrained large language models (LLMs) to graph-structured data, using natural language to describe the graphs. The authors propose using graph description through prompts based on the Graph Modelling Language (GML) and evaluate the performance of GPT-2 and GPT-3 on graph learning tasks. They further propose data augmentation techniques and pretraining strategies specific to the graph domain.",
    "type": {
      "value": "Empirical",
      "justification": "The paper presents experimental results, comparisons with other models, and various data augmentation strategies, indicating it is an empirical study.",
      "quote": "By evaluating GPT-2 and three GPT-3 variants on CYCLES and ZINC (GoÃÅmez-Bombarelli et al., 2018; Dwivedi et al., 2020), we show that using stronger LLMs results in better downstream graph performance."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The primary focus is on utilizing pretrained language models and natural language prompts for graph tasks.",
        "quote": "We explore if LLMs can learn from graph-structured data when the graphs are described using natural language."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Graph Learning",
          "justification": "The paper's main focus is on using language models for graph learning tasks.",
          "quote": "We demonstrate that pretrained LLMs fine-tuned on GML-based prompts are a promising approach to solve graph learning tasks."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Data Augmentation",
          "justification": "The paper proposes a specific data augmentation strategy to improve generalization in graph learning tasks.",
          "quote": "We further propose a data augmentation strategy for graph data to improve generalization that is motivated by node permutation invariance principles that are critical for the success of GNN approaches."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Model Pretraining",
          "justification": "The paper explores pretraining strategies for language models on graph tasks.",
          "quote": "We also explore pretraining on graph tasks as a potential way to narrow the gap between LLMs and GNNs."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-2",
          "justification": "GPT-2 is one of the main pretrained language models evaluated in the paper.",
          "quote": "We mainly use GPT-2 in our experiments (Radford et al., 2019) as it is computationally feasible and simple to fine-tune."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model was not introduced in this paper but was used for experiments.",
          "quote": "GPT-2 (Radford et al., 2019)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper indicates the execution and fine-tuning of GPT-2 in experiments.",
          "quote": "We mainly use GPT-2 in our experiments."
        },
        "is_compared": {
          "value": 1,
          "justification": "GPT-2's performance is compared with other models in the experiments.",
          "quote": "In Table 2, we report results on the CYCLES and ZINC dataset (Dwivedi et al., 2020) for a selection of LLM architectures and compare them to a selection of popular GNN models."
        },
        "referenced_paper_title": {
          "value": "Language Models are Unsupervised Multitask Learners",
          "justification": "This is the referenced paper for GPT-2.",
          "quote": "GPT-2 (Radford et al., 2019)."
        }
      },
      {
        "name": {
          "value": "GPT-3",
          "justification": "GPT-3 is another main pretrained language model evaluated in the paper.",
          "quote": "We further investigate the merit of several strategies to improve LLM performance in the case of GPT-2. We first observe that language pretraining (GPT-2) clearly performs better compared to training the model from scratch (GPT-2-scratch), indicating that language-pretrained LLMs are good candidates to be fine-tuned for graph learning tasks."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The model was not introduced in this paper but was used for experiments.",
          "quote": "GPT-3 (Brown et al., 2020)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper indicates the execution and fine-tuning of GPT-3 in experiments.",
          "quote": "We follow standard train, validation and test splits of the ZINC dataset with 10k train, 1k validation and 1k test graphs (Dwivedi et al., 2020)."
        },
        "is_compared": {
          "value": 1,
          "justification": "GPT-3's performance is compared with other models in the experiments.",
          "quote": "In Table 2, we report results on the CYCLES and ZINC dataset (Dwivedi et al., 2020) for a selection of LLM architectures and compare them to a selection of popular GNN models."
        },
        "referenced_paper_title": {
          "value": "Language Models are Few-Shot Learners",
          "justification": "This is the referenced paper for GPT-3.",
          "quote": "GPT-3 (Brown et al., 2020)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ZINC",
          "justification": "ZINC is one of the datasets used for evaluating the models in the paper.",
          "quote": "We follow standard train, validation and test splits of the ZINC dataset with 10k train, 1k validation and 1k test graphs (Dwivedi et al., 2020)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking Graph Neural Networks",
          "justification": "This is the referenced paper for the ZINC dataset.",
          "quote": "ZINC dataset (Dwivedi et al., 2020)."
        }
      },
      {
        "name": {
          "value": "CYCLES",
          "justification": "CYCLES is another dataset used for evaluating the models in the paper.",
          "quote": "For the CYCLES dataset, we use 9k train, 1k validation and 10k test graphs."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking Graph Neural Networks",
          "justification": "This is the referenced paper for the CYCLES dataset.",
          "quote": "CYCLES dataset (Dwivedi et al., 2020)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Transformers",
          "justification": "The paper uses variants of the GPT models, which are based on the Transformers library.",
          "quote": "Recent work of Wang et al. (2023) also explored LLMs (GPT-3/4) for solving graph tasks using natural language."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Attention Is All You Need",
          "justification": "This is the referenced paper for the Transformers library.",
          "quote": "Transformers (Vaswani et al., 2017)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1436,
    "prompt_tokens": 6006,
    "total_tokens": 7442
  }
}