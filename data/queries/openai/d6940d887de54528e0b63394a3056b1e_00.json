{
  "paper": "d6940d887de54528e0b63394a3056b1e.txt",
  "words": 8313,
  "extractions": {
    "title": {
      "value": "GrowSpace: A reinforcement learning environment for plant architecture",
      "justification": "The title is clearly stated in the paper as 'GrowSpace: A reinforcement learning environment for plant architecture'.",
      "quote": "GrowSpace: A reinforcement learning environment for plant architecture"
    },
    "description": "The paper presents GrowSpace, a reinforcement learning environment designed to simulate plant architecture and responses to light stimuli. The GrowSpace framework allows users to simulate plant growth and control branching patterns through reinforcement learning techniques. This environment is built to provide a sandbox for testing hypotheses about plant behavioural responses to light, facilitating novel research in plant science and reinforcement learning.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes experiments and results comparing reinforcement learning agents' performance in the GrowSpace environment, indicating an empirical research approach.",
      "quote": "In this section we demonstrate how GrowSpace is challenging by comparing RL baseline algorithms and through case studies on different settings of the available challenges."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper focuses on using reinforcement learning techniques to simulate and control plant growth, which explicitly places it within the reinforcement learning domain.",
        "quote": "GrowSpace provides an artificial modular environment that is simulated to the advancements of plant biological systems all while using a reinforcement learning framework."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Plant Science",
          "justification": "The paper integrates plant science with AI by simulating plant growth and responses to environmental stimuli.",
          "quote": "More broadly, GrowSpace spans across several fields such as plant science, agriculture, RL, and robotics."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computer Simulation",
          "justification": "GrowSpace is a simulation environment designed to mimic real-world plant growth.",
          "quote": "GrowSpace provides an artificial modular environment that is simulated to the advancements of plant biological systems all while using a reinforcement learning framework."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Robotics",
          "justification": "The mention of robotics indicates an interest in simulating autonomous control mechanisms similar to those studied in robotics, reflecting its relevance to the field.",
          "quote": "More broadly, GrowSpace spans across several fields such as plant science, agriculture, RL, and robotics."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Proximal Policy Optimization (PPO)",
          "justification": "PPO is one of the reinforcement learning algorithms used in the experiments to test the GrowSpace environment.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017)"
        },
        "aliases": [
          "PPO"
        ],
        "is_contributed": {
          "value": false,
          "justification": "PPO is a well-established reinforcement learning algorithm, not contributed by the paper.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017)"
        },
        "is_executed": {
          "value": true,
          "justification": "The paper describes executing PPO to assess its performance in the GrowSpace environment.",
          "quote": "As PPO was the best performing baseline, it was ran on all case studies defined in Section 2.5.1"
        },
        "is_compared": {
          "value": true,
          "justification": "PPO is compared with other algorithms like A2C and Rainbow DQN in the study.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017), Advantage Actor Critic (A2C), and Rainbow DQN."
        },
        "referenced_paper_title": {
          "value": "Proximal Policy Optimization algorithms",
          "justification": "The referenced paper title provides the definitive description of the PPO algorithm used in this study.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017)"
        }
      },
      {
        "name": {
          "value": "Advantage Actor Critic (A2C)",
          "justification": "A2C is used as a baseline algorithm in the paper’s experiments.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017), Advantage Actor Critic (A2C)"
        },
        "aliases": [
          "A2C"
        ],
        "is_contributed": {
          "value": false,
          "justification": "A2C is a standard reinforcement learning model and not contributed by the authors of the paper.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017), Advantage Actor Critic (A2C)"
        },
        "is_executed": {
          "value": true,
          "justification": "The paper tests A2C's performance in the GrowSpace environment, indicating its execution.",
          "quote": "Advantage Actor Critic (A2C) (Grondman et al., 2012)"
        },
        "is_compared": {
          "value": true,
          "justification": "A2C's performance is compared with other models like PPO and Rainbow DQN within the paper.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017), Advantage Actor Critic (A2C), and Rainbow DQN."
        },
        "referenced_paper_title": {
          "value": "A survey of actor-critic reinforcement learning: Standard and natural policy gradients",
          "justification": "The A2C model is referenced in this title which describes the actor-critic approaches in reinforcement learning.",
          "quote": "Advantage Actor Critic (A2C) (Grondman et al., 2012)"
        }
      },
      {
        "name": {
          "value": "Rainbow DQN",
          "justification": "Rainbow DQN is highlighted as a benchmark algorithm in the performance studies conducted in the paper.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017), Advantage Actor Critic (A2C), and Rainbow DQN."
        },
        "aliases": [
          "Rainbow"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Rainbow DQN is a known model in the machine learning literature and is not contributed by the paper.",
          "quote": "Rainbow: Combining improvements in deep reinforcement learning. In: Thirty-Second AAAI Conference on Artificial Intelligence."
        },
        "is_executed": {
          "value": true,
          "justification": "Rainbow DQN is one of the models executed to evaluate learning in the GrowSpace environment.",
          "quote": "Rainbow (green) performed the least well, followed by A2C (blue) and PPO (red) performs better in the task to grow the plant to a desired point."
        },
        "is_compared": {
          "value": true,
          "justification": "Rainbow DQN is compared against A2C and PPO within the context of this research.",
          "quote": "We compare Proximal Policy Optimization (PPO) (Schulman et al., 2017), Advantage Actor Critic (A2C), and Rainbow DQN."
        },
        "referenced_paper_title": {
          "value": "Rainbow: Combining improvements in deep reinforcement learning",
          "justification": "This paper title directly references the Rainbow DQN algorithm used and compared in this study.",
          "quote": "Rainbow: Combining improvements in deep reinforcement learning. In: Thirty-Second AAAI Conference on Artificial Intelligence."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is mentioned as used for the Grow in a specific shape task, rendering digit shapes for the reinforcement learning agent to replicate through plant growth simulation.",
          "quote": "For this task, the environment is reshaped to a width and height of 28 × 28 pixels (i.e. the size of a MNIST image)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The MNIST database of handwritten digits",
          "justification": "MNIST is a well-established dataset referred in this study for structuring plant growth challenges.",
          "quote": "As default shapes for benchmarking purposes we consider the MNIST dataset (LeCun, 1998), which is widely used in machine learning."
        }
      },
      {
        "name": {
          "value": "GrowSpace Dataset",
          "justification": "The dataset is mentioned explicitly in the paper as available on GitHub for simulating the GrowSpace environment.",
          "quote": "Dataset link: https://github.com/YasmeenVH/growspace"
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "GrowSpace: A reinforcement learning environment for plant architecture",
          "justification": "The title of the paper itself clarifies the GrowSpace dataset is intrinsic to the research.",
          "quote": "Dataset link: https://github.com/YasmeenVH/growspace"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenAI Gym",
          "justification": "OpenAI Gym is utilized for creating the GrowSpace environment by providing interfaces for reinforcement learning algorithms.",
          "quote": "Theoretical results in RL rely on having a perfect model of the dynamics of a Markov Decision Process (MDP)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Openai gym",
          "justification": "This reference discusses the OpenAI Gym library that forms the basis for the simulation environment.",
          "quote": "OpenAI developed an open-source python library known as Gym (Brockman et al., 2016)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1819,
    "prompt_tokens": 13404,
    "total_tokens": 15223,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}