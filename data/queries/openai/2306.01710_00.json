{
  "paper": "2306.01710.txt",
  "words": 13349,
  "extractions": {
    "title": {
      "value": "A Data-Driven Measure of Relative Uncertainty for Misclassification Detection",
      "justification": "The title of the paper is provided at the top of the document.",
      "quote": "A DATA-DRIVEN MEASURE OF RELATIVE UNCERTAINTY FOR MISCLASSIFICATION DETECTION"
    },
    "description": "This paper introduces a novel, data-driven measure of uncertainty to improve misclassification detection in machine learning models. The proposed measure evaluates the uncertainty relative to different instances within the data, allowing it to detect misclassifications more effectively than traditional methods like Shannon entropy. The approach is empirically validated on multiple image classification tasks, where it outperforms state-of-the-art methods.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper presents empirical results from experiments conducted on multiple image classification tasks to demonstrate the effectiveness of the proposed uncertainty measure.",
      "quote": "We demonstrate empirical improvements over multiple image classification tasks, outperforming state-of-the-art misclassification detection methods."
    },
    "primary_research_field": {
      "name": {
        "value": "Uncertainty Estimation",
        "justification": "The paper focuses on a novel measure of uncertainty for improving misclassification detection, which falls under the domain of Uncertainty Estimation.",
        "quote": "...introduce a novel data-driven measure of uncertainty relative to an observer for misclassification detection."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Misclassification Detection",
          "justification": "The primary objective of the proposed method is to detect misclassifications by evaluating the uncertainty associated with the predictions.",
          "quote": "The goal of misclassification detection is to create techniques that can evaluate the reliability of decisions made by classifiers and determine whether they can be trusted or not."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DenseNet-121",
          "justification": "DenseNet-121 is explicitly mentioned as one of the models used for evaluation.",
          "quote": "DenseNet-121"
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "DenseNet-121 is a pre-existing model used for evaluation rather than a contribution of the paper.",
          "quote": "DenseNet-121 (Huang et al., 2017)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was trained and evaluated as part of the experiments in the paper.",
          "quote": "We trained the model on the training dataset."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of DenseNet-121 was compared with other models in the experiments.",
          "quote": "We observe that, on average, our method performs best 11/20 experiments and is equal to the second best in 4/9 out of the remaining experiments."
        },
        "referenced_paper_title": {
          "value": "Densely Connected Convolutional Networks",
          "justification": "DenseNet-121 is part of the DenseNet series introduced in this paper, which is referenced in the context of the model's name.",
          "quote": "DenseNet-121 (Huang et al., 2017)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is explicitly mentioned as one of the datasets used for evaluation.",
          "quote": "CIFAR-10"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "CIFAR-10 dataset is part of this body of work, which is referenced in the context of its usage.",
          "quote": "CIFAR-10 (Krizhevsky, 2009)"
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is explicitly mentioned as one of the datasets used for evaluation.",
          "quote": "CIFAR-100"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "CIFAR-100 dataset is part of this body of work, which is referenced in the context of its usage.",
          "quote": "CIFAR-100 (Krizhevsky, 2009)"
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is mentioned as one of the datasets used for additional performance evaluation.",
          "quote": "Results for the ImageNet benchmark, we observe that Doctor gained a lot from the calibration"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "ImageNet dataset is discussed within this referenced paper, as it is widely recognized for large-scale visual recognition.",
          "quote": "ImageNet dataset"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenReview",
          "justification": "The paper explicitly mentions OpenReview as the repository hosting some related work.",
          "quote": "International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "International Conference on Learning Representations (ICLR) 2017 Proceedings",
          "justification": "The paper mentions this reference in the context of related work hosted on OpenReview.",
          "quote": "International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1075,
    "prompt_tokens": 27566,
    "total_tokens": 28641
  }
}