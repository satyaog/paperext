{
  "paper": "2305.18283.txt",
  "words": 4096,
  "extractions": {
    "title": {
      "value": "CommonAccent: Exploring Large Acoustic Pretrained Models for Accent Classification Based on Common Voice",
      "justification": "The title accurately reflects the main focus of the paper, which is exploring large acoustic pretrained models for accent classification based on the Common Voice dataset.",
      "quote": "CommonAccent: Exploring Large Acoustic Pretrained Models for Accent Classification Based on Common Voice"
    },
    "description": "The paper explores two large acoustic pretrained models, ECAPA-TDNN and Wav2Vec 2.0/XLSR, for the task of accent classification in multiple languages. The authors provide a detailed recipe for using these models with the SpeechBrain toolkit and introduce a new benchmark dataset, CommonAccent, derived from the Common Voice dataset. The results indicate strong performance in accent classification, particularly with the Wav2Vec 2.0/XLSR model.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves conducting experiments to fine-tune existing models and assess their performance on the task of accent classification, which is characteristic of an empirical study.",
      "quote": "In this paper, we study the accent classification problem, which is a critical building block towards accent-aware ASR."
    },
    "primary_research_field": {
      "name": {
        "value": "Speech Processing",
        "justification": "The paper deals with the processing and classification of speech data, with a specific focus on recognizing accented speech.",
        "quote": "Despite the recent advancements in Automatic Speech Recognition (ASR), the recognition of accented speech still remains a dominant problem."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Accent Classification",
          "justification": "The specific focus of the research is on classifying different accents within the speech data.",
          "quote": "We address multilingual accent classification through the ECAPA-TDNN and Wav2Vec 2.0/XLSR architectures."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ECAPA-TDNN",
          "justification": "The ECAPA-TDNN model is used as one of the primary models for accent classification in this study.",
          "quote": "We address multilingual accent classification through the ECAPA-TDNN and Wav2Vec 2.0/XLSR architectures."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "fine-tuned"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Wav2Vec 2.0/XLSR",
          "justification": "Wav2Vec 2.0 is used in its multilingual XLSR form for accent classification, and the model is fine-tuned for the task.",
          "quote": "We address multilingual accent classification through the ECAPA-TDNN and Wav2Vec 2.0/XLSR architectures."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "fine-tuned"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Common Voice 7.0",
          "justification": "Common Voice 7.0 dataset is used for English accent classification in this study.",
          "quote": "Our recipe fine-tunes either ECAPA-TDNN [7] or w2v2 [3] models (also XLSR) in the accent classification task. Our system follows closely the CommonLanguage recipe available in SpeechBrain. Additionally, we open-source fine-tuned models in the HuggingFace Hub."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Common Voice 11.0",
          "justification": "Common Voice 11.0 dataset is used for German, Spanish, and Italian accent classification in this study.",
          "quote": "Our model follows closely the CommonLanguage recipe available in SpeechBrain. Additionally, we open-source fine-tuned models for English, Spanish, German, and Italian in the HuggingFace Hub. We also use Common Voice 11.0 for additional languages and accent classification."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "SpeechBrain",
          "justification": "The SpeechBrain toolkit is used extensively for the experiment setups and recipe implementations in the study.",
          "quote": "Our aim is to provide insight and guidance for evaluating fine-tuned LAMs in a more inclusive manner... Specifically, in this work, we introduce a simple-to-follow recipe on the SpeechBrain [6] toolkit to perform accent classification based on speech recordings."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 934,
    "prompt_tokens": 7859,
    "total_tokens": 8793
  }
}