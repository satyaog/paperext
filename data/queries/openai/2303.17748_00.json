{
  "paper": "2303.17748.txt",
  "words": 5896,
  "extractions": {
    "title": {
      "value": "MLGCN: An Ultra Efficient Graph Convolution Neural Model for D Point Cloud Analysis",
      "justification": "The title is explicitly mentioned in the paper header and footer.",
      "quote": "MLGCN: A N U LTRA E FFICIENT G RAPH C ONVOLUTION\nN EURAL M ODEL FOR 3D P OINT C LOUD A NALYSIS"
    },
    "description": "This paper introduces a novel Multi-Level Graph Convolution Neural (MLGCN) model designed for efficient 3D point cloud analysis. It effectively uses Graph Neural Network (GNN) blocks in conjunction with precomputed KNN graphs to offer a computationally efficient solution for object classification and part segmentation tasks from 3D point clouds.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper provides experimental results, benchmarks, and comparisons to demonstrate the efficiency and effectiveness of the proposed MLGCN model.",
      "quote": "We now evaluate the performance of our MLGCN models with respect to different metrics. We demonstrate that our models achieve comparable accuracy to existing models in both classification and segmentation tasks while being considerably smaller and faster."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The primary focus of the paper is on the analysis of 3D point clouds, a key problem in computer vision.",
        "quote": "The analysis of 3D point clouds has diverse applications in robotics, vision and graphics."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "3D Shape Analysis",
          "justification": "The paper emphasizes 3D shape analysis, including tasks like object classification and part segmentation from point clouds.",
          "quote": "Thus, our MLGCN model could be particular relevant to point cloud based 3D shape analysis in industrial applications when computing resources are scarce."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Graph Neural Networks",
          "justification": "The paper builds its methodology around Graph Neural Networks (GNNs) for processing 3D point clouds.",
          "quote": "To address these limitations we introduce a novel Multi-level Graph Convolution Neural (MLGCN) model, which uses Graph Neural Networks (GNN) blocks to extract features from 3D point clouds at specific locality levels."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "MLGCN",
          "justification": "MLGCN is the primary model introduced in the paper for efficient 3D point cloud analysis.",
          "quote": "To address these limitations we introduce a novel Multi-level Graph Convolution Neural (MLGCN) model, which uses Graph Neural Networks (GNN) blocks to extract features from 3D point clouds at specific locality levels."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "MLGCN is the primary contribution of the paper.",
          "quote": "To address these limitations we introduce a novel Multi-level Graph Convolution Neural (MLGCN) model, which uses Graph Neural Networks (GNN) blocks to extract features from 3D point clouds at specific locality levels."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper presents experimental results based on executing MLGCN on GPUs.",
          "quote": "We trained our models on a machine with a single P100 GPU with 12GB memory."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares MLGCN to other state-of-the-art models, providing quantitative metrics on the performance.",
          "quote": "As shown in Table 1, when comparing Light-MLGCN with the best model in terms of accuracy, we see that it is more than 100 times more efficient in terms of FLOPS, and is also more than 100 times smaller in terms of the number of parameters and more than 60 times smaller in terms of the model size."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "MLGCN is an original model introduced in this paper, and hence does not refer to any previous specific paper for its core concept.",
          "quote": "To address these limitations we introduce a novel Multi-level Graph Convolution Neural (MLGCN) model, which uses Graph Neural Networks (GNN) blocks to extract features from 3D point clouds at specific locality levels."
        }
      },
      {
        "name": {
          "value": "Light-MLGCN",
          "justification": "Light-MLGCN is a variant of the MLGCN model designed for higher computational and storage efficiency.",
          "quote": "Here, we introduce two sample architectures with a MLGCN backbone, Light-MLGCN, and Lighter-MLGCN. These are example models to demonstrate the efficiency of MLGCN-based models."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "Light-MLGCN is a variant introduced by the authors to showcase the efficiency of the MLGCN model architecture.",
          "quote": "Here, we introduce two sample architectures with a MLGCN backbone, Light-MLGCN, and Lighter-MLGCN."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed on GPUs as indicated by the experimental details.",
          "quote": "We trained our models on a machine with a single P100 GPU with 12GB memory."
        },
        "is_compared": {
          "value": 1,
          "justification": "Light-MLGCN is compared to various other models, showcasing its efficiency and effectiveness.",
          "quote": "As shown in Table 1, when comparing Light-MLGCN with the best model in terms of accuracy, we see that it is more than 100 times more efficient in terms of FLOPS, and is also more than 100 times smaller in terms of the number of parameters and more than 60 times smaller in terms of model size."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Light-MLGCN is a variant model introduced within this paper and does not refer to another specific paper.",
          "quote": "Here, we introduce two sample architectures with a MLGCN backbone, Light-MLGCN, and Lighter-MLGCN."
        }
      },
      {
        "name": {
          "value": "Lighter-MLGCN",
          "justification": "Lighter-MLGCN is introduced as an even more lightweight version of MLGCN, to highlight the efficiency of the MLGCN architecture.",
          "quote": "Here, we introduce two sample architectures with a MLGCN backbone, Light-MLGCN, and Lighter-MLGCN. These are example models to demonstrate the efficiency of MLGCN-based models."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "Lighter-MLGCN is a variant introduced by the authors to demonstrate the efficiency of the MLGCN model architecture.",
          "quote": "Here, we introduce two sample architectures with a MLGCN backbone, Light-MLGCN, and Lighter-MLGCN."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed on GPUs as indicated by the experimental details.",
          "quote": "We trained our models on a machine with a single P100 GPU with 12GB memory."
        },
        "is_compared": {
          "value": 1,
          "justification": "Lighter-MLGCN is compared to various other models, showcasing its efficiency and effectiveness.",
          "quote": "As shown in Table 1, when comparing Light-MLGCN with the best model in terms of accuracy, we see that it is more than 100 times more efficient in terms of FLOPS, and is also more than 100 times smaller in terms of the number of parameters and more than 60 times smaller in terms of model size."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Lighter-MLGCN is a variant model introduced within this paper and does not refer to another specific paper.",
          "quote": "Here, we introduce two sample architectures with a MLGCN backbone, Light-MLGCN, and Lighter-MLGCN."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ModelNet-40",
          "justification": "The ModelNet-40 dataset is explicitly used for evaluating the classification performance of the MLGCN models.",
          "quote": "Our primary experiment involves comparing the accuracy and speed of our models on ModelNet-40 [16], a dataset consisting of 9,843 training and 2,468 testing meshed CAD models from 40 distinct categories."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "3d shapenets: A deep representation for volumetric shapes",
          "justification": "The dataset reference is clearly denoted in the paper.",
          "quote": "Our primary experiment involves comparing the accuracy and speed of our models on ModelNet-40 [16], a dataset consisting of 9,843 training and 2,468 testing meshed CAD models from 40 distinct categories."
        }
      },
      {
        "name": {
          "value": "ShapeNetPart",
          "justification": "The ShapeNetPart dataset is used in the paper for evaluating the part segmentation task.",
          "quote": "In addition to the 3D classification problem, we also evaluated the performance of our models on the part segmentation task using the ShapeNetPart dataset [17]. This dataset contains 16,881 3D shapes from 16 different classes, where each class has 2 to 6 parts, resulting in a total of 50 different parts."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A scalable active framework for region annotation in 3d shape collections",
          "justification": "The dataset reference is clearly denoted in the paper.",
          "quote": "In addition to the 3D classification problem, we also evaluated the performance of our models on the part segmentation task using the ShapeNetPart dataset [17]. This dataset contains 16,881 3D shapes from 16 different classes, where each class has 2 to 6 parts, resulting in a total of 50 different parts."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1997,
    "prompt_tokens": 10682,
    "total_tokens": 12679
  }
}