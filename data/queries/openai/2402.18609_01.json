{
  "paper": "2402.18609.txt",
  "words": 9270,
  "extractions": {
    "title": {
      "value": "ICE-SEARCH: A Language Model-Driven Feature Selection Approach",
      "justification": "The title clearly reflects the content and focus of the paper, which revolves around a methodology named ICE-SEARCH that combines language models with feature selection techniques.",
      "quote": "ICE-SEARCH: A Language Model-Driven Feature Selection Approach"
    },
    "description": "This paper presents ICE-SEARCH, a novel methodology that integrates language models (LMs) with evolutionary algorithms for feature selection (FS) tasks in Medical Predictive Analytics (MPA). The approach leverages the adaptive capabilities of LMs to improve FS, particularly in medical datasets for stroke, cardiovascular disease, and diabetes predictions.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper conducts empirical evaluations of the ICE-SEARCH methodology on real-world datasets for stroke, cardiovascular disease, and diabetes predictions, demonstrating its effectiveness and robustness.",
      "quote": "To demonstrate the efficacy of our approach, we analyze the performance of ICE-SEARCH on three critical tasks--stroke prediction, cardiovascular disease prediction, and diabetes prediction--using three increasingly complex datasets."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper merges concepts of deep learning, particularly language models, with evolutionary feature selection algorithms to address tasks in medical predictive analytics.",
        "quote": "This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Medical Predictive Analytics",
          "justification": "The sub-research field is specified as Medical Predictive Analytics, as the paper focuses on applying the ICE-SEARCH method to make predictions about medical conditions like stroke, cardiovascular disease, and diabetes.",
          "quote": "Our evaluation of this methodology spans three crucial MPA tasks: stroke, cardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ICE-SEARCH",
          "justification": "ICE-SEARCH is the primary model introduced and contributed by this paper, combining language models with evolutionary algorithms for feature selection.",
          "quote": "The proposed In-Context Evolutionary Search (ICE-SEARCH) method is the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Stroke Prediction Dataset",
          "justification": "The dataset is used to evaluate the ICE-SEARCH method for its effectiveness in predicting stroke cases.",
          "quote": "The stroke prediction dataset from Kaggle comprises 10 parameters including patient age, gender, medical history (specifically hypertension and heart disease), marital status, occupation type, residential environment, average glucose level, body mass index, and smoking status."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Cardiovascular Disease Dataset",
          "justification": "This dataset is employed to assess the ICE-SEARCH method's performance in predicting cardiovascular disease.",
          "quote": "The cardiovascular health dataset has a near-equal distribution of both outcomes. It contains 31,783 negative samples and 30,962 positive samples, and includes 11 features including age (in days), height (in centimetres), weight (in kilograms), gender (categorical code), systolic blood pressure, diastolic blood pressure (both in mmHg), cholesterol levels (categorized as normal, above normal, well above normal), glucose levels (similarly categorized), along with binary indicators for smoking, alcohol intake, and physical activity, with no missing values."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Diabetes Dataset",
          "justification": "This dataset is utilized to validate the ICE-SEARCH method for diabetes predictions.",
          "quote": "The diabetes dataset features 218K negative samples, 35K positive samples, and no missing entries."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Phi-2",
          "justification": "Phi-2 is used as one of the backbone language models to test the ICE-SEARCH method.",
          "quote": "The experiment, we use Phi2 models respectively as the backbone LM, each containing fewer than 8 billion parameters."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "LLaMA2 7B",
          "justification": "LLaMA2 7B, specifically the 4-bit quantized version, is also used as a backbone language model in the experiments.",
          "quote": "We use a 4-bit quantized version of LLaMA2 7B models respectively as the backbone LM, each containing fewer than 8 billion parameters."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1011,
    "prompt_tokens": 16125,
    "total_tokens": 17136
  }
}