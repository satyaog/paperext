{
  "paper": "2Q8TZWAHv4.txt",
  "words": 12038,
  "extractions": {
    "title": {
      "value": "GOAt: ExplAINING GRAPH NEURAL NETWORKS VIA GRAPH OUTPUT ATTRIBUTION",
      "justification": "The title precisely describes the main focus of the paper, which is to introduce a novel method called GOAt for explaining Graph Neural Networks.",
      "quote": "GOAt: EXPLAINING GRAPH NEURAL NETWORKS VIA GRAPH OUTPUT ATTRIBUTION"
    },
    "description": "This paper introduces Graph Output Attribution (GOAt), a novel method aimed at improving the interpretability of Graph Neural Networks (GNNs). The method attributes graph outputs to input graph features, providing explanations that are faithful, discriminative, and stable. Extensive experiments show that GOAt outperforms state-of-the-art explainers in terms of fidelity, discriminability, and stability.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper features extensive experiments comparing the proposed method GOAt with various state-of-the-art GNN explainers, demonstrating its superior performance through empirical evidence.",
      "quote": "Through extensive experiments on synthetic and real-world data, we show that our method not only outperforms various state-of-the-art GNN explainers in terms of the commonly used fidelity metric, but also exhibits stronger discriminability, and stability by a remarkable margin."
    },
    "primary_research_field": {
      "name": {
        "value": "Graph Neural Networks",
        "justification": "The primary focus of the paper is on explaining Graph Neural Networks (GNNs).",
        "quote": "Understanding the decision-making process of Graph Neural Networks (GNNs) is crucial to their interpretability."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Explainable AI",
          "justification": "GOAt aims at enhancing the explainability of GNNs, making it a notable contribution in the explainable AI domain.",
          "quote": "This paper introduces Graph Output Attribution (GOAt), a novel method to attribute graph outputs to input graph features, creating GNN explanations that are faithful, discriminative, as well as stable across similar samples."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The paper mentions NLP as one of the various fields where GNNs have demonstrated success, although it is not the main focus.",
          "quote": "Graph Neural Networks (GNNs) have demonstrated notable success in learning representations from graph-structured data in various fields (Kipf & Welling, 2017; Hamilton et al., 2017; Xu et al., 2019)."
        },
        "aliases": [
          "NLP"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GOAt",
          "justification": "GOAt is the novel method proposed in this paper for attributing graph outputs to input features to explain GNNs.",
          "quote": "This paper introduces Graph Output Attribution (GOAt), a novel method to attribute graph outputs to input graph features, creating GNN explanations that are faithful, discriminative, as well as stable across similar samples."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "GOAt is the primary contribution of this paper.",
          "quote": "This paper introduces Graph Output Attribution (GOAt), a novel method to attribute graph outputs to input graph features, creating GNN explanations that are faithful, discriminative, as well as stable across similar samples."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes extensive experiments to evaluate GOAt.",
          "quote": "Through extensive experiments on synthetic and real-world data, we show that our method not only outperforms various state-of-the-art GNN explainers in terms of the commonly used fidelity metric, but also exhibits stronger discriminability, and stability by a remarkable margin."
        },
        "is_compared": {
          "value": 1,
          "justification": "GOAt is compared to various state-of-the-art GNN explainers in the experiments.",
          "quote": "Through extensive experiments on synthetic and real-world data, we show that our method not only outperforms various state-of-the-art GNN explainers in terms of the commonly used fidelity metric, but also exhibits stronger discriminability, and stability by a remarkable margin."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "GOAt is a novel method introduced in this paper itself, so there is no referenced paper for it.",
          "quote": "This paper introduces Graph Output Attribution (GOAt), a novel method to attribute graph outputs to input graph features, creating GNN explanations that are faithful, discriminative, as well as stable across similar samples."
        }
      },
      {
        "name": {
          "value": "GCN",
          "justification": "GCN is one of the typical GNN variants used in case studies to demonstrate GOAt.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "aliases": [
          "Graph Convolutional Network"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "GCN is not a novel model contributed in this paper; it is used as a comparison model.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "is_executed": {
          "value": 1,
          "justification": "GCN is executed in the experimental evaluations of GOAt.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "is_compared": {
          "value": 1,
          "justification": "GCN is compared as part of the case studies and experimental evaluations.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "referenced_paper_title": {
          "value": "Semi-Supervised Classification with Graph Convolutional Networks",
          "justification": "The GCN model was introduced in the paper titled 'Semi-Supervised Classification with Graph Convolutional Networks' by Kipf & Welling, 2017.",
          "quote": "Graph Neural Networks (GNNs) have demonstrated notable success in learning representations from graph-structured data in various fields (Kipf & Welling, 2017; Hamilton et al., 2017; Xu et al., 2019)."
        }
      },
      {
        "name": {
          "value": "GraphSAGE",
          "justification": "GraphSAGE is one of the typical GNN variants used in case studies to demonstrate GOAt.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "GraphSAGE is not a novel model contributed in this paper; it is used as a comparison model.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "is_executed": {
          "value": 1,
          "justification": "GraphSAGE is executed in the experimental evaluations of GOAt.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "is_compared": {
          "value": 1,
          "justification": "GraphSAGE is compared as part of the case studies and experimental evaluations.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "referenced_paper_title": {
          "value": "Inductive Representation Learning on Large Graphs",
          "justification": "The GraphSAGE model was introduced in the paper titled 'Inductive Representation Learning on Large Graphs' by Hamilton et al., 2017.",
          "quote": "Graph Neural Networks (GNNs) have demonstrated notable success in learning representations from graph-structured data in various fields (Kipf & Welling, 2017; Hamilton et al., 2017; Xu et al., 2019)."
        }
      },
      {
        "name": {
          "value": "GIN",
          "justification": "GIN is one of the typical GNN variants used in case studies to demonstrate GOAt.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "aliases": [
          "Graph Isomorphism Network"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "GIN is not a novel model contributed in this paper; it is used as a comparison model.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "is_executed": {
          "value": 1,
          "justification": "GIN is executed in the experimental evaluations of GOAt.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "is_compared": {
          "value": 1,
          "justification": "GIN is compared as part of the case studies and experimental evaluations.",
          "quote": "We present case studies that demonstrate the effectiveness of our analytical explanation method GOAt on typical GNN variants, including GCN, GraphSAGE, and GIN."
        },
        "referenced_paper_title": {
          "value": "How Powerful are Graph Neural Networks?",
          "justification": "The GIN model was introduced in the paper titled 'How Powerful are Graph Neural Networks?' by Xu et al., 2019.",
          "quote": "Graph Neural Networks (GNNs) have demonstrated notable success in learning representations from graph-structured data in various fields (Kipf & Welling, 2017; Hamilton et al., 2017; Xu et al., 2019)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "BA-2Motifs",
          "justification": "The BA-2Motifs dataset is used as an experimental dataset in this research.",
          "quote": "For graph classification task, we evaluate on a synthetic dataset, BA-2motifs (Luo et al., 2020), and two real-world datasets, Mutagenicity (Kazius et al., 2005) and NCI1 (Pires et al., 2015)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Parameterized Explainer for Graph Neural Network",
          "justification": "The BA-2Motifs dataset is referenced from the paper titled 'Parameterized Explainer for Graph Neural Network' by Luo et al., 2020.",
          "quote": "For graph classification task, we evaluate on a synthetic dataset, BA-2motifs (Luo et al., 2020), and two real-world datasets, Mutagenicity (Kazius et al., 2005) and NCI1 (Pires et al., 2015)."
        }
      },
      {
        "name": {
          "value": "Mutagenicity",
          "justification": "The Mutagenicity dataset is used as an experimental dataset in this research.",
          "quote": "For graph classification task, we evaluate on a synthetic dataset, BA-2motifs (Luo et al., 2020), and two real-world datasets, Mutagenicity (Kazius et al., 2005) and NCI1 (Pires et al., 2015)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Derivation and validation of toxicophores for mutagenicity prediction",
          "justification": "The Mutagenicity dataset is referenced from the paper titled 'Derivation and validation of toxicophores for mutagenicity prediction' by Kazius et al., 2005.",
          "quote": "For graph classification task, we evaluate on a synthetic dataset, BA-2motifs (Luo et al., 2020), and two real-world datasets, Mutagenicity (Kazius et al., 2005) and NCI1 (Pires et al., 2015)."
        }
      },
      {
        "name": {
          "value": "NCI1",
          "justification": "The NCI1 dataset is used as an experimental dataset in this research.",
          "quote": "For graph classification task, we evaluate on a synthetic dataset, BA-2motifs (Luo et al., 2020), and two real-world datasets, Mutagenicity (Kazius et al., 2005) and NCI1 (Pires et al., 2015)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "pkcsm: predicting small-molecule pharmacokinetic and toxicity properties using graph-based signatures",
          "justification": "The NCI1 dataset is referenced from the paper titled 'pkcsm: predicting small-molecule pharmacokinetic and toxicity properties using graph-based signatures' by Pires et al., 2015.",
          "quote": "For graph classification task, we evaluate on a synthetic dataset, BA-2motifs (Luo et al., 2020), and two real-world datasets, Mutagenicity (Kazius et al., 2005) and NCI1 (Pires et al., 2015)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is one of the libraries used to implement and run the experiments in this paper.",
          "quote": "We evaluated the GOAt method on various datasets and GNNs implemented in PyTorch."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "The PyTorch library is referenced from the paper titled 'Automatic differentiation in PyTorch'.",
          "quote": "We evaluated the GOAt method on various datasets and GNNs implemented in PyTorch."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2782,
    "prompt_tokens": 22520,
    "total_tokens": 25302
  }
}