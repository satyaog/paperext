{
  "paper": "2211.01866.txt",
  "words": 9378,
  "extractions": {
    "title": {
      "value": "ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations",
      "justification": "This is the title presented on the first page of the paper.",
      "quote": "Title: ImageNet-X: Understanding Model Mistakes with Factor of Variation Annotations"
    },
    "description": "The paper introduces ImageNet-X, a set of annotations for the ImageNet dataset aimed at understanding model mistakes in image recognition tasks. The annotations classify failures based on factors such as pose, background, or lighting. The authors utilize these annotations to investigate the failure modes of over 2,200 vision models, providing insights into how different models and training procedures affect the robustness of these models against various factors.",
    "type": {
      "value": "empirical study",
      "justification": "The paper presents empirical analyses and experimental results regarding the failure modes of vision models using the ImageNet-X annotations.",
      "quote": "We investigate 2,200 current recognition models and study the types of mistakes as a function of model’s (1) architecture – e.g. transformer vs. convolutional –, (2) learning paradigm – e.g. supervised vs. self-supervised –, and (3) training procedures – e.g. data augmentation."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The research primarily deals with vision models and their robustness against various factors in image data.",
        "quote": "Understanding the failure modes of computer vision models ..."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Model Robustness",
          "justification": "The research explores the robustness of different vision models against variations in image data.",
          "quote": "We find that models, regardless of architecture, training dataset size, and even robustness interventions all share similar failure types ..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Data Augmentation",
          "justification": "A significant portion of the research investigates the impact of data augmentation strategies on model robustness.",
          "quote": "We find data augmentations can boost models’ robustness ... Common augmentations such as cropping and color-jittering however, can have unintended consequences ..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-50",
          "justification": "The paper mentions utilizing ResNet-50 model for defining prototypical images and various analyses.",
          "quote": "The prototypical images as the most likely images under ResNet-50 model."
        },
        "aliases": [
          "ResNet"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ResNet-50 is not introduced in this paper but is used for analysis.",
          "quote": "The prototypical images as the most likely images under ResNet-50 model."
        },
        "is_executed": {
          "value": 1,
          "justification": "ResNet-50 is used for deriving the prototypical images and other analyses.",
          "quote": "The prototypical images as the most likely images under ResNet-50 model."
        },
        "is_compared": {
          "value": 1,
          "justification": "ResNet-50's performance is compared against other models in the paper.",
          "quote": "With new labels from previous work, ... model weaknesses coincide with labeling errors."
        },
        "referenced_paper_title": {
          "value": "Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification",
          "justification": "This is the reference paper for ResNet mentioned in the text.",
          "quote": "ResNet-50 [15]"
        }
      },
      {
        "name": {
          "value": "Vision Transformer (ViT)",
          "justification": "ViT is used in the study for comparison against Convolutional Neural Networks like ResNet.",
          "quote": "An example of Vision Transformer’s Mistakes"
        },
        "aliases": [
          "ViT"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "ViT is not introduced in this paper but is used for analysis.",
          "quote": "We include additional self supervised models for completeness."
        },
        "is_executed": {
          "value": 1,
          "justification": "ViT is utilized for the robustness experiments in the paper.",
          "quote": "An example of Vision Transformer’s Mistakes"
        },
        "is_compared": {
          "value": 1,
          "justification": "ViT's performance is compared with various other models in the study.",
          "quote": "Interestingly, the model becomes more sensitive to pose variations."
        },
        "referenced_paper_title": {
          "value": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
          "justification": "This is the reference paper for Vision Transformer mentioned in the text.",
          "quote": "We include additional self supervised models for completeness."
        }
      },
      {
        "name": {
          "value": "DINO",
          "justification": "DINO, a self-supervised learning model, is used in the study.",
          "quote": "Vision Transformer’s Mistakes... We further probe robustness by examining how model bias differs among meta-labels of classes groups."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "DINO is not introduced in this paper but is used for analysis.",
          "quote": "We include additional self supervised models for completeness."
        },
        "is_executed": {
          "value": 1,
          "justification": "DINO is utilized for the robustness experiments.",
          "quote": "Vision Transformer’s Mistakes... We further probe robustness by examining how model bias differs among meta-labels of classes groups."
        },
        "is_compared": {
          "value": 1,
          "justification": "DINO's performance is compared against other models in the paper.",
          "quote": "We include additional self supervised models for completeness."
        },
        "referenced_paper_title": {
          "value": "Emerging Properties in Self-Supervised Vision Transformers",
          "justification": "This is the reference paper for DINO mentioned in the text.",
          "quote": "We analyze popular self-supervised models like DINO."
        }
      },
      {
        "name": {
          "value": "SimCLR",
          "justification": "SimCLR, a self-supervised learning model, is used in the study.",
          "quote": "We measure the impact of self-supervised learning with SimCLR."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "SimCLR is not introduced in this paper but is used for analysis.",
          "quote": "We measure the impact of self-supervised learning with SimCLR."
        },
        "is_executed": {
          "value": 1,
          "justification": "SimCLR is utilized for the robustness experiments.",
          "quote": "We measure the impact of self-supervised learning with SimCLR."
        },
        "is_compared": {
          "value": 1,
          "justification": "SimCLR's performance is compared against other models in the paper.",
          "quote": "As shown in the figures, SimCLR exhibits ..."
        },
        "referenced_paper_title": {
          "value": "A Simple Framework for Contrastive Learning of Visual Representations",
          "justification": "This is the reference paper for SimCLR mentioned in the text.",
          "quote": "We compare baseline supervised models with SimCLR."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet-X",
          "justification": "ImageNet-X is the primary dataset introduced in this paper.",
          "quote": "To address this need, we introduce ImageNet-X."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "ImageNet-X is introduced in this paper.",
          "quote": "To address this need, we introduce ImageNet-X."
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "The paper makes extensive use of the ImageNet dataset for validation and training.",
          "quote": "Deep learning surpassing human performance on ImageNet ... We then analyze, in section 3, the failure types of more than 2,200 models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "This is the reference paper for the ImageNet dataset mentioned in the text.",
          "quote": "Deep learning surpassing human performance on ImageNet [23, 15]"
        }
      },
      {
        "name": {
          "value": "ImageNet-21k",
          "justification": "Used for pre-training certain models in the study.",
          "quote": "We probe model robustness with varying levels of granularity by measuring bias towards or against ImageNet-X factors. Here we walk through the biases of a ViT (vision transformer model) trained on ImageNet-21k"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "This is the reference paper for the ImageNet dataset mentioned in the text.",
          "quote": "Deep learning surpassing human performance on ImageNet [23, 15]"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2137,
    "prompt_tokens": 17481,
    "total_tokens": 19618
  }
}