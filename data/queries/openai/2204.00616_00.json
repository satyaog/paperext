{
  "paper": "2204.00616.txt",
  "words": 15129,
  "extractions": {
    "title": {
      "value": "Simplicial Embeddings in Self-Supervised Learning and Downstream Classification",
      "justification": "This is the exact title of the paper given.",
      "quote": "S IMPLICIAL E MBEDDINGS IN S ELF -S UPERVISED\nL EARNING AND D OWNSTREAM C LASSIFICATION"
    },
    "description": "The paper investigates the use of Simplicial Embeddings (SEM) in self-supervised learning (SSL) and its effects on downstream classification tasks. SEMs use a projection into simplicial spaces during pre-training, which helps in learning sparse, highly interpretable representations that promise better generalization and robustness across various tasks and datasets.",
    "type": {
      "value": "Empirical",
      "justification": "The paper provides empirical evidence by demonstrating improved generalization on natural image datasets and comparing different models and approaches.",
      "quote": "Furthermore, we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100 and ImageNet."
    },
    "primary_research_field": {
      "name": {
        "value": "Self-Supervised Learning",
        "justification": "The paper focuses on the use of Simplicial Embeddings in the context of self-supervised learning.",
        "quote": "Self-supervised learning (SSL) is an emerging family\nof methods that aim to learn representations of data\nwithout manual supervision, such as class labels."
      },
      "aliases": [
        "SSL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Representation Learning",
          "justification": "The paper discusses learning sparse and overcomplete representations using SEM in SSL.",
          "quote": "In this work, we show that SSL may be used to learn sparse and overcomplete representations."
        },
        "aliases": [
          "Representation Learning"
        ]
      },
      {
        "name": {
          "value": "Downstream Classification",
          "justification": "The paper evaluates the performance of learned representations on various downstream classification tasks.",
          "quote": "For downstream classification, we may discretize the learned representation by, for example, taking the argmax for each simplex."
        },
        "aliases": [
          "Classification"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "BYOL+SEM",
          "justification": "The paper mentions and compares the performance of BYOL+SEM to other models.",
          "quote": "BYOL+SEM (x2)"
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "BYOL+SEM is one of the proposed models for integrating SEM into existing SSL methods.",
          "quote": "In this work, we show that SSL may be used to learn sparse and overcomplete representations."
        },
        "is_executed": {
          "value": 1,
          "justification": "BYOL+SEM was executed to obtain experimental results on CIFAR-100 and ImageNet.",
          "quote": "For downstream classification, we may discretize the learned representation by, for example, taking the argmax for each simplex."
        },
        "is_compared": {
          "value": 1,
          "justification": "BYOL+SEM was compared with baseline SSL methods like BYOL in terms of performance on downstream tasks.",
          "quote": "In Figure 1, we show improvements on in-distribution comparison to the baseline."
        },
        "referenced_paper_title": {
          "value": "Bootstrap your own latent a new approach to self-supervised learning",
          "justification": "BYOL+SEM is an extension on the BYOL model which was detailed in the referenced paper.",
          "quote": "In BYOL, we insert the SEM after the encoder..."
        }
      },
      {
        "name": {
          "value": "SWaV+SEM",
          "justification": "The paper mentions and compares the performance of SWaV+SEM to other models.",
          "quote": "SwAV and SwAV + SEM (1000 epochs) Top-1 Accuracy"
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "SWaV+SEM is one of the proposed models for integrating SEM into existing SSL methods.",
          "quote": "In this work, we show that SSL may be used to learn sparse and overcomplete representations."
        },
        "is_executed": {
          "value": 1,
          "justification": "SWaV+SEM was executed to obtain experimental results on CIFAR-100 and ImageNet.",
          "quote": "Applying it to seven different SSL methods (Chen et al., 2020b; He et al., 2020; Grill et al., 2020; Caron et al., 2020; 2021; Zbontar et al., 2021; Bardes et al., 2022), we find accuracy increases of 2% to 4% on CIFAR-100."
        },
        "is_compared": {
          "value": 1,
          "justification": "SWaV+SEM was compared with baseline SSL methods like SWaV in terms of performance on downstream tasks.",
          "quote": "We take standard SimCLR (Chen et al., 2020b), MoCo-v2 (He et al., 2020), BYOL (Grill et al., 2020) Barlow-Twins (Zbontar et al., 2021), SwAV (Caron et al., 2020)"
        },
        "referenced_paper_title": {
          "value": "Unsupervised learning of visual features by contrasting cluster assignments",
          "justification": "SWaV+SEM is an extension on the SWaV model which was detailed in the referenced paper.",
          "quote": "In this work, we show that SSL may be used to learn sparse and overcomplete representations."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "The paper uses CIFAR-100 to demonstrate the improved performance of models trained with Simplicial Embeddings.",
          "quote": "we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "CIFAR-100 is a well-known dataset introduced in this referenced paper.",
          "quote": "we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100"
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "The paper uses ImageNet to empirically demonstrate the improved generalization of models trained with Simplicial Embeddings.",
          "quote": "we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100 and ImageNet"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "ImageNet: A large-scale hierarchical image database",
          "justification": "ImageNet is a large benchmark dataset widely used in deep learning and introduced in the referenced paper.",
          "quote": "we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR-100 and ImageNet"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper acknowledges the use of PyTorch for its deep learning implementations.",
          "quote": "Finally, this project would not have been possible without the contribution of the following open source projects: Pytorch (Paszke et al., 2019)"
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "PyTorch is acknowledged in the paper as a significant tool for their deep learning experiments.",
          "quote": "Finally, this project would not have been possible without the contribution of the following open source projects: Pytorch (Paszke et al., 2019)"
        }
      },
      {
        "name": {
          "value": "Solo-Learn",
          "justification": "The paper mentions using the Solo-Learn library for the baseline models in their experiments.",
          "quote": "For all experiments, we build off the implementation of the baseline models from the Solo-Learn library (da Costa et al., 2021)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Solo-learn: A library of self-supervised methods for visual representation learning",
          "justification": "Solo-Learn provides a library for self-supervised learning methods and was used for the experiments.",
          "quote": "For all experiments, we build off the implementation of the baseline models from the Solo-Learn library (da Costa et al., 2021)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2028,
    "prompt_tokens": 29024,
    "total_tokens": 31052
  }
}