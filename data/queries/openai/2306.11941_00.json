{
  "paper": "2306.11941.txt",
  "words": 11302,
  "extractions": {
    "title": {
      "value": "Efficient Dynamics Modeling in Interactive Environments with Koopman Theory",
      "justification": "This is the title of the paper as indicated in the document.",
      "quote": "Efficient Dynamics Modeling in Interactive Environments with Koopman Theory"
    },
    "description": "This paper leverages Koopman theory to linearize the nonlinear dynamics of interactive environments into a high-dimensional latent space for long-range prediction. It offers improvements in efficiency and accuracy over existing approaches and demonstrates its utility in model-based planning and model-free RL.",
    "type": {
      "value": "Empirical",
      "justification": "The paper presents experimental results to demonstrate the effectiveness of the proposed method in comparison to existing approaches.",
      "quote": "Our experimental results in offline-RL datasets demonstrate the effectiveness of our approach for reward and state prediction over a long horizon."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper focuses on improving long-range prediction capabilities which are crucial for Reinforcement Learning algorithms.",
        "quote": "The accurate modeling of dynamics in interactive environments is critical for successful long-range prediction. Such a capability could advance Reinforcement Learning (RL) and Planning algorithms, but achieving it is challenging."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Model-based Reinforcement Learning",
          "justification": "The proposed linear latent dynamics model from Koopman theory is incorporated into model-based planning strategies to validate its effectiveness.",
          "quote": "We show that this model can be easily incorporated into dynamics modeling for model-based planning and model-free RL and report promising experimental results."
        },
        "aliases": [
          "Model-based RL"
        ]
      },
      {
        "name": {
          "value": "Model-free Reinforcement Learning",
          "justification": "The paper includes applications of the proposed dynamics model in model-free RL for improving representation learning.",
          "quote": "Finally, we also present encouraging results for model-based planning and model-free RL with our Koopman-based dynamics model."
        },
        "aliases": [
          "Model-free RL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Koopman-based Dynamics Model",
          "justification": "The paper introduces and uses a dynamics model based on Koopman theory, referred to as Koopman-based dynamics model.",
          "quote": "We also show that this model can be easily incorporated into dynamics modeling for model-based planning and model-free RL and report promising experimental results."
        },
        "aliases": [
          "Koopman Dynamics Model"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The Koopman-based dynamics model is introduced and utilized in this paper for improved dynamics modeling.",
          "quote": "We formulate an efficient linear latent dynamics model from Koopman theory that can be parallelized during training for long-range dynamics modeling in interactive environments."
        },
        "is_executed": {
          "value": 1,
          "justification": "The implementation details and the efficient execution of the Koopman-based dynamics model are discussed in the paper.",
          "quote": "In particular, we report competitive results against dynamics modeling baselines that use Multi-Layer Perceptrons (MLPs), Gated Recurrent Units (GRUs), Transformers and Diagonal State Space Models Gu et al. (2022a) while being significantly faster."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of the Koopman-based dynamics model is compared with other models in the paper.",
          "quote": "In particular, we report competitive results against dynamics modeling baselines that use Multi-Layer Perceptrons (MLPs), Gated Recurrent Units (GRUs), Transformers and Diagonal State Space Models Gu et al. (2022a) while being significantly faster."
        },
        "referenced_paper_title": {
          "value": "Modern Koopman Theory for Dynamical Systems",
          "justification": "The paper builds on Koopman theory which is elaborated in the reference paper 'Modern Koopman Theory for Dynamical Systems'.",
          "quote": "The application of Koopman theory allows us to linearise a nonlinear dynamical system by creating a bijective mapping to linear dynamics in a possibly infinite dimensional space of observables.1"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "D4RL",
          "justification": "The D4RL dataset is used for training and evaluating the proposed dynamics model in various reinforcement learning environments.",
          "quote": "For the forward dynamics modeling experiments, we use the D4RL Fu et al. (2020) dataset, which is a popular offline-RL environment."
        },
        "aliases": [
          "D4RL"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "D4rl: Datasets for Deep Data-Driven Reinforcement Learning",
          "justification": "The D4RL dataset is taken from the reference cited as 'D4rl: Datasets for Deep Data-Driven Reinforcement Learning'.",
          "quote": "For the forward dynamics modeling experiments, we use the D4RL Fu et al. (2020) dataset, which is a popular offline-RL environment."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "JAX",
          "justification": "JAX is explicitly mentioned in the paper as used for implementing the Koopman-based dynamics model.",
          "quote": "(see Appendix J for an efficient Jax implementation of the model)"
        },
        "aliases": [
          "JAX"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "JAX: Autograd and XLA",
          "justification": "JAX: Autograd and XLA is the reference tool used for implementing the model as described in the paper.",
          "quote": "(see Appendix J for an efficient Jax implementation of the model)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1075,
    "prompt_tokens": 21380,
    "total_tokens": 22455
  }
}