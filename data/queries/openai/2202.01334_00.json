{
  "paper": "2202.01334.txt",
  "words": 8335,
  "extractions": {
    "title": {
      "value": "Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization",
      "justification": "This is the exact title provided by the user.",
      "quote": "Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization"
    },
    "description": "This paper proposes a dynamic vector quantization (DVQ) method that adaptively selects the discretization tightness (the number of discrete codes and codebook size) based on input complexity. The method aims to improve model performance on visual reasoning and reinforcement learning tasks by dynamically adjusting the communication bottlenecks between modular components within a model or between agents in multi-agent reinforcement learning (MARL).",
    "type": {
      "value": "Empirical study",
      "justification": "The paper includes theoretical analysis and empirical experiments to validate the proposed DVQ method.",
      "quote": "We empirically show improvement in performance by using DVQ to discretize inter-component communication within a deep learning model and inter-agent communication between agents, compared to using VQ with fixed bottleneck capacity."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research primarily focuses on improvements in discretization techniques within deep learning models and their applications in visual reasoning and reinforcement learning.",
        "quote": "Vector Quantization (VQ) is a method for discretizing latent representations and has become a major part of the deep learning toolkit."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "A significant portion of the paper is dedicated to improving performance in reinforcement learning tasks using the proposed DVQ method.",
          "quote": "We show that dynamically varying tightness in communication bottlenecks can improve model performance on visual reasoning and reinforcement learning tasks."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The paper also experiments with visual reasoning tasks, which are inherently related to the field of Computer Vision.",
          "quote": "We explore the effects of using DVQ to bottleneck inter-module communication for visual reasoning tasks."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Dynamic Vector Quantization (DVQ)",
          "justification": "This is the primary model proposed by the paper.",
          "quote": "We propose a dynamic vector quantization method (DVQ) that adaptively chooses the number of discrete codes and the codebook size that control tightness of the bottleneck."
        },
        "aliases": [
          "DVQ"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The paper proposes DVQ as a novel contribution to the field.",
          "quote": "We propose a dynamic vector quantization method (DVQ) that adaptively chooses the number of discrete codes and the codebook size that control tightness of the bottleneck."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments in which DVQ is used.",
          "quote": "We empirically show improvement in performance by using DVQ to discretize inter-component communication within a deep learning model and inter-agent communication between agents, compared to using VQ with fixed bottleneck capacity."
        },
        "is_compared": {
          "value": 1,
          "justification": "DVQ is compared to fixed-bottleneck VQ in the experiments.",
          "quote": "We empirically show improvement in performance by using DVQ to discretize inter-component communication within a deep learning model and inter-agent communication between agents, compared to using VQ with fixed bottleneck capacity."
        },
        "referenced_paper_title": {
          "value": "None",
          "justification": "DVQ is a new contribution introduced in this paper, so it does not reference a prior paper for its introduction.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Vector Quantization (VQ)",
          "justification": "VQ is the baseline model which the paper is comparing its proposed method against.",
          "quote": "Vector Quantization (VQ) is a method for discretizing latent representations and has become a major part of the deep learning toolkit."
        },
        "aliases": [
          "VQ"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "VQ is not introduced by this paper but serves as a baseline for comparisons.",
          "quote": "Vector Quantization (VQ) is a method for discretizing latent representations and has become a major part of the deep learning toolkit."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments using VQ as a baseline.",
          "quote": "We empirically show improvement in performance by using DVQ to discretize inter-component communication within a deep learning model and inter-agent communication between agents, compared to using VQ with fixed bottleneck capacity."
        },
        "is_compared": {
          "value": 1,
          "justification": "VQ is used as a baseline model for comparison in the experiments.",
          "quote": "We empirically show improvement in performance by using DVQ to discretize inter-component communication within a deep learning model and inter-agent communication between agents, compared to using VQ with fixed bottleneck capacity."
        },
        "referenced_paper_title": {
          "value": "Neural Discrete Representation Learning",
          "justification": "The baseline VQ model is taken from the paper titled 'Neural Discrete Representation Learning.'",
          "quote": "Discretization of latent representations via vector quantization is a method for improving the robustness and generalization of learned models (Oord et al., 2017; Liu et al., 2021)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Atari 2600 Games",
          "justification": "Used for evaluating the visual reasoning capabilities of the proposed method.",
          "quote": "We explore the effects of using DVQ to bottleneck inter-module communication for visual reasoning tasks. The tasks are to predict object movement in a grid world (referred to as 'Shapes') and 7 different Atari game environments."
        },
        "aliases": [
          "Atari Games"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "The Atari 2600 games dataset is commonly used and doesn't require specific referencing.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Shapes Dataset",
          "justification": "Used for the visual reasoning task to predict object movement in grid world environments.",
          "quote": "The tasks are to predict object movement in a grid world (referred to as 'Shapes') and 7 different Atari game environments."
        },
        "aliases": [
          "Shapes"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "The Shapes dataset is used specifically for this paper's experiments.",
          "quote": ""
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1589,
    "prompt_tokens": 15510,
    "total_tokens": 17099
  }
}