{
  "paper": "2403.06026.txt",
  "words": 5089,
  "extractions": {
    "title": {
      "value": "Towards a Generic Representation of Combinatorial Problems for Learning-Based Approaches",
      "justification": "Official title from the document",
      "quote": "Towards a Generic Representation of Combinatorial Problems for Learning-Based Approaches"
    },
    "description": "This paper proposes a fully generic representation of combinatorial problems for learning-based approaches. The authors introduce an approach that constructs a graph by breaking down any constraint of a combinatorial problem into an abstract syntax tree and expressing relationships through the edges. A graph neural network (GNN) architecture is introduced to learn efficiently from this representation. Experimental results show that the proposed architecture achieves performance comparable to dedicated architectures while maintaining generality.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper includes experimental results on four combinatorial problems showcasing the performance of their proposed architecture.",
      "quote": "Experimental results on four combinatorial problems demonstrate that our architecture achieves performance comparable to dedicated architectures while maintaining generality."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper focuses on learning-based approaches for solving combinatorial problems, specifically using neural networks and graph representations.",
        "quote": "In recent years, there has been a growing interest in using learning-based approaches for solving combinatorial problems, either in an end-to-end manner or in conjunction with traditional optimization algorithms."
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Graph Neural Networks",
          "justification": "The paper proposes a graph neural network (GNN) architecture tailored to learning from their proposed generic graph representation of combinatorial problems.",
          "quote": "Among deep learning architectures, graph neural networks (GNNs) [29] have proven to be a powerful and flexible tool for solving combinatorial problems."
        },
        "aliases": [
          "GNN"
        ]
      },
      {
        "name": {
          "value": "Combinatorial Optimization",
          "justification": "The paper addresses combinatorial optimization problems and proposes a method to represent these problems in a generic way for learning-based approaches.",
          "quote": "Combinatorial optimization has drawn the attention of computer scientists since the discipline emerged."
        },
        "aliases": [
          "CO"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Graph Neural Network (GNN)",
          "justification": "The proposed model in the paper is a graph neural network designed to learn from the generic graph representation of combinatorial problems.",
          "quote": "To achieve the next step and learn from this representation, we designed a tailored graph neural network (GNN) architecture to leverage this encoding."
        },
        "aliases": [
          "GNN"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The GNN model is specifically proposed in the paper as a novel contribution.",
          "quote": "To achieve the next step and learn from this representation, we designed a tailored graph neural network (GNN) architecture to leverage this encoding."
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments in the paper were conducted using GNN on a GPU.",
          "quote": "All models were trained with PyTorch [26] and PyTorch-Geometric [12] on a single Nvidia V100 32 GB GPU for up to 4 days or until convergence."
        },
        "is_compared": {
          "value": 1,
          "justification": "The GNN model's performance is compared with problem-specific architectures in the experimentation section.",
          "quote": "We compared our approach with problem-specific architectures and the tripartite graph of Marty et al. (2023) [23]."
        },
        "referenced_paper_title": {
          "value": "The graph neural network model",
          "justification": "The GNN model is referenced from previous works on graph neural networks, which are cited in the paper.",
          "quote": "Among deep learning architectures, graph neural networks (GNNs) [29] have proven to be a powerful and flexible tool for solving combinatorial problems."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Random Dataset for SAT",
          "justification": "The paper used a dataset of random SAT instances generated as described by Selsam et al. (2018).",
          "quote": "Instances are generated with the random generator of Selsam et al. (2018) [30]."
        },
        "aliases": [
          "Random SAT Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning a SAT solver from single-bit supervision",
          "justification": "The SAT dataset generation method is referenced from Selsam et al. (2018).",
          "quote": "Instances are generated with the random generator of Selsam et al. (2018) [30]."
        }
      },
      {
        "name": {
          "value": "Random Dataset for TSP",
          "justification": "A dataset of random TSP instances was generated as described by Prates et al. (2019).",
          "quote": "Instances are generated with the random generator of Prates et al. (2018) [27]."
        },
        "aliases": [
          "Random TSP Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning to solve np-complete problems: A graph neural network for decision TSP",
          "justification": "The TSP dataset generation method is referenced from Prates et al. (2018).",
          "quote": "Instances are generated with the random generator of Prates et al. (2018) [27]."
        }
      },
      {
        "name": {
          "value": "Random Dataset for Graph Coloring",
          "justification": "A dataset of random Graph Coloring instances was generated as described by Lemos et al. (2019).",
          "quote": "Instances are generated following Lemos et al. (2019) [19]."
        },
        "aliases": [
          "Random Graph Coloring Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Graph colouring meets deep learning: Effective graph neural network models for combinatorial problems",
          "justification": "The Graph Coloring dataset generation method is referenced from Lemos et al. (2019).",
          "quote": "Instances are generated following Lemos et al. (2019) [19]."
        }
      },
      {
        "name": {
          "value": "Random Dataset for Knapsack",
          "justification": "A dataset of random Knapsack instances was generated for the experiments.",
          "quote": "We built instances containing 20 to 40 items and solved them to optimality to find the optimal value V âˆ—."
        },
        "aliases": [
          "Random Knapsack Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper did not reference a specific prior work for the generation of Knapsack instances.",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper explicitly mentions using PyTorch for training the models.",
          "quote": "All models were trained with PyTorch [26] and PyTorchGeometric [12] on a single Nvidia V100 32 GB GPU for up to 4 days or until convergence."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The PyTorch library is referenced as the main deep learning framework used for training the models.",
          "quote": "All models were trained with PyTorch [26] and PyTorch-Geometric [12] on a single Nvidia V100 32 GB GPU for up to 4 days or until convergence."
        }
      },
      {
        "name": {
          "value": "PyTorch-Geometric",
          "justification": "The paper explicitly mentions using PyTorch-Geometric for graph-related deep learning tasks.",
          "quote": "All models were trained with PyTorch [26] and PyTorchGeometric [12] on a single Nvidia V100 32 GB GPU for up to 4 days or until convergence."
        },
        "aliases": [
          "PyG"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fast graph representation learning with PyTorch Geometric",
          "justification": "The PyTorch-Geometric library is referenced as the framework used in conjunction with PyTorch for graph neural networks.",
          "quote": "All models were trained with PyTorch [26] and PyTorchGeometric [12] on a single Nvidia V100 32 GB GPU for up to 4 days or until convergence."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1578,
    "prompt_tokens": 9514,
    "total_tokens": 11092
  }
}