{
  "paper": "99ca106e47ca42935fa258a8d287adfd.txt",
  "words": 6159,
  "extractions": {
    "title": {
      "value": "Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots",
      "justification": "The title of the paper is clearly mentioned at the beginning of the document.",
      "quote": "Reinforcement Learning for Blind Stair Climbing with Legged and Wheeled-Legged Robots"
    },
    "description": "This paper explores a reinforcement learning-based method to enable legged and wheeled-legged robots to climb stairs. The proposed system employs an asymmetric actor-critic structure and uses simulated environments for training, focusing on position-based RL tasks. It demonstrates the method's effectiveness on various robots, such as the Ascento, Unitree Go1, Cassie, and ANYmal, showcasing its transferability to real-world scenarios without reliance on perceptive sensors.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical results from simulations and real-world tests on various robots like Ascento and ANYmal, demonstrating their stair climbing capabilities using the proposed RL method.",
      "quote": "We present our results on different quadrupeds and bipedal robots in simulation and showcase how our method allows the balancing robot Ascento to climb 15cm stairs in the real world."
    },
    "primary_research_field": {
      "name": {
        "value": "Robotics",
        "justification": "The paper focuses on the development of stair-climbing capabilities for robots, which is a direct application in the field of robotics.",
        "quote": "Mobile ground robots have been widely studied and used for various tasks, such as delivery, inspection, and security, [1]."
      },
      "aliases": [
        "Robotic Systems"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The methodology of the paper is based on reinforcement learning which is used to develop a versatile controller for robots to climb stairs.",
          "quote": "This study proposes a method aimed at addressing this limitation, employing reinforcement learning to develop a versatile controller applicable to a wide range of robots."
        },
        "aliases": [
          "RL"
        ]
      },
      {
        "name": {
          "value": "Control Systems",
          "justification": "The paper discusses the development of control policies for robots, which is a core aspect of control systems engineering.",
          "quote": "This study proposes a method aimed at addressing this limitation, employing reinforcement learning to develop a versatile controller applicable to a wide range of robots."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Asymmetric Actor-Critic (PPO)",
          "justification": "The paper introduces and utilizes an asymmetric actor-critic architecture for training the reinforcement learning controller.",
          "quote": "2) Learning Algorithm: We use the RL algorithm PPO, with an asymmetric actor-critic structure."
        },
        "aliases": [
          "PPO"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The paper presents a variant of the actor-critic structure as a core part of its methodology, indicating a contribution to the model's application in this context.",
          "quote": "This is a variant of the standard actor-critic algorithm in RL, where the actor and critic use separate networks, allowing them to update independently."
        },
        "is_executed": {
          "value": true,
          "justification": "The asymmetric actor-critic structure is used in the experiments to train the robots' stair-climbing abilities.",
          "quote": "In this work, we use the open-source PPO implementation published by the Robotics Systems Lab (RSL) from ETH."
        },
        "is_compared": {
          "value": false,
          "justification": "There is no direct mention of this model being compared to other models within the context of the paper.",
          "quote": "There is no direct mention of this model being compared to other models within the context of the paper."
        },
        "referenced_paper_title": {
          "value": "Proximal Policy Optimization Algorithms",
          "justification": "The paper references PPO as part of its methodology and basis for the asymmetric actor-critic structure.",
          "quote": "In this work, we use the open-source PPO implementation published by the Robotics Systems Lab (RSL) from ETH."
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "Isaac Gym",
          "justification": "The paper explicitly mentions using Isaac Gym as the training platform for reinforcement learning applications.",
          "quote": "Simulator: We used Isaac Gym [21] as our training platform, specifically designed for RL applications."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Isaac Gym: High Performance GPU-Based Physics Simulation for Robot Learning",
          "justification": "Isaac Gym is mentioned as the simulation tool used for training in reinforcement learning tasks.",
          "quote": "Simulator: We used Isaac Gym [21] as our training platform, specifically designed for RL applications."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 909,
    "prompt_tokens": 11341,
    "total_tokens": 12250,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}