{
  "paper": "8b86fbde96db3a45c9175d2e5d509abc.txt",
  "words": 12895,
  "extractions": {
    "title": {
      "value": "The feature landscape of visual cortex",
      "justification": "Title of the paper as stated at the top.",
      "quote": "The feature landscape of visual cortex\nRudi Tong1, Ronan da Silva1,8, Dongyan Lin1,2,8, Arna Ghosh2,3,8, James Wilsenach4,5,8, Erica Cianfarano1,2,\nPouya Bashivan2,6, Blake Richards1,2,3,7, Stuart Trenholm1*\nMontreal Neurological Institute, McGill University, Montreal, Canada"
    },
    "description": "This paper explores the distinct feature preferences of neurons in different visual cortical areas in mouse. By recording neuronal activity in vivo and analyzing it with artificial neural networks (ANNs), the study identifies feature preferences and the functional organization of the visual cortex areas. Furthermore, the study investigates why such organization occurs and the implications for encoding visual information.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves experiments such as in vivo neuronal recordings and modeling neuronal responses to visual stimuli.",
      "quote": "Understanding computations in the visual system requires a characterization of the distinct feature preferences of neurons in different visual cortical areas. To address this, we recorded from thousands of neurons across six visual cortical areas in mouse and leveraged generative AI methods combined with closed-loop neuronal recordings to identify each neuron’s visual feature preference."
    },
    "primary_research_field": {
      "name": {
        "value": "Neuroscience",
        "justification": "The paper mainly investigates neuronal responses and feature preferences in the visual cortex, which are core topics in neuroscience.",
        "quote": "Understanding computations in the visual system requires a characterization of the distinct feature preferences of neurons in different visual cortical areas."
      },
      "aliases": [
        "Neural Computations",
        "Visual Neuroscience"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The study employs artificial neural networks to model and analyze visual stimuli and neuronal responses, techniques that are central to Computer Vision research.",
          "quote": "Next, we used ANNs to model the responses from neurons in each cortical area (Figure 1b). We used a shallow convolutional neural network with a factorized readout layer that separates the visual features (i.e. ‘what’) and the spatial locations in the images that drive neurons (i.e. ‘where’), referred to as the ‘spatial mask’."
        },
        "aliases": [
          "CV",
          "Machine Vision"
        ]
      },
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The study heavily utilizes deep learning models, specifically artificial neural networks, for analyzing and predicting neuronal responses.",
          "quote": "To address this, we used in vivo 2-photon calcium imaging to record from thousands of neurons across mouse V1 and five HVAs. We leveraged advances in modelling neuronal responses using artificial neural networks (ANNs) to build predictive models of the neurons, which we used to generate preferred stimuli for individual neurons."
        },
        "aliases": [
          "DL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Artificial Neural Networks (ANNs)",
          "justification": "The study uses artificial neural networks to model neuron responses and identify preferred visual stimuli.",
          "quote": "To gain an understanding of the visual features encoded by neurons in various visual cortical areas in the mouse, we modelled neuron responses to visual stimuli in different areas with artificial neural networks (ANNs)."
        },
        "aliases": [
          "ANNs"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The study utilizes existing artificial neural network architectures for modeling purposes and does not contribute new models.",
          "quote": "To gain an understanding of the visual features encoded by neurons in various visual cortical areas in the mouse, we modelled neuron responses to visual stimuli in different areas with artificial neural networks (ANNs)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The artificial neural networks were trained and executed as part of the study to predict neuronal responses.",
          "quote": "To gain an understanding of the visual features encoded by neurons in various visual cortical areas in the mouse, we modelled neuron responses to visual stimuli in different areas with artificial neural networks (ANNs)."
        },
        "is_compared": {
          "value": 0,
          "justification": "While ANN-based predictions are validated against experimental data, the study does not numerically compare different ANN models.",
          "quote": "For each cortical area, we trained a unique ANN to predict the responses of individual neurons to the natural images."
        },
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "No specific referenced paper for the ANN models was cited in the provided text.",
          "quote": "Not applicable"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "The study uses the ImageNet dataset to present natural images to the animal models.",
          "quote": "We presented 10,000 natural images taken from ImageNet to the spatial mask centered units."
        },
        "aliases": [
          "ILSVRC"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A large-scale hierarchical image database.",
          "justification": "The reference for ImageNet was included in the text.",
          "quote": "27. ImageNet: A large-scale hierarchical image database."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Lucent",
          "justification": "The study uses the Lucent library to generate preferred stimuli from ANN models.",
          "quote": "Preferred stimuli were generated using the Lucent library (https://github.com/greentfrapp/lucent)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "There is no specific referenced paper for the Lucent library in the text.",
          "quote": "Not applicable"
        }
      },
      {
        "name": {
          "value": "Suite2P",
          "justification": "The study used Suite2P to identify neurons and extract their responses from imaging data.",
          "quote": "Following data acquisition, recordings were processed using Suite2P to identify neurons and extract their responses (deconvolved spiking responses)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Suite2p: beyond 10,000 neurons with standard two-photon microscopy.",
          "justification": "The reference for Suite2P was included in the text.",
          "quote": "41. Suite2p: beyond 10,000 neurons with standard two-photon microscopy."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1524,
    "prompt_tokens": 22479,
    "total_tokens": 24003
  }
}