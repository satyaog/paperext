{
  "paper": "2311.16176.txt",
  "words": 7965,
  "extractions": {
    "title": {
      "value": "Mitigating Biases with Diverse Ensembles and Diffusion Models",
      "justification": "This is the title of the paper.",
      "quote": "Mitigating Biases with Diverse Ensembles and Diffusion Models"
    },
    "description": "This paper proposes an ensemble diversification framework that leverages Diffusion Probabilistic Models (DPMs) to mitigate shortcut learning and bias in deep neural networks. By generating synthetic counterfactuals that break spurious correlations present in the training data, the authors aim to enhance model diversity via ensemble disagreement. The study demonstrates improved generalization and diversification performance on datasets, achieving state-of-the-art results in bias mitigation without the need for additional supervised signals.",
    "type": {
      "value": "Empirical Study",
      "justification": "The study conducts extensive experiments and provides empirical evidence to support its conclusions on model diversification and bias mitigation using Diffusion Probabilistic Models (DPMs).",
      "quote": "We show that counterfactuals from appropriately trained DPMs can be used to achieve state-of-the-art diversification and shortcut bias mitigation."
    },
    "primary_research_field": {
      "name": {
        "value": "Bias Mitigation in Machine Learning",
        "justification": "The primary focus of the paper is on mitigating biases due to shortcut learning in machine learning models by using diverse ensembles and Diffusion Probabilistic Models (DPMs).",
        "quote": "The primary objective of this work is to mitigate shortcut learning tendencies, particularly when they result in strong, unwarranted biases..."
      },
      "aliases": [
        "Bias Mitigation",
        "Ensemble Diversity"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Ensemble Methods",
          "justification": "The paper explores the use of ensemble methods for model diversification to address shortcut learning and biases.",
          "quote": "To achieve this objective, we propose an ensemble framework relying on unlabelled ood data for diversification."
        },
        "aliases": [
          "Ensemble Learning"
        ]
      },
      {
        "name": {
          "value": "Generative Models",
          "justification": "The study utilizes Diffusion Probabilistic Models (DPMs) as generative tools to create synthetic counterfactuals that aid in mitigating biases.",
          "quote": "We leverage Diffusion Probabilistic Models (DPMs) to generate synthetic data for ensemble disagreement."
        },
        "aliases": [
          "Diffusion Models",
          "Generative Adversarial Networks"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Diffusion Probabilistic Models (DPMs)",
          "justification": "The main model used in the study for generating synthetic data to mitigate biases is the Diffusion Probabilistic Model.",
          "quote": "We leverage Diffusion Probabilistic Models (DPMs) to generate synthetic data for ensemble disagreement."
        },
        "aliases": [
          "DPMs"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The paper leverages existing Diffusion Probabilistic Models for the study and does not claim to contribute a new model.",
          "quote": "We leverage Diffusion Probabilistic Models (DPMs) to generate synthetic data for ensemble disagreement."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper involves executing the DPMs for generating synthetic data during the experiments.",
          "quote": "We generate â‰ˆ 100k samples from DPMs trained at varying number of epochs between 1 to 1K, to be used for ensemble diversification and analysis."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the use of DPMs against other diversification methods involving out-of-distribution data.",
          "quote": "Our experiments confirm that the extent and quality of our diffusion-guided ensemble diversification is on par with existing methods that rely on additional data."
        },
        "referenced_paper_title": {
          "value": "Denoising Diffusion Probabilistic Models",
          "justification": "The referenced most relevant work for Diffusion Probabilistic Models used in this paper.",
          "quote": "Denoising Diffusion Probabilistic Models"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "DSprites",
          "justification": "The DSprites dataset is used in the study for controlled experiments on bias mitigation using synthetic counterfactuals.",
          "quote": "DSprites: DSprites includes a comprehensive set of symbolic objects generated with variations in five latent variables: shape, scale, orientation, and X-Y position."
        },
        "aliases": [],
        "role": "USED",
        "referenced_paper_title": {
          "value": "DSprites: Disentanglement testing Sprites dataset",
          "justification": "The referenced work for the DSprites dataset used in this study.",
          "quote": "DSprites: DSprites includes a comprehensive set of symbolic objects..."
        }
      },
      {
        "name": {
          "value": "UTKFace",
          "justification": "The UTKFace dataset is used for experiments to study bias mitigation in real-world, less controlled setup.",
          "quote": "UTKFace: UTKFace provides a dataset of 23,708 facial images annotated with attributes like age, gender, and ethnicity."
        },
        "aliases": [],
        "role": "USED",
        "referenced_paper_title": {
          "value": "Age Progression/Regression by Conditional Adversarial Autoencoder",
          "justification": "The referenced work for the UTKFace dataset used in this study.",
          "quote": "Age Progression/Regression by Conditional Adversarial Autoencoder"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "ResNet",
          "justification": "The ResNet library is used for training the ensemble models in the experiments.",
          "quote": "We train a diverse ensemble comprising 100 ResNet-18 models on both ColorDSprites and UTKFace."
        },
        "aliases": [],
        "role": "USED",
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "The referenced paper for the ResNet library used in the models for this study.",
          "quote": "We train a diverse ensemble comprising 100 ResNet-18 models..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1134,
    "prompt_tokens": 14835,
    "total_tokens": 15969
  }
}