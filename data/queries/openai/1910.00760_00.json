{
  "paper": "1910.00760.txt",
  "words": 7599,
  "extractions": {
    "title": {
      "value": "Efficient Graph Generation with Graph Recurrent Attention Networks",
      "justification": "The title summarizes the core contribution of the paper—efficient graph generation using the proposed GRANs model.",
      "quote": "Efficient Graph Generation with Graph Recurrent Attention Networks"
    },
    "description": "The paper proposes Graph Recurrent Attention Networks (GRANs), a deep generative model that efficiently and effectively generates large graph structures while maintaining state-of-the-art sample quality. The model uses an attention-based graph neural network for auto-regressive graph generation and introduces innovations such as marginalizing node orderings and parameterizing output distributions with a mixture of Bernoulli distributions.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes extensive experiments to verify the effectiveness of the proposed GRAN model on both synthetic and real graph datasets, along with comparisons to other existing models.",
      "quote": "In this section we empirically verify the effectiveness of our model on both synthetic and real graph datasets with drastically varying sizes and characteristics."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper falls under the deep learning research domain as it focuses on developing deep generative models for graph structures.",
        "quote": "We propose a new family of efficient and expressive deep generative models of graphs, called Graph Recurrent Attention Networks (GRANs)."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Graph Neural Networks",
          "justification": "The paper specifically deals with the generation of graphs using Graph Neural Networks and introduces an attention mechanism to improve the quality and efficiency of the generative process.",
          "quote": "Moreover, we parameterize the output distribution per block using a mixture of Bernoulli, which captures the correlations among generated edges within the block."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Graph Recurrent Attention Network",
          "justification": "The paper introduces this model as its main contribution for efficient graph generation.",
          "quote": "We propose a new family of efficient and expressive deep generative models of graphs, called Graph Recurrent Attention Networks (GRANs)."
        },
        "aliases": [
          "GRAN"
        ],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "GraphRNN",
          "justification": "The paper mentions GraphRNN as one of the models it compares with in terms of performance on various datasets.",
          "quote": "Currently, the most scalable auto-regressive framework that is both general (i.e., not moleculespecific) and able to exploit graph structure is the GraphRNN model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Grid",
          "justification": "The grid dataset is used to benchmark the GRAN model against other models in terms of graph generation quality and efficiency.",
          "quote": "Grid: We generate 100 standard 2D grid graphs with 100 ≤ |V | ≤ 400."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Protein",
          "justification": "The protein dataset is used for evaluating the performance of the proposed GRAN model.",
          "quote": "Protein: This dataset contains 918 protein graphs with 100 ≤ |V | ≤ 500."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Point Cloud",
          "justification": "The point cloud dataset consisting of 3D household objects is used to test the scalability of the GRAN model.",
          "quote": "Point Cloud: FirstMM-DB is a dataset of 41 simulated 3D point clouds of household objects with an average graph size of over 1k nodes, and maximum graph size over 5k nodes."
        },
        "aliases": [
          "FirstMM-DB"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Lobster",
          "justification": "The random lobster graphs dataset is used in additional experiments to evaluate the effectiveness of the GRAN model.",
          "quote": "Lobster: We generate 100 random lobster graphs with 10 ≤ |V | ≤ 100."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "NetworkX",
          "justification": "The NetworkX library is used for working with the node orderings in the dataset.",
          "quote": "In our case, it is the default ordering used by NetworkX."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1170,
    "prompt_tokens": 12900,
    "total_tokens": 14070
  }
}