{
  "paper": "2210.16114.txt",
  "words": 9916,
  "extractions": {
    "title": {
      "value": "T OWARDS RELIABLE NEURAL SPECIFICATIONS",
      "justification": "This is the exact title as given in the paper.",
      "quote": "T OWARDS RELIABLE NEURAL SPECIFICATIONS"
    },
    "description": "The paper addresses the challenge of reliable specifications in AI systems by proposing a new family of specifications called neural representation as specification, which uses neural activation patterns (NAPs) to enhance the correctness and robustness of neural network predictions, potentially covering larger input regions compared to traditional methods. The effectiveness of NAPs is demonstrated through empirical studies on datasets like MNIST and CIFAR10.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper proposes a new method and empirically evaluates it on different datasets to show its effectiveness.",
      "quote": "we propose a new family of specifications called neural representation as specification... We conduct thorough experimental evaluations from both statistical and formal verification perspectives."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper primarily focuses on improving the specifications and verification aspect of neural network models, which is a core area of Machine Learning.",
        "quote": "The advances in deep neural networks (DNNs) have brought a wide societal impact in many domains such as transportation, healthcare, finance, e-commerce, and education."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Neural Network Verification",
          "justification": "The paper's main contribution is introducing and verifying a new specification method for neural networks.",
          "quote": "Having reliable specifications is an unavoidable challenge in achieving verifiable correctness, robustness, and interpretability of AI systems."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Adversarial Robustness",
          "justification": "The paper addresses the shortcomings of existing adversarial robustness specifications and proposes an alternative using NAPs.",
          "quote": "Most works ...use the specification of adversarial robustness for classification tasks... However, from a learning perspective, this would lead to overfitted specification...we propose a new family of specifications...neural activation patterns (NAPs)."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Formal Methods in Machine Learning",
          "justification": "The focus on formal verification and validation methods for neural networks places this paper within the scope of formal methods in ML.",
          "quote": "Existing works approach this challenge by building on formal methods – a field of computer science and engineering that involves verifying properties of systems using rigorous mathematical specifications and proofs."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "The paper uses the MNIST dataset to show the effectiveness of the proposed neural activation patterns in verifying neural network predictions.",
          "quote": "For the MNIST dataset, a verifiable NAP mined from the training images could cover up to 84% testing images."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition.",
          "justification": "Provided as a key reference for MNIST dataset which was used in the study.",
          "quote": "Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition."
        }
      },
      {
        "name": {
          "value": "CIFAR10",
          "justification": "The CIFAR10 dataset was used to demonstrate the scalability and effectiveness of the proposed approach on a more complex dataset.",
          "quote": "Moreover, we can push the verifiable bound to 10 times larger on the CIFAR10 benchmark."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images.",
          "justification": "Provided as a key reference for CIFAR10 dataset which was used in the study.",
          "quote": "A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Marabou",
          "justification": "Marabou was used in the experiments to verify the neural activation patterns and properties.",
          "quote": "We show that NAPs can be easily checked by out-of-the-box neural network verification tools used in VNNCOMP – the annual neural network verification competition, such as Marabou."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "G. Katz, D. A. Huang, D. Ibeling, K. Julian, C. Lazarus, R. Lim, P. Shah, S. Thakoor, H. Wu, A. Zeljic, D. L. Dill, M. J. Kochenderfer, and C. W. Barrett. The marabou framework for verification and analysis of deep neural networks.",
          "justification": "Provided as a key reference for the Marabou library which was used in the study.",
          "quote": "G. Katz, D. A. Huang, D. Ibeling, K. Julian, C. Lazarus, R. Lim, P. Shah, S. Thakoor, H. Wu, A. Zeljic, D. L. Dill, M. J. Kochenderfer, and C. W. Barrett. The marabou framework for verification and analysis of deep neural networks."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1070,
    "prompt_tokens": 19017,
    "total_tokens": 20087
  }
}