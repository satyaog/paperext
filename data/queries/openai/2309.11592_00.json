{
  "paper": "2309.11592.txt",
  "words": 10037,
  "extractions": {
    "title": {
      "value": "Parallel-entoring for Offline Model-based Optimization",
      "justification": "This is the title of the paper.",
      "quote": "Parallel-mentoring for Offline Model-based Optimization"
    },
    "description": "This paper presents a novel method called parallel-mentoring for offline model-based optimization (MBO), which aims to maximize a black-box objective function using a static dataset of designs and scores from various domains. The method utilizes an ensemble of multiple proxies, facilitating mentoring among them to enhance robustness against out-of-distribution issues. Specifically, the proposed tri-mentoring case uses three proxies and involves voting-based pairwise supervision and adaptive soft-labeling to generate and refine ranking supervision signals. Experiments validate the effectiveness of the method.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper involves experiments to validate the effectiveness of the proposed parallel-mentoring method for offline model-based optimization.",
      "quote": "Experiments validate the effectiveness of our method."
    },
    "primary_research_field": {
      "name": {
        "value": "Model-based Optimization",
        "justification": "The primary focus of this paper is on offline model-based optimization using deep learning techniques.",
        "quote": "We study offline model-based optimization to maximize a black-box objective function with a static dataset of designs and scores."
      },
      "aliases": [
        "MBO"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The use of deep learning techniques is critical to train the proxies for the model-based optimization described in the paper.",
          "quote": "A prevalent approach to addressing the problem is to train a deep neural network (DNN) model parameterized as fθ (·), on the static dataset."
        },
        "aliases": [
          "DL"
        ]
      },
      {
        "name": {
          "value": "Ensemble Learning",
          "justification": "The paper's method involves training an ensemble of multiple proxies to improve the robustness of the MBO process.",
          "quote": "Recent studies have observed that employing a mean ensemble of trained proxies for gradient ascent in offline MBO generally leads to superior designs compared to using a single proxy."
        },
        "aliases": [
          "EL"
        ]
      },
      {
        "name": {
          "value": "Bi-level Optimization",
          "justification": "The adaptive soft-labeling module in the proposed method is based on a bi-level optimization framework.",
          "quote": "To this end, we introduce an adaptive soft-labeling module with soft-labels initialized as consensus labels. Based on bi-level optimization, this module fine-tunes proxies in the inner level and learns more accurate labels in the outer level to adaptively mentor proxies."
        },
        "aliases": [
          "BiO"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Tri-mentoring",
          "justification": "The paper contributes the tri-mentoring model to enhance offline model-based optimization using three proxies.",
          "quote": "To this end, we propose an effective and novel method called parallel-mentoring that facilitates mentoring among parallel proxies to train a more robust ensemble against the out-of-distribution issue. This paper primarily focuses on the three-proxy case, referred to as tri-mentoring."
        },
        "aliases": [
          "Tri-mentoring",
          "Parallel Mentoring"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "Tri-mentoring is a novel method proposed and contributed by this paper.",
          "quote": "we propose parallel-mentoring as an effective and novel method that facilitates mentoring among parallel proxies... This paper primarily focuses on the three-proxy case, referred to as tri-mentoring."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was executed as part of the experiments conducted to validate its effectiveness.",
          "quote": "Experiments validate the effectiveness of our method."
        },
        "is_compared": {
          "value": 1,
          "justification": "Tri-mentoring was compared numerically against other methods as shown in experimental sections.",
          "quote": "We conduct extensive experiments on design-bench to investigate the effectiveness and robustness of the proposed method. In Section 4.4, we benchmark our approach against several well-established baselines."
        },
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no reference to a prior paper for this model since it is originally proposed in this work.",
          "quote": "None"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Design-Bench",
          "justification": "The Design-Bench dataset is used in the experiments to validate the proposed tri-mentoring method.",
          "quote": "We conduct extensive experiments on design-bench to investigate the effectiveness and robustness of the proposed method."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Design-bench: Benchmarks for data-driven offline model-based optimization",
          "justification": "The referenced paper for the Design-Bench dataset is specified in the experiments section.",
          "quote": "We conduct experiments on the four continuous tasks... Evaluation. We use the oracle evaluation of design-bench to evaluate a certain design and the details of the oracle functions are reported in Design-Bench Benchmark Tasks in [1]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "higher",
          "justification": "The higher library is used for higher-order optimization in the adaptive soft-labeling module.",
          "quote": "The nested optimization problem can be easily solved by higher, a library for higher-order optimization."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Generalized inner loop meta-learning",
          "justification": "The referenced paper for the higher library is cited in the methodology section.",
          "quote": "The nested optimization problem can be easily solved by higher, a library for higher-order optimization [19]."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1077,
    "prompt_tokens": 18782,
    "total_tokens": 19859
  }
}