{
  "paper": "ZgXfXSz51n.txt",
  "words": 9938,
  "extractions": {
    "title": {
      "value": "Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning",
      "justification": "It is the main title of the research paper.",
      "quote": "Guillotine Regularization: Why removing layers is needed to improve generalization in Self-Supervised Learning"
    },
    "description": "This paper addresses the phenomenon in Self-Supervised Learning (SSL) where removing the last few layers of a trained network significantly improves performance on downstream tasks. The study introduces and explores the concept of Guillotine Regularization and investigates how the optimal layer to remove depends on training optimization, training data, and downstream tasks.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper focuses on empirical evaluations and experiments to show the effectiveness of Guillotine Regularization and its impact on SSL models.",
      "quote": "To show through experiments that the optimal layer to cut heavily depend on the training optimization, training data and downstream task for both supervised and self-supervised models."
    },
    "primary_research_field": {
      "name": {
        "value": "Self-Supervised Learning",
        "justification": "The paper is chiefly concerned with understanding the behavior and improving the performance of Self-Supervised Learning models by introducing a new regularization technique.",
        "quote": "Self-supervised learning... rely on the addition of few non linear layers (MLP) – termed projection head – on top of a well established neural network – termed backbone – during training."
      },
      "aliases": [
        "SSL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The experiments conducted in the paper, such as those on ImageNet, focus on vision tasks, thus falling under the domain of Computer Vision.",
          "quote": "This trick of throwing away the projector is actually critical for SSL methods to display competitive performances on ImageNet for which more than 30 percentage points can be gained that way."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet50",
          "justification": "ResNet50 is used as the trunk in experiments to evaluate the efficacy of Guillotine Regularization.",
          "quote": "We measure with linear probes the accuracy at different layers on a Resnet50 (as Trunk)."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "The ResNet50 model is not introduced by this paper; it is used as a baseline for experiments.",
          "quote": "This addition is done regardless of the neural network used as backbone, it could be a ResNet50 (He et al., 2016) or a Vision Transformer (Dosovitskiy et al., 2021)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The ResNet50 model is executed as part of the experiments conducted in the research paper.",
          "quote": "When training a supervised model on the object rotation prediction task and evaluating the linear probe on the same task across different layers, the best results are obtained on the last layer."
        },
        "is_compared": {
          "value": 1,
          "justification": "ResNet50 is compared against other models to evaluate the performance effects of Guillotine Regularization.",
          "quote": "For each method, we show the mean and standard deviation across 3 runs (The std between different runs is low)."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "This is the original paper where ResNet50, the model used in this study, was introduced.",
          "quote": "This addition is done regardless of the neural network used as backbone, it could be a ResNet50 (He et al., 2016) or a Vision Transformer (Dosovitskiy et al., 2021)."
        }
      },
      {
        "name": {
          "value": "Vision Transformer (ViT)",
          "justification": "Vision Transformer (ViT) is also used in experiments to validate the consistency of Guillotine Regularization across different architectures.",
          "quote": "Same experiment as in Figure 9 but this time, we measure with linear probes the accuracy at different layers on a VIT-B (as Trunk)."
        },
        "aliases": [
          "ViT"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The Vision Transformer (ViT) is not a novel contribution of this paper; it is used as part of the experiments.",
          "quote": "This addition is done regardless of the neural network used as backbone, it could be a ResNet50 (He et al., 2016) or a Vision Transformer (Dosovitskiy et al., 2021)."
        },
        "is_executed": {
          "value": 1,
          "justification": "ViT is executed as part of the experimental evaluation in this research.",
          "quote": "In the supervised learning setting, the best performances are obtained when using the last layers of the model. But, when looking at self-supervised methods, the gap in performances between the linear probe trained at different levels can be as high as 20 points of percentage."
        },
        "is_compared": {
          "value": 1,
          "justification": "ViT is compared to ResNet50 and other models to evaluate the impact of Guillotine Regularization.",
          "quote": "Since the outputs of the VIT-B has a lower number of dimensions than a ResNet, we added at the trunk of the VIT-B a linear layer with ReLU activation to project into a 2048 dimensional vector."
        },
        "referenced_paper_title": {
          "value": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
          "justification": "This is the original paper where Vision Transformer (ViT), the model used in this study, was introduced.",
          "quote": "This addition is done regardless of the neural network used as backbone, it could be a ResNet50 (He et al., 2016) or a Vision Transformer (Dosovitskiy et al., 2021)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is used extensively in the experiments to evaluate model performance and the effects of Guillotine Regularization.",
          "quote": "This trick of throwing away the projector is actually critical for SSL methods to display competitive performances on ImageNet for which more than 30 percentage points can be gained that way."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "ImageNet: A Large-Scale Hierarchical Image Database",
          "justification": "The referenced paper is the original publication that introduces the ImageNet dataset.",
          "quote": "In this paper, we examine that question thoroughly. We first place the SSL trick of removing the projector post-training under the umbrella of a generically applicable method that we call Guillotine Regularization."
        }
      },
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is one of the downstream datasets used to test the generalizability of SSL models with Guillotine Regularization.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper is the original publication that introduces the CIFAR-10 dataset.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        }
      },
      {
        "name": {
          "value": "CLEVR",
          "justification": "CLEVR is one of the downstream datasets used in the experiments for evaluating SSL models.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
          "justification": "The referenced paper is the original publication that introduces the CLEVR dataset.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        }
      },
      {
        "name": {
          "value": "Places205",
          "justification": "Places205 is used as one of the downstream tasks in the experiments to test the generalization of models employing Guillotine Regularization.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Learning Deep Features for Scene Recognition using Places Database",
          "justification": "The referenced paper is the original publication that introduces the Places205 dataset.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        }
      },
      {
        "name": {
          "value": "Eurosat",
          "justification": "Eurosat is used as one of the downstream datasets in the experiments evaluating the efficacy of Guillotine Regularization.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification",
          "justification": "The referenced paper is the original publication that introduces the Eurosat dataset.",
          "quote": "Figure 3c in which we train a supervised Resnet50 over ImageNet. Then, we freeze the weights of the model and train a linear probe over ImageNet (Deng et al., 2009), CIFAR10 (Krizhevsky, 2009), Place205 (Zhou et al., 2014), CLEVR (Johnson et al., 2017) and Eurosat (Helber et al., 2019) at different layers."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is mentioned as the deep learning framework used for the experiments in this study.",
          "quote": "We use Pytorch (Paszke et al., 2019) and FFCV-SSL (Bordes et al., 2023; Leclerc et al., 2022) as data loader."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "The referenced paper introduces PyTorch, the deep learning framework used for the experiments in this study.",
          "quote": "We use Pytorch (Paszke et al., 2019) and FFCV-SSL (Bordes et al., 2023; Leclerc et al., 2022) as data loader."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2623,
    "prompt_tokens": 16477,
    "total_tokens": 19100
  }
}