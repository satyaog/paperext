{
  "paper": "2302.08956.txt",
  "words": 8253,
  "extractions": {
    "title": {
      "value": "AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages",
      "justification": "The title is clearly mentioned at the beginning of the paper and on the first page.",
      "quote": "AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages"
    },
    "description": "This paper introduces AfriSenti, a sentiment analysis benchmark dataset consisting of over 110,000 tweets in 14 African languages. The dataset was curated for the AfriSenti-SemEval shared task and aims to fill the gap in NLP research for African languages by providing high-quality annotated data. The paper describes the data collection methodology, the challenges faced during annotation, and baseline experiments conducted using the datasets.",
    "type": {
      "value": "empirical study",
      "justification": "The paper focuses on data collection, annotation, and conducting baseline experiments which involve empirical analysis.",
      "quote": "We describe the data collection methodology, annotation process, and the challenges we dealt with when curating each dataset. We further report baseline experiments conducted on the different datasets and discuss their usefulness."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper is focused on sentiment analysis, which is a sub-field of Natural Language Processing.",
        "quote": "An influential sub-area of NLP deals with sentiment, valence, emotions, and affect in language (Liu, 2020)."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Sentiment Analysis",
          "justification": "The primary focus of the paper is on creating and analyzing a sentiment analysis benchmark for African languages.",
          "quote": "To enable sentiment analysis research in African languages, we present AfriSenti, the largest sentiment analysis benchmark for under-represented African languages"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "XLM-R",
          "justification": "XLM-R is one of the pre-trained language models fine-tuned and evaluated as a baseline in the experiments.",
          "quote": "we selected two representative PLMs: XLM-R-{base & large} (Conneau et al., 2020)"
        },
        "aliases": [
          "XLM-R-base",
          "XLM-R-large"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The model is used as a baseline and was not developed or contributed by the authors of the paper.",
          "quote": "we selected two representative PLMs: XLM-R-{base & large} (Conneau et al., 2020)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was fine-tuned and evaluated in the experiments.",
          "quote": "Monolingual baseline models We fine-tune massively multilingual PLMs trained on 100 languages from around the world as well as Africa-centric PLMs trained exclusively on languages spoken in Africa. "
        },
        "is_compared": {
          "value": 1,
          "justification": "The model's performance is compared to other models such as mDeBERTa, AfriBERTa, and AfroXLMR.",
          "quote": "AfroXLMR-large achieves the best overall performance and improves over XLM-T by 2.5 F1 points, which shows the benefit of scaling for large PLMs."
        },
        "referenced_paper_title": {
          "value": "Unsupervised cross-lingual representation learning at scale",
          "justification": "The paper by Conneau et al. (2020) on XLM-R is referenced in the context of baseline models.",
          "quote": "we selected two representative PLMs: XLM-R-{base & large} (Conneau et al., 2020)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "AfriSenti",
          "justification": "The entire paper revolves around the creation and analysis of the AfriSenti dataset, a sentiment analysis benchmark for African languages.",
          "quote": "To enable sentiment analysis research in African languages, we present AfriSenti, the largest sentiment analysis benchmark for under-represented African languages—covering 110,000+ tweets annotated as positive, negative or neutral, in 14 languages"
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages",
          "justification": "The dataset is introduced and thoroughly discussed in this paper.",
          "quote": "To enable sentiment analysis research in African languages, we present AfriSenti."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "HuggingFace",
          "justification": "The paper mentions using standard configurations for text classification fine-tuning on HuggingFace.",
          "quote": "We used a standard configuration for text classification fine-tuning on HuggingFace with a learning rate of 2e − 5 for smaller PLMs and 1e − 5 for larger PLMs, a batch size of 128, and 10 epochs."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "HuggingFace’s Transformers",
          "justification": "HuggingFace's tools and libraries are utilized for fine-tuning and evaluating models in the paper.",
          "quote": "We used a standard configuration for text classification fine-tuning on HuggingFace"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1028,
    "prompt_tokens": 16900,
    "total_tokens": 17928
  }
}