{
  "paper": "2311.04147.txt",
  "words": 9874,
  "extractions": {
    "title": {
      "value": "Multi-resolution Time-Series Transformer for Long-term Forecasting",
      "justification": "This is the title given at the beginning of the research paper.",
      "quote": "Multi-resolution Time-Series Transformer for Long-term Forecasting"
    },
    "description": "The paper proposes a novel time-series transformer framework, Multi-resolution Time-Series Transformer (MTST), which incorporates multi-scale analysis for long-term forecasting. The framework employs a multi-branch architecture to model temporal patterns at different resolutions and employs relative positional encoding to better capture periodic components. Detailed experiments demonstrate that MTST outperforms state-of-the-art forecasting methods.",
    "type": {
      "value": "Empirical study",
      "justification": "The paper conducts extensive experiments and comparisons to demonstrate the effectiveness of the proposed MTST framework.",
      "quote": "Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques."
    },
    "primary_research_field": {
      "name": {
        "value": "Time-Series Forecasting",
        "justification": "The paper focuses on improving the forecasting of multivariate time-series data using transformer architectures.",
        "quote": "Multi-resolution Time-Series Transformer for Long-term Forecasting"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The paper leverages deep learning models and techniques to improve time-series forecasting.",
          "quote": "Multi-resolution Time-Series Transformer (MTST) which consists of a multi-branch architecture for simultaneous modeling."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Transformer Models",
          "justification": "The paper introduces a novel transformer-based architecture for time-series forecasting.",
          "quote": "Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST), which consists of a multi-branch architecture."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Multi-resolution Time-Series Transformer (MTST)",
          "justification": "MTST is a novel framework proposed in the paper specifically designed for time-series forecasting.",
          "quote": "Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST)."
        },
        "aliases": [
          "MTST"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "MTST is introduced and developed by the authors as a contribution of this research.",
          "quote": "Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The MTST model was implemented and tested in various experiments in the paper.",
          "quote": "Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST."
        },
        "is_compared": {
          "value": 1,
          "justification": "MTST is compared with several state-of-the-art forecasting techniques in the conducted experiments.",
          "quote": "Extensive experiments on several real-world datasets demonstrate the effectiveness of MTST in comparison to state-of-the-art forecasting techniques."
        },
        "referenced_paper_title": {
          "value": "Not applicable",
          "justification": "MTST is a novel contribution by the authors and is not based on a previous paper.",
          "quote": "Inspired by this observation, we propose a novel framework, Multi-resolution Time-Series Transformer (MTST)."
        }
      },
      {
        "name": {
          "value": "DLinear",
          "justification": "DLinear is used as a baseline model for comparison in the experiments.",
          "quote": "A simple linear model outperforms most timestamp-level TSTs."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "DLinear is used for comparison and not introduced as a novel model in this paper.",
          "quote": "A simple linear model outperforms most timestamp-level TSTs."
        },
        "is_executed": {
          "value": 1,
          "justification": "DLinear was implemented and tested as part of the comparative experiments.",
          "quote": "A simple linear model outperforms most timestamp-level TSTs."
        },
        "is_compared": {
          "value": 1,
          "justification": "DLinear is compared with MTST and other models in the experiments.",
          "quote": "A simple linear model outperforms most timestamp-level TSTs."
        },
        "referenced_paper_title": {
          "value": "Are Transformers Effective for Time Series Forecasting?",
          "justification": "The DLinear model is taken from this reference paper by Zeng et al.",
          "quote": "A simple linear model outperforms most timestamp-level TSTs (Zeng et al., 2023)."
        }
      },
      {
        "name": {
          "value": "PatchTST",
          "justification": "PatchTST is another transformer-based model used for comparison in the experiments.",
          "quote": "Another related approach is CrossFormer (Zhang and Yan, 2023), which aims to capture both cross-time and cross-variate dependencies using attention."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "PatchTST is used for comparison and not introduced as a novel model in this paper.",
          "quote": "Another related approach is CrossFormer (Zhang and Yan, 2023), which aims to capture both cross-time and cross-variate dependencies using attention."
        },
        "is_executed": {
          "value": 1,
          "justification": "PatchTST was implemented and tested as part of the comparative experiments.",
          "quote": "Another related approach is CrossFormer (Zhang and Yan, 2023), which aims to capture both cross-time and cross-variate dependencies using attention."
        },
        "is_compared": {
          "value": 1,
          "justification": "PatchTST is compared with MTST and other models in the experiments.",
          "quote": "Another related approach is CrossFormer (Zhang and Yan, 2023), which aims to capture both cross-time and cross-variate dependencies using attention."
        },
        "referenced_paper_title": {
          "value": "A Time Series is Worth 64 Words: Long-term Forecasting with Transformers",
          "justification": "PatchTST is taken from this reference paper by Nie et al.",
          "quote": "We evaluate our proposed model in comparison with the state-of-the-art (SOTA) time-series transformer â€“ PatchTST (Nie et al., 2023)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Electricity",
          "justification": "The Electricity dataset is used for performance evaluation in the experiments.",
          "quote": "As shown in an example from the Electricity dataset (Figure 1), the role of the branch with larger-size patches."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "ElectricityLoadDiagrams20112014",
          "justification": "The Electricity dataset is derived from this reference.",
          "quote": "Electricity contains hourly time-series of the electricity consumption of 321 customers from 2012 to 2014 (Trindade, 2015)."
        }
      },
      {
        "name": {
          "value": "Traffic",
          "justification": "The Traffic dataset is used for performance evaluation in the experiments.",
          "quote": "Traffic is a dataset provided by Caltrans Performance Measurement System (PeMS)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "The paper does not reference a specific paper for the Traffic dataset.",
          "quote": "Traffic is a dataset provided by Caltrans Performance Measurement System (PeMS), collecting hourly data of the road occupancy rates measured by different sensors on San Francisco Bay area freeways from California Department of Transportation."
        }
      },
      {
        "name": {
          "value": "Weather",
          "justification": "The Weather dataset is used for performance evaluation in the experiments.",
          "quote": "Weather is a collection of 2020 weather data from 21 meteorological indicators, including air temperature and humidity, provided by the Max-Planck Institute for Biogeochemistry."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "The paper does not reference a specific paper for the Weather dataset.",
          "quote": "Weather is a collection of 2020 weather data from 21 meteorological indicators, including air temperature and humidity, provided by the Max-Planck Institute for Biogeochemistry."
        }
      },
      {
        "name": {
          "value": "ETTh1",
          "justification": "ETTh1 is one of four ETT datasets used for performance evaluation in the experiments.",
          "quote": "We evaluate the performance of our proposed MTST on seven widely-used public benchmark datasets, including Weather, Traffic, Electricity and four ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
          "justification": "ETT datasets are provided by Zhou et al. in this reference paper.",
          "quote": "ETT datasets are composed of a series of sensor measurements, including load and oil temperature, collected from electricity transformers between 2016 and 2018, provided by Zhou et al. (2021)."
        }
      },
      {
        "name": {
          "value": "ETTh2",
          "justification": "ETTh2 is one of four ETT datasets used for performance evaluation in the experiments.",
          "quote": "We evaluate the performance of our proposed MTST on seven widely-used public benchmark datasets, including Weather, Traffic, Electricity and four ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
          "justification": "ETT datasets are provided by Zhou et al. in this reference paper.",
          "quote": "ETT datasets are composed of a series of sensor measurements, including load and oil temperature, collected from electricity transformers between 2016 and 2018, provided by Zhou et al. (2021)."
        }
      },
      {
        "name": {
          "value": "ETTm1",
          "justification": "ETTm1 is one of four ETT datasets used for performance evaluation in the experiments.",
          "quote": "We evaluate the performance of our proposed MTST on seven widely-used public benchmark datasets, including Weather, Traffic, Electricity and four ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
          "justification": "ETT datasets are provided by Zhou et al. in this reference paper.",
          "quote": "ETT datasets are composed of a series of sensor measurements, including load and oil temperature, collected from electricity transformers between 2016 and 2018, provided by Zhou et al. (2021)."
        }
      },
      {
        "name": {
          "value": "ETTm2",
          "justification": "ETTm2 is one of four ETT datasets used for performance evaluation in the experiments.",
          "quote": "We evaluate the performance of our proposed MTST on seven widely-used public benchmark datasets, including Weather, Traffic, Electricity and four ETT datasets (ETTh1, ETTh2, ETTm1, ETTm2)."
        },
        "aliases": [],
        "role": "Used",
        "referenced_paper_title": {
          "value": "Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting",
          "justification": "ETT datasets are provided by Zhou et al. in this reference paper.",
          "quote": "ETT datasets are composed of a series of sensor measurements, including load and oil temperature, collected from electricity transformers between 2016 and 2018, provided by Zhou et al. (2021)."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2795,
    "prompt_tokens": 22167,
    "total_tokens": 24962
  }
}