{
  "paper": "2311.00801.txt",
  "words": 26263,
  "extractions": {
    "title": {
      "value": "GIST: Generated Inputs Sets Transferability in Deep Learning",
      "justification": "The title 'GIST: Generated Inputs Sets Transferability in Deep Learning' is explicitly stated at the beginning of the paper.",
      "quote": "GIST: Generated Inputs Sets Transferability in Deep Learning"
    },
    "description": "This paper introduces GIST, a novel approach aimed at the efficient transfer of test sets for Deep Neural Networks (DNNs). GIST enables the selection of appropriate test sets from existing ones to match desired properties such as neuron coverage or fault types without the need to regenerate them from scratch, saving computational resources and time. The paper empirically validates the feasibility of GIST using various DNN models, different properties, and datasets.",
    "type": {
      "value": "Empirical",
      "justification": "The paper conducts empirical validations to demonstrate GIST's feasibility and effectiveness, using different DNN models, properties, and datasets.",
      "quote": "To demonstrate GIST feasibility, we empirically investigate the potential for transferability of test sets using as the properties to transfer a fault type coverage property inspired by recent works of Aghababaeyan et al. [3] and a neuron coverage property based on k-Multi Section Neuron Coverage [39]."
    },
    "primary_research_field": {
      "name": {
        "value": "Software Testing and Debugging in Deep Learning",
        "justification": "The primary focus of the paper is on improving the testing process of Deep Neural Networks through the transfer of test sets, aligning it with the field of software testing and debugging in deep learning.",
        "quote": "CCS Concepts: • Computing methodologies → Machine learning; • Software and its engineering → Software testing and debugging; Empirical software validation."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Test Input Generation",
          "justification": "The paper specifically addresses methods related to generating and selecting test inputs for DNNs.",
          "quote": "To foster the verifiability and testability of Deep Neural Networks (DNN), an increasing number of methods for test case generation techniques are being developed."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Transfer Learning",
          "justification": "The paper explores the concept of transferability of test cases from one DNN to another, a concept rooted in transfer learning.",
          "quote": "Given a property selected by a user (e.g., neurons covered, faults), GIST enables the selection of good test sets from the point of view of this property among available test sets."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Deep Neural Network (DNN) Testing",
          "justification": "The focus of the research is on improving the testing process of DNNs.</quote>",
          "quote": "As such, as with any software code, DNN programs should be adequately tested to ensure that they behave properly."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "CIFAR10",
          "justification": "The paper uses CIFAR10 as one of the datasets for evaluating GIST.",
          "quote": "We evaluate GIST on two datasets: CIFAR10 [32] for image and Movie Review [50] for text."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper for CIFAR10 is titled 'Learning multiple layers of features from tiny images' by Krizhevsky, A., & Hinton, G.",
          "quote": "Alex Krizhevsky, Geoffrey Hinton, et al. 2009. Learning multiple layers of features from tiny images."
        }
      },
      {
        "name": {
          "value": "Movie Reviews",
          "justification": "The paper uses the Movie Reviews dataset as one of the datasets for evaluating GIST.",
          "quote": "We evaluate GIST on two datasets: CIFAR10 [32] for image and Movie Review [50] for text."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
          "justification": "The referenced paper for the Movie Reviews dataset is titled 'Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales' by Pang, B., & Lee, L.",
          "quote": "Bo Pang and Lillian Lee. 2005. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the ACL."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "MMGeneration",
          "justification": "The paper mentions using the MMGeneration library for implementing the BigGAN architecture.",
          "quote": "As the technique makes use of a BigGAN architecture for the test input generation process, we use the MMGeneration library [12] implementation and checkpoints of the CIFAR10 BigGAN."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "MMGeneration: OpenMMLab Generative Model Toolbox and Benchmark",
          "justification": "The referenced library for MMGeneration is titled 'MMGeneration: OpenMMLab Generative Model Toolbox and Benchmark'.",
          "quote": "MMGeneration Contributors. 2021. MMGeneration: OpenMMLab Generative Model Toolbox and Benchmark."
        }
      },
      {
        "name": {
          "value": "TextAttack",
          "justification": "The paper uses the TextAttack library for generating test inputs for text data.",
          "quote": "Similarly, for the text dataset, we used the state-of-the-art method provided by the TextAttack library [46]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP",
          "justification": "The referenced library for TextAttack is titled 'TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP'.",
          "quote": "John Morris, Eli Lifland, Jin Yong Yoo, Jake Grigsby, Di Jin, and Yanjun Qi. 2020. TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. 119–126."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1493,
    "prompt_tokens": 50799,
    "total_tokens": 52292
  }
}