{
  "paper": "2301.11517.txt",
  "words": 8941,
  "extractions": {
    "title": {
      "value": "Task-Agnostic Graph Neural Network Evaluation via Adversarial Collaboration",
      "justification": "The title is clearly stated on the first page of the research paper.",
      "quote": "TASK -AGNOSTIC G RAPH N EURAL N ETWORK E VALUATION VIA A DVERSARIAL C OLLABORATION"
    },
    "description": "This paper introduces Graph Adversarial Collaboration (GraphAC), a new, principled, and task-agnostic framework for evaluating Graph Neural Networks (GNNs) through contrastive self-supervision. The framework does not require handcrafted augmentations and is designed to stably and reliably evaluate the expressiveness of different GNNs without relying on specific downstream tasks.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes experiments and results that demonstrate the effectiveness of the proposed GraphAC framework. It evaluates different GNNs' expressiveness through empirical data.",
      "quote": "Our solution: Graph Adversarial Collaboration (GraphAC). We address both aforementioned questions by proposing a conceptually novel, principled, and task-agnostic framework for evaluating GNNs in the context of molecular data, via a self-supervised, adversarial collaboration manner, without the need of handcrafted augmentations. In the GraphAC framework, two GNNs directly compete against each other on the same unlabeled graphs. The more expressive GNN produces more complex and informative graph embeddings and is thereby able to win the game."
    },
    "primary_research_field": {
      "name": {
        "value": "Graph Neural Networks",
        "justification": "The primary research field is Graph Neural Networks, as the paper is focused on evaluating different GNN architectures.",
        "quote": "Graph Neural Networks (GNNs) have gained immense research attention in recent years, leading to significant progress that has been successfully implemented across a broad range of fields, including chemistry (Gilmer et al., 2017) and biology (Stokes et al., 2020). This makes GNNs important tools in the molecular representation learning landscape, and improving their development is of great interest to the biomedical machine learning community."
      },
      "aliases": [
        "GNNs"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Contrastive Learning",
          "justification": "The paper integrates principles from contrastive self-supervised learning to propose a new evaluation framework for GNNs.",
          "quote": "Contrastive Self-Supervised Learning To the best of our knowledge, there has not been any published attempt to develop a method for evaluating deep learning models by directly competing two models in a contrastive self-supervised environment, no matter in the general machine learning or the graph representation learning communities."
        },
        "aliases": [
          "Contrastive Self-Supervised Learning"
        ]
      },
      {
        "name": {
          "value": "Molecular Representations",
          "justification": "The methodology applied in the paper often uses molecular data to evaluate GNNs, making it relevant to the molecular representation learning domain.",
          "quote": "Graph Neural Networks (GNNs) have gained immense research attention in recent years, leading to significant progress that has been successfully implemented across a broad range of fields, including chemistry (Gilmer et al., 2017) and biology (Stokes et al., 2020). This makes GNNs important tools in the molecular representation learning landscape, and improving their development is of great interest to the biomedical machine learning community."
        },
        "aliases": [
          "Molecular Representation Learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Graph Adversarial Collaboration (GraphAC)",
          "justification": "GraphAC is the primary model proposed and developed in this paper.",
          "quote": "Our solution: Graph Adversarial Collaboration (GraphAC). We address both aforementioned questions by proposing a conceptually novel, principled, and task-agnostic framework for evaluating GNNs in the context of molecular data, via a self-supervised, adversarial collaboration manner, without the need of handcrafted augmentations."
        },
        "aliases": [
          "GraphAC"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The paper's main contribution is the GraphAC framework.",
          "quote": "We address both aforementioned questions by proposing a conceptually novel, principled, and task-agnostic framework for evaluating GNNs in the context of molecular data, via a self-supervised, adversarial collaboration manner, without the need of handcrafted augmentations."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes empirical experiments utilizing the GraphAC framework.",
          "quote": "Training and experiments were conducted on an NVIDIA A100 SXM GPU with 80GB graphics memory. All experiments were trained for 50 epochs."
        },
        "is_compared": {
          "value": 1,
          "justification": "GraphAC is compared against existing GNNs to demonstrate its effectiveness.",
          "quote": "These results demonstrate that GraphAC can successfully distinguish GNNs of different expressiveness across various aspects, and consistently favors the more expressive GNNs: 1) deeper GNNs; 2) GNNs with larger hidden dimensions; 3) combining multiple aggregators > sum > mean > max as aggregators (Xu et al., 2019; Corso et al., 2020); 4) PNA > GIN > GCN (Xu et al., 2019; Corso et al., 2020); and 5) GNNs that include edge features."
        },
        "referenced_paper_title": {
          "value": "Barlow Twins: Self-Supervised Learning via Redundancy Reduction",
          "justification": "The GraphAC framework is inspired by the Barlow Twins self-supervised learning method.",
          "quote": "Inspired by the novel principle, we propose a new architecture and an original modification to the existing Barlow Twins loss (Zbontar et al., 2021) that enables the GNNs to stably compete against each other, while ensuring that more expressive GNNs can always win."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ogbg-molpcba",
          "justification": "The ogbg-molpcba dataset is used to evaluate the effectiveness of the proposed GraphAC framework.",
          "quote": "Therefore, we use the largest molecular property prediction dataset from OGB (Hu et al., 2020), namely the ogbg-molpcba dataset."
        },
        "aliases": [
          "ogbg-molpcba"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Open Graph Benchmark: Datasets for machine learning on graphs",
          "justification": "The paper references the ogbg-molpcba dataset from the Open Graph Benchmark.",
          "quote": "Therefore, we use the largest molecular property prediction dataset from OGB (Hu et al., 2020), namely the ogbg-molpcba dataset."
        }
      },
      {
        "name": {
          "value": "ogbg-code2",
          "justification": "The ogbg-code2 dataset is used as an additional dataset to confirm GraphAC's task-agnostic nature.",
          "quote": "In order to confirm that GraphAC is indeed task-agnostic, we also evaluate GraphAC on the ogbg-code2 dataset, which contains 452,741 abstract syntax trees obtained from Python method definitions, with on average 125.2 nodes and 124.2 edges per tree."
        },
        "aliases": [
          "ogbg-code2"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Open Graph Benchmark: Datasets for machine learning on graphs",
          "justification": "The paper references the ogbg-code2 dataset as part of the Open Graph Benchmark.",
          "quote": "In order to confirm that GraphAC is indeed task-agnostic, we also evaluate GraphAC on the ogbg-code2 dataset, which contains 452,741 abstract syntax trees obtained from Python method definitions, with on average 125.2 nodes and 124.2 edges per tree."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The authors used PyTorch to implement the experiments and models.",
          "quote": "Algorithm 1 PyTorch-style pseudocode for GraphACâ€™s framework"
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A Method for Stochastic Optimization",
          "justification": "The PyTorch library is commonly used for implementing state-of-the-art deep learning models, such as those described using the Adam optimizer in the referenced paper.",
          "quote": "Adam: A Method for Stochastic Optimization"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1662,
    "prompt_tokens": 17113,
    "total_tokens": 18775
  }
}