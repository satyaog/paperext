{
  "paper": "2403.14421.txt",
  "words": 10313,
  "extractions": {
    "title": {
      "value": "DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning",
      "justification": "The title is explicitly mentioned at the beginning of the paper.",
      "quote": "DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning"
    },
    "description": "This paper introduces DP-RDM, a differentially private retrieval-augmented diffusion model for generating high-quality image samples with rigorous privacy guarantees. The proposed algorithm generates images from text prompts without fine-tuning the model on private datasets, thereby addressing sample-level memorization issues in text-to-image diffusion models. The method is validated on datasets like MS-COCO, Shutterstock, and CIFAR-10, showing significant improvements.",
    "type": {
      "value": "empirical study",
      "justification": "The paper includes experiments and evaluations on several datasets to demonstrate the efficacy of the proposed DP-RDM model.",
      "quote": "we evaluate its text-to-image generation performance on several large-scale image datasets."
    },
    "primary_research_field": {
      "name": {
        "value": "deep learning",
        "justification": "The research involves developing a new model for text-to-image generation, a common area within deep learning.",
        "quote": "Text-to-image diffusion models have been shown to suffer from sample-level memorization..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "generative models",
          "justification": "The focus of the research is on developing a new generative model: DP-RDM for text-to-image generation.",
          "quote": "To remedy this issue, we develop the first differentially private (DP) retrieval-augmented generation algorithm..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DP-RDM",
          "justification": "DP-RDM is the primary model introduced and discussed throughout the paper.",
          "quote": "we develop the first differentially private (DP) retrieval-augmented generation algorithm..."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MS-COCO",
          "justification": "MS-COCO is used for evaluating the model.",
          "quote": "we evaluate our DP-RDM on three datasets—CIFAR-10, MS-COCO and Shutterstock"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is used for evaluating the model.",
          "quote": "we evaluate our DP-RDM on three datasets—CIFAR-10, MS-COCO and Shutterstock"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Shutterstock",
          "justification": "Shutterstock is used for evaluating the model.",
          "quote": "we evaluate our DP-RDM on three datasets—CIFAR-10, MS-COCO and Shutterstock"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 634,
    "prompt_tokens": 18354,
    "total_tokens": 18988
  }
}