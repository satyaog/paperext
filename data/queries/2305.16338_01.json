{
  "paper": "2305.16338.txt",
  "words": 9242,
  "extractions": {
    "title": {
      "value": "Think Before You Act: Decision Transformers with Internal Working Memory",
      "justification": "This is the exact title of the paper referenced.",
      "quote": "Think Before You Act: Decision Transformers with Internal Working Memory"
    },
    "description": "This paper addresses inefficiencies in LLM-based decision-making agents related to the forgetting phenomenon, where models forget previous tasks when learning new ones. The authors propose using an internal working memory module to store, blend, and retrieve information for different downstream tasks, improving training efficiency and generalization. They introduce Decision Transformers with Memory (DT-Mem) and evaluate it on Atari games and Meta-World environments, showing improved performance over existing methods.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents experimental results and evaluations of the proposed DT-Mem model on Atari games and Meta-World environments.",
      "quote": "Evaluation results show that the proposed method improves training efficiency and generalization in both Atari games and meta-world object manipulation tasks."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research focuses on improving model architecture and training techniques for decision-making tasks, which falls under Deep Learning.",
        "quote": "With the tremendous success of large language model-based (LLM-based) foundation models..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The paper addresses the reinforcement learning problem and proposes a new model architecture to improve performance on RL tasks.",
          "quote": "Recently, with the tremendous success of large language model-based (LLM-based) foundation models, an increasing number of researchers have focused on LLM-based decision-making agents."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DT-Mem",
          "justification": "DT-Mem (Decision Transformers with Memory) is the primary model proposed and evaluated in the paper.",
          "quote": "Thus motivated, we propose Decision Transformers with Memory (DT-Mem)."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_inference_only": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "GPT-3",
          "justification": "GPT-3 is used as a reference to highlight the generalization capabilities of large language models.",
          "quote": "As shown with GPT-3 [5] and follow-up work [21, 7], the generalization of these LLMs depends significantly on the model size, i.e. the number of parameters."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_inference_only": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Multi-game Decision Transformer",
          "justification": "MDT is used as a reference model for comparison with the proposed DT-Mem model.",
          "quote": "We fine-tune only the working memory in this work because we rely on the generalization capacity of a pre-trained Decision Transformer (DT). Transformers are often pre-trained on large-scale datasets, as in the case of models like Multi-game DT [22] and Hyper-DT [38]."
        },
        "aliases": [
          "MDT"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_inference_only": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Hyper-Decision Transformer",
          "justification": "HDT is used as a reference model for comparison with the proposed DT-Mem model.",
          "quote": "Transformers are often pre-trained on large-scale datasets, as in the case of models like Multi-game DT [22] and Hyper-DT [38], and this pre-training enables them to capture broad knowledge that is transferable across tasks."
        },
        "aliases": [
          "HDT"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_inference_only": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "DQN Replay Dataset",
          "justification": "The dataset is mentioned in the evaluation section and used for training Decision Transformer models, including DT-Mem.",
          "quote": "we used the same Atari dataset1 , which comprises multiple training runs of DQN trajectories."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "GPT-2",
          "justification": "GPT-2 architecture is referenced in the design of the model's Transformer module.",
          "quote": "The Transformer module follows the architecture of GPT-2 [28], but without the feed-forward layer after attention blocks."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1099,
    "prompt_tokens": 15087,
    "total_tokens": 16186
  }
}