{
  "paper": "2401.04890.txt",
  "words": 43983,
  "extractions": {
    "description": "This work introduces a principle called mechanism sparsity regularization to achieve partial disentanglement of latent factors by learning the sparse causal graphical model that explains them. The authors develop a nonparametric identifiability theory and propose an estimation procedure involving variational autoencoders and a sparsity constraint. The theory and method are tested using various synthetic datasets.",
    "title": {
      "value": "Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal Dependencies",
      "justification": "The title is mentioned at the beginning of the paper and clearly encapsulates the main focus of the research.",
      "quote": "Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal Dependencies SeÃÅbastien Lachapelle"
    },
    "type": {
      "value": "theoretical",
      "justification": "The paper primarily introduces and develops theoretical principles and identifiability results for disentangling latent factors.",
      "quote": "We develop a nonparametric identifiability theory that formalizes this principle and shows that the latent factors can be recovered by regularizing the learned causal graph to be sparse."
    },
    "research_field": {
      "value": "Deep Learning",
      "justification": "The work focuses on disentanglement, representation learning, and the application of neural networks, which are core areas in Deep Learning.",
      "quote": "The goal is then to recover the latent factors zi up to permutation and rescaling as well as the causal relationships explaining them. This is closely related to the problem of disentanglement."
    },
    "sub_research_field": {
      "value": "Representation Learning",
      "justification": "The research specifically targets the disentanglement of latent factors, a key topic within the subfield of Representation Learning.",
      "quote": "This is closely related to the problem of disentanglement which also aims at extracting interpretable variables from high-dimensional observations."
    },
    "models": [
      {
        "name": {
          "value": "Variational Autoencoder (VAE)",
          "justification": "VAEs are commonly used for learning latent variable models, and the paper mentions their use explicitly for estimation.",
          "quote": "Lastly, we propose an estimation procedure based on variational autoencoders and a sparsity constraint and demonstrate it on various synthetic datasets."
        },
        "role": "used",
        "type": {
          "value": "latent variable model",
          "justification": "VAEs are known for modeling latent variables in high-dimensional data.",
          "quote": "Lastly, we propose an estimation procedure based on variational autoencoders and a sparsity constraint."
        },
        "mode": "trained"
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Synthetic datasets",
          "justification": "The paper mentions using various synthetic datasets to demonstrate their method.",
          "quote": "Lastly, we propose an estimation procedure based on variational autoencoders and a sparsity constraint and demonstrate it on various synthetic datasets."
        },
        "role": "used"
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 677,
    "prompt_tokens": 72326,
    "total_tokens": 73003
  }
}