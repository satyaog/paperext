{
  "paper": "2305.19452.txt",
  "words": 9099,
  "extractions": {
    "title": {
      "value": "Bigger, Better, Faster: Human-level Atari with human-level efficiency",
      "justification": "This is the title of the paper.",
      "quote": ""
    },
    "description": "This research paper introduces BBF, a value-based Deep Reinforcement Learning agent that achieves super-human performance in the Atari 100K benchmark. The agent leverages network scaling and other design choices to achieve sample-efficient learning, surpassing previous model-free agents and competing with model-based approaches like EfficientZero in terms of sample efficiency.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents the BBF agent and provides empirical results from experiments conducted on the Atari 100k benchmark.",
      "quote": "We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep reinforcement learning",
        "justification": "The paper focuses on deep reinforcement learning and its application to the Atari 100K benchmark.",
        "quote": "Deep reinforcement learning (RL) has been central to a number of successes including playing complex games at a human or super-human level, such as OpenAI Five (Berner et al., 2019), AlphaGo (Silver et al., 2016), and AlphaStar (Vinyals et al., 2019), controlling nuclear fusion plasma in a tokomak (Degrave et al., 2022), and integrating human feedback for conversational agents (Ouyang et al., 2022)."
      },
      "aliases": [
        "Deep reinforcement learning",
        "RL"
      ]
    },
    "sub_research_fields": [],
    "models": [
      {
        "name": {
          "value": "BBF",
          "justification": "The paper refers to the agent as \\\"BBF.\\\"",
          "quote": "We introduce a value-based RL agent, which we call BBF, that achieves super-human performance in the Atari 100K benchmark."
        },
        "aliases": [
          "BBF",
          "Bigger, Better, Faster"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The authors introduce BBF as a novel agent.",
          "quote": "To this end, we introduce BBF, a model-free RL agent that achieves super-human performance – interquartile mean (Agarwal et al., 2021b) human-normalized score above 1.0 – while being much more computationally efficient than EfficientZero (Figure 2)."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper includes results from running experiments with BBF.",
          "quote": "Figure 2 demonstrates the strong performance of BBF relative to some of the best-performing Atari 100K agents: EfficientZero (Ye et al., 2021), SR-SPR (D’Oro et al., 2023), and IRIS (Micheli et al., 2023)."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares BBF with several other agents, including EfficientZero, SR-SPR, and IRIS.",
          "quote": "Figure 2 demonstrates the strong performance of BBF relative to some of the best-performing Atari 100K agents: EfficientZero (Ye et al., 2021), SR-SPR (D’Oro et al., 2023), and IRIS (Micheli et al., 2023)."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper itself introduces BBF, so there is no referenced paper.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 19543
  }
}