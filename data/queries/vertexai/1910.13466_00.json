{
  "paper": "1910.13466.txt",
  "words": 6906,
  "extractions": {
    "title": {
      "value": "Ordered Memory",
      "justification": "The title of the paper is \"Ordered Memory\".",
      "quote": "Ordered Memory"
    },
    "description": "The paper introduces Ordered Memory (OM), a novel neural network architecture for natural language processing tasks that require compositional understanding. OM maintains a stack-like memory structure, similar to a shift-reduce parser, to recursively compose representations of sub-trees from input sequences. The model is evaluated on logical inference (Bowman et al., 2015) and ListOps (Nangia and Bowman, 2018) tasks, demonstrating strong performance and the ability to induce latent tree structures. Additionally, the model achieves competitive results on the Stanford Sentiment Treebank (SST). Notably, the paper introduces a new Gated Recursive Cell inspired by the Transformer architecture, contributing to the model\\'s effectiveness in capturing compositional relationships.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents a new model and conducts empirical evaluations, making it an empirical research paper.",
      "quote": "We demonstrate that our method generalizes for synthetic tasks where the ability to parse is crucial to solving them."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper primarily focuses on natural language processing (NLP) tasks.",
        "quote": "A long-sought after goal in natural language processing is to build models that account for the compositional nature of language"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Compositional Understanding",
          "justification": "The core focus is on developing models that can understand and represent the compositional structure of language.",
          "quote": "A long-sought after goal in natural language processing is to build models that account for the compositional nature of language â€” granting them an ability to understand complex, unseen expressions from the meaning of simpler, known expressions (Montague, 1970; Dowty, 2007)."
        },
        "aliases": [
          "Compositional Understanding",
          "Grammar Induction",
          "Latent Tree Learning",
          "Sentence Representation"
        ]
      },
      {
        "name": {
          "value": "Logical Inference",
          "justification": "The paper specifically addresses the challenge of logical inference and systematic generalization in language models.",
          "quote": "We demonstrate that our method generalizes for synthetic tasks where the ability to parse is crucial to solving them. In the Logical inference dataset (Bowman et al., 2015), we show that our model can systematically generalize to unseen combination of operators."
        },
        "aliases": [
          "Logical Inference",
          "Systematic Generalization"
        ]
      },
      {
        "name": {
          "value": "Sentiment Analysis",
          "justification": "The Stanford Sentiment Treebank (SST) is used as one of the benchmark datasets, indicating a focus on sentiment analysis.",
          "quote": "We also perform experiments on the Stanford Sentiment Treebank, in both binary classification and fine-grained settings (SST-2 & SST-5), and find that we achieve comparative results to the current benchmarks."
        },
        "aliases": [
          "Sentiment Analysis"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Ordered Memory",
          "justification": "The paper refers to the proposed model as \"Ordered Memory\" or \"OM\".",
          "quote": "In this paper, we propose the Ordered Memory architecture."
        },
        "aliases": [
          "Ordered Memory",
          "OM"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The paper introduces Ordered Memory as a novel contribution.",
          "quote": "In this paper, we propose a novel architecture: Ordered Memory (OM), which includes a new memory updating mechanism and a new Gated Recursive Cell."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper provides experimental results of OM on various tasks.",
          "quote": "We demonstrate that our method generalizes for synthetic tasks where the ability to parse is crucial to solving them."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares OM with various baseline models including LSTM, RRNet, ON-LSTM, Transformer, Universal Transformer, TreeLSTM, and TreeRNN.",
          "quote": "We compare our model with LSTM, RRNet (Jacob et al., 2018), ON-LSTM (Shen et al., 2018), Tranformer (Vaswani et al., 2017), Universal Transformer (Dehghani et al., 2018), TreeLSTM (Tai et al., 2015), TreeRNN (Bowman et al., 2015), and TreeCell."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No referenced paper is explicitly mentioned for Ordered Memory.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "LSTM",
          "justification": "The paper refers to the model as \"LSTM\".",
          "quote": "We compare our model with LSTM [...]"
        },
        "aliases": [
          "LSTM"
        ],
        "is_contributed": {
          "value": false,
          "justification": "LSTM is not a contribution of this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper uses an existing implementation of LSTM.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "LSTM is used as one of the baselines for comparison.",
          "quote": "We compare our model with LSTM [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No specific paper is referenced for LSTM in this context.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "RRNet",
          "justification": "The model is referred to as \"RRNet\".",
          "quote": "We compare our model with [...] RRNet (Jacob et al., 2018) [...]"
        },
        "aliases": [
          "RRNet"
        ],
        "is_contributed": {
          "value": false,
          "justification": "RRNet is not a contribution of this work.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The authors used existing implementations or results.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "RRNet is included in the performance comparison.",
          "quote": "We compare our model with [...] RRNet (Jacob et al., 2018) [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper cites \"Jacob et al., 2018\" when mentioning RRNet.",
          "quote": "We compare our model with [...] RRNet (Jacob et al., 2018) [...]"
        }
      },
      {
        "name": {
          "value": "ON-LSTM",
          "justification": "The model is named \"ON-LSTM\".",
          "quote": "We compare our model with [...] ON-LSTM (Shen et al., 2018) [...]"
        },
        "aliases": [
          "ON-LSTM"
        ],
        "is_contributed": {
          "value": false,
          "justification": "ON-LSTM is not introduced in this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper appears to use an existing implementation of ON-LSTM.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares its model against ON-LSTM.",
          "quote": "We compare our model with [...] ON-LSTM (Shen et al., 2018) [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The reference \"Shen et al., 2018\" is provided for ON-LSTM.",
          "quote": "We compare our model with [...] ON-LSTM (Shen et al., 2018) [...]"
        }
      },
      {
        "name": {
          "value": "Transformer",
          "justification": "The model is referred to as \"Transformer\".",
          "quote": "We compare our model with [...] Transformer (Vaswani et al., 2017) [...]"
        },
        "aliases": [
          "Transformer"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The Transformer model is not a contribution of this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": true,
          "justification": "The paper uses an existing Transformer implementation.",
          "quote": "The Transformer models were implemented by modifying the code from the Annotated Transformer."
        },
        "is_compared": {
          "value": true,
          "justification": "Transformer is one of the models compared against.",
          "quote": "We compare our model with [...] Transformer (Vaswani et al., 2017) [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The citation \"Vaswani et al., 2017\" is given for Transformer.",
          "quote": "We compare our model with [...] Transformer (Vaswani et al., 2017) [...]"
        }
      },
      {
        "name": {
          "value": "Universal Transformer",
          "justification": "The model is named \"Universal Transformer\".",
          "quote": "We compare our model with [...] Universal Transformer (Dehghani et al., 2018) [...]"
        },
        "aliases": [
          "Universal Transformer"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Universal Transformer is not introduced in this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper seems to utilize an existing implementation.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "The authors compare their model with Universal Transformer.",
          "quote": "We compare our model with [...] Universal Transformer (Dehghani et al., 2018) [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper cites \"Dehghani et al., 2018\" for Universal Transformer.",
          "quote": "We compare our model with [...] Universal Transformer (Dehghani et al., 2018) [...]"
        }
      },
      {
        "name": {
          "value": "TreeLSTM",
          "justification": "The paper refers to the model as \"TreeLSTM\".",
          "quote": "We compare our model with [...] TreeLSTM (Tai et al., 2015) [...]"
        },
        "aliases": [
          "TreeLSTM"
        ],
        "is_contributed": {
          "value": false,
          "justification": "This paper does not introduce TreeLSTM.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The authors used an existing implementation of TreeLSTM.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "TreeLSTM is included in the comparison of models.",
          "quote": "We compare our model with [...] TreeLSTM (Tai et al., 2015) [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The citation \"Tai et al., 2015\" is provided for TreeLSTM.",
          "quote": "We compare our model with [...] TreeLSTM (Tai et al., 2015) [...]"
        }
      },
      {
        "name": {
          "value": "TreeRNN",
          "justification": "The name of the model is \"TreeRNN\".",
          "quote": "We compare our model with [...] TreeRNN (Bowman et al., 2015) [...]"
        },
        "aliases": [
          "TreeRNN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "TreeRNN is not introduced by the authors in this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper appears to use an existing implementation.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "TreeRNN is one of the models compared in the paper.",
          "quote": "We compare our model with [...] TreeRNN (Bowman et al., 2015) [...]"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The citation \"Bowman et al., 2015\" is associated with TreeRNN.",
          "quote": "We compare our model with [...] TreeRNN (Bowman et al., 2015) [...]"
        }
      },
      {
        "name": {
          "value": "TreeCell",
          "justification": "The paper refers to this simplified model as \"TreeCell\" in the experiments.",
          "quote": "The TreeCell experiment was performed as a control to isolate the performance of using the cell(Â·) composition function versus using both using cell(Â·) and learning the composition with OM."
        },
        "aliases": [
          "TreeCell",
          "cell(Â·)"
        ],
        "is_contributed": {
          "value": true,
          "justification": "While the paper introduces a new Gated Recursive Cell, it also presents a simplified version, referred to as \"TreeCell\" in the experiments, for comparison purposes.",
          "quote": "The TreeCell experiment was performed as a control to isolate the performance of using the cell(Â·) composition function versus using both using cell(Â·) and learning the composition with OM."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper presents experimental results for TreeCell.",
          "quote": "The TreeCell experiment was performed as a control to isolate the performance of using the cell(Â·) composition function versus using both using cell(Â·) and learning the composition with OM."
        },
        "is_compared": {
          "value": true,
          "justification": "TreeCell is used as a baseline model in the experiments.",
          "quote": "We compare our model with LSTM, RRNet (Jacob et al., 2018), ON-LSTM (Shen et al., 2018), Tranformer (Vaswani et al., 2017), Universal Transformer (Dehghani et al., 2018), TreeLSTM (Tai et al., 2015), TreeRNN (Bowman et al., 2015), and TreeCell."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no separate paper referenced for TreeCell as it seems to be a variation introduced by the authors for this specific comparison.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Gated Recursive Cell",
          "justification": "The paper explicitly names this component as \"Gated Recursive Cell\".",
          "quote": "We also introduce a new Gated Recursive Cell to compose lower level representations into higher level one."
        },
        "aliases": [
          "Gated Recursive Cell"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The authors propose a \"new Gated Recursive Cell\" as part of their OM architecture.",
          "quote": "In this paper, we propose a novel architecture: Ordered Memory (OM), which includes a new memory updating mechanism and a new Gated Recursive Cell."
        },
        "is_executed": {
          "value": true,
          "justification": "The Gated Recursive Cell is an integral part of the OM model, and the paper presents experimental results for OM, implying the cell was also executed.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "The paper implicitly compares the Gated Recursive Cell by comparing the overall OM model (which incorporates the cell) with other models.",
          "quote": "We also introduce a new Gated Recursive Cell to compose lower level representations into higher level one."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "While the paper draws inspiration from the Transformer for its cell design, it does not directly reference a specific paper for the Gated Recursive Cell itself.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 14878
  }
}