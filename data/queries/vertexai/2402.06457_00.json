{
  "paper": "2402.06457.txt",
  "words": 8032,
  "extractions": {
    "title": {
      "value": "V-STaR: Training Verifiers for Self-Taught Reasoners",
      "justification": "The title of the paper is \"V-STaR: Training Verifiers for Self-Taught Reasoners\".",
      "quote": "V-STaR: Training Verifiers for Self-Taught Reasoners"
    },
    "description": "This research paper proposes V-STaR, a method for improving the reasoning ability of large language models (LLMs) by utilizing both correct and incorrect solutions generated during self-improvement. The paper focuses on training a verifier using DPO (Direct Preference Optimization) that judges the correctness of model-generated solutions. The authors demonstrate the effectiveness of V-STaR on math reasoning (GSM8K, MATH) and code generation (MBPP, HumanEval) tasks using LLaMA2 and CodeLLaMA models.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical results and is therefore empirical.",
      "quote": "We empirically evaluate V-STaR on math reasoning"
    },
    "primary_research_field": {
      "name": {
        "value": "Large Language Models",
        "justification": "This paper is in the field of Large Language Models.",
        "quote": "approaches for large language models (LLMs)"
      },
      "aliases": [
        "LLMs",
        "large language models"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Improvement",
          "justification": "This paper focuses on self-improvement methods for LLMs.",
          "quote": "Common self-improvement approaches for large language models"
        },
        "aliases": [
          "self-improvement"
        ]
      },
      {
        "name": {
          "value": "Reasoning",
          "justification": "This paper focuses on improving reasoning abilities of LLMs.",
          "quote": "improve their problemsolving ability"
        },
        "aliases": [
          "reasoning",
          "problem-solving"
        ]
      },
      {
        "name": {
          "value": "Verification",
          "justification": "This paper proposes training a verifier to enhance reasoning in LLMs.",
          "quote": "to train a verifier using DPO that judges correctness of model-generated solutions"
        },
        "aliases": [
          "verification"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "V-STaR",
          "justification": "V-STaR is the name of the model proposed in the paper.",
          "quote": "We propose V-STaR, a data-efficient and simple to implement approach that utilizes correct and incorrect generated solutions from an iteratively trained generator to train a strong verifier."
        },
        "aliases": [
          "LLM",
          "LLMs",
          "language model",
          "language models",
          "pretrained LLM",
          "frozen LLM",
          "generator",
          "reasoners",
          "V-STaR",
          "STaR",
          "RFT",
          "ReSTEM",
          "ORM",
          "LoRA",
          "LLaMA2",
          "CodeLLaMA"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The paper proposes V-STaR, a new model for reasoning.",
          "quote": "we propose V-STaR that utilizes both incorrect and correct generated solutions"
        },
        "is_executed": {
          "value": true,
          "justification": "The paper evaluates V-STaR on different tasks.",
          "quote": "we compare V-STaR to other self-improvement and verification-based methods"
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares V-STaR with other models.",
          "quote": "we compare V-STaR to other self-improvement and verification-based methods"
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No reference paper is mentioned for this model.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 14831
  }
}