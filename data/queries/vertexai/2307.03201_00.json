{
  "paper": "2307.03201.txt",
  "words": 14818,
  "extractions": {
    "title": {
      "value": "Scaling Laws Do Not Scale",
      "justification": "The paper is titled 'Scaling Laws Do Not Scale'.",
      "quote": "Scaling Laws Do Not Scale"
    },
    "description": "This research paper argues that as the size of datasets used to train large AI models increases, so does the number of communities they impact. As such, it may become increasingly difficult to measure the performance of such models with a single metric, since different communities may come to value different aspects of the model. This is especially true since there are already disagreements over how to measure qualities like \"fairness\" and \"transparency\" in AI. The authors propose that future research on AI scaling laws should consider this, and perhaps incorporate a new axis representing the size of the evaluation dataset, or the number of communities represented in it.",
    "type": {
      "value": "theoretical",
      "justification": "The paper presents a theoretical argument about the limitations of scaling laws, so it is a theoretical paper.",
      "quote": "We demonstrate that current AI scaling law analyses overlook the large and diverse set of constructs required to truly assess performance for large and diverse sets of communities."
    },
    "primary_research_field": {
      "name": {
        "value": "AI Ethics",
        "justification": "The paper primarily discusses the societal impacts of AI scaling laws.",
        "quote": "In the context of AI systems that are used by or directly impact people, an evaluation metric, the dependent variable underlying many scaling laws, reflects the performance or quality of the system for those people."
      },
      "aliases": []
    },
    "sub_research_fields": [],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 25977
  }
}