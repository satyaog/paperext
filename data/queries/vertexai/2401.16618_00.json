{
  "paper": "2401.16618.txt",
  "words": 5841,
  "extractions": {
    "title": {
      "value": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking",
      "justification": "This is the title of the paper.",
      "quote": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking"
    },
    "description": "This research paper presents a centralized deep Q-network (DQN) controller as a substitute for the prevalent PID controllers in the context of 6-DOF swimming robots, focusing on underwater object tracking. It highlights DQN advantages such as data efficiency and off-policy learning while being simpler than other RL methods. The approach starts with classical controllers for safe exploration and transitions to DQN for full robot control. The paper validates a centralized RL agent\\'s effectiveness over separated PID controllers through experiments in a Unity-based simulator, showcasing improved performance compared to traditional methods.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents experimental results from simulations, making it empirical.",
      "quote": "Our experiments, conducted within a Unity-based simulator, validate the effectiveness of a centralized RL agent over separated PID controllers, showcasing the applicability of our framework for training the underwater RL agent and improved performance compared to traditional control methods."
    },
    "primary_research_field": {
      "name": {
        "value": "6DOF swimming robots",
        "justification": "The paper focuses on controlling the motion of 6DOF swimming robots.",
        "quote": "In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots."
      },
      "aliases": [
        "6DOF swimming robots"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Underwater object tracking",
          "justification": "These are listed as index terms indicating the paper's focus.",
          "quote": "Index Termsâ€” 6DOF swimming robot, centralized controller, deep Q network, underwater object tracking, online learning, real-time RL."
        },
        "aliases": [
          "Underwater object tracking",
          "online learning",
          "real-time RL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Deep Q-Network",
          "justification": "The paper refers to the model as a Deep Q-Network (DQN).",
          "quote": "In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The authors propose the use of DQN for underwater robot control, but it is not presented as a novel contribution of the paper.",
          "quote": "In this paper, we present an exploration and assessment of employing a centralized deep Q-network (DQN) controller as a substitute for the prevalent use of PID controllers in the context of 6DOF swimming robots."
        },
        "is_executed": {
          "value": true,
          "justification": "The DQN model is implemented and executed in a Unity-based simulator.",
          "quote": "Our experiments, conducted within a Unity-based simulator, validate the effectiveness of a centralized RL agent over separated PID controllers, showcasing the applicability of our framework for training the underwater RL agent and improved performance compared to traditional control methods."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares the performance of a DQN with traditional PID controllers.",
          "quote": "In this paper, we demonstrate that a centralized DQN controller can outperform the traditional approach of using separated PID controllers."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No specific paper is referenced for the Deep Q-Network, as it is a widely known model.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 11070
  }
}