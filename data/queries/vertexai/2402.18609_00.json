{
  "paper": "2402.18609.txt",
  "words": 9270,
  "extractions": {
    "title": {
      "value": "ICE-SEARCH: A L ANGUAGE M ODEL -D RIVEN F EATURE S ELECTION A PPROACH A P REPRINT",
      "justification": "The title is mentioned in the paper.",
      "quote": "ICE-SEARCH: A L ANGUAGE M ODEL -D RIVEN F EATURE S ELECTION A PPROACH A P REPRINT"
    },
    "description": "This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications. ICE-SEARCH harnesses the crossover and mutation capabilities inherent in LMs within an evolutionary framework,\\nsignificantly improving FS through the model’s comprehensive world knowledge and its adaptability to a variety of roles. Our evaluation of this methodology spans three crucial MPA tasks: stroke,\\ncardiovascular disease, and diabetes, where ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art\\n(SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICESEARCH ranks as SOTA in cardiovascular disease prediction. Our results not only demonstrate the efficacy of ICE-SEARCH in medical FS but also underscore the versatility, efficiency, and scalability of integrating LMs in FS tasks. The study emphasizes the critical role of incorporating domainspecific insights, illustrating ICE-SEARCH’s robustness, generalizability, and swift convergence.\\nThis opens avenues for further research into comprehensive and intricate FS landscapes, marking a significant stride in the application of artificial intelligence in medical predictive analytics.",
    "type": {
      "value": "empirical",
      "justification": "The authors propose and evaluate a new method for feature selection",
      "quote": "This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method, the first work that melds language models (LMs) with evolutionary algorithms for feature selection (FS) tasks and demonstrates its effectiveness in Medical Predictive Analytics (MPA) applications."
    },
    "primary_research_field": {
      "name": {
        "value": "Medical Predictive Analytics",
        "justification": "Medical Predictive Analytics (MPA) represents a critical and specialized sector within health informatics",
        "quote": "Medical Predictive Analytics (MPA) represents a critical and specialized sector within health informatics dedicated to the sophisticated examination of medical data."
      },
      "aliases": [
        "Medical Predictive Analytics",
        "MPA",
        "health informatics"
      ]
    },
    "sub_research_fields": [],
    "models": [
      {
        "name": {
          "value": "ICE-SEARCH",
          "justification": "The name of the method is mentioned in the title",
          "quote": "ICE-SEARCH: A L ANGUAGE M ODEL -D RIVEN F EATURE S ELECTION A PPROACH"
        },
        "aliases": [
          "ICE-SEARCH",
          "Decision-Randomized ICE-SEARCH"
        ],
        "is_contributed": {
          "value": true,
          "justification": "This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method",
          "quote": "This study unveils the In-Context Evolutionary Search (ICE-SEARCH) method"
        },
        "is_executed": {
          "value": true,
          "justification": "The authors use their proposed method in their experiments",
          "quote": "Our evaluation of this methodology spans three crucial MPA tasks: stroke,\\ncardiovascular disease, and diabetes"
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares the proposed method with a variety of other methods and states that the proposed method outperforms the other methods",
          "quote": "ICE-SEARCH outperforms traditional FS methods in pinpointing essential features for medical applications. ICE-SEARCH achieves State-of-the-Art\\n(SOTA) performance in stroke prediction and diabetes prediction; the Decision-Randomized ICESEARCH ranks as SOTA in cardiovascular disease prediction."
        },
        "referenced_paper_title": {
          "value": "ICE-SEARCH: A L ANGUAGE M ODEL -D RIVEN F EATURE S ELECTION A PPROACH A P REPRINT",
          "justification": "This seems to be the paper describing the ICE-SEARCH method.",
          "quote": "ICE-SEARCH: A L ANGUAGE M ODEL -D RIVEN F EATURE S ELECTION A PPROACH A P REPRINT"
        }
      },
      {
        "name": {
          "value": "Phi2",
          "justification": "The names of the models are mentioned in the paper.",
          "quote": "In the experiment, we use Phi2 ( Javaheripi and Bubeck [2023]) and 4-bit quantized version of LLaMA2 7B( Touvron et al. [2023]) models respectively as the backbone LM, each containing fewer than 8 billion parameters."
        },
        "aliases": [
          "Phi2",
          "4-bit quantized version of LLaMA2 7B",
          "LLaMA2 7B",
          "LLaMA 2 7B"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't mention if Phi2 or 4-bit quantized version of LLaMA2 7B are contributed in this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": true,
          "justification": "The authors use Phi2 and 4-bit quantized version of LLaMA2 7B in their experiments",
          "quote": "In the experiment, we use Phi2 ( Javaheripi and Bubeck [2023]) and 4-bit quantized version of LLaMA2 7B( Touvron et al. [2023]) models respectively as the backbone LM, each containing fewer than 8 billion parameters."
        },
        "is_compared": {
          "value": true,
          "justification": "The authors use Phi2 and 4-bit quantized version of LLaMA2 7B in their experiments",
          "quote": "In the experiment, we use Phi2 ( Javaheripi and Bubeck [2023]) and 4-bit quantized version of LLaMA2 7B( Touvron et al. [2023]) models respectively as the backbone LM, each containing fewer than 8 billion parameters."
        },
        "referenced_paper_title": {
          "value": "Phi-2: The surprising power of small language models",
          "justification": "This seems to be the paper describing the Phi2 model.",
          "quote": "Phi-2: The surprising power of small language models"
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 18974
  }
}