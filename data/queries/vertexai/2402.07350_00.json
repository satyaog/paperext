{
  "paper": "2402.07350.txt",
  "words": 13973,
  "extractions": {
    "title": {
      "value": "Antagonistic AI",
      "justification": " ",
      "quote": " "
    },
    "description": "This paper discusses a new paradigm for AI systems called Antagonistic AI, which challenges the dominant paradigm of sycophantic AI. The authors argue that AI systems that are disagreeable, rude, interrupting, confrontational, and challenging can have benefits for users, such as forcing them to confront their assumptions, build resilience, or develop healthier relational boundaries. The paper presents formative explorations, including prompting experiments and a speculative design workshop, to explore the design space of antagonistic AI. The authors identify three types of antagonism (adversarial, argumentative, and personal), seven categories of potential benefits, and a suite of design tactics. They also discuss the ethical challenges of this space and identify three dimensions for the responsible design of antagonistic AI: consent, context, and framing.",
    "type": {
      "value": "theoretical",
      "justification": "The paper presents a conceptual framework, design explorations, and discusses ethical considerations, making it a theoretical paper.",
      "quote": "In this provocation, we herald the shadow of the sycophantic paradigm, a design space we call antagonistic AI : AI systems that are actively dismissive, disagreeable, closed-off, critical, flippant,\\ndifficult, interrupting, etc.—in short, AI which act opposite to the norms and values baked into today’s commercial LLMs."
    },
    "primary_research_field": {
      "name": {
        "value": "Artificial Intelligence",
        "justification": "This paper primarily focuses on Artificial intelligence, specifically on aligning AI systems with human values and exploring the ethical implications of a new AI paradigm.",
        "quote": "Central to debates about risk and safety is the field of AI alignment, which aims to align AI systems with “human values”"
      },
      "aliases": [
        "AI",
        "AI alignment",
        "human-AI interaction",
        "human-AI collaboration",
        "AI ethics"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Human-computer interaction",
          "justification": "The paper heavily emphasizes Human-Computer Interaction, drawing from concepts like Speculative Design, Critical Design, Uncomfortable Interactions, and Critical Technical Practice. The authors also suggest using storytelling and experiential structures from literature and performance studies in designing antagonistic AI systems.",
          "quote": "Our perspective and methodology connects with traditions in design and human-computer interaction (HCI) such as speculative design, critical design, uncomfortable interactions, and Agre’s critical technical practice."
        },
        "aliases": [
          "HCI",
          "human-computer interaction",
          "HCI theory",
          "Interaction paradigms",
          "Interaction design theory"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Antagonistic AI",
          "justification": "The paper explores a new paradigm for existing and future AI systems called Antagonistic AI.",
          "quote": "The vast majority of discourse around AI development assumes that subservient, “moral” models aligned with “human values” are universally beneficial —in short, that good AI is sycophantic AI. We explore the shadow of the sycophantic paradigm, a design space we term antagonistic AI : AI systems that are disagreeable, rude, interrupting, confrontational, challenging, etc.—embedding opposite behaviors or values."
        },
        "aliases": [
          "LLMs",
          "large language models",
          "AI",
          "AI systems",
          "chatbots",
          "GPT-4",
          "Llama-2",
          "Goody2"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper does not contribute any new models, but explores the design space of existing models to behave antagonistically.",
          "quote": " "
        },
        "is_executed": {
          "value": true,
          "justification": "The authors conduct prompting experiments with popular LLMs like GPT-4 and Llama-2 to explore antagonistic AI.",
          "quote": "To get a sense for what real interaction with antagonistic AI systems might feel like—including potential benefits and risks—we experimented with prompting popular LLMs to behave antagonistically."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper discusses a new paradigm of AI systems called Antagonistic AI, which is contrasted with the current paradigm of sycophantic AI. The authors argue that AI systems that are disagreeable, rude, interrupting, confrontational, and challenging can have benefits for users, such as forcing them to confront their assumptions, build resilience, or develop healthier relational boundaries.",
          "quote": "The vast majority of discourse around AI development assumes that subservient, “moral” models aligned with “human values” are universally beneficial —in short, that good AI is sycophantic AI. We explore the shadow of the sycophantic paradigm, a design space we term antagonistic AI : AI systems that are disagreeable, rude, interrupting, confrontational, challenging, etc.—embedding opposite behaviors or values."
        },
        "referenced_paper_title": {
          "value": " ",
          "justification": " ",
          "quote": " "
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 23147
  }
}