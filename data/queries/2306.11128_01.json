{
  "paper": "2306.11128.txt",
  "words": 8248,
  "extractions": {
    "title": {
      "value": "CAMMARL : Conformal Action Modeling in Multi Agent Reinforcement Learning",
      "justification": "The title is clearly stated at the top of the text.",
      "quote": "CAMMARL : Conformal Action Modeling in Multi Agent Reinforcement Learning"
    },
    "description": "This research proposes a novel multi-agent reinforcement learning (MARL) algorithm named CAMMARL. The main idea is to model the actions of other agents as conformal prediction sets, which provide high-probability guarantees of containing the true actions. The algorithm aims to optimize an autonomous agentâ€™s decision-making capabilities in multi-agent environments. The performance of CAMMARL is demonstrated through various experiments in cooperative multi-agent tasks.",
    "type": {
      "value": "Empirical Study",
      "justification": "The paper includes several experiments to demonstrate the performance of the proposed CAMMARL algorithm in different multi-agent environments.",
      "quote": "Through several experiments in two fully cooperative multi-agent tasks, we show that CAMMARL elevates the capabilities of an autonomous agent in MARL by modeling conformal prediction sets over the behavior of other agents."
    },
    "primary_research_field": {
      "value": "Deep Learning",
      "justification": "The focus is on a novel algorithm for multi-agent reinforcement learning, a subfield of machine learning which is inherently a part of deep learning.",
      "quote": "In this article, we propose a novel multi-agent reinforcement learning (MARL) algorithm CAM MARL, which involves modeling the actions of other agents in different situations in the form of confident sets."
    },
    "sub_research_fields": [
      {
        "value": "Reinforcement Learning",
        "justification": "The study specifically deals with reinforcement learning and extends it to multi-agent settings.",
        "quote": "Multi-agent reinforcement learning (MARL). Numerous deep MARL research works that focus on partial observability in fully cooperative settings indirectly involve reasoning about the intentions of teammates or opponents in an environment."
      }
    ],
    "models": [],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "Proximal Policy Optimization (PPO)",
          "justification": "PPO is explicitly mentioned as the algorithm used to update the decision-making policies for the RL agents.",
          "quote": "We use proximal policy optimization (PPO) (Schulman et al., 2017) to update the decision-making policy for both the RL agents."
        },
        "role": "Used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 535,
    "prompt_tokens": 13162,
    "total_tokens": 13697
  }
}