title:
  value: Pre-Training and Fine-Tuning Generative Flow Networks
  justification: The title clearly indicates the focus on both pre-training and fine-tuning GFlowNets.
  quote: Pre-Training and Fine-Tuning Generative Flow Networks
description: This paper proposes a novel approach for pre-training Generative Flow Networks (GFlowNets) in a reward-free,
  unsupervised manner. The authors introduce an outcome-conditioned GFlowNet (OC-GFN) which learns to reach targeted outcomes
  in a self-supervised way, enabling efficient adaptation to downstream tasks. The paper demonstrates significant improvements
  in sample diversity and efficiency through extensive experiments in domains like GridWorld and biological sequence design
  tasks.
type:
  value: empirical
  justification: The paper includes extensive experimental results validating the efficacy of the proposed approach.
  quote: Extensive experimental results validate the efficacy of our approach, demonstrating the effectiveness of pre-training
    the OC-GFN, and its ability to swiftly adapt to downstream tasks and discover modes more efficiently.
primary_research_field:
  name:
    value: Deep Learning
    justification: The paper is focused on a novel approach for pre-training and fine-tuning deep learning models, specifically
      Generative Flow Networks.
    quote: In this paper, we propose a novel method for reward-free unsupervised pre-training of GFlowNets.
  aliases: []
sub_research_fields:
- name:
    value: Generative Models
    justification: The focus on Generative Flow Networks (GFlowNets) and improving their training and adaptation processes
      aligns this paper with the sub-field of Generative Models in deep learning.
    quote: Generative Flow Networks (GFlowNets) are amortized samplers that learn stochastic policies to sequentially generate
      compositional objects from a given unnormalized reward distribution.
  aliases: []
models:
- name:
    value: Outcome-Conditioned Generative Flow Network
    justification: Specifically mentioned as the key model introduced in the paper.
    quote: We propose a novel method for reward-free unsupervised pre-training of GFlowNets. We formulate the problem of pre-training
      GFlowNets as a self-supervised problem of learning an outcome-conditioned GFlowNet (OC-GFN).
  aliases:
  - OC-GFN
  is_contributed:
    value: true
    justification: Role:['contributed', 'used', 'referenced']
    quote: contributed
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Generative augmented flow networks
    justification: Specifically mentioned as the key model introduced in the paper.
    quote: In the reward-free unsupervised pre-training phase, we train a (unconditional) GAFN (Pan et al., 2023b) and an
      outcome-conditioned GFN (OC-GFN) on a map without task-specific rewards, where GAFN is trained purely from self-supervised
      intrinsic rewards according to Algorithm 1. We
  aliases:
  - GAFN
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: contributed
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: GridWorld
    justification: The dataset is used for evaluating the proposed pre-training and fine-tuning strategy.
    quote: Extensive experimental results validate the efficacy of our approach, demonstrating the effectiveness of pre-training
      the OC-GFN... on the GridWorld domain.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries: []
