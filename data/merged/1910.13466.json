{
  "title": {
    "value": "Ordered Memory",
    "justification": "Title of the paper as presented in the document",
    "quote": "Ordered Memory"
  },
  "description": "The paper proposes the Ordered Memory architecture, inspired by Ordered Neurons. It introduces a new attention-based mechanism and a new Gated Recursive Cell (GRC). The Ordered Memory model is evaluated on tasks like logical inference and list operations, showing strong performance and the ability to interpret induced tree structures.",
  "type": {
    "value": "empirical",
    "justification": "The paper presents an architecture and evaluates it on several experiments with datasets.",
    "quote": "In this paper, we propose a novel architecture: Ordered Memory (OM), which includes a new memory updating mechanism and a new Gated Recursive Cell. We demonstrate that our method generalizes for synthetic tasks where the ability to parse is crucial to solving them."
  },
  "primary_research_field": {
    "name": {
      "value": "Deep Learning",
      "justification": "The paper proposes a new neural network architecture and evaluates it on deep learning tasks.",
      "quote": "Stack-augmented recurrent neural networks (RNNs) have been of interest to the deep learning community for some time."
    },
    "aliases": []
  },
  "sub_research_fields": [
    {
      "name": {
        "value": "Long-Term Memory",
        "justification": "",
        "quote": ""
      },
      "aliases": []
    },
    {
      "name": {
        "value": "Recurrent Neural Networks",
        "justification": "",
        "quote": ""
      },
      "aliases": ["RNN"]
    },
    {
      "name": {
        "value": "Memory",
        "justification": "",
        "quote": ""
      },
      "aliases": []
    },
    {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "",
        "quote": ""
      },
      "aliases": ["RL"]
    }
  ],
  "models": [
    {
      "name": {
        "value": "Ordered Neurons",
        "justification": "Mentioned as a model related to the proposed Ordered Memory architecture.",
        "quote": "Ordered Memory is implemented following the principles introduced in Ordered Neurons (Shen et al., 2018). Our model is related to ON-LSTM in several aspects"
      },
      "aliases": ["ON-LSTM"],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Ordered Memory",
        "justification": "It is the main contribution of the paper.",
        "quote": "In this paper, we propose the Ordered Memory architecture."
      },
      "aliases": ["OM"],
      "is_contributed": {
        "value": true,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "contributed"
      },
      "is_executed": {
        "value": true,
        "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
        "quote": "trained"
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "RL-SPINN",
        "justification": "Mentioned as a model related to the proposed Ordered Memory architecture.",
        "quote": "Yogatama et al. (2016) proposes RL-SPINN where the discrete stack operations are directly learned by reinforcement learning."
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": false,
        "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
        "quote": "trained"
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": "Figure 3: (a) shows the accuracy of different models on the ListOps dataset. All models have 128 dimensions. Results for models with * are taken from Nangia and Bowman (2018). (b) shows our model accuracy on the ListOps task when varying the the size of the training set."
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "RRNet",
        "justification": "Mentioned as a model related to the proposed Ordered Memory architecture.",
        "quote": "The results for RRNet were taken from Jacob et al. (2018)."
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": false,
        "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
        "quote": "trained"
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Transformer",
        "justification": "Used for comparison in the experiments.",
        "quote": "For the Transformer and Universal Transformer, we follow the entailment architecture introduced in Radford et al. (2018)."
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": true,
        "justification": "",
        "quote": "Figure 3: (a) shows the accuracy of different models on the ListOps dataset. All models have 128 dimensions. Results for models with * are taken from Nangia and Bowman (2018). (b) shows our model accuracy on the ListOps task when varying the the size of the training set."
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": "Figure 3: (a) shows the accuracy of different models on the ListOps dataset. All models have 128 dimensions. Results for models with * are taken from Nangia and Bowman (2018). (b) shows our model accuracy on the ListOps task when varying the the size of the training set."
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Gumbel Tree-LSTM",
        "justification": "Used for comparison in the experiments.",
        "quote": "The TreeCell is a recursive neural network based on the Gated Recursive Cell function proposed in section 3.2."
      },
      "aliases": ["Tree-LSTM"],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": true,
        "justification": "",
        "quote": "Table 1: Test accuracy of the models, trained on operation lengths of ≤ 6, with their out-of- distribution results shown here (lengths 7-12)."
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "TreeCell",
        "justification": "",
        "quote": ""
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": true,
        "justification": "",
        "quote": "Table 1: Test accuracy of the models, trained on operation lengths of ≤ 6, with their out-of- distribution results shown here (lengths 7-12)."
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "TreeRNN",
        "justification": "",
        "quote": ""
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": true,
        "justification": "",
        "quote": "Table 1: Test accuracy of the models, trained on operation lengths of ≤ 6, with their out-of- distribution results shown here (lengths 7-12)."
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Universal Transformer",
        "justification": "Used for comparison in the experiments.",
        "quote": "For the Transformer and Universal Transformer, we follow the entailment architecture introduced in Radford et al. (2018)."
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": true,
        "justification": "",
        "quote": "Table 1: Test accuracy of the models, trained on operation lengths of ≤ 6, with their out-of- distribution results shown here (lengths 7-12)."
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ],
  "datasets": [
    {
      "name": {
        "value": "ListOps",
        "justification": "Used to evaluate the model.",
        "quote": "We evaluate the tree learning capabilities of our model on two datasets: logical inference (Bowman et al., 2015) and ListOps (Nangia and Bowman, 2018)."
      },
      "aliases": [],
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Logical Inference",
        "justification": "The Logical Inference dataset is used to evaluate the generalization of the proposed Ordered Memory model.",
        "quote": "We evaluate the tree learning capabilities of our model on two datasets: logical inference (Bowman et al., 2015) and ListOps (Nangia and Bowman, 2018)."
      },
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Stanford Sentiment Treebank",
        "justification": "A subset task from Stanford Sentiment Treebank used in the experiments.",
        "quote": "We also perform experiments on the Stanford Sentiment Treebank, in both binary classification and fine-grained settings (SST-2 & SST-5)"
      },
      "aliases": ["SST-2"],
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Stanford Sentiment Treebank",
        "justification": "A subset task from Stanford Sentiment Treebank used in the experiments.",
        "quote": "We also perform experiments on the Stanford Sentiment Treebank, in both binary classification and fine-grained settings (SST-2 & SST-5)"
      },
      "aliases": ["SST-5"],
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ],
  "libraries": [
    {
      "name": {
        "value": "Evalb",
        "justification": "Used to evaluate parsing performance.",
        "quote": "All parsing scores are given by Evalb https://nlp.cs.nyu.edu/evalb/"
      },
      "aliases": [],
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ]
}