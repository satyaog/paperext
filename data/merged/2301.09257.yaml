title:
  value: Real-Time Simultaneous Localization and Mapping with LiDAR Intensity
  justification: The title is clearly stated at the beginning of the provided text.
  quote: Real-Time Simultaneous Localization and Mapping with LiDAR Intensity
description: This paper proposes a novel real-time LiDAR intensity image-based SLAM system aimed at solving the geometric
  degeneracy problem in unstructured environments. It directly extracts feature points from intensity images for scan registration
  to estimate the robot's ego-movement and includes systems for loop closure detection and pose graph optimization.
type:
  value: Empirical
  justification: The paper includes experimental evaluations and performance comparisons with other methods, indicating empirical
    research.
  quote: "IV. EXPERIMENTAL RESULTS To prove our algorithm\u2019s reliability, we present our experimental results in an indoor\
    \ environment with long corridors, a multi-storey indoor environment, a mountain, and a street environment."
primary_research_field:
  name:
    value: SLAM
    justification: ''
    quote: ''
  aliases: []
sub_research_fields:
- name:
    value: Simultaneous Localization and Mapping
    justification: The topic of SLAM is central to the paper's focus, as evidenced by both the title and the content discussing
      various SLAM methods.
    quote: We propose a novel real-time LiDAR intensity image-based simultaneous localization and mapping method
  aliases:
  - SLAM
- name:
    value: LiDAR
    justification: ''
    quote: ''
  aliases: []
- name:
    value: Point-Cloud
    justification: ''
    quote: ''
  aliases: []
models:
- name:
    value: A-LOAM
    justification: A-LOAM is specifically mentioned as a SLAM system with which the proposed method is compared experimentally.
    quote: We also test our algorithm indoors with a Spot robot (from Boston Dynamics) equipped with Ouster Os0-64 LiDAR (Fig.
      9a). The scene of this experiment mainly contains the same long corridor as Fig. 9b. In this scenario, we ran different
      algorithms for testing the ability of localization and map building in real world. Both Fig. 6a and Fig. 7a are the
      maps generated by our algorithm. Fig. 6b and Fig. 7b then show the trajectories of different algorithms in the corresponding
      environments.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Cartographer
    justification: Cartographer is mentioned as using a scan-to-submap matching strategy for mapping.
    quote: Another popular work is Cartographer [14], which uses a scan-to-submap matching strategy with loop closure detection
      and graph optimization.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: DLO
    justification: DLO is mentioned as a model within the context of related work on SLAM systems.
    quote: DLO [15] is another direct LiDAR odometry algorithm that can match consecutive frames of point cloud directly with
      high accuracy in real-time for computationally-limited robot platforms, but it is sensitive to dynamic objects.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LeGO-LOAM
    justification: LeGO-LOAM is described as a SLAM method that uses LiDAR for ground vehicles.
    quote: LeGO-LOAM [7] is also a real-time odometry and mapping SLAM method, which uses only the LiDAR of ground vehicles
      as a front-end sensor.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: training
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LIO-SAM
    justification: LIO-SAM is mentioned as a tightly-coupled LiDAR-inertial odometry system.
    quote: Shang et al. [5] proposed LIO-SAM, which is a tightly-coupled LiDAR-inertial odometry system.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LOAM
    justification: LOAM is referenced as a representative work in LiDAR-based SLAM.
    quote: One representative work is LOAM [2], a real-time method for estimating odometry and mapping.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LVI-SAM
    justification: LVI-SAM is mentioned as a related work within the scope of SLAM systems.
    quote: "Numerous SLAM methods based on LiDAR [3], [5]\u2013[7] have been proposed over the past few years. Most of them\
      \ are based on the geometric features (e.g., edges and planes [2], [7]) of LiDAR point clouds."
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: ORB-SLAM
    justification: ORB-SLAM is referenced as a method for performing visual SLAM.
    quote: We extract the corresponding feature points with ORB features from intensity images.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: PointNet
    justification: PointNet is listed as leveraging deep learning to extract semantic features from 3D point clouds.
    quote: PointNet [21] and PointNet++ [22] leverage deep learning techniques to directly extract semantic features from
      3D point clouds, enabling their use in segmentation and extraction of semantic information.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: Open-source dataset provided by Shan et al.
    justification: The reference to a public dataset provided by Shan et al. suggests the use of an established dataset for
      benchmarking.
    quote: We first tested our method with a public dataset provided by Shan et al. [27] which was collected by Ouster OS1-128
      LiDAR.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries:
- name:
    value: g2o
    justification: g2o is explicitly mentioned as the framework used for solving pose graph optimization.
    quote: Finally, we use g2o [36] to solve the pose graph optimization problem.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
