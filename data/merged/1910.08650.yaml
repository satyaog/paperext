title:
  value: Toward Metrics for Differentiating Out-of-Distribution Sets
  justification: The title is explicitly mentioned on the first page of the paper.
  quote: Toward Metrics for Differentiating Out-of-Distribution Sets
description: The paper addresses the challenge of classifying out-of-distribution (OOD) samples with confidence using Convolutional
  Neural Networks (CNNs). It proposes a method to differentiate OOD sets based on generalization errors and introduces three
  efficient metrics (Softmax-based Entropy, Coverage Ratio, and Coverage Distance) to select the most effective OOD sets for
  training well-generalized, calibrated CNN models. The effectiveness is demonstrated across various image and audio classification
  tasks.
type:
  value: Empirical Study
  justification: The paper involves conducting numerous empirical experiments to evaluate the proposed metrics and validate
    the effectiveness of OOD sets for training CNN models.
  quote: "We empirically verify that the most protective OOD sets \u2013 selected according to our metrics..."
primary_research_field:
  name:
    value: Deep Learning
    justification: The research focuses on improving the performance of Deep Learning models by addressing the issue of out-of-distribution
      samples.
    quote: Vanilla CNNs, as uncalibrated classifiers, suffer from classifying out-of-distribution (OOD) samples nearly as
      confidently as in-distribution samples.
  aliases: []
sub_research_fields:
- name:
    value: Out-Of-Distribution Detection
    justification: The core of the paper is to develop metrics and methods to improve OOD sample detection and classification
      using CNN models.
    quote: Our main goal in this paper is to characterizing properties of OOD sets for recognizing a proper one for training
      an end-to-end A-CNN and calibrated vanilla CNN with high detection rate on unseen OOD sets...
  aliases: []
models:
- name:
    value: A-CNN
    justification: This model is explicitly developed in the research to handle OOD sample detection by adding an extra rejection
      class.
    quote: We exploit A-CNN as an end-to-end model for OOD detection task.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: A-CNN
    justification: Augmented Convolutional Neural Network, a vanilla CNN with an additional rejection class used for OOD detection.
    quote: We exploit A-CNN as an end-to-end model for OOD detection task.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: Used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: Trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Calibrated CNN
    justification: Calibrated CNNs are trained for making uncertain predictions for OOD samples while confidently classifying
      in-distribution ones.
    quote: For instance, calibrated vanilla CNNs [15, 13, 20] are trained to make uncertain predictions for OOD samples while
      still confidently and correctly classifying in-distribution ones.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Vanilla CNN
    justification: Vanilla CNN is used as a baseline model in the experiments conducted to evaluate the effectiveness of the
      proposed metrics.
    quote: It has been shown that state-of-the-art (vanilla) deep neural networks (e.g., CNN) are uncalibrated such that they
      are making predictions for OOD samples with a confidence that is as high as those of in-distribution samples.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Vanilla CNN
    justification: Standard Convolutional Neural Network used for benchmarking and training as part of the study.
    quote: Vanilla CNNs, as uncalibrated classifiers, suffer from classifying out-of-distribution (OOD) samples nearly as
      confidently as in-distribution samples.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: Used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: Trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: CIFAR-10
    justification: The CIFAR-10 dataset is used as an in-distribution dataset in several experiments conducted in the paper.
    quote: It has also been shown in [19], where using SVHN as OOD set for CIFAR-10 is leading to an A-CNN with inferior generalization
      properties.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: CIFAR-10
    justification: One of the benchmark datasets used in the paper for testing and training.
    quote: In an extensive series of experiments on image and audio classification tasks, we empirically show that A-CNNs
      and calibrated vanilla CNNs trained on the most protective OOD set have higher detection rates (lower generalization
      error) on unseen OOD sets in comparison with those trained on the least protective OOD set.
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: CIFAR-100
    justification: CIFAR-100 is used as an out-of-distribution dataset in the experiments.
    quote: It has also been shown in [19], where using SVHN as OOD set for CIFAR-10 is leading to an A-CNN with inferior generalization
      properties.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: CIFAR-100
    justification: Used as an out-of-distribution dataset in the experiments.
    quote: for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: ECS
    justification: ECS is used as an out-of-distribution dataset for audio classification tasks.
    quote: OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well
      as white-noise sound as a synthetic OOD set.
  aliases:
  - Environmental Sound Classification
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: ECS
    justification: Used in the audio classification tasks as an out-of-distribution set.
    quote: OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well
      as white-noise sound as a synthetic OOD set.
  aliases:
  - Environmental Sound Classification
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Google Command
    justification: The Google Command dataset is used as an out-of-distribution dataset in the audio classification experiments.
    quote: OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well
      as white-noise sound as a synthetic OOD set.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Google Command
    justification: Used in the audio classification experiments as an OOD set.
    quote: OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well
      as white-noise sound as a synthetic OOD set.
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: ISUN
    justification: ISUN is used as an out-of-distribution dataset in the experiments.
    quote: For image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets and Gaussian noise
      as a synthetic OOD set.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: ISUN
    justification: Used as one of the out-of-distribution sets for image classification tasks.
    quote: for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LSUN
    justification: LSUN is used as an out-of-distribution dataset in the experiments.
    quote: For image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets and Gaussian noise
      as a synthetic OOD set.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LSUN
    justification: Also used as an out-of-distribution set in the experiments for image classification tasks.
    quote: for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SVHN
    justification: SVHN is both used as an in-distribution dataset and an out-of-distribution dataset in various experiments.
    quote: It has also been shown in [19], where using SVHN as OOD set for CIFAR-10 is leading to an A-CNN with inferior generalization
      properties.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SVHN
    justification: Another benchmark dataset used in the paper for empirical evaluations.
    quote: We conduct a series of experiments on several classification tasks including two image benchmarks, namely CIFAR-10
      and SVHN, and one audio benchmark, namely Urban-Sound [28].
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TinyImageNet
    justification: TinyImageNet is used as an out-of-distribution dataset for evaluating the models.
    quote: For image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets and Gaussian noise
      as a synthetic OOD set.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TinyImageNet
    justification: Another dataset used as an out-of-distribution set in the experiments.
    quote: for image classification tasks, we consider LSUN, ISUN, CIFAR-100 and TinyImageNet as OOD sets
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TuT
    justification: The TuT dataset is used as an out-of-distribution dataset in the audio classification experiments.
    quote: OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well
      as white-noise sound as a synthetic OOD set.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TuT
    justification: This dataset was used for audio classification tasks as an out-of-distribution set.
    quote: OOD sets considered are TuT [25], Google Command [32] and ECS (Environmental Sound Classification) [26], as well
      as white-noise sound as a synthetic OOD set.
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Urban-Sound
    justification: The Urban-Sound dataset is used to verify the effectiveness of the proposed metrics in audio classification
      tasks.
    quote: We conduct a series of experiments on several classification tasks including two image benchmarks, namely CIFAR-10
      and SVHN, and one audio benchmark, namely Urban-Sound.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Urban-Sound
    justification: This is the audio benchmark dataset used for the experiments performed in the paper.
    quote: We conduct a series of experiments on several classification tasks including two image benchmarks, namely CIFAR-10
      and SVHN, and one audio benchmark, namely Urban-Sound [28].
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries: []
