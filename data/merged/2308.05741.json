{
  "title": {
    "value": "Neural Progressive Meshes",
    "justification": "The title is derived from the beginning of the research paper.",
    "quote": "Neural Progressive Meshes YUN-CHUN CHEN, University of Toronto, Canada VLADIMIR G. KIM, Adobe Research, USA NOAM AIGERMAN, Adobe Research, USA ALEC JACOBSON, Adobe Research, University of Toronto, Canada"
  },
  "description": "The paper introduces Neural Progressive Meshes, a framework leveraging a neural network-based encoder-decoder architecture that derives a progressive compressed representation of 3D meshes for efficient transmission.",
  "type": {
    "value": "Empirical",
    "justification": "The study evaluates the proposed method using quantitative metrics and comparisons to several baseline methods, conducting multiple experiments.",
    "quote": "We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms of compression ratio and reconstruction quality."
  },
  "primary_research_field": {
    "name": {
      "value": "Computer Vision",
      "justification": "The paper addresses problems related to the efficient transmission and reconstruction of 3D meshes, which is a topic within the computer vision research field.",
      "quote": "arXiv:2308.05741v1 [cs.CV] 10 Aug 2023"
    },
    "aliases": []
  },
  "sub_research_fields": [
    {
      "name": {
        "value": "3D Vision",
        "justification": "The work focuses on the processing, compression, and reconstruction of 3D meshes, fitting within the sub-research field of 3D Vision.",
        "quote": "We present a framework that learns a progressive compressed representation of meshes for transmission purposes."
      },
      "aliases": []
    }
  ],
  "models": [
    {
      "name": {
        "value": "Neural Progressive Mesh",
        "justification": "This is the model introduced and developed in the paper.",
        "quote": "Fig. 1. Neural Progressive Meshes. We present a framework that learns a progressive compressed representation of meshes for transmission purposes."
      },
      "aliases": [],
      "is_contributed": {
        "value": true,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "contributed"
      },
      "is_executed": {
        "value": true,
        "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
        "quote": "trained"
      },
      "is_inference_only": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": true,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "Neural Subdivision",
        "justification": "Neural Subdivision, a pre-existing model, is adapted for the decoder in the framework.",
        "quote": "The client uses a subdivision-based decoder adapted from Neural Subdivision [Liu et al. 2020] to reconstruct a high-resolution mesh."
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": false,
        "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
        "quote": "trained"
      },
      "is_inference_only": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    },
    {
      "name": {
        "value": "SubdivNet",
        "justification": "SubdivNet is used within the neural network framework described.",
        "quote": "The server first uses TetWild [Hu et al. 2018] to preprocess it and then uses a subdivision-based encoder adapted from SubdivNet [Hu et al. 2022] to map geometric details of the original mesh."
      },
      "aliases": [],
      "is_contributed": {
        "value": false,
        "justification": "Role:['contributed', 'used', 'referenced']",
        "quote": "used"
      },
      "is_executed": {
        "value": false,
        "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
        "quote": "trained"
      },
      "is_inference_only": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "is_compared": {
        "value": false,
        "justification": "",
        "quote": ""
      },
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ],
  "datasets": [
    {
      "name": {
        "value": "Thingi10K",
        "justification": "This dataset is used to evaluate the proposed method.",
        "quote": "We evaluate our network on the Thingi10K [Zhou and Jacobson 2016] dataset, split into the training, validation, and test sets."
      },
      "aliases": [],
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ],
  "libraries": [
    {
      "name": {
        "value": "PyTorch",
        "justification": "PyTorch is used for training the neural networks involved in the study.",
        "quote": "We train our network using the ADAM [Kingma and Ba 2014] optimizer in PyTorch [Paszke et al. 2019]."
      },
      "aliases": [],
      "role": "used",
      "referenced_paper_title": {
        "value": "",
        "justification": "",
        "quote": ""
      }
    }
  ]
}