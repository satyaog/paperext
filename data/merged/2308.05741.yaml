title:
  value: Neural Progressive Meshes
  justification: The title is derived from the beginning of the research paper.
  quote: Neural Progressive Meshes YUN-CHUN CHEN, University of Toronto, Canada VLADIMIR G. KIM, Adobe Research, USA NOAM
    AIGERMAN, Adobe Research, USA ALEC JACOBSON, Adobe Research, University of Toronto, Canada
description: The paper introduces Neural Progressive Meshes, a framework leveraging a neural network-based encoder-decoder
  architecture that derives a progressive compressed representation of 3D meshes for efficient transmission.
type:
  value: empirical
  justification: The study evaluates the proposed method using quantitative metrics and comparisons to several baseline methods,
    conducting multiple experiments.
  quote: We evaluate our method on a diverse set of complex 3D shapes and demonstrate that it outperforms baselines in terms
    of compression ratio and reconstruction quality.
primary_research_field:
  name:
    value: Computer Vision
    justification: The paper addresses problems related to the efficient transmission and reconstruction of 3D meshes, which
      is a topic within the computer vision research field.
    quote: arXiv:2308.05741v1 [cs.CV] 10 Aug 2023
  aliases: []
sub_research_fields:
- name:
    value: 3D Reconstruction
    justification: The study focuses on the reconstruction of 3D meshes using a progressive transmission framework.
    quote: We present a framework that learns a progressive compressed representation of meshes for transmission purposes.
  aliases: []
- name:
    value: 3D Vision
    justification: The work focuses on the processing, compression, and reconstruction of 3D meshes, fitting within the sub-research
      field of 3D Vision.
    quote: We present a framework that learns a progressive compressed representation of meshes for transmission purposes.
  aliases: []
models:
- name:
    value: Neural Progressive Mesh
    justification: This is the model introduced and developed in the paper.
    quote: Fig. 1. Neural Progressive Meshes. We present a framework that learns a progressive compressed representation of
      meshes for transmission purposes.
  aliases: []
  is_contributed:
    value: true
    justification: Role:['contributed', 'used', 'referenced']
    quote: contributed
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Neural Subdivision
    justification: Neural Subdivision, a pre-existing model, is adapted for the decoder in the framework.
    quote: The client uses a subdivision-based decoder adapted from Neural Subdivision [Liu et al. 2020] to reconstruct a
      high-resolution mesh.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TetWild
    justification: SubdivNet is used within the neural network framework described.
    quote: The server first uses TetWild [Hu et al. 2018] to preprocess it and then uses a subdivision-based encoder adapted
      from SubdivNet [Hu et al. 2022] to map geometric details of the original mesh.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SubdivNet
    justification: SubdivNet is used within the neural network framework described.
    quote: The server first uses TetWild [Hu et al. 2018] to preprocess it and then uses a subdivision-based encoder adapted
      from SubdivNet [Hu et al. 2022] to map geometric details of the original mesh.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: Thingi10K
    justification: This dataset is used to evaluate the proposed method.
    quote: We evaluate our network on the Thingi10K [Zhou and Jacobson 2016] dataset, split into the training, validation,
      and test sets.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries:
- name:
    value: PyTorch
    justification: PyTorch is used for training the neural networks involved in the study.
    quote: We train our network using the ADAM [Kingma and Ba 2014] optimizer in PyTorch [Paszke et al. 2019].
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
