title:
  value: 'OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning'
  justification: The title is clearly mentioned at the beginning of the paper.
  quote: 'OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning'
description: This paper introduces an object-centric compositional neural module network (OC-NMN) designed for visual generative
  reasoning tasks. The model decomposes tasks into a series of primitives applied to objects using modularity. This approach
  aims to improve out-of-distribution generalization by leveraging neural templates composed of neural modules. The proposed
  method is evaluated using a new benchmark, Arith-MNIST, which involves arithmetic operations on visual digits.
type:
  value: Empirical Study
  justification: The paper presents experimental results from applying the proposed model to a new benchmark dataset called
    Arith-MNIST and compares it to existing baselines.
  quote: Using this benchmark, we evaluate the systematic compositional generalization of models on a set of controlled and
    easily extendable axes and show the benefits of object-centric inductive biases.
primary_research_field:
  name:
    value: Computer Vision
    justification: The paper addresses visual generative reasoning tasks, which fall under the domain of computer vision.
    quote: In this work, in the context of visual reasoning, we show how modularity can be leveraged to derive a compositional
      data augmentation framework inspired by imagination.
  aliases: []
sub_research_fields:
- name:
    value: Visual Reasoning
    justification: The paper specifically focuses on visual generative reasoning tasks and introduces a model designed for
      such tasks.
    quote: Our model OC-NMN (Object-centric Compositional Neural Module Network) can be seen as part of the neural module
      networks (NMNs) family of models, adapted to generative visual analogical reasoning tasks like ARC.
  aliases: []
- name:
    value: Out-of-distributiona generalization
    justification: ''
    quote: ''
  aliases: []
- name:
    value: Compositional Neural Module Network
    justification: ''
    quote: ''
  aliases: []
models:
- name:
    value: DNC-GRU
    justification: This model serves as one of the baselines for comparison in the experiments.
    quote: The second baseline consists of a stack of Transformer encoder layers, and takes as input a set composed of the
      query slots, the controller output,and a CLS token from which we retrieve the final answer. We denote this model DNC-Transformer.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: DNC-Transformer
    justification: This model is another baseline used for comparison.
    quote: We denote this model DNC-Transformer. All architectural details and hyperparameters are described in the Appendix.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: FLAN-T5
    justification: FLAN-T5 is evaluated on the text equivalent tasks in the experiments.
    quote: We also report the performance of a state-of-the-art language model baseline FLAN-T5 on the text equivalent tasks.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: GPT-4
    justification: GPT-4 is used to evaluate generalization to unseen digit-color configurations.
    quote: We evaluate GPT-4 on the easy split and obtain an accuracy of 16 in the best case. More details about the GPT-4
      training can be found in the Appendix.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Neural Abstract Reasoner
    justification: NAR is one of the models used for comparison in the experiments.
    quote: we evaluate GPT-4 on the easy split and obtain an accuracy of 16 in the best case.
  aliases:
  - NAR
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: OC-NMN
    justification: The paper proposes this new model for compositional neural module networks applied to visual reasoning
      tasks.
    quote: Our method, denoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes visual generative reasoning
      tasks into a series of primitives applied to objects without using a domain-specific language.
  aliases: []
  is_contributed:
    value: true
    justification: Role:['contributed', 'used', 'referenced']
    quote: contributed
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: Abstract Reasoning Corpus
    justification: The ARC dataset is specifically mentioned as a reference point for generative reasoning tasks.
    quote: To that end, Chollet (2019) proposed a generative reasoning task, the Abstract Reasoning Corpus (ARC), where the
      model is given a few examples of input-output (I/O) pairs and has to understand the underlying common program that was
      applied to the inputs to obtain the outputs.
  aliases:
  - ARC
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Arith-MNIST
    justification: The paper introduces this dataset as a new benchmark for evaluating visual reasoning models on arithmetic
      tasks involving MNIST digits.
    quote: We propose a simpler set of tasks that involve a set of controlled arithmetic operations on digits.
  aliases: []
  role: contributed
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries: []
