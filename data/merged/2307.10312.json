{
  "description": "This paper examines the application of safety engineering frameworks, particularly Failure Mode and Effects Analysis (FMEA) and System Theoretic Process Analysis (STPA), in assessing the social and ethical risks in the development and deployment of text-to-image (T2I) models. By using these frameworks, the authors identify potential failures and hazards in various stages of the T2I model life cycle, including data processing, model integration, and use by artists.",
  "title": {
    "value": "Beyond the ML Model: Applying Safety Engineering Frameworks to Text-to-Image Development",
    "justification": "Title of the paper as it appears in the document.",
    "quote": "Beyond the ML Model: Applying Safety Engineering Frameworks to Text-to-Image Development"
  },
  "type": {
    "value": "Empirical study",
    "justification": "The paper presents empirical evidence from applying safety engineering frameworks to T2I models and analyzing real-world case studies with users and practitioners.",
    "quote": "While we did not conduct a full STPA/FMEA analysis, this case study offers empirical evidence on how safety engineering frameworks could be translated to analyzing social and ethical risks."
  },
  "research_field": {
    "value": "Deep Learning",
    "justification": "The paper deals with the development and deployment of deep learning models, specifically text-to-image models.",
    "quote": "In this work, we applied two well-established safety engineering frameworks (FMEA, STPA) to a case study involving text-to-image models at three stages of the ML product development pipeline: data processing, integration of a T2I model with other models, and use."
  },
  "sub_research_field": {
    "value": "Model Safety [[Ethics in AI]]",
    "justification": "The focus of the paper is on applying safety frameworks to identify social and ethical risks in AI models, particularly text-to-image models.",
    "quote": "By conducting this type of analysis on the process (and not the model itself), a practitioner can identify both known and novel failures (and their resulting harms) that can emerge from training data processing choices."
  },
  "models": [
    {
      "name": {
        "value": "DALL-E 2",
        "justification": "The paper mentions the use of DALL-E 2 as an example of a text-to-image model.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "role": "referenced",
      "type": {
        "value": "Text-to-Image",
        "justification": "DALL-E 2 is a model designed for generating images from textual descriptions.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "mode": "inference"
    },
    {
      "name": {
        "value": "Imagen",
        "justification": "The paper mentions the use of Imagen as an example of a text-to-image model.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "role": "referenced",
      "type": {
        "value": "Text-to-Image Generation",
        "justification": "Imagen is a model designed for generating images from textual descriptions.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "mode": "inference"
    },
    {
      "name": {
        "value": "Parti",
        "justification": "The paper mentions the use of Parti as an example of a text-to-image model.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "role": "referenced",
      "type": {
        "value": "Text-to-Image Generation",
        "justification": "Parti is a model designed for generating images from textual descriptions.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "mode": "inference"
    },
    {
      "name": {
        "value": "Stable Diffusion",
        "justification": "The paper mentions the use of Stable Diffusion as an example of a text-to-image model.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "role": "referenced",
      "type": {
        "value": "Text-to-Image Generation",
        "justification": "Stable Diffusion is a model designed for generating images from textual descriptions.",
        "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
      },
      "mode": "inference"
    }
  ],
  "datasets": [
    {
      "name": {
        "value": "FIT400M",
        "justification": "The paper mentions the FIT400M dataset in the context of data processing steps for training T2I models.",
        "quote": "For our proof-of-concept analysis, we use the data processing steps outlined in the publicly available data card for the Parti model [17]."
      },
      "role": "referenced"
    }
  ],
  "libraries": []
}