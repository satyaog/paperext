title:
  value: Listenable Maps for Audio Classifiers
  justification: The title of the paper is 'Listenable Maps for Audio Classifiers', as stated at the beginning and throughout
    the document.
  quote: This paper contributes to this emerging field by introducing a novel method called Listenable Maps for Audio Classifiers
    (L-MAC).
description: This paper introduces Listenable Maps for Audio Classifiers (L-MAC), a posthoc interpretation method designed
  to generate listenable and faithful interpretations for pretrained audio classifiers. L-MAC employs a decoder that produces
  binary masks over the spectrogram of the original input audio. These masks identify relevant portions of the audio that
  influenced the classifier's decision. The decoder is trained using a loss function that promotes high classifier confidence
  for the masked-in audio and low probability for the masked-out portions. Quantitative and qualitative evaluations demonstrate
  that L-MAC outperforms several existing methods, including gradient and masking-based techniques, in producing faithful
  and user-preferred interpretations.
type:
  value: empirical study
  justification: The paper conducts experiments, user studies, and quantitative evaluations to demonstrate that L-MAC produces
    more faithful and listenable interpretations compared to existing methods.
  quote: Quantitative evaluations on both in-domain and out-of-domain data demonstrate that L-MAC consistently produces more
    faithful interpretations than several gradient and masking-based methodologies. Furthermore, a user study confirms that,
    on average, users prefer the interpretations generated by the proposed technique.
primary_research_field:
  name:
    value: Audio Signal Processing
    justification: ''
    quote: ''
  aliases:
  - Audio Processing
  - Audio
sub_research_fields:
- name:
    value: Explainable AI
    justification: The paper is focused on posthoc interpretation methods for pretrained machine learning models, making it
      a contribution to the field of Explainable AI (XAI).
    quote: Explainable Machine Learning is a research area that aims to render the models transparent concerning their decision-making
      mechanisms. This paper contributes to this emerging field by introducing a novel method called Listenable Maps for Audio
      Classifiers (L-MAC).
  aliases: []
- name:
    value: Interpretability
    justification: The primary focus of the paper is on generating interpretations for pre-trained machine learning models
      in the audio domain.
    quote: Many existing posthoc interpretability methods are primarily designed for computer vision, where the task often
      involves classifying objects against a clean background.
  aliases:
  - Explainable AI
models:
- name:
    value: CNN14
    justification: The CNN14 model is used as the pretrained classifier on which L-MAC is evaluated and trained.
    quote: In these experiments, we first train a CNN14 classifier (Kong et al., 2020) on the ESC-50 dataset (Piczak) augmented
      with WHAM! noise, to simulate real-world mixtures. The classifier is trained on folds 1, 2, and 3 and obtains 75% and
      78% classification accuracy on folds 5 and 4, respectively.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: 'Panns: Large-scale pretrained audio neural networks for audio pattern recognition'
    justification: ''
    quote: ''
- name:
    value: L-MAC
    justification: The focus of the paper is to introduce and evaluate the L-MAC model as a posthoc interpretation method
      for audio classifiers.
    quote: To address this issue, we introduce Listenable Maps for Audio Classifiers (L-MAC), a posthoc interpretation method
      that generates faithful and listenable interpretations.
  aliases: []
  is_contributed:
    value: true
    justification: Role:['contributed', 'used', 'referenced']
    quote: contributed
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SHAP
    justification: ''
    quote: ''
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: ''
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: ''
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: A unified approach to interpreting model predictions
    justification: ''
    quote: ''
datasets:
- name:
    value: ESC-50
    justification: ESC-50 is mentioned as the dataset used for training and evaluation throughout the paper.
    quote: We utilized the ESC50 dataset (Piczak) which contains 50 environmental sound classes for both setups.
  aliases: []
  role: Used
  referenced_paper_title:
    value: 'ESC: Dataset for Environmental Sound Classification'
    justification: ''
    quote: ''
- name:
    value: VGG-Sound
    justification: VGG-Sound is mentioned as the dataset used for pretraining the classifier CNN14.
    quote: The CNN14 classifier we employed has 12 2D convolutional layers and is pre-trained on the VGG-sound dataset (Chen
      et al., 2020a) using SimCLR (Chen et al., 2020b).
  aliases: []
  role: Used
  referenced_paper_title:
    value: 'Vggsound: A large-scale audio-visual dataset'
    justification: ''
    quote: ''
libraries:
- name:
    value: Captum
    justification: Captum is mentioned for implementing the gradient-based interpretation methods used for comparison.
    quote: ''
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SpeechBrain
    justification: ''
    quote: ''
  aliases: []
  role: Used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
