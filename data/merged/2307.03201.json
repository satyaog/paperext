{
  "description": "This paper scrutinizes the applicability of AI scaling laws, questioning their universal claims by highlighting the dangers of overlooking diverse sub-populations within datasets. It suggests that evaluation metrics are precarious and can obscure underperformance or biased outcomes, especially as dataset sizes grow and encapsulate more diverse communities.",
  "title": {
    "value": "Scaling Laws Do Not Scale",
    "justification": "The information is taken directly from the paper's title.",
    "quote": "Scaling Laws Do Not Scale"
  },
  "type": {
    "value": "Theoretical",
    "justification": "The paper is deeply engaged in a theoretical examination of AI scaling laws and their implications, without conducting empirical experiments.",
    "quote": "Our claim is divided into four parts. First, that evaluation metrics reﬂect the composition of the evaluation dataset, which is shaped by the sampling approach used to collect that data; second, that the number of sub-groups within a given dataset grows with data size; third, those sub-groups can have incompatible values and preferences for appropriate evaluation metrics; and fourth, that the risk of that metric incompability grows with dataset size."
  },
  "research_field": {
    "value": "Artificial Intelligence",
    "justification": "The context and discussions are centered around the theoretical framework and evaluation metrics in AI, particularly focusing on deep learning models.",
    "quote": "Recent work has proposed a power law relationship, referred to as “scaling laws,” between the performance of artiﬁcial intelligence (AI) models and aspects of those models’ design (e.g., dataset size)."
  },
  "sub_research_field": {
    "value": "Evaluation Metrics",
    "justification": "The paper discusses the validity and implications of evaluation metrics in the context of scaling laws for AI models, highlighting issues such as metric incompatibility and non-stationarity.",
    "quote": "Scaling Laws, Large Language Models"
  },
  "models": [],
  "datasets": [
    {
      "name": {
        "value": "BBQ Benchmark",
        "justification": "The BBQ Benchmark is discussed as a tool for evaluating biases in AI models, emphasizing the need for context-specific metrics to reflect the values of different communities.",
        "quote": "Parrish et al. developed a bias benchmark dataset (BBQ) for question-answering to evaluate the performance of large language models."
      },
      "role": "referenced"
    },
    {
      "name": {
        "value": "Colossal Clean Crawled Corpus (C4)",
        "justification": "The dataset is used to illustrate examples of large datasets that underpin current scaling laws in AI models.",
        "quote": "Despite claims that a larger training dataset (e.g., a crawl of the predominantly English-speaking Internet [53]) will lead to improved model performance, when such models are deployed at scale, the larger numbers of people included in the evaluation dataset—and thus a larger number of communities—may lead to breakdowns in model performance for diﬀerent communities."
      },
      "role": "Referenced"
    },
    {
      "name": {
        "value": "LAION",
        "justification": "The LAION dataset is mentioned in a similar context to C4, discussing the potential biases and representativeness challenges inherent in large-scale web crawled datasets.",
        "quote": "Similarly, massive datasets used to train large models, such as the Colossal Clean Crawled Corpus (C4), trained on a crawl of the web, or others such as LAION."
      },
      "role": "referenced"
    }
  ],
  "libraries": []
}