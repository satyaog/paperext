title:
  value: A Survey on Deep Learning for Theorem Proving
  justification: The title succinctly describes the content and focus of the paper.
  quote: A Survey on Deep Learning for Theorem Proving
description: This paper offers a comprehensive survey of deep learning techniques applied to the field of theorem proving,
  reviewing existing approaches, available datasets, evaluation metrics, and suggesting future research directions.
type:
  value: theoretical
  justification: The paper provides a thorough review and analysis of existing deep learning methods, datasets, and performance
    metrics within the specific field of theorem proving, but doesnt run any experiments.
  quote: This paper presents a pioneering comprehensive survey of deep learning for theorem proving by offering i) a thorough
    review of existing approaches... ii) a meticulous summary of available datasets... iii) a detailed analysis of evaluation
    metrics and the performance of state-of-the-art.
primary_research_field:
  name:
    value: Mathematics
    justification: The survey focuses on the application of deep learning techniques within the domain of theorem proving.
    quote: (@fabrice removed the quote)
  aliases: []
sub_research_fields:
- name:
    value: Theorem Proving
    justification: The sub-research field explicitly narrows down to the intersection of theorem proving and deep learning
      methods.
    quote: Exploring learning-based approaches for theorem proving has been a long-standing research focus...
  aliases: []
models:
- name:
    value: AlphaGeometry
    justification: AlphaGeometry is noted for its application in the domain of geometry theorem proving.
    quote: Notably, AlphaGeometry (Trinh et al., 2024) trains a decoder-only Transformer to predict the auxiliary constructions
      in the proofs of International Mathematical Olympiad (IMO) geometry problems.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: training
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Codex
    justification: Codex is discussed for its use in autoformalization.
    quote: Wu et al. (2022); Azerbayev et al. (2023); Jiang et al. (2023a) explore advanced LLMs like Codex and GPT-4 (Achiam
      et al., 2023) for informalization...
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: GPT-4
    justification: GPT-4 is highlighted for its contributions to autoformalization and proof generation.
    quote: Using GPT-4, MMA (Jiang et al., 2023a) informalizes all theorem statements in Archive of Formal Proofs and mathlib...
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: GPT-f
    justification: GPT-f is listed in the context of proofstep generation and various models have been referenced including
      GPT-3 and GPT-4.
    quote: Specifically, GPT-f (Polu & Sutskever, 2020) first apply a conditional language modeling objective to train decoder-only
      Transformers to generate a proof step...
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: Referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: Inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: NaturalProver
    justification: NaturalProver is described as employing constrained decoding to aid in proof generation, leveraging GPT-3.
    quote: NaturalProver (Welleck et al., 2022) trains GPT-3 (Brown et al., 2020) with constrained decoding to encourage using
      retrieved references in the proof steps.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: Referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: Inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: PaLM
    justification: PaLM is mentioned as being studied for autoformalization.
    quote: Wu et al. (2022); Agrawal et al. (2022); Gadgil et al. (2022) study the prospects of autoformalization using PaLM
      (Chowdhery et al., 2023)...
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Thor
    justification: Thor is mentioned as a model that integrates language models with automated theorem provers, enhancing
      the process of generating proofs.
    quote: Thor (Jiang et al., 2022) adds a <hammer> token to learn when to invoke an ATP tool for premise selection to simplify
      the proof.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: Referenced
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: Inference
  is_compared:
    value: false
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: CoqGym
    justification: CoqGym is recognized specifically as a large-scale dataset for Coq proofs.
    quote: with CoqGym constructing a dataset from 123 projects encompassing 71k proofs.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: GamePad
    justification: GamePad is highlighted as a Coq dataset for formal proofs.
    quote: Notable datasets for Coq include Gamepad (Huang et al., 2019)...
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: PISA
    justification: ''
    quote: "For Isabelle, datasets like IsarStep (Li et al., 2021a), PISA (Jiang et al., 2021), and Magnushammer (Miku\u0142\
      a et al., 2024) are built on the Archive of Formal Proofs and Isabelle Standard Library, where PISA extracts 183K theorems\
      \ and 2.16M proof steps."
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Magnushammer
    justification: ''
    quote: "For Isabelle, datasets like IsarStep (Li et al., 2021a), PISA (Jiang et al., 2021), and Magnushammer (Miku\u0142\
      a et al., 2024) are built on the Archive of Formal Proofs and Isabelle Standard Library, where PISA extracts 183K theorems\
      \ and 2.16M proof steps."
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: HolStep
    justification: HolStep is noted as a dataset for the HOL Light proof assistant, facilitating research in premise selection
      and proof generation.
    quote: Notable datasets for Coq include Gamepad, CoqGym, and PRISM... Datasets for other proof assistants include HolStep
      (Kaliszyk et al., 2017) and HOList (Bansal et al., 2019) for HOL Light
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: HOList
    justification: HOList is noted as a dataset for the HOL Light proof assistant, facilitating research in premise selection
      and proof generation.
    quote: Notable datasets for Coq include Gamepad, CoqGym, and PRISM... Datasets for other proof assistants include HolStep
      (Kaliszyk et al., 2017) and HOList (Bansal et al., 2019) for HOL Light
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: IsarStep
    justification: IsarStep is mentioned for its utility in formal theorem proving within Isabelle.
    quote: For Isabelle, datasets like IsarStep (Li et al., 2021a)... are built on the Archive of Formal Proofs and Isabelle
      Standard Library...
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: MiniF2F
    justification: MiniF2F is highlighted as a dataset that contains Olympiad-level problems manually formalized in multiple
      proof systems.
    quote: Notably, MiniF2F (Zheng et al., 2022) manually formalizes 488 Olympiad-level problems across 4 proof systems and
      equally splits them into a validation set and a test set.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: NL-PS
    justification: NL-PS is mentioned as a dataset designed for premise selection from natural language.
    quote: NL-PS (Ferreira & Freitas, 2020a) first builds a natural language premise selection dataset sourced from ProofWiki.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: MATcH
    justification: mentioned as a dataset for matching using the MREC corpus.
    quote: MATcH (Li et al., 2023) constructs over 180k statement-proof pairs for matching using the MREC corpus.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: NaturalProofs
    justification: NaturalProofs is referred to as a dataset that includes data from various sources for better diversity.
    quote: Similarly, NaturalProofs (Welleck et al., 2021) further incorporates data from Stacks and textbooks, resulting
      in a dataset with roughly 25k examples.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: NaturalProofs-Gen
    justification: NaturalProofs-Gen is referred to as a variant of NaturalProofs
    quote: Adapted from it, NaturalProofs-Gen (Welleck et al., 2022) contains around 14.5k theorems for informal proof generation.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: PRISM
    justification: PRISM is mentioned as one of the datasets that contain formal theorems and proofs extracted for the Coq
      proof assistant.
    quote: Notable datasets for Coq include Gamepad, CoqGym, and PRISM (Reichel et al., 2023), with CoqGym constructing a
      dataset from 123 projects encompassing 71k proofs.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: ProofNet
    justification: ProofNet is mentioned as a dataset for formalizing IMO and undergraduate-level problems.
    quote: ProofNet (Azerbayev et al., 2023) formalizes the theorem statements of IMO and undergraduate-level problems in
      Lean.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LeanStep
    justification: ''
    quote: LeanStep (Han et al., 2022), LeanDojo (Yang et al., 2023), and MLFMF (Bauer et al., 2023) leverage the mathlib
      library (mathlib Community, 2020) in Lean. In particular, LeanDojo extracts over 98k theorems and proofs with 130k premises
      from mathlib.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LeanDojo
    justification: ''
    quote: LeanStep (Han et al., 2022), LeanDojo (Yang et al., 2023), and MLFMF (Bauer et al., 2023) leverage the mathlib
      library (mathlib Community, 2020) in Lean. In particular, LeanDojo extracts over 98k theorems and proofs with 130k premises
      from mathlib.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: MLFMF
    justification: ''
    quote: LeanStep (Han et al., 2022), LeanDojo (Yang et al., 2023), and MLFMF (Bauer et al., 2023) leverage the mathlib
      library (mathlib Community, 2020) in Lean. In particular, LeanDojo extracts over 98k theorems and proofs with 130k premises
      from mathlib.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: MPTP2078
    justification: ''
    quote: MPTP2078 (Alama et al., 2014)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Mizar40
    justification: ''
    quote: Mizar40 (Kaliszyk & Urban, 2015b)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: M2K
    justification: ''
    quote: M2K (Kaliszyk et al., 2018) for Mizar
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries:
- name:
    value: Coq
    justification: Coq is specifically identified as a proof assistant used extensively in the research.
    quote: Coq (Barras et al., 1999)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: HOL Light
    justification: HOL Light is recognized for its role as a proof assistant in formal theorem proving.
    quote: HOL Light (Harrison, 1996)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Isabelle
    justification: Isabelle is highlighted as a proof assistant utilized in interactive theorem proving.
    quote: Isabelle (Paulson, 1994), HOL Light (Harrison, 1996), Coq (Barras et al., 1999), and Lean (Moura & Ullrich, 2021)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Lean
    justification: Lean is highlighted as one of the major proof assistants used in formal theorem proving.
    quote: Lean (Moura & Ullrich, 2021)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Vampire
    justification: Vampire is described as an automated theorem proving system employed extensively in the field.
    quote: "Saturation-based theorem provers, including E (Schulz, 2002) and Vampire (Kov\xE1\u0301cs & Voronkov, 2013), mainly\
      \ operate on first-order logic (FOL)..."
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: leanCoP
    justification: leanCoP is a tableau-based method referenced for its approach in automated theorem proving.
    quote: Similarly, geometric ATP systems such as GEX (Chou et al., 2000) prove geometry problems by iteratively applying
      deduction rules. Other approaches, such as tableau-based methods like leanCoP (Otten & Bibel, 2003)...
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: leanRoP
    justification: leanRoP is included for its relevance in connection-based theorem proving methods.
    quote: Other approaches, such as tableau-based methods like leanCoP... and connection tableau methods like leanRoP (Gauthier
      et al., 2020), use other forms of proof calculi for proof construction.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: mathlib
    justification: mathlib is mentioned as a significant library used within the Lean proof assistant.
    quote: Lean's mathlib library (mathlib Community, 2020)
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
