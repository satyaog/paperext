title:
  value: Ordered Memory
  justification: Title of the paper as presented in the document
  quote: Ordered Memory
description: The paper proposes the Ordered Memory architecture, inspired by Ordered Neurons. It introduces a new attention-based
  mechanism and a new Gated Recursive Cell (GRC). The Ordered Memory model is evaluated on tasks like logical inference and
  list operations, showing strong performance and the ability to interpret induced tree structures.
type:
  value: empirical
  justification: The paper presents an architecture and evaluates it on several experiments with datasets.
  quote: 'In this paper, we propose a novel architecture: Ordered Memory (OM), which includes a new memory updating mechanism
    and a new Gated Recursive Cell. We demonstrate that our method generalizes for synthetic tasks where the ability to parse
    is crucial to solving them.'
primary_research_field:
  name:
    value: Deep Learning
    justification: The paper proposes a new neural network architecture and evaluates it on deep learning tasks.
    quote: Stack-augmented recurrent neural networks (RNNs) have been of interest to the deep learning community for some
      time.
  aliases: []
sub_research_fields:
- name:
    value: Long-Term Memory
    justification: ''
    quote: ''
  aliases: []
- name:
    value: Recurrent Neural Networks
    justification: ''
    quote: ''
  aliases:
  - RNN
- name:
    value: Memory
    justification: ''
    quote: ''
  aliases: []
- name:
    value: Reinforcement Learning
    justification: ''
    quote: ''
  aliases:
  - RL
models:
- name:
    value: Ordered Neurons
    justification: Mentioned as a model related to the proposed Ordered Memory architecture.
    quote: Ordered Memory is implemented following the principles introduced in Ordered Neurons (Shen et al., 2018). Our model
      is related to ON-LSTM in several aspects
  aliases:
  - ON-LSTM
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: ''
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Ordered Memory
    justification: It is the main contribution of the paper.
    quote: In this paper, we propose the Ordered Memory architecture.
  aliases:
  - OM
  is_contributed:
    value: true
    justification: Role:['contributed', 'used', 'referenced']
    quote: contributed
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: RL-SPINN
    justification: Mentioned as a model related to the proposed Ordered Memory architecture.
    quote: Yogatama et al. (2016) proposes RL-SPINN where the discrete stack operations are directly learned by reinforcement
      learning.
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: 'Figure 3: (a) shows the accuracy of different models on the ListOps dataset. All models have 128 dimensions. Results
      for models with * are taken from Nangia and Bowman (2018). (b) shows our model accuracy on the ListOps task when varying
      the the size of the training set.'
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: RRNet
    justification: Mentioned as a model related to the proposed Ordered Memory architecture.
    quote: The results for RRNet were taken from Jacob et al. (2018).
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: false
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: trained
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Transformer
    justification: Used for comparison in the experiments.
    quote: For the Transformer and Universal Transformer, we follow the entailment architecture introduced in Radford et al.
      (2018).
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: 'Figure 3: (a) shows the accuracy of different models on the ListOps dataset. All models have 128 dimensions. Results
      for models with * are taken from Nangia and Bowman (2018). (b) shows our model accuracy on the ListOps task when varying
      the the size of the training set.'
  is_compared:
    value: true
    justification: ''
    quote: 'Figure 3: (a) shows the accuracy of different models on the ListOps dataset. All models have 128 dimensions. Results
      for models with * are taken from Nangia and Bowman (2018). (b) shows our model accuracy on the ListOps task when varying
      the the size of the training set.'
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Gumbel Tree-LSTM
    justification: Used for comparison in the experiments.
    quote: The TreeCell is a recursive neural network based on the Gated Recursive Cell function proposed in section 3.2.
  aliases:
  - Tree-LSTM
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: "Table 1: Test accuracy of the models, trained on operation lengths of \u2264 6, with their out-of- distribution\
      \ results shown here (lengths 7-12)."
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TreeCell
    justification: ''
    quote: ''
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: "Table 1: Test accuracy of the models, trained on operation lengths of \u2264 6, with their out-of- distribution\
      \ results shown here (lengths 7-12)."
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TreeRNN
    justification: ''
    quote: ''
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: "Table 1: Test accuracy of the models, trained on operation lengths of \u2264 6, with their out-of- distribution\
      \ results shown here (lengths 7-12)."
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Universal Transformer
    justification: Used for comparison in the experiments.
    quote: For the Transformer and Universal Transformer, we follow the entailment architecture introduced in Radford et al.
      (2018).
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: "Table 1: Test accuracy of the models, trained on operation lengths of \u2264 6, with their out-of- distribution\
      \ results shown here (lengths 7-12)."
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: ListOps
    justification: Used to evaluate the model.
    quote: 'We evaluate the tree learning capabilities of our model on two datasets: logical inference (Bowman et al., 2015)
      and ListOps (Nangia and Bowman, 2018).'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Logical Inference
    justification: The Logical Inference dataset is used to evaluate the generalization of the proposed Ordered Memory model.
    quote: 'We evaluate the tree learning capabilities of our model on two datasets: logical inference (Bowman et al., 2015)
      and ListOps (Nangia and Bowman, 2018).'
  aliases:
  - SST-2
  - SST-5
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Stanford Sentiment Treebank
    justification: A subset task from Stanford Sentiment Treebank used in the experiments.
    quote: We also perform experiments on the Stanford Sentiment Treebank, in both binary classification and fine-grained
      settings (SST-2 & SST-5)
  aliases:
  - SST-2
  - SST-5
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries:
- name:
    value: Evalb
    justification: Used to evaluate parsing performance.
    quote: All parsing scores are given by Evalb https://nlp.cs.nyu.edu/evalb/
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
