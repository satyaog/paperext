title:
  value: 'Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal
    Dependencies'
  justification: This is the exact title of the paper as given by the user.
  quote: 'Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal
    Dependencies'
description: This research paper proposes mechanism sparsity regularization as a principle for disentanglement in machine
  learning models. The authors introduce a method to induce disentanglement by simultaneously learning the latent factors
  and the sparse causal graphical model that explains them. They develop a nonparametric identifiability theory to formalize
  this principle and guarantee partial disentanglement by enforcing sparse temporal dependencies and sparse influence from
  auxiliary variables.
type:
  value: empirical
  justification: ''
  quote: ''
primary_research_field:
  name:
    value: Deep Learning
    justification: The paper deals with representation learning and identifiability theory within the context of deep learning
      and causal inference.
    quote: This work introduces a novel principle for disentanglement we call mechanism sparsity regularization, which applies
      when the latent factors of interest depend sparsely on observed auxiliary variables and/or past latent factors. We propose
      a representation learning method that induces disentanglement by simultaneously learning the latent factors and the
      sparse causal graphical model that explains them.
  aliases: []
sub_research_fields:
- name:
    value: Representation Learning
    justification: The paper specifically deals with disentanglement in the context of representation learning, aiming to
      recover latent factors and their causal relations.
    quote: This is closely related to the problem of disentanglement (Bengio et al., 2013; Higgins et al., 2017; Locatello
      et al., 2020) which also aims at extracting interpretable variables from high-dimensional observations, but without
      the emphasis on modelling their causal relations.
  aliases: []
- name:
    value: Disentanglement
    justification: ''
    quote: ''
  aliases: []
- name:
    value: Causal representation learning
    justification: ''
    quote: ''
  aliases: []
- name:
    value: nonlinear independant component analysis
    justification: ''
    quote: ''
  aliases: []
models:
- name:
    value: iVAE
    justification: ''
    quote: ''
  aliases:
  - Identifiable VAE
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: training
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: 'Variational autoencoders and nonlinear ica: A unifying framework'
    justification: ''
    quote: ''
- name:
    value: TCVAE
    justification: ''
    quote: ''
  aliases:
  - Total Correlation Variational Autoencoder
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: training
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: Isolating sources of disentanglement in vaes
    justification: ''
    quote: ''
- name:
    value: SlowVAE
    justification: ''
    quote: ''
  aliases:
  - Total Correlation Variational Autoencoder
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ModelMode:['trained', 'fine-tuned', 'inference']
    quote: training
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: Towards nonlinear disentanglement in natural data with temporal sparse coding
    justification: ''
    quote: ''
datasets:
- name:
    value: Synthetic datasets
    justification: The paper utilizes various synthetic datasets to demonstrate the effectiveness of the proposed methods
      and validate the theoretical results.
    quote: Lastly, we propose an estimation procedure based on variational autoencoders and a sparsity constraint and demonstrate
      it on various synthetic datasets.
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries: []
