title:
  value: Scaling Laws Do Not Scale
  justification: The information is taken directly from the paper's title.
  quote: Scaling Laws Do Not Scale
description: This paper scrutinizes the applicability of AI scaling laws, questioning their universal claims by highlighting
  the dangers of overlooking diverse sub-populations within datasets. It suggests that evaluation metrics are precarious and
  can obscure underperformance or biased outcomes, especially as dataset sizes grow and encapsulate more diverse communities.
type:
  value: theoretical
  justification: The paper is deeply engaged in a theoretical examination of AI scaling laws and their implications, without
    conducting empirical experiments.
  quote: "Our claim is divided into four parts. First, that evaluation metrics re\uFB02ect the composition of the evaluation\
    \ dataset, which is shaped by the sampling approach used to collect that data; second, that the number of sub-groups within\
    \ a given dataset grows with data size; third, those sub-groups can have incompatible values and preferences for appropriate\
    \ evaluation metrics; and fourth, that the risk of that metric incompability grows with dataset size."
primary_research_field:
  name:
    value: Deep Learning
    justification: The paper discusses scaling laws in the context of training large AI models, which is a fundamental topic
      in Deep Learning research. The arguments and recommendations pertain directly to the development and evaluation of deep
      learning systems.
    quote: "Recent work has proposed a power law relationship, referred to as 'scaling laws,' between the performance of artificial\
      \ intelligence (AI) models and aspects of those models\u2019 design (e.g., dataset size)."
  aliases: []
sub_research_fields:
- name:
    value: Evaluation Metrics
    justification: The paper discusses the validity and implications of evaluation metrics in the context of scaling laws
      for AI models, highlighting issues such as metric incompatibility and non-stationarity.
    quote: ''
  aliases: []
- name:
    value: Scaling Laws
    justification: ''
    quote: ''
  aliases: []
- name:
    value: Large Language Models
    justification: ''
    quote: ''
  aliases:
  - LLM
models: []
datasets:
- name:
    value: BBQ Benchmark
    justification: The BBQ Benchmark is discussed as a tool for evaluating biases in AI models, emphasizing the need for context-specific
      metrics to reflect the values of different communities.
    quote: Parrish et al. developed a bias benchmark dataset (BBQ) for question-answering to evaluate the performance of large
      language models.
  aliases:
  - BBQ
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: Colossal Clean Crawled Corpus
    justification: The dataset is used to illustrate examples of large datasets that underpin current scaling laws in AI models.
    quote: "Despite claims that a larger training dataset (e.g., a crawl of the predominantly English-speaking Internet [53])\
      \ will lead to improved model performance, when such models are deployed at scale, the larger numbers of people included\
      \ in the evaluation dataset\u2014and thus a larger number of communities\u2014may lead to breakdowns in model performance\
      \ for di\uFB00erent communities."
  aliases:
  - C4
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: LAION
    justification: The LAION dataset is mentioned in a similar context to C4, discussing the potential biases and representativeness
      challenges inherent in large-scale web crawled datasets.
    quote: Similarly, massive datasets used to train large models, such as the Colossal Clean Crawled Corpus (C4), trained
      on a crawl of the web, or others such as LAION.
  aliases: []
  role: referenced
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries: []
