title:
  value: Unsupervised Layer-wise Score Aggregation for Textual OOD Detection
  justification: Extracted from the title of the paper.
  quote: Unsupervised Layer-wise Score Aggregation for Textual OOD Detection
description: The paper presents a novel unsupervised method for Out-of-Distribution (OOD) detection for textual data by aggregating
  layer-wise anomaly scores from a model's encoder. The authors demonstrate that the last layer's representation is not always
  the most effective for OOD detection and propose an automatic aggregation method to leverage all hidden layers without requiring
  access to OOD samples.
type:
  value: empirical
  justification: The paper involves conducting experiments to evaluate the performance of their proposed method on a new benchmark
    dataset and comparing it with existing methods.
  quote: 'We conduct extensive experiments on our newly proposed benchmark: We introduce MILTOOD-C A MultI Lingual Text OOD
    detection benchmark for Classification tasks'
primary_research_field:
  name:
    value: Out-of-distribution
    justification: ''
    quote: Out-of-distribution (OOD) detection is a rapidly growing field due to new robustness and security requirements
      driven by an increased number of AI-based systems
  aliases:
  - OOD
sub_research_fields:
- name:
    value: Natural Language Processing
    justification: The paper specifically addresses OOD detection in textual data, which falls under the sub-field of Natural
      Language Processing (NLP).
    quote: Although OOD detection has attracted much attention in computer vision (Huang et al. 2022; Wang et al. 2022c; Fang
      et al. 2022), few studies focused on textual data
  aliases:
  - NLP
models:
- name:
    value: BERT
    justification: The experiments involve fine-tuning BERT models for various benchmark tests.
    quote: 'To ensure that our results are consistent not only across tasks and shifts, but also across model architec- tures,
      we train classifiers based on 6 different Transformer (Vaswani et al. 2017) decoders: BERT (Devlin et al.  2018) (base,
      large and multilingual versions), DISTILBERT (Sanh et al. 2019) and RoBERTa (Liu et al. 2019) (base and large versions)
      fine-tuned on each task.'
  aliases:
  - BERT-large
  - BERT-multilingual
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: ''
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: DISTILBERT
    justification: The paper mentions using DISTILBERT models for their experiments.
    quote: 'To ensure that our results are consistent not only across tasks and shifts, but also across model architec- tures,
      we train classifiers based on 6 different Transformer (Vaswani et al. 2017) decoders: BERT (Devlin et al.  2018) (base,
      large and multilingual versions), DISTILBERT (Sanh et al. 2019) and RoBERTa (Liu et al. 2019) (base and large versions)
      fine-tuned on each task.'
  aliases: []
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: ''
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: RoBERTa
    justification: RoBERTa models are used in the experiments as per the detailed mention in the paper.
    quote: 'To ensure that our results are consistent not only across tasks and shifts, but also across model architec- tures,
      we train classifiers based on 6 different Transformer (Vaswani et al. 2017) decoders: BERT (Devlin et al.  2018) (base,
      large and multilingual versions), DISTILBERT (Sanh et al. 2019) and RoBERTa (Liu et al. 2019) (base and large versions)
      fine-tuned on each task.'
  aliases:
  - RoBERTa-large
  is_contributed:
    value: false
    justification: Role:['contributed', 'used', 'referenced']
    quote: used
  is_executed:
    value: true
    justification: ''
    quote: ''
  is_compared:
    value: true
    justification: ''
    quote: ''
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
datasets:
- name:
    value: SetFit/20-newsgroups
    justification: The 20 Newsgroups dataset is mentioned as one of the datasets that the proposed method is evaluated on.
    quote: 'It features three types of IN-DS: sentiment analysis (i.e., SST2 (Socher et al. 2013), IMDB (Maas et al. 2011)),
      topic classification (i.e., 20Newsgroup (Joachims 1996))'
  aliases:
  - 20-newsgroups
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: IMDB
    justification: IMDB dataset is used for evaluation in the paper.
    quote: 'It features three types of IN-DS: sentiment analysis (i.e., SST2 (Socher et al. 2013), IMDB (Maas et al. 2011)),
      topic classification (i.e., 20Newsgroup (Joachims 1996))'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: MILTOOD-C
    justification: MILTOOD-C is the new dataset proposed in the paper for multilingual textual OOD detection.
    quote: We introduce MILTOOD-C A MultI Lingual Text OOD detection benchmark for Classification tasks
  aliases: []
  role: contributed
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SST2
    justification: SST2 is among the datasets used for text classification tasks for evaluation of the proposed method.
    quote: 'It features three types of IN-DS: sentiment analysis (i.e., SST2 (Socher et al. 2013), IMDB (Maas et al. 2011)),
      topic classification (i.e., 20Newsgroup (Joachims 1996))'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: TREC
    justification: ''
    quote: 'We relied on the benchmark proposed by Zhou, Liu, and Chen (2021); Hendrycks et al. (2020). It features three
      types of IN-DS: sentiment analysis (i.e., SST2 (Socher et al. 2013), IMDB (Maas et al. 2011)), topic classi- fication
      (i.e., 20Newsgroup (Joachims 1996)) and question answering (i.e., TREC-10 and TREC-50 (Li and Roth 2002))'
  aliases:
  - TREC-10
  - TREC-50
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: AmazonScience/massive
    justification: ''
    quote: We also included the Massive (FitzGerald et al. 2022) dataset and the Banking (Casanueva et al. 2020) for a larger
      num- ber of classes and NLI datasets (i.e., RTE (Burger and Ferro 2005; Hickl et al. 2006) and MNLI (Williams, Nangia,
      and Bowman 2018)) following Colombo et al. (2022).
  aliases:
  - Massive
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: banking77
    justification: ''
    quote: We also included the Massive (FitzGerald et al. 2022) dataset and the Banking (Casanueva et al. 2020) for a larger
      num- ber of classes and NLI datasets (i.e., RTE (Burger and Ferro 2005; Hickl et al. 2006) and MNLI (Williams, Nangia,
      and Bowman 2018)) following Colombo et al. (2022).
  aliases:
  - Banking
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: RTE
    justification: ''
    quote: We also included the Massive (FitzGerald et al. 2022) dataset and the Banking (Casanueva et al. 2020) for a larger
      num- ber of classes and NLI datasets (i.e., RTE (Burger and Ferro 2005; Hickl et al. 2006) and MNLI (Williams, Nangia,
      and Bowman 2018)) following Colombo et al. (2022).
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: MNLI
    justification: ''
    quote: We also included the Massive (FitzGerald et al. 2022) dataset and the Banking (Casanueva et al. 2020) for a larger
      num- ber of classes and NLI datasets (i.e., RTE (Burger and Ferro 2005; Hickl et al. 2006) and MNLI (Williams, Nangia,
      and Bowman 2018)) following Colombo et al. (2022).
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: HINT3
    justification: ''
    quote: To go one step further in terms of number of classes, we considered HINT3(Arora et al. 2020) and clink (Larson
      et al. 2019a).
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: SefFit/emotion
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: glue
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: super-glue
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: go-emotions
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: clinc-oos
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: xquad
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: catalonia-independence
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: muchocine
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: allocine
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: paws-x
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: swiss-judgment-prediction
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: xnli
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: tweet-sentiment-multilingual
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
- name:
    value: xstance
    justification: ''
    quote: 'Table 3: List of Datasets'
  aliases: []
  role: used
  referenced_paper_title:
    value: ''
    justification: ''
    quote: ''
libraries: []
