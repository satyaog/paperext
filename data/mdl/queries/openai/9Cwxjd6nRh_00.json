{
  "paper": "9Cwxjd6nRh.txt",
  "words": 14326,
  "extractions": {
    "title": {
      "value": "High Fidelity Visualization of What Your Self-Supervised Representation Knows About",
      "justification": "The title reflects the focus of the paper, which is on visualizing and analyzing self-supervised representations using a conditional diffusion model.",
      "quote": "H IGH F IDELITY V ISUALIZATION OF W HAT YOUR S ELF S UPERVISED R EPRESENTATION K NOWS A BOUT"
    },
    "description": "This paper explores a method to visualize and analyze representations learned by self-supervised learning (SSL) models by using a conditional diffusion model (RCDM) to generate images from these representations. The approach allows for high-quality visualization and comparison of SSL and supervised learning representations, offering insights into what information these representations retain or ignore. The paper presents both qualitative and quantitative evaluations of this method, highlighting its advantages in visualizing SSL representations without needing labeled data.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments to evaluate the proposed model's ability to generate realistic images and analyze self-supervised representations through visualization.",
      "quote": "This paper’s main contributions are: • To devise a conditional diffusion model architecture (RCDM)... • To showcase its usefulness for qualitatively analyzing SSL representations and embeddings..."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The research focuses on generating and analyzing images, which is a central task in the field of Computer Vision.",
        "quote": "By contrast, we want to sample images that map as closely as possible to the original image in the representation space, as our focus is to build a tool to analyse SSL representations, to enable visualising what images correspond precisely to a representation."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper specifically discusses self-supervised learning methods and the analysis of their representations.",
          "quote": "A BSTRACT Discovering what is learned by neural networks remains a challenge. In selfsupervised learning, classification is the most common task used to evaluate how good a representation is."
        },
        "aliases": [
          "SSL"
        ]
      },
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper uses a generative model (conditional diffusion model) to generate images from representations.",
          "quote": "For this we build a conditional generative model that (implicitly) models p(x|h) and allows to sample diverse x′ ∼ p(x|h)."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Neural Network Visualization",
          "justification": "The primary contribution is visualizing what the neural network representation knows, which fits into visualization in neural networks.",
          "quote": "The main goal of our work is thus to enable the visualization of representations learned by SSL methods, as a tool to improve our understanding."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Representation-Conditioned Diffusion Model (RCDM)",
          "justification": "The paper introduces RCDM as a novel model for visualizing self-supervised representations.",
          "quote": "This paper’s main contributions are: • To devise a conditional diffusion model architecture (RCDM) suitable for conditioning on large vector representations"
        },
        "aliases": [
          "RCDM"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The RCDM is introduced as a new model in the paper.",
          "quote": "This paper’s main contributions are: • To devise a conditional diffusion model architecture (RCDM)..."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper details experiments where RCDM is used to generate images, indicating execution of the model.",
          "quote": "We trained our RepresentationConditionned Diffusion Model (RCDM)..."
        },
        "is_compared": {
          "value": true,
          "justification": "The RCDM's performance is compared with other models through metrics like FID.",
          "quote": "Our model provides high-quality images, measured in term of FID, on par with state-of-the-art models (Tab. 2a), and is suited for out-of-distribution samples (see Fig. 1)."
        },
        "referenced_paper_title": {
          "value": "Diffusion Models Beat GANs on Image Synthesis",
          "justification": "The architecture of the model, RCDM, is based on the Ablated Diffusion Model by Dhariwal & Nichol referenced in the paper.",
          "quote": "This paper’s main contributions are: • To devise a conditional diffusion model architecture (RCDM)... inspired by Dhariwal & Nichol (2021), for our conditional generative model."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset is used to train and evaluate the generative model.",
          "quote": "We trained our RepresentationConditionned Diffusion Model (RCDM), conditioned on the 2048 dimensional representation given by a Resnet50 (He et al., 2016) trained with Dino (Caron et al., 2021) on ImageNet (Russakovsky et al., 2015)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "The referenced paper is cited as the source of the ImageNet dataset.",
          "quote": "Then we compute the representations of a set of images from ImageNet validation data to condition the sampling from the trained RCDM."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is mentioned as being used for evaluation setup, indicating its role as a utilized library.",
          "quote": "For each method, we computed FID and IS with the same evaluation setup in Pytorch."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "It provides a credible reference for the PyTorch library, although it's not directly quoted in the paper.",
          "quote": "For each method, we computed FID and IS with the same evaluation setup in Pytorch."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1204,
    "prompt_tokens": 22989,
    "total_tokens": 24193,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}