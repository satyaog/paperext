{
  "paper": "ef0a4e3a05a2074967f481f667ee1a7d.txt",
  "words": 4656,
  "extractions": {
    "title": {
      "value": "ENHANCING SUPERVISED VISUALIZATION THROUGH AUTOENCODER AND RANDOM FOREST PROXIMITIES FOR OUT-OF-SAMPLE EXTENSION",
      "justification": "The title is directly stated at the beginning of the paper.",
      "quote": "ENHANCING SUPERVISED VISUALIZATION THROUGH AUTOENCODER AND RANDOM FOREST PROXIMITIES FOR OUT-OF-SAMPLE EXTENSION"
    },
    "description": "The paper introduces a novel method to extend RF-PHATE for out-of-sample data using regularized autoencoder architectures. By integrating random forest proximities and autoencoders, the approach effectively visualizes out-of-sample data while maintaining the qualities of relevant embeddings. The architecture allows for training with reduced data without sacrificing quality and is suitable for semi-supervised learning tasks.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves experiments and comparisons with quantitative assessments of model architectures.",
      "quote": "Through quantitative assessment of various autoencoder architectures, we identify that networks that reconstruct random forest proximities are more robust for the embedding extension problem."
    },
    "primary_research_field": {
      "name": {
        "value": "Dimensionality Reduction",
        "justification": "The paper mainly focuses on improving dimensionality reduction techniques for visualization tasks.",
        "quote": "The value of supervised dimensionality reduction lies in its ability to uncover meaningful connections between data features and labels."
      },
      "aliases": [
        "Supervised Visualization"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Autoencoders",
          "justification": "Autoencoders are central to the proposed methodology for out-of-sample extension.",
          "quote": "We introduce a set of regularized autoencoder (AE) architectures that address out-of-sample extension."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Random Forest Proximities",
          "justification": "The paper integrates regularized autoencoder architectures with random forest proximities.",
          "quote": "complement RF-PHATE’s visualization strengths with the extensibility of AEs to enhance this supervised embedding method."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "RF-PHATE",
          "justification": "RF-PHATE is a method used in the study for supervised embedding and visualization.",
          "quote": "This method, RF-PHATE, is capable of embedding meaningful relationships in a variety of noisy data spaces, such as Raman spectroscopy and COVID-19 patient plasma data."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The method is mentioned as a baseline or comparison in the study, but not a direct contribution of this paper.",
          "quote": "We complement RF-PHATE’s visualization strengths with the extensibility of AEs to enhance this supervised embedding method."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not specify execution details for RF-PHATE within the experiments.",
          "quote": "Our experiments show that the RF-PHATE AE extensions can effectively construct a latent representation that is faithful to the original RF-PHATE algorithm."
        },
        "is_compared": {
          "value": true,
          "justification": "The model is used for comparison with the newly proposed methods and is part of the experimental evaluations.",
          "quote": "We compared the AE architectures using the Mantel test to assess how well each model extends the RF-PHATE embedding to a test set."
        },
        "referenced_paper_title": {
          "value": "Gaining biological insights through supervised data visualization",
          "justification": "The RF-PHATE method is broadly referenced in prior work by the authors.",
          "quote": "J. S. Rhodes, A. Aumon, et al., “Gaining biological insights through supervised data visualization,”"
        }
      },
      {
        "name": {
          "value": "Geometry Regularized Autoencoder (GRAE)",
          "justification": "GRAE is one of the models used as an inspiration for developing the new architectures in this paper.",
          "quote": "We introduce a set of regularized autoencoder (AE) architectures that address out-of-sample extension, taking inspiration from the principles of GRAE."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "While GRAE-like principles are incorporated, the specific model GRAE is employed as a basis rather than a contribution.",
          "quote": "taking inspiration from the principles of GRAE [16] which uses a manifold embedding to regularize the AE."
        },
        "is_executed": {
          "value": true,
          "justification": "The principles of GRAE were implemented to develop the new models and were used in evaluations.",
          "quote": "AE networks that reconstruct pairwise proximities are better suited to extend embeddings than AEs that reconstruct the original data."
        },
        "is_compared": {
          "value": true,
          "justification": "GRAE serves as a baseline comparison against which the new architectures are evaluated.",
          "quote": "The regularized models that reconstruct proximities, rather than the original features, generally produce embedding extensions truer to the original RF-PHATE embeddings."
        },
        "referenced_paper_title": {
          "value": "Geometry regularized autoencoders",
          "justification": "GRAE is cited as one of the foundations of the new model architectures.",
          "quote": "A.F. Duque, S. Morin, G. Wolf, and K.R. Moon, “Geometry regularized autoencoders,” IEEE PAMI, vol. 45, no. 6, pp. 7381–7394, 2022."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Fashion-MNIST",
          "justification": "Fashion-MNIST is explicitly mentioned as a dataset used in the experiments.",
          "quote": "The results are given in Figure 3, which plots these scores across 10 runs using the Fashion-MNIST dataset [23]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms",
          "justification": "The original paper where Fashion-MNIST is introduced is cited in the text.",
          "quote": "H. Xiao, K. Rasul, and R. Vollgraf, “Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,” arXiv, 2017."
        }
      },
      {
        "name": {
          "value": "UCI Machine Learning Repository",
          "justification": "The paper uses multiple datasets from the UCI Machine Learning Repository, which is widely recognized in the machine learning field.",
          "quote": "1 From UCI [22], or otherwise publicly available..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "UCI machine learning repository",
          "justification": "The UCI Repository is explicitly cited in reference.",
          "quote": "D. Dua and C. Graff, “UCI machine learning repository,” 2017, (Accessed on 03/02/2023)."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1339,
    "prompt_tokens": 8977,
    "total_tokens": 10316,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}