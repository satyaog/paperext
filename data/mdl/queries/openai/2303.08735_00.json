{
  "paper": "2303.08735.txt",
  "words": 12052,
  "extractions": {
    "title": {
      "value": "A Bayesian Non--Stationary Heteroskedastic Time Series Model for Multivariate Critical Care Data",
      "justification": "This is the title of the paper as provided by the user",
      "quote": "A Bayesian Non-Stationary Heteroskedastic Time Series Model for Multivariate Critical Care Data"
    },
    "description": "The paper proposes a multivariate GARCH model for non-stationary health time series by modifying the variance of observations in the standard state space model and validates it using synthetic data and real ICU data from Montreal and MIMIC-III datasets.",
    "type": {
      "value": "empirical",
      "justification": "The paper validates the proposed model on synthetic data and real ICU data",
      "quote": "We validate our model on synthetic data, and then use it to analyze a data set obtained from an intensive care unit in a Montreal hospital. We further show that our proposed models offer better performance, in terms of WAIC, than standard state space models."
    },
    "primary_research_field": {
      "name": {
        "value": "Time Series Analysis",
        "justification": "The paper focuses on modeling non-stationary health time series data",
        "quote": "We propose a multivariate GARCH model for non-stationary health time series by modifying the variance of the observations of the standard state space model."
      },
      "aliases": [
        "Time-Series"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Healthcare Analytics",
          "justification": "The paper applies the model to critical care patient data to ensure better patient care and outcome",
          "quote": "Modeling such data accurately would help to ensure better patient care and outcome."
        },
        "aliases": [
          "Healthcare"
        ]
      },
      {
        "name": {
          "value": "Bayesian Inference",
          "justification": "The paper leverages Bayesian methods for inference",
          "quote": "We follow the Bayesian paradigm to perform the inference procedure."
        },
        "aliases": [
          "Bayesian"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GARCH-SSM",
          "justification": "Named in the context of the paper as a combination of GARCH and state space models",
          "quote": "In the bivariate model for HR and BP.\nThe proposed model leverages the conditional nature of both DLMs and GARCH type heteroskedasticity."
        },
        "aliases": [
          "GARCH State Space Model"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The paper proposes this model",
          "quote": "We propose a multivariate GARCH model for non-stationary health time series"
        },
        "is_executed": {
          "value": true,
          "justification": "The model is executed on the datasets in the paper",
          "quote": "We validate our model on synthetic data, and then use it to analyze a data set obtained from an intensive care unit in a Montreal hospital."
        },
        "is_compared": {
          "value": true,
          "justification": "The modelâ€™s performance is compared using WAIC metrics with other state space models",
          "quote": "We further show that our proposed models offer better performance, in terms of WAIC, than standard state space models."
        },
        "referenced_paper_title": {
          "value": "Generalized autoregressive conditional heteroskedasticity",
          "justification": "GARCH is introduced by Bollerslev [22] and therefore references the foundational paper",
          "quote": "The main elaboration deploys the generalized autoregressive conditional heteroskedasticity (GARCH) model [22]."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Montreal ICU dataset",
          "justification": "The name is based on the Montreal  ICU dataset explicitly mentioned in the paper",
          "quote": "Our proposed model and analysis are inspired by data obtained from an intensive care unit (ICU) at the McGill University Health Centre (MUHC), Montreal."
        },
        "aliases": [
          "Montreal ICU"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no direct reference paper mentioned for this dataset",
          "quote": "None"
        }
      },
      {
        "name": {
          "value": "MIMIC-III Waveform Database",
          "justification": "The MIMIC-III Waveform Database is explicitly mentioned in the paper as containing digitized ICU data",
          "quote": "the MIMIC-III Waveform Database [23, 24]. The MIMIC-III Waveform Database contains digitized ICU data for approximately 30,000 ICU patients."
        },
        "aliases": [
          "MIMIC-III"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "MIMIC-III, a freely accessible critical care database",
          "justification": "The referenced papers are included in the dataset references [23, 24]",
          "quote": "the MIMIC-III Waveform Database [23, 24]. The MIMIC-III Waveform Database contains digitized ICU data for approximately 30,000 ICU patients."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "dlm package in R",
          "justification": "The library is explicitly mentioned in the paper for handling dynamic linear models",
          "quote": "The dlm package in R can fit the standard Bayesian DLM for many of the models indicated above, including models that exhibit mean-reversion, and by changing the form of the matrices F 0 and G at specific time points, can also fit models with structural breaks."
        },
        "aliases": [
          "dlm"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "None",
          "justification": "There is no direct reference paper mentioned for this library",
          "quote": "None"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1063,
    "prompt_tokens": 20675,
    "total_tokens": 21738
  }
}