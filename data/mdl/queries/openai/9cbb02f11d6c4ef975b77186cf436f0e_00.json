{
  "paper": "9cbb02f11d6c4ef975b77186cf436f0e.txt",
  "words": 13037,
  "extractions": {
    "title": {
      "value": "Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers",
      "justification": "The title clearly states the focus of the paper on detecting brittle decisions by leveraging margin consistency in deep robust classifiers.",
      "quote": "Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers"
    },
    "description": "This paper introduces margin consistency as a concept to efficiently detect vulnerable samples in robustly trained deep learning models. The study analyzes robust models on CIFAR10 and CIFAR100 datasets to demonstrate the correlation between input space margins and logit margins, proposing the use of logit margin as a proxy for vulnerability detection of samples. The paper also addresses cases where models lack sufficient margin consistency by learning a pseudo-margin from feature representations. It aims to facilitate scalable methods for assessing adversarial vulnerability in deep neural networks, enhancing their robustness in real-time deployment scenarios.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts comprehensive empirical analysis to demonstrate the margin consistency in various robust models using CIFAR10 and CIFAR100 datasets, and focuses on empirical robustness evaluation through experiments.",
      "quote": "Next, through comprehensive empirical analysis of various robustly trained models on CIFAR10 and CIFAR100 datasets, we show that they indicate high margin consistency with a strong correlation between their input space margins and the logit margins."
    },
    "primary_research_field": {
      "name": {
        "value": "Adversarial Robustness",
        "justification": "The paper focuses on improving adversarial robustness in deep learning models by detecting brittle decisions and non-robust samples.",
        "quote": "Despite extensive research on adversarial training strategies to improve robustness, the decisions of even the most robust deep learning models can still be quite sensitive to imperceptible perturbations..."
      },
      "aliases": [
        "Adversarial Training",
        "Robustness Evaluation"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The paper evaluates models using datasets widely used in computer vision tasks, such as CIFAR10 and CIFAR100.",
          "quote": "Through an extensive empirical investigation of pre-trained models on CIFAR10 and CIFAR100..."
        },
        "aliases": [
          "CV"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet-18",
          "justification": "ResNet-18 is mentioned as one of the models evaluated for margin consistency and adversarial robustness.",
          "quote": "with a few more models that are ResNet-18 (He et al., 2016) models we trained on CIFAR10 with Standard Adversarial Training..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ResNet-18 is utilized as a standard model for evaluation, rather than being an original contribution of this paper.",
          "quote": "ResNet-18 (He et al., 2016) models we trained on CIFAR10..."
        },
        "is_executed": {
          "value": true,
          "justification": "ResNet-18 was executed to evaluate its margin consistency and robustness using adversarial attacks.",
          "quote": "ResNet-18 models we trained on CIFAR10 with Standard Adversarial Training..."
        },
        "is_compared": {
          "value": true,
          "justification": "ResNet-18 is compared numerically with other models for their margin consistency and vulnerability detection performances.",
          "quote": "Empirically investigating pre-trained models on CIFAR10 and CIFAR100..."
        },
        "referenced_paper_title": {
          "value": "Deep residual learning for image recognition",
          "justification": "The referenced paper is the original one that introduced ResNet architectures, which includes ResNet-18.",
          "quote": "ResNet-18 (He et al., 2016)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR10",
          "justification": "CIFAR10 is one of the datasets used for evaluating the margin consistency and adversarial robustness of models in the paper.",
          "quote": "Through comprehensive empirical analysis of various robustly trained models on CIFAR10 and CIFAR100 datasets..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The CIFAR10 dataset was introduced in this referential paper, which is a standard dataset for image classification.",
          "quote": "Krizhevsky, A. Learning multiple layers of features from tiny images. Technical Report TR-2009, University of Toronto, 2009."
        }
      },
      {
        "name": {
          "value": "CIFAR100",
          "justification": "CIFAR100 is used as a dataset for empirical investigations of robustly trained models' margin consistency.",
          "quote": "Through comprehensive empirical analysis of various robustly trained models on CIFAR10 and CIFAR100 datasets..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "CIFAR100, similar to CIFAR10, was introduced by Alex Krizhevsky and is sourced from the same technical report.",
          "quote": "Krizhevsky, A. Learning multiple layers of features from tiny images. Technical Report TR-2009, University of Toronto, 2009."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is commonly used for adversarial training and deep learning experiments and is likely used for this paper too given the empirical setup described.",
          "quote": "The experimentation was likely conducted using standard machine learning libraries such as PyTorch for training and evaluating robust models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "This paper commonly references PyTorch for the implementation of deep learning models and experiments.",
          "quote": "PyTorch references commonly include 'Automatic differentiation in PyTorch' and related works for such experiments."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1149,
    "prompt_tokens": 27386,
    "total_tokens": 28535,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}