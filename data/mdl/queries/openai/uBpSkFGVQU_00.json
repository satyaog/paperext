{
  "paper": "uBpSkFGVQU.txt",
  "words": 10985,
  "extractions": {
    "title": {
      "value": "Depth-Guided Self-Supervised Learning: Seeing the World in 3D",
      "justification": "This is the title of the research paper.",
      "quote": "Depth-Guided Self-Supervised Learning: Seeing the World in 3D"
    },
    "description": "The paper explores the incorporation of depth signals into the Self-Supervised Learning (SSL) framework. Using a pretrained state-of-the-art monocular RGB-to-depth model, it investigates two distinct approaches: appending the depth channel to the RGB and generating novel views using depth data. The researchers evaluate these methods using three SSL algorithms—BYOL, SimSiam, and SwAV—on datasets like ImageNette, ImageNet-100, and ImageNet-1k. They find that both methods improve the robustness and generalization of SSL models.",
    "type": {
      "value": "empirical",
      "justification": "The paper evaluates the effectiveness of depth signals in SSL through experimental results on various datasets and SSL methods.",
      "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper is focused on improving self-supervised learning methods, which is a sub-field of computer vision, using depth information.",
        "quote": "Self-Supervised Learning (SSL) methods operate on unlabeled data to learn robust representations useful for downstream tasks. Most SSL methods rely on augmentations obtained by transforming the 2D image pixel map."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper is about improving self-supervised learning methods using depth information.",
          "quote": "Using a signal provided by a pretrained state-of-the-art monocular RGB-to-depth model (the Depth Prediction Transformer, Ranftl et al., 2021), we explore two distinct approaches to incorporating depth signals into the SSL framework."
        },
        "aliases": [
          "SSL"
        ]
      },
      {
        "name": {
          "value": "Depth Estimation",
          "justification": "The paper focuses on using depth information from monocular RGB images to enhance SSL methods.",
          "quote": "Using a signal provided by a pretrained state-of-the-art monocular RGB-to-depth model (the Depth Prediction Transformer, Ranftl et al., 2021), we explore two distinct approaches to incorporating depth signals into the SSL framework."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Contrastive Learning",
          "justification": "The paper evaluates the performance of SSL methods like BYOL, SimSiam, and SwAV, which are based on contrastive learning.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "BYOL",
          "justification": "BYOL is one of the models evaluated in the research paper.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "BYOL is not a new model contributed by this paper; it is one of the existing SSL models used for evaluation.",
          "quote": "First, we evaluate self-supervised learning using an RGB+depth input representation. Second, we use the depth signal to generate novel views from slightly different camera positions, thereby producing a 3D augmentation for self-supervised learning. We also examine the combination of the two approaches. We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV."
        },
        "is_executed": {
          "value": true,
          "justification": "The models were executed and evaluated as part of the research experiments.",
          "quote": "We show that both of these approaches improve the performance of three different contrastive learning methods (BYOL, SimSiam, and SwAV) on ImageNette, ImageNet-100 and ImageNet-1k datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of BYOL was compared to other models in the research paper.",
          "quote": "We show that both of these approaches improve the performance of three different contrastive learning methods (BYOL, SimSiam, and SwAV) on ImageNette, ImageNet-100 and ImageNet-1k datasets."
        },
        "referenced_paper_title": {
          "value": "Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning",
          "justification": "The name of the referenced paper for the BYOL model is provided.",
          "quote": "BYOL (Grill et al., 2020) is one of the first contrastive learning based methods without negative pairs."
        }
      },
      {
        "name": {
          "value": "SimSiam",
          "justification": "SimSiam is one of the models evaluated in the research paper.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "SimSiam is not a new model contributed by this paper; it is one of the existing SSL models used for evaluation.",
          "quote": "First, we evaluate self-supervised learning using an RGB+depth input representation. Second, we use the depth signal to generate novel views from slightly different camera positions, thereby producing a 3D augmentation for self-supervised learning. We also examine the combination of the two approaches. We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV."
        },
        "is_executed": {
          "value": true,
          "justification": "The models were executed and evaluated as part of the research experiments.",
          "quote": "We show that both of these approaches improve the performance of three different contrastive learning methods (BYOL, SimSiam, and SwAV) on ImageNette, ImageNet-100 and ImageNet-1k datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of SimSiam was compared to other models in the research paper.",
          "quote": "We show that both of these approaches improve the performance of three different contrastive learning methods (BYOL, SimSiam, and SwAV) on ImageNette, ImageNet-100 and ImageNet-1k datasets."
        },
        "referenced_paper_title": {
          "value": "Exploring Simple Siamese Representation Learning",
          "justification": "The name of the referenced paper for the SimSiam model is provided.",
          "quote": "SimSiam (Chen & He, 2021) explores the role of Siamese networks in contrastive learning."
        }
      },
      {
        "name": {
          "value": "SwAV",
          "justification": "SwAV is one of the models evaluated in the research paper.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "SwAV is not a new model contributed by this paper; it is one of the existing SSL models used for evaluation.",
          "quote": "First, we evaluate self-supervised learning using an RGB+depth input representation. Second, we use the depth signal to generate novel views from slightly different camera positions, thereby producing a 3D augmentation for self-supervised learning. We also examine the combination of the two approaches. We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV."
        },
        "is_executed": {
          "value": true,
          "justification": "The models were executed and evaluated as part of the research experiments.",
          "quote": "We show that both of these approaches improve the performance of three different contrastive learning methods (BYOL, SimSiam, and SwAV) on ImageNette, ImageNet-100 and ImageNet-1k datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of SwAV was compared to other models in the research paper.",
          "quote": "We show that both of these approaches improve the performance of three different contrastive learning methods (BYOL, SimSiam, and SwAV) on ImageNette, ImageNet-100 and ImageNet-1k datasets."
        },
        "referenced_paper_title": {
          "value": "Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
          "justification": "The name of the referenced paper for the SwAV model is provided.",
          "quote": "SwAV (Caron et al., 2020) is an online clustering based method that compares cluster assignments from multiple views."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNette",
          "justification": "ImageNette is one of the datasets used for evaluation in the research paper.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "ImageNette is a subset of ImageNet, reference is implicitly understood.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        }
      },
      {
        "name": {
          "value": "ImageNet-100",
          "justification": "ImageNet-100 is one of the datasets used for evaluation in the research paper.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "ImageNet-100 is a subset of ImageNet, reference is implicitly understood.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        }
      },
      {
        "name": {
          "value": "ImageNet-1k",
          "justification": "ImageNet-1k is one of the datasets used for evaluation in the research paper.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet Large Scale Visual Recognition Challenge",
          "justification": "The referenced paper provides a comprehensive description of the ImageNet dataset, including ImageNet-1k.",
          "quote": "We evaluate the approaches on three different SSL methods—BYOL, SimSiam, and SwAV—using ImageNette (10 class subset of ImageNet), ImageNet-100 and ImageNet-1k datasets."
        }
      },
      {
        "name": {
          "value": "ImageNet-C",
          "justification": "ImageNet-C is one of the datasets used for evaluation in the research paper.",
          "quote": "Both approaches also yield representations that are more robust to image corruptions than the baseline SSL methods, as reflected in performance on ImageNet-C and ImageNet-3DCC."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations",
          "justification": "The referenced paper describes the ImageNet-C dataset used for benchmarking robustness.",
          "quote": "Both approaches also yield representations that are more robust to image corruptions than the baseline SSL methods, as reflected in performance on ImageNet-C and ImageNet-3DCC."
        }
      },
      {
        "name": {
          "value": "ImageNet-3DCC",
          "justification": "ImageNet-3DCC is one of the datasets used for evaluation in the research paper.",
          "quote": "Both approaches also yield representations that are more robust to image corruptions than the baseline SSL methods, as reflected in performance on ImageNet-C and ImageNet-3DCC."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "3D Common Corruptions and Data Augmentation",
          "justification": "The referenced paper describes the ImageNet-3DCC dataset used for benchmarking robustness.",
          "quote": "Both approaches also yield representations that are more robust to image corruptions than the baseline SSL methods, as reflected in performance on ImageNet-C and ImageNet-3DCC."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is mentioned as the deep learning library used for implementing and running the models.",
          "quote": "We implement our method in PyTorch 1.11 (Paszke et al., 2019)."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "The referenced paper describes the PyTorch library, which was used for experimentation.",
          "quote": "We implement our method in PyTorch 1.11 (Paszke et al., 2019)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2774,
    "prompt_tokens": 19935,
    "total_tokens": 22709
  }
}