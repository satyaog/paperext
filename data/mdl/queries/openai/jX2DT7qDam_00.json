{
  "paper": "jX2DT7qDam.txt",
  "words": 16041,
  "extractions": {
    "title": {
      "value": "Jointly-Learned Exit and Inference for a Dynamic Neural Network: JEI-DNN",
      "justification": "The title clearly indicates the novel aspect of the research, which is the joint learning approach for dynamic neural networks.",
      "quote": "J OINTLY-L EARNED E XIT AND I NFERENCE FOR A DYNAMIC N EURAL N ETWORK : JEI-DNN"
    },
    "description": "The paper introduces a novel joint learning procedure for Early-Exit Dynamic Neural Networks (EEDNs) called JEI-DNN. The approach addresses the train-test mismatch and provides better uncertainty characterization. It involves joint training of gating mechanisms and intermediate inference modules on fixed backbone networks, aiming to optimize both accuracy and inference cost.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical results comparing the JEI-DNN method to other state-of-the-art methods on various datasets, demonstrating its performance and improvements.",
      "quote": "We show empirically that the approach leads to a better overall inference/performance trade-off."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper focuses on improving computational efficiency in neural networks applied to visual tasks such as image classification, which is a key area in Computer Vision.",
        "quote": "We use the vision transformers T2T-ViT-7 and T2T-ViT-14 pretrained on the ImageNet dataset..."
      },
      "aliases": [
        "CV"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Dynamic Neural Networks",
          "justification": "The research is primarily focused on dynamic execution within neural networks, specifically through early-exit mechanisms.",
          "quote": "Early-exit dynamic networks (EEDNs) tailor their depth to the sample, allowing easy-to-infer samples to exit at shallower layers."
        },
        "aliases": [
          "EEDN"
        ]
      },
      {
        "name": {
          "value": "Uncertainty Characterization",
          "justification": "A significant aspect of the research is the use of the model for providing reliable uncertainty sources like conformal intervals and well-calibrated predicted probabilities.",
          "quote": "The architecture produces reliable uncertainty characterization in the form of conformal intervals and well-calibrated predicted probabilities."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Vision Transformers",
          "justification": "The study uses Vision Transformers as the backbone model, specifically in the application of the JEI-DNN framework.",
          "quote": "We use the vision transformers T2T-ViT-7 and T2T-ViT-14 pretrained on the ImageNet dataset..."
        },
        "aliases": [
          "ViT"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "JEI-DNN",
          "justification": "The JEI-DNN model is the main contribution of the paper, introducing a joint learning framework for EEDN architectures.",
          "quote": "We propose a novel learning procedure for the GMs and IMs given a fixed backbone network. Our approach involves joint training..."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The paper presents JEI-DNN as a newly proposed model method for dynamic neural networks.",
          "quote": "We propose a novel learning procedure for the GMs and IMs given a fixed backbone network."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was actually implemented and tested on various datasets using GPU-optimized methods.",
          "quote": "See Appendix 9.3 for details on computation of the inference cost and ECE."
        },
        "is_compared": {
          "value": true,
          "justification": "JEI-DNN's performance is evaluated and compared against several state-of-the-art models in terms of accuracy and cost efficiency.",
          "quote": "Our suggested approach significantly outperforms the baselines for all datasets."
        },
        "referenced_paper_title": {
          "value": "Not Provided",
          "justification": "JEI-DNN is presented as a new method specifically in this paper, so there isn't a previously referenced paper title for it.",
          "quote": "We propose a novel learning procedure for the GMs and IMs given a fixed backbone network."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ImageNet",
          "justification": "The paper mentions ImageNet as one of the datasets used for empirical evaluation of JEI-DNN.",
          "quote": "We use the vision transformers T2T-ViT-7 and T2T-ViT-14 pretrained on the ImageNet dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A large-scale hierarchical image database",
          "justification": "The dataset is a well-known benchmark in Computer Vision research, often used and referenced in related works.",
          "quote": "Imagenet: A large-scale hierarchical image database. In Proc. IEEE/CVF Conf. on Computer Vision and Pattern Recognit. (CVPR), 2009."
        }
      },
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is used for benchmarking the JEI-DNN model's performance as per the experimental results.",
          "quote": "We use the vision transformers T2T-ViT-7... which we then transfer-learn to the datasets: CIFAR10, CIFAR100..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images.",
          "justification": "CIFAR-10 is a widely used benchmark in computer vision, referenced for its standard use.",
          "quote": "Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009."
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is mentioned as one of the datasets for the model evaluation.",
          "quote": "We use the vision transformers T2T-ViT-7... which we then transfer-learn to the datasets: CIFAR10, CIFAR100..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images.",
          "justification": "CIFAR-100, like CIFAR-10, is a recognized dataset in the field, often used for experimental validation.",
          "quote": "Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009."
        }
      },
      {
        "name": {
          "value": "SVHN",
          "justification": "SVHN dataset is used for performance comparisons of the JEI-DNN method.",
          "quote": "We also use the cropped-digit SVHN dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Reading digits in natural images with unsupervised feature learning.",
          "justification": "SVHN is a notable dataset in digit recognition problems, frequently used as a benchmark.",
          "quote": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading digits in natural images with unsupervised feature learning. In Proc. NIPS..."
        }
      },
      {
        "name": {
          "value": "CIFAR-100-LT",
          "justification": "The paper states using CIFAR-100 with a long-tail distribution for model testing.",
          "quote": "CIFAR100-LT (Krizhevsky, 2009) and SVHN (Netzer et al., 2011)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images.",
          "justification": "CIFAR-100-LT is a variant of the standard CIFAR-100 dataset, commonly referenced in machine learning research.",
          "quote": "Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of Toronto, 2009."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1530,
    "prompt_tokens": 27451,
    "total_tokens": 28981,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}