{
  "paper": "a2d8171c6c3465ca67ece717c1b7cdb2.txt",
  "words": 8182,
  "extractions": {
    "title": {
      "value": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models",
      "justification": "The title clearly indicates the main focus of the paper, which is on the detection of hallucinations in machine translation for both low and high resource languages using large language models.",
      "quote": "Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models"
    },
    "description": "This paper studies hallucination detection in machine translation using large language models and semantic similarity with multilingual embeddings. It explores the performance of different models across 16 language directions, focusing on both high- and low-resource languages.",
    "type": {
      "value": "empirical",
      "justification": "The paper evaluates sentence-level hallucination detection approaches and compares the performance of different models based on empirical data.",
      "quote": "This paper evaluates sentence-level hallucination detection approaches using Large Language Models (LLMs) and semantic similarity within massively multilingual embeddings."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The main focus is on machine translation, which is a significant application domain of Natural Language Processing.",
        "quote": "Detecting hallucinations in Machine Translation (MT) remains a critical challenge..."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Translation",
          "justification": "The core topic of the paper is about detecting hallucinations specifically in machine translation output.",
          "quote": "Detecting hallucinations in Machine Translation (MT) remains a critical challenge..."
        },
        "aliases": [
          "MT"
        ]
      },
      {
        "name": {
          "value": "Large Language Models",
          "justification": "The paper prominently discusses the use of large language models for detection tasks.",
          "quote": "Evaluates sentence-level hallucination detection approaches using Large Language Models (LLMs)"
        },
        "aliases": [
          "LLMs"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Llama3-70B",
          "justification": "The paper evaluates the Llama3-70B model for performance in hallucination detection, noting its comparative effectiveness.",
          "quote": "On average, for HRLs, Llama3-70B outperforms the previous state of the art by as much as 0.16 MCC..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Llama3-70B is mentioned as an evaluated model but not as a contribution of this paper.",
          "quote": "We evaluate OpenAI’s GPT4-turbo and GPT4o; Cohere’s Command R and Command R+; Mistral’s Mistral-8x22b; Anthropic’s Claude Sonnet and Claude Opus and Meta’s Llama3-70B."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was actively used and its performance was assessed as a part of the experimental study.",
          "quote": "For HRLs, on average across directions, the Llama3-70B model significantly surpasses the previous SOTA method..."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares Llama3-70B to other models in terms of performance on the hallucination detection task.",
          "quote": "Llama3-70B surpasses the previous best performing model, BLASER-QE, by 16 points."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no specific reference to a paper as a source of the Llama3-70B model within the document.",
          "quote": "We evaluate OpenAI’s GPT4-turbo and GPT4o; Coher's Command R and Command R+; Mistral's Mistral-8x22b; Anthropic's Claude Sonnet and Claude Opus and Meta's Llama3-70B."
        }
      },
      {
        "name": {
          "value": "Claude Sonnet",
          "justification": "The Claude Sonnet model is evaluated for its performance in low-resource language settings and achieves notable results.",
          "quote": "However, for LRLs we observe that Claude Sonnet outperforms other LLMs on average by 0.03 MCC."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Claude Sonnet is not a contribution of this paper; it is used from external sources for evaluation.",
          "quote": "Evaluates OpenAI’s GPT4-turbo and GPT4o; Cohere’s Command R and Command R+; Mistral’s Mistral-8x22b; Anthropic’s Claude Sonnet and Claude Opus and Meta’s Llama3-70B."
        },
        "is_executed": {
          "value": true,
          "justification": "The performance of Claude Sonnet for hallucination detection in LRL is actively evaluated.",
          "quote": "For LRLs, Claude Sonnet is the best performing model."
        },
        "is_compared": {
          "value": true,
          "justification": "Claude Sonnet is compared with other models based on its MCC scores for LRL tasks.",
          "quote": "For LRLs, Claude Sonnet achieves the highest average MCC."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no specific reference to a paper as a source of the Claude Sonnet model within the document.",
          "quote": "Evaluates OpenAI’s GPT4-turbo and GPT4o; Cohere’s Command R and Command R+; Mistral’s Mistral-8x22b; Anthropic’s Claude Sonnet and Claude Opus and Meta’s Llama3-70B."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "HalOmi benchmark dataset",
          "justification": "HalOmi is explicitly discussed as being used for evaluating hallucination detection in the context of translation.",
          "quote": "We evaluated our methods on the HalOmi dataset."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "HalOmi: A manually annotated benchmark for multilingual hallucination and omission detection in machine translation",
          "justification": "The referenced paper provides the context for the HalOmi dataset used in the research.",
          "quote": "Recently, Dale et al. (2023) introduced HalOmi — a benchmark dataset for detecting hallucination in MT that includes EN↔HRLs and EN↔LRLs."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1232,
    "prompt_tokens": 16126,
    "total_tokens": 17358,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}