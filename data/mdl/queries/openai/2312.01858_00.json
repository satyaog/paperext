{
  "paper": "2312.01858.txt",
  "words": 8582,
  "extractions": {
    "title": {
      "value": "Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness",
      "justification": "Title of the research paper.",
      "quote": "Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness"
    },
    "description": "This study examines the potential of Large Language Models (LLMs) as knowledge bases by emphasizing the need for precise and implication-aware fact editing. It introduces a new evaluation protocol and the DepEdit dataset to comprehensively assess the editing process's compliance with specificity (surface form) and implication awareness (logical implications through If-Then rules). Extensive experiments utilizing the DepEdit dataset highlight current limitations in knowledge editing methods, specifically their sensitivity to fact surface forms and their limited ability to infer logical implications of edited facts.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments and quantitative evaluations using the DepEdit dataset to test different knowledge editing methods.",
      "quote": "Extensive experiments on DepEdit show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on editing and evaluating knowledge within LLMs, which is a core topic in Natural Language Processing.",
        "quote": "The potential of using a large language model (LLM) as a knowledge base (KB) has sparked significant interest."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Knowledge Representation and Reasoning",
          "justification": "The study addresses how LLMs maintain and edit knowledge accurately, considering logical constraints.",
          "quote": "To manage the knowledge acquired by LLMs, we need to ensure that the editing of learned facts respects internal logical constraints, which are known as dependency of knowledge."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Fact-checking",
          "justification": "Fact-checking involves verifying and editing facts, which is central to the paper's focus.",
          "quote": "We propose an evaluation protocol with an accompanying question-answering dataset, DepEdit, that provides a comprehensive assessment of the editing process considering the above notions of dependency."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Machine Learning Evaluation",
          "justification": "The paper develops an evaluation protocol and conducts experiments to assess various machine learning models.",
          "quote": "Extensive experiments on DepEdit show that existing knowledge editing methods are sensitive to the surface form of knowledge, and that they have limited performance in inferring the implications of edited facts."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "BART",
          "justification": "BART is used as a pre-trained model baseline for evaluating knowledge editing methods.",
          "quote": "We used the pre-trained BART-based (Lewis et al., 2020) model from De Cao et al. (2021) as the base model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "BART is used from previous research and not contributed by this paper.",
          "quote": "We used the pre-trained BART-based (Lewis et al., 2020) model from De Cao et al. (2021) as the base model."
        },
        "is_executed": {
          "value": true,
          "justification": "The experiments mentioned in the paper utilized this model.",
          "quote": "We used the pre-trained BART-based (Lewis et al., 2020) model from De Cao et al. (2021) as the base model."
        },
        "is_compared": {
          "value": true,
          "justification": "BART was evaluated and compared with other methods in the study.",
          "quote": "We compare with two pre-trained language models, BART (Lewis et al., 2020) as used by De Cao et al. (2021) and GPT-XL (Radford et al., 2019), which serve as baselines for knowledge editing methods."
        },
        "referenced_paper_title": {
          "value": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
          "justification": "Referenced in the context of BART being used as the base model in this paper.",
          "quote": "We used the pre-trained BART-based (Lewis et al., 2020) model from De Cao et al. (2021) as the base model."
        }
      },
      {
        "name": {
          "value": "GPT-XL",
          "justification": "GPT-XL is used as another pre-trained model baseline for evaluating knowledge editing methods.",
          "quote": "We compare with two pre-trained language models, BART (Lewis et al., 2020) as used by De Cao et al. (2021) and GPT-XL (Radford et al., 2019) as used by Meng et al. (2022b), which serve as baselines for knowledge editing methods."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GPT-XL is used from previous research and not contributed by this paper.",
          "quote": "We compare with two pre-trained language models, BART (Lewis et al., 2020) as used by De Cao et al. (2021) and GPT-XL (Radford et al., 2019) as used by Meng et al. (2022b), which serve as baselines for knowledge editing methods."
        },
        "is_executed": {
          "value": true,
          "justification": "The experiments mentioned in the paper utilized this model.",
          "quote": "We compare with two pre-trained language models, BART (Lewis et al., 2020) as used by De Cao et al. (2021) and GPT-XL (Radford et al., 2019) as used by Meng et al. (2022b), which serve as baselines for knowledge editing methods."
        },
        "is_compared": {
          "value": true,
          "justification": "GPT-XL was evaluated and compared with other methods in the study.",
          "quote": "We compare with two pre-trained language models, BART (Lewis et al., 2020) as used by De Cao et al. (2021) and GPT-XL (Radford et al., 2019) as used by Meng et al. (2022b), which serve as baselines for knowledge editing methods."
        },
        "referenced_paper_title": {
          "value": "Language Models are Unsupervised Multitask Learners",
          "justification": "Referenced in the context of GPT-XL being used as one of the base models in this paper.",
          "quote": "We compare with two pre-trained language models, BART (Lewis et al., 2020) as used by De Cao et al. (2021) and GPT-XL (Radford et al., 2019) as used by Meng et al. (2022b), which serve as baselines for knowledge editing methods."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "DepEdit",
          "justification": "DepEdit is introduced as a new dataset for evaluating knowledge editing in language models.",
          "quote": "We propose an evaluation protocol with an accompanying question-answering dataset, DepEdit, that provides a comprehensive assessment of the editing process considering the above notions of dependency."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "DepEdit is directly contributed by this paper.",
          "quote": "We propose an evaluation protocol with an accompanying question-answering dataset, DepEdit, that provides a comprehensive assessment of the editing process considering the above notions of dependency."
        }
      },
      {
        "name": {
          "value": "zsRE",
          "justification": "zsRE dataset is used as a source for transforming triplets into QA pairs in DepEdit.",
          "quote": "In order to facilitate models’ evaluation based on both specificity and implication awareness, we introduce DepEdit, a new dataset for evaluating edits in language models using the zsRE dataset (Levy et al., 2017)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Zero-Shot Relation Extraction via Reading Comprehension",
          "justification": "Referenced as the source dataset utilized in creating DepEdit.",
          "quote": "In order to facilitate models’ evaluation based on both specificity and implication awareness, we introduce DepEdit, a new dataset for evaluating edits in language models using the zsRE dataset (Levy et al., 2017)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "WikiData query engine",
          "justification": "The WikiData query engine is used for searching potential relations in the zsRE dataset.",
          "quote": "For the new relations not presented in zsRE (Levy et al., 2017), we hired crowd-sourcing workers to transform the triplet (e1 , r1 , e2 ) to a question-answer pair such that we obtain new questions about e1 and r1 , and a corresponding answer e2 ."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Wikidata query engine is mentioned as a tool used in the research process but not as a reference paper.",
          "quote": "For the new relations not presented in zsRE (Levy et al., 2017), we hired crowd-sourcing workers to transform the triplet (e1 , r1 , e2 ) to a question-answer pair such that we obtain new questions about e1 and r1 , and a corresponding answer e2 ."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1875,
    "prompt_tokens": 14602,
    "total_tokens": 16477
  }
}