{
  "paper": "84456f28edf7c52ee1f9ca089707275f.txt",
  "words": 8947,
  "extractions": {
    "title": {
      "value": "Multi-Scale Representation Learning for Protein Fitness Prediction",
      "justification": "The title is clearly mentioned at the beginning of the document.",
      "quote": "Multi-Scale Representation Learning for Protein Fitness Prediction"
    },
    "description": "This paper presents a novel multimodal representation learning framework named Sequence-Structure-Surface Fitness (S3F) model, for protein fitness prediction by integrating sequence, structure, and surface features of proteins. The method shows significant improvements over state-of-the-art models in protein fitness prediction benchmarks by effectively capturing protein features across multiple scales.",
    "type": {
      "value": "empirical",
      "justification": "The paper introduces a new model and evaluates it on benchmarks, indicating empirical research.",
      "quote": "We thoroughly evaluate our methods on the 217 assays from the ProteinGym benchmark, demonstrating their state-of-the-art performance and fast pre-training efficiency (§ 4.2);"
    },
    "primary_research_field": {
      "name": {
        "value": "Protein Representation Learning",
        "justification": "The paper is focused on learning representations of proteins for fitness prediction, which falls under Protein Representation Learning.",
        "quote": "Previous research in protein representation learning has explored diverse modalities including sequences, multiple sequence alignments (MSAs), structures, and surfaces [32, 13, 20, 33]."
      },
      "aliases": [
        "Protein Fitness Prediction"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Deep Mutational Scanning",
          "justification": "The paper evaluates models using deep mutational scanning assays, indicating a focus on this sub-field.",
          "quote": "Our methods are rigorously evaluated using the comprehensive ProteinGym benchmark [31], which includes 217 substitution deep mutational scanning assays."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Multi-Scale Learning",
          "justification": "The paper introduces a multi-scale representation learning framework, indicating a focus on multi-scale learning.",
          "quote": "Our experimental results show that S2F achieves competitive results with prior methods, while S3F reaches state-of-the-art performance after incorporating surface features."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Geometric Deep Learning",
          "justification": "The paper uses Geometric Vector Perceptron networks, pointing to a focus on geometric deep learning.",
          "quote": "GVPs replace standard Multi-Layer Perceptrons (MLPs) in Graph Neural Networks, operating on scalar and geometric features that transform as vectors under spatial coordinate rotations."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Sequence-Structure-Surface Fitness (S3F) model",
          "justification": "The paper introduces the S3F model as a novel contribution to predict protein fitness more accurately by integrating sequence, structure, and surface information.",
          "quote": "In this work, we introduce a multi-scale protein representation learning framework that integrates comprehensive levels of protein information for zero-shot protein fitness prediction."
        },
        "aliases": [
          "S3F"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The S3F model is explicitly presented as the main contribution of the paper.",
          "quote": "To address these limitations, we introduce the Sequence-Structure-Surface Fitness (S3F) model — a novel multimodal representation learning framework."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is executed and benchmarked against existing models, indicating it was run in practice.",
          "quote": "Our experimental results show that S2F achieves competitive results with prior methods, while S3F reaches state-of-the-art performance after incorporating surface features."
        },
        "is_compared": {
          "value": true,
          "justification": "The S3F model is compared against other models like SaProt and TranceptEVE in terms of performance metrics.",
          "quote": "S3F becomes the best model in this category, even outperforming the top alignment-based model, TranceptEVE, by a significant margin in terms of Spearman’s rank correlation."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "There isn’t a specific paper reference provided for S3F as it is presented as a novel contribution of this paper.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Sequence-Structure Fitness (S2F) model",
          "justification": "The paper also introduces the S2F model as a prelude to the S3F model, contributing to the stepwise development of the full feature integration.",
          "quote": "We begin with a Sequence-Structure Fitness Model (S2F) by combining a protein language model with a structure-based encoder."
        },
        "aliases": [
          "S2F"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The S2F model is introduced as part of the study's contributions to integrate sequence and structure features.",
          "quote": "We begin with a Sequence-Structure Fitness Model (S2F) by combining a protein language model with a structure-based encoder."
        },
        "is_executed": {
          "value": true,
          "justification": "The S2F model is tested and compared against benchmarks, indicating its execution.",
          "quote": "S2F achieves competitive results with prior methods."
        },
        "is_compared": {
          "value": true,
          "justification": "The S2F model is compared with other methods like ESM2 and SaProt.",
          "quote": "S2F achieves competitive results with prior methods, while S3F reaches state-of-the-art performance."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Like S3F, S2F is also a contribution of this paper without a specific prior reference.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ProteinGym benchmark",
          "justification": "The ProteinGym benchmark is used to rigorously evaluate the models proposed in the paper.",
          "quote": "Our methods are rigorously evaluated using the comprehensive ProteinGym benchmark [31], which includes 217 substitution deep mutational scanning assays."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ProteinGym: large-scale benchmarks for protein fitness prediction and design",
          "justification": "The paper specifically references the ProteinGym benchmark, indicating a separate reference document.",
          "quote": "Our methods are rigorously evaluated using the comprehensive ProteinGym benchmark [31], which includes 217 substitution deep mutational scanning assays."
        }
      },
      {
        "name": {
          "value": "CATH dataset",
          "justification": "The CATH dataset is utilized for pre-training the models, as mentioned in the methodology.",
          "quote": "These multi-scale protein encoders are pre-trained using a residue type prediction loss on the CATH dataset [30], enabling zero-shot prediction of mutation effects."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "CATH: an expanded resource to predict protein function through structure and sequence",
          "justification": "The paper references the CATH dataset as part of its dataset resources.",
          "quote": "These multi-scale protein encoders are pre-trained using a residue type prediction loss on the CATH dataset [30]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "AlphaFold2",
          "justification": "AlphaFold2 is used for predicting protein structures in the paper.",
          "quote": "We use AlphaFold2 to predict the wild-type structures."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "AlphaFold2 is a well-known existing tool and not tied to a specific newly mentioned research paper in the context of being used here.",
          "quote": "We use AlphaFold2 to predict the wild-type structures."
        }
      },
      {
        "name": {
          "value": "Geometric Vector Perceptron (GVP)",
          "justification": "GVP is explicitly mentioned as being used for geometric message passing in the structure of the model.",
          "quote": "We use Geometric Vector Perceptrons (GVP) [19] to perform message passing across the graph."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning from protein structure with geometric vector perceptrons",
          "justification": "The GVP is a mentioned technique with its referenced paper title as indicated in the text.",
          "quote": "We use Geometric Vector Perceptrons (GVP) [19] to perform message passing across the graph."
        }
      },
      {
        "name": {
          "value": "ESM-2-650M",
          "justification": "ESM-2-650M is used as a protein language model for initializing node features in the sequence-structure encoders.",
          "quote": "Through message passing on structure and surface graphs, our methods, S2F (blue) and S3F (green), accurately predict the residue type distribution at each masked position."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Evolutionary-scale prediction of atomic-level protein structure with a language model",
          "justification": "The paper provides a context which cites ESM-2-650M as an integral part of the methodology, linking the library to a specific referenced paper.",
          "quote": "Through message passing on structure and surface graphs, our methods, S2F (blue) and S3F (green), accurately predict the residue type distribution at each masked position."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1787,
    "prompt_tokens": 16688,
    "total_tokens": 18475,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}