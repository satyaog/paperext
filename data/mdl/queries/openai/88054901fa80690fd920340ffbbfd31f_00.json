{
  "paper": "88054901fa80690fd920340ffbbfd31f.txt",
  "words": 7915,
  "extractions": {
    "title": {
      "value": "Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot",
      "justification": "The title of the paper is clearly mentioned at the beginning of the provided text.",
      "quote": "Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot"
    },
    "description": "This paper introduces a hierarchical reinforcement learning framework aimed at enabling quadrupedal robots to perform precise soccer shooting skills. The framework leverages model-free reinforcement learning to tackle the motion control and motion planning challenges involved in shooting a deformable soccer ball to a specific target using a legged robot. The proposed methodology is validated through real-world experiments with an A1 quadrupedal robot.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments to validate the proposed framework for enabling quadrupedal robots to shoot a soccer ball, hence it is empirical.",
      "quote": "We validate the proposed methodology in real-world experiments using a quadrupedal robot, and demonstrate the feasibility of attaining a robust control policy for dynamic soccer shooting motions."
    },
    "primary_research_field": {
      "name": {
        "value": "Robotics",
        "justification": "The paper primarily deals with robotic applications, specifically focusing on enabling a quadrupedal robot to perform soccer shooting tasks.",
        "quote": "In conclusion, we demonstrate a hierarchical reinforcement learning framework to enable precise soccer shooting skills on quadrupedal robots."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The core methodology used in the paper is based on reinforcement learning techniques.",
          "quote": "In this paper, we propose a hierarchical framework that leverages deep reinforcement learning to train (a) a robust motion control policy that can track arbitrary motions and (b) a planning policy to decide the desired kicking motion."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Robot Learning",
          "justification": "The paper discusses the learning policies for robot control to perform specific tasks.",
          "quote": "Our motion control policy learns various full-body motions in order to track random parametric end-effector (toe) trajectories while maintaining balance during standing."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Sim-to-Real Transfer",
          "justification": "The paper addresses the challenges of transferring reinforcement learning policies from simulation to real-world robots.",
          "quote": "We first focus on training a robust control policy in simulation that can be transferred from simulation to the real world to allow the robot to track arbitrary end-effector trajectories without causing the robot to fall over."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Hierarchical Reinforcement Learning Framework",
          "justification": "This is the primary model introduced and utilized in the paper for the soccer shooting task with the quadrupedal robot.",
          "quote": "The central contribution of this work is the design and development of a hierarchical reinforcement learning frameworks for precise soccer shooting skills using quadrupedal robots."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The hierarchical reinforcement learning framework is introduced and developed within this paper.",
          "quote": "The central contribution of this work is the design and development of a hierarchical reinforcement learning frameworks for precise soccer shooting skills using quadrupedal robots."
        },
        "is_executed": {
          "value": true,
          "justification": "The framework is deployed and tested on a real quadrupedal robot in the paper.",
          "quote": "We validate the proposed methodology in real-world experiments using a quadrupedal robot."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not emphasize numerical comparisons with other models, instead it focuses on the implementation and verification of its own framework.",
          "quote": "In conclusion, we demonstrate a hierarchical reinforcement learning framework to enable precise soccer shooting skills on quadrupedal robots."
        },
        "referenced_paper_title": {
          "value": "Legged robots that keep on learning: Fine-tuning locomotion policies in the real world",
          "justification": "Reference [16] discusses similar domains of learning and adaptations for legged robots, which aligns with the framework proposed in this paper.",
          "quote": "After the control policy is ready, a planning policy Ï€ p is pretrained to plan for desired shooting motion for the controller in order to shoot the ball to the goal. Such a planning policy is firstly trained in simulation with a rigid ball in Stage 2 then fine-tuned in the real world."
        }
      },
      {
        "name": {
          "value": "Proximal Policy Optimization",
          "justification": "PPO is a substantial component of the training methodology for the policies within the proposed hierarchical framework.",
          "quote": "The parameters of the control policy is optimized by Proximal Policy Optimization [34] to maximize the total expected discounted reward in one episode."
        },
        "aliases": [
          "PPO"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Proximal Policy Optimization is a well-known existing algorithm used for training in this paper, not developed within this paper.",
          "quote": "The parameters of the control policy is optimized by Proximal Policy Optimization [34] to maximize the total expected discounted reward in one episode."
        },
        "is_executed": {
          "value": true,
          "justification": "PPO is used to train the control policies in simulation as part of the model development.",
          "quote": "The parameters of the control policy is optimized by Proximal Policy Optimization [34] to maximize the total expected discounted reward in one episode."
        },
        "is_compared": {
          "value": false,
          "justification": "There is no indication of a numerical comparison between PPO and other optimization methods in the text.",
          "quote": "The parameters of the control policy is optimized by Proximal Policy Optimization [34] to maximize the total expected discounted reward in one episode."
        },
        "referenced_paper_title": {
          "value": "Proximal Policy Optimization Algorithms",
          "justification": "This is the reference paper for Proximal Policy Optimization, which is the method used to optimize control policies.",
          "quote": "The parameters of the control policy is optimized by Proximal Policy Optimization [34] to maximize the total expected discounted reward in one episode."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1187,
    "prompt_tokens": 13069,
    "total_tokens": 14256,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}