{
  "paper": "9442665d55ee25103effc343aad8fc20.txt",
  "words": 6407,
  "extractions": {
    "title": {
      "value": "Explaining Graph Neural Networks Using Interpretable Local Surrogates",
      "justification": "This is the title of the paper provided by the user.",
      "quote": "Explaining Graph Neural Networks Using Interpretable Local Surrogates"
    },
    "description": "The paper proposes an interpretable local surrogate (ILS) method for understanding the predictions of black-box graph models.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts comprehensive evaluations and experiments to demonstrate the effectiveness of their proposed method.",
      "quote": "We conduct comprehensive evaluations of our method on both graph-level and node-level experiments, comparing its performance against state-of-the-art explainability methods."
    },
    "primary_research_field": {
      "name": {
        "value": "Graph Neural Networks Explainability",
        "justification": "The primary focus of the paper is on methods to interpret the predictions of graph neural networks (GNNs).",
        "quote": "Graph Neural Network Explainability focuses on developing methods to interpret GNNs, allowing users to trust and comprehend their outputs."
      },
      "aliases": [
        "GNN Explainability",
        "Graph Neural Network Interpretability"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Local Surrogate Models",
          "justification": "The paper primarily focuses on the use of interpretable local surrogate models to approximate the behavior of black-box GNNs.",
          "quote": "We propose an interpretable local surrogate (ILS) method for understanding the predictions of blackbox graph models."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Graph Neural Network",
          "justification": "The focus of the paper is on explaining the predictions of Graph Neural Networks (GNNs).",
          "quote": "Graph Neural networks (GNNs) are neural architectures that are widely used for analyzing data with complex relational structures."
        },
        "aliases": [
          "GNN"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The model is the subject being explained rather than a contribution of this paper.",
          "quote": "In this work, we propose an instance-level graph explainability method named Interpretable Local Surrogates (ILS). ILS approximates the graph black-box model in the local neighbourhood of an instance with an interpretable surrogate that can be probed to explain the prediction."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper conducts empirical evaluations involving GNNs.",
          "quote": "We conduct experiments for explaining GNN models trained on both graph-level and node-level tasks."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of the proposed method is compared against state-of-the-art explainability methods for GNNs.",
          "quote": "We conduct experiments for explaining GNN models trained on both graph-level and node-level tasks, comparing its performance against state-of-the-art explainability methods."
        },
        "referenced_paper_title": {
          "value": "The graph neural network model",
          "justification": "This paper proposes the Graph Neural Network model, forming the basis for the models being explained in the current research.",
          "quote": "Graph Neural networks (GNNs) (Scarselli et al., 2008) are neural architectures that are widely used for analyzing data with complex relational structures."
        }
      },
      {
        "name": {
          "value": "GIN",
          "justification": "GIN (Graph Isomorphism Network) is used as a model for graph-level tasks in the experiments.",
          "quote": "We train a GIN model (Xu et al., 2019) on a BA-GraphR dataset consisting of 1000 graphs with 40 nodes each for the graph classification and regression tasks."
        },
        "aliases": [
          "Graph Isomorphism Network"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "This is not a new model introduced by this paper but an existing one used for evaluation.",
          "quote": "We train a GIN model (Xu et al., 2019) on a BA-GraphR dataset consisting of 1000 graphs with 40 nodes each for the graph classification and regression tasks."
        },
        "is_executed": {
          "value": 1,
          "justification": "GIN is trained and used to generate results for testing the ILS method.",
          "quote": "We train a GIN model (Xu et al., 2019) on a BA-GraphR dataset consisting of 1000 graphs with 40 nodes each for the graph classification and regression tasks."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the ILS method against others using the GIN model.",
          "quote": "In this table ILS is compared with the gradient and PGExplainer baselines."
        },
        "referenced_paper_title": {
          "value": "How powerful are graph neural networks?",
          "justification": "This paper proposes the Graph Isomorphism Network, an important baseline used in the current research.",
          "quote": "We train a GIN model (Xu et al., 2019) on a BA-GraphR dataset consisting of 1000 graphs with 40 nodes each for the graph classification and regression tasks."
        }
      },
      {
        "name": {
          "value": "GCN",
          "justification": "GCN (Graph Convolutional Network) is used as a baseline and for node-level tasks in the experiments.",
          "quote": "In these experiments, we use the trained GCN models used in previous work (Pereira et al., 2023; Luo et al., 2020) as the black-box model."
        },
        "aliases": [
          "Graph Convolutional Network"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "This is an existing model used for evaluation in the study.",
          "quote": "In these experiments, we use the trained GCN models used in previous work (Pereira et al., 2023; Luo et al., 2020) as the black-box model."
        },
        "is_executed": {
          "value": 1,
          "justification": "GCNs are executed to evaluate the ILS method.",
          "quote": "In these experiments, we use the trained GCN models used in previous work (Pereira et al., 2023; Luo et al., 2020) as the black-box model."
        },
        "is_compared": {
          "value": 1,
          "justification": "The ILS method is compared against other methods using the GCN model.",
          "quote": "Despite its simplicity, our method is the best-performing method on all the datasets except for Tree-Cycles and BA-House."
        },
        "referenced_paper_title": {
          "value": "The graph neural network model",
          "justification": "This paper proposes the Graph Neural Network model, forming the basis for GCNs evaluated in the study.",
          "quote": "In these experiments, we use the trained GCN models used in previous work (Pereira et al., 2023; Luo et al., 2020) as the black-box model."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "BA-GraphR",
          "justification": "An original dataset created to test the proposed explainability methods.",
          "quote": "For graph regression, we introduce a novel synthetic dataset that incorporates dependencies on both graph structure and node labels."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "This dataset is introduced in the current paper and has no reference title.",
          "quote": "For graph regression, we introduce a novel synthetic dataset that incorporates dependencies on both graph structure and node labels."
        }
      },
      {
        "name": {
          "value": "BA-House",
          "justification": "BA-House is used for node-level explainability tasks in the experiments.",
          "quote": "BA-House: a random BA graph with 700 nodes where 80 house-shaped motifs of size 5 have been attached with one edge to randomly selected nodes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Parameterized explainer for graph neural network",
          "justification": "This dataset is extensively used for node-level explainability tasks, as referenced in the literature.",
          "quote": "For the node-level explainability task we rely on six datasets that are widely used in other explainability literature."
        }
      },
      {
        "name": {
          "value": "BA-Community",
          "justification": "BA-Community is used for node-level explainability tasks in the experiments.",
          "quote": "BA-Community: two BA-house graphs connected by an edge between two randomly selected nodes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Parameterized explainer for graph neural network",
          "justification": "This dataset is extensively used for node-level explainability tasks, as referenced in the literature.",
          "quote": "For the node-level explainability task we rely on six datasets that are widely used in other explainability literature."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "pytorch geometric",
          "justification": "Pytorch Geometric is used for implementing and running the deep learning experiments.",
          "quote": "In the graph-level experiments, we used built-in function of pytorch geometric explain (Fey & Lenssen, 2019) for PGExplainer."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fast graph representation learning with pytorch geometric",
          "justification": "The reference paper for pytorch geometric used in the study.",
          "quote": "In the graph-level experiments, we used built-in function of pytorch geometric explain (Fey & Lenssen, 2019) for PGExplainer."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 4117,
    "prompt_tokens": 25505,
    "total_tokens": 29622
  }
}