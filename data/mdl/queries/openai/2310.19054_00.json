{
  "paper": "2310.19054.txt",
  "words": 14009,
  "extractions": {
    "title": {
      "value": "OBJECT-CENTRIC ARCHITECTURES ENABLE EFFICIENT CAUSAL REPRESENTATION LEARNING",
      "justification": "The title of the paper is clearly mentioned at the beginning of the document.",
      "quote": "O BJECT- CENTRIC ARCHITECTURES ENABLE EFFICIENT CAUSAL REPRESENTATION LEARNING"
    },
    "description": "The paper discusses how object-centric architectures can be leveraged for causal representation learning, specifically modifying the Slot Attention architecture to disentangle object properties more data-efficiently. Various synthetic experiments are performed to support the claims.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes empirical results on both 2D and 3D synthetic benchmarks to illustrate the performance of the proposed model.",
      "quote": "We illustrate these results by developing a property disentanglement algorithm...and show that our approach is very effective at disentangling the properties of objects on both 2D and 3D synthetic benchmarks."
    },
    "primary_research_field": {
      "name": {
        "value": "Causal Representation Learning",
        "justification": "The paper focuses on causal representation learning using object-centric architectures.",
        "quote": "Causal representation learning has showed a variety of settings in which we can disentangle latent variables with identifiability guarantees."
      },
      "aliases": [
        "CRL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Object-Centric Learning",
          "justification": "The paper leverages object-centric architectures to achieve its goals in causal representation learning.",
          "quote": "In parallel to this line of work, there has been significant progress in the object-centric learning literature... that has developed a suite of architectures that allow us to separate observations into sets of object representations."
        },
        "aliases": [
          "OCL"
        ]
      },
      {
        "name": {
          "value": "Disentanglement",
          "justification": "The paper aims to disentangle object properties using a modified Slot Attention architecture.",
          "quote": "By modifying the Slot Attention architecture... we develop an object-centric architecture that leverages weak supervision from sparse perturbations to disentangle each object’s properties."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Disentangled Slot Attention",
          "justification": "The model 'Disentangled Slot Attention' is mentioned and assessed in the empirical studies presented in the paper.",
          "quote": "We show that it is possible to recover the injective performance by disentangling object-centric representations ('Disentangled Slot Attention')."
        },
        "aliases": [
          "DSA"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The paper introduces modifications to the Slot Attention architecture for better disentanglement.",
          "quote": "By modifying the Slot Attention architecture... we develop an object-centric architecture that leverages weak supervision from sparse perturbations to disentangle each object’s properties."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was run to obtain empirical results on both 2D and 3D synthetic benchmarks.",
          "quote": "We illustrate these results by developing a property disentanglement algorithm... and show that our approach is very effective at disentangling the properties of objects on both 2D and 3D synthetic benchmarks."
        },
        "is_compared": {
          "value": true,
          "justification": "The Disentangled Slot Attention model's performance is compared against other models like Injective ResNet.",
          "quote": "Figure 1 (right) shows that... we show that it is possible to recover the injective performance by disentangling object-centric representations ('Disentangled Slot Attention')."
        },
        "referenced_paper_title": {
          "value": "Object-centric Learning with Slot Attention",
          "justification": "The base Slot Attention architecture, on which the Disentangled Slot Attention is based, is originally proposed in 'Object-centric Learning with Slot Attention'.",
          "quote": "By modifying the Slot Attention architecture (Locatello et al., 2020b)..."
        }
      },
      {
        "name": {
          "value": "SA-MESH",
          "justification": "The paper leverages the SA-MESH object-centric architecture.",
          "quote": "We illustrate these results by developing a property disentanglement algorithm that combines Zhang et al. (2023)’s SA-MESH object-centric architecture with Ahuja et al. (2022b)’s approach to disentanglement."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "SA-MESH is used but not contributed by this paper.",
          "quote": "We illustrate these results by developing a property disentanglement algorithm that combines Zhang et al. (2023)’s SA-MESH object-centric architecture with Ahuja et al. (2022b)’s approach to disentanglement."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is used and executed to develop the property disentanglement algorithm.",
          "quote": "We illustrate these results by developing a property disentanglement algorithm that combines Zhang et al. (2023)’s SA-MESH object-centric architecture with Ahuja et al. (2022b)’s approach to disentanglement."
        },
        "is_compared": {
          "value": true,
          "justification": "The model's performance is implicitly compared as it forms part of the proposed solution.",
          "quote": "We illustrate these results by developing a property disentanglement algorithm that combines Zhang et al. (2023)’s SA-MESH object-centric architecture with Ahuja et al. (2022b)’s approach to disentanglement."
        },
        "referenced_paper_title": {
          "value": "Unlocking Slot Attention by Changing Optimal Transport Costs",
          "justification": "The paper leverages 'Unlocking Slot Attention by Changing Optimal Transport Costs' for the SA-MESH architecture.",
          "quote": "SA-MESH modification of the original Locatello et al. slot attention architecture... for details on the architectures, see Appendix B."
        }
      },
      {
        "name": {
          "value": "Injective ResNet",
          "justification": "The Injective ResNet model is compared against the proposed Disentangled Slot Attention model.",
          "quote": "Figure 1 (right) shows that when the identity of the balls is not distinguishable, the disentanglement performance of a recent approach from Ahuja et al. (2022b) is upper-bounded by 1/k where k is the number of balls."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The Injective ResNet is referenced as a comparative model.",
          "quote": "Figure 1 (right) shows that when the identity of the balls is not distinguishable, the disentanglement performance of a recent approach from Ahuja et al. (2022b) is upper-bounded by 1/k where k is the number of balls."
        },
        "is_executed": {
          "value": false,
          "justification": "It is not explicitly mentioned if the Injective ResNet was executed in the scope of this paper.",
          "quote": "Figure 1 (right) shows that when the identity of the balls is not distinguishable, the disentanglement performance of a recent approach from Ahuja et al. (2022b) is upper-bounded by 1/k where k is the number of balls."
        },
        "is_compared": {
          "value": true,
          "justification": "The Injective ResNet model is compared against the proposed Disentangled Slot Attention model.",
          "quote": "Figure 1 (right) shows that when the identity of the balls is not distinguishable, the disentanglement performance of a recent approach from Ahuja et al. (2022b) is upper-bounded by 1/k where k is the number of balls."
        },
        "referenced_paper_title": {
          "value": "Weakly Supervised Representation Learning with Sparse Perturbations",
          "justification": "The Injective ResNet model is based on the approach in 'Weakly Supervised Representation Learning with Sparse Perturbations'.",
          "quote": "achieves an MCC score of at most k1 where k is the number of objects when colors are selected randomly ('Non-injective ResNet')."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "2D Shapes",
          "justification": "The paper evaluates the model on a synthetic dataset called 2D Shapes.",
          "quote": "We evaluated our method on 2D and 3D synthetic image datasets that allowed us to carefully control various aspects of the environment, such as the number of objects, their sizes, shapes, colors, relative position, and dynamics."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "This is a synthetic dataset created for the experiments in the paper and does not reference another paper.",
          "quote": "We evaluated our method on 2D and 3D synthetic image datasets that allowed us to carefully control various aspects of the environment, such as the number of objects, their sizes, shapes, colors, relative position, and dynamics."
        }
      },
      {
        "name": {
          "value": "3D Shapes",
          "justification": "The paper evaluates the model on a synthetic dataset called 3D Shapes.",
          "quote": "We evaluated our method on 2D and 3D synthetic image datasets that allowed us to carefully control various aspects of the environment, such as the number of objects, their sizes, shapes, colors, relative position, and dynamics."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "This is a synthetic dataset created for the experiments in the paper and does not reference another paper.",
          "quote": "We evaluated our method on 2D and 3D synthetic image datasets that allowed us to carefully control various aspects of the environment, such as the number of objects, their sizes, shapes, colors, relative position, and dynamics."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2279,
    "prompt_tokens": 24135,
    "total_tokens": 26414
  }
}