{
  "paper": "bda11b14491e39a75e6887383e4df104.txt",
  "words": 12842,
  "extractions": {
    "title": {
      "value": "The Factorization Curse: Which Tokens You Predict Underlie the Reversal Curse and More",
      "justification": "The title is clearly stated at the beginning of the document and reflects the main focus of the paper on investigating the factorization curse in language models.",
      "quote": "The Factorization Curse: Which Tokens You Predict Underlie the Reversal Curse and More"
    },
    "description": "This paper investigates the factorization curse in language models, which is framed as a failure to learn the same joint distribution under different factorizations. The study presents a series of controlled experiments, introduces the WikiReversal testbed, and suggests that factorization-agnostic objectives can mitigate the reversal curse, thereby improving knowledge storage and planning capabilities in language models.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts a series of experiments to explore the factorization curse in language models and presents empirical evidence to support the hypotheses.",
      "quote": "To validate our hypothesis and explore potential solutions, we conduct extensive experiments in controlled settings in Section 3.1, focusing on the effects of pretraining objectives on knowledge storage."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper addresses issues in language models related to factorization and information retrieval, which are central topics in the field of Natural Language Processing.",
        "quote": "The reversal curse highlights how language models struggle to reliably retrieve information seen during training given some context."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Language Models",
          "justification": "The paper focuses on the internal mechanisms of language models such as GPT and Llama, discussing their training objectives and retrieval capabilities.",
          "quote": "Through this lens, we show the reversal curse is not merely a failure to learn logical implications, but a more general problem related to learning objectives."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT",
          "justification": "GPT is mentioned as an example of popular large models that use the autoregressive objective contributing to the reversal curse.",
          "quote": "left-to-right next token prediction, autoregressive (AR) objective used in popular large models such as GPT (Radford et al., 2019) and Llama models (Touvron et al., 2023a,b), underlies the reversal curse."
        },
        "aliases": [
          "Generative Pre-trained Transformer"
        ],
        "is_contributed": {
          "value": false,
          "justification": "GPT is cited as a pre-existing model and not as a contribution of this paper.",
          "quote": "left-to-right next token prediction, autoregressive (AR) objective used in popular large models such as GPT (Radford et al., 2019) and Llama models (Touvron et al., 2023a,b), underlies the reversal curse."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper discusses GPT in the context of theoretical contributions rather than execution or experimentation.",
          "quote": "left-to-right next token prediction, autoregressive (AR) objective used in popular large models"
        },
        "is_compared": {
          "value": true,
          "justification": "GPT is compared against other language models in terms of objectives and performance regarding the reversal curse.",
          "quote": "Through this lens, we show the reversal curse is not merely a failure to learn logical implications, but a more general problem related to learning objectives."
        },
        "referenced_paper_title": {
          "value": "Language models are unsupervised multitask learners",
          "justification": "GPT is based on the foundational work documented in 'Language models are unsupervised multitask learners', referenced in the paper.",
          "quote": "Autoregressive (AR) objective used in popular large models such as GPT (Radford et al., 2019)."
        }
      },
      {
        "name": {
          "value": "Llama",
          "justification": "Llama is used as an example of models using autoregressive training, which is a point of discussion in addressing the factorization curse.",
          "quote": "left-to-right next token prediction, autoregressive (AR) objective used in popular large models such as GPT (Radford et al., 2019) and Llama models (Touvron et al., 2023a,b), underlies the reversal curse."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Llama is referenced as a pre-existing model and not as a new contribution in this paper.",
          "quote": "left-to-right next token prediction, autoregressive (AR) objective used in popular large models such as GPT (Radford et al., 2019) and Llama models (Touvron et al., 2023a,b), underlies the reversal curse."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper refers to Llama in the context of theoretical discussion rather than practical execution or new experimental execution.",
          "quote": "left-to-right next token prediction, autoregressive (AR) objective used in popular large models such as GPT and Llama models."
        },
        "is_compared": {
          "value": true,
          "justification": "Llama is compared to other models regarding factorization issues and its impact on information retrieval capabilities.",
          "quote": "Through this lens, we show the reversal curse is not merely a failure to learn logical implications, but a more general problem related to learning objectives."
        },
        "referenced_paper_title": {
          "value": "Llama: Open and efficient foundation language models",
          "justification": "The paper references 'Llama: Open and efficient foundation language models' by Touvron et al. for foundational details about Llama.",
          "quote": "Llama models (Touvron et al., 2023a,b)"
        }
      },
      {
        "name": {
          "value": "WikiReversal",
          "justification": "WikiReversal is introduced as a setting to closely simulate a knowledge-intensive fine-tuning task.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs that closely replicates a knowledge-intensive finetuning application."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "WikiReversal is a new testbed introduced in the paper for studying knowledge retrieval under different token factorizations.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs."
        },
        "is_executed": {
          "value": true,
          "justification": "WikiReversal is used in experiments to test hypotheses about factorization-agnostic objectives.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs that closely replicates a knowledge-intensive finetuning application."
        },
        "is_compared": {
          "value": false,
          "justification": "WikiReversal serves as an experimental setting and is not mentioned as being compared numerically against other models or settings.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs that closely replicates a knowledge-intensive finetuning application."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "WikiReversal is introduced in this paper, not referenced from another source, so there is no reference paper title.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs."
        }
      },
      {
        "name": {
          "value": "Mistral",
          "justification": "Mistral is referenced as a model architecture specifically designed for autoregressive training in the empirical studies conducted.",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019) and Mistral (Jiang et al., 2023)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Mistral is not a new contribution of the paper; it is used for comparison purposes.",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019) and Mistral (Jiang et al., 2023)."
        },
        "is_executed": {
          "value": true,
          "justification": "Mistral is explicitly stated to be used in experiments for autoregressive training.",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019) and Mistral (Jiang et al., 2023)."
        },
        "is_compared": {
          "value": false,
          "justification": "While Mistral is used in experiments, the specific numerical comparisons to other models within the text are not highlighted.",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019) and Mistral (Jiang et al., 2023)."
        },
        "referenced_paper_title": {
          "value": "Mistral 7B",
          "justification": "Mistral is described based on prior work Mistral 7B as referenced in the text for its definition and background.",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019) and Mistral (Jiang et al., 2023)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "BioS",
          "justification": "BioS is used in experiments to study the retrieval capabilities under different training objectives.",
          "quote": "BioS (Zhu & Li, 2023) is a synthetic dataset consisting of biographies for 10k fictional individuals."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Are We Falling in a Middle-Intelligence Trap? An Analysis and Mitigation of the Reversal Curse",
          "justification": "The dataset BioS has been used previously in work by Zhu and Li, referenced for its context in studying language models.",
          "quote": "BioS (Zhu & Li, 2023) is a synthetic dataset consisting of biographies for 10k fictional individuals."
        }
      },
      {
        "name": {
          "value": "GenWiki",
          "justification": "GenWiki is used for generating the WikiReversal dataset, based on real-world text passages and entity annotations from Wikipedia.",
          "quote": "The dataset is derived from the GenWiki corpus based on DBpedia (Jin et al., 2020)"
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "GenWiki: A dataset of 1.3 million content-sharing text and graphs for unsupervised graph-to-text generation",
          "justification": "GenWiki's foundational paper is referenced for providing the base from which the WikiReversal dataset is created.",
          "quote": "The dataset is derived from the GenWiki corpus based on DBpedia (Jin et al., 2020)"
        }
      },
      {
        "name": {
          "value": "WikiReversal",
          "justification": "WikiReversal is the new dataset introduced in the paper to evaluate language models' ability to solve the factorization curse in realistic scenarios.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs that closely replicates a knowledge-intensive finetuning application."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "WikiReversal is a new contribution by the authors, so there is no existing reference paper.",
          "quote": "Section 3.2 introduces WikiReversal, a realistic testbed based on Wikipedia knowledge graphs."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "BERT",
          "justification": "BERT is used for masked language modeling experiments in the paper.",
          "quote": "For masked language modeling (MLM), we use BERT (Devlin et al., 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
          "justification": "The referenced paper 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding' provides background on BERT.",
          "quote": "For masked language modeling (MLM), we use BERT (Devlin et al., 2019)."
        }
      },
      {
        "name": {
          "value": "GPT-2",
          "justification": "GPT-2 is utilized for autoregressive training objectives in the experimental comparisons of the paper.",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Language models are unsupervised multitask learners",
          "justification": "GPT-2 is a continuation and specific instance of the GPT models discussed in 'Language models are unsupervised multitask learners.'",
          "quote": "For autoregressive (AR) training, we use GPT-2 (Radford et al., 2019)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2521,
    "prompt_tokens": 22548,
    "total_tokens": 25069,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}