{
  "paper": "c1241147dab9dd2fd978aa49cdbd82b3.txt",
  "words": 15263,
  "extractions": {
    "title": {
      "value": "ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning",
      "justification": "The title is explicitly mentioned at the beginning of the document.",
      "quote": "ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning"
    },
    "description": "The paper proposes a hierarchical reinforcement learning system named ASHA for assistive teleoperation using human feedback. It focuses on efficiently learning user interfaces to control robots through high-dimensional and noisy inputs like webcam images of eye gaze. The method utilizes offline pre-training and human-in-the-loop online learning to interpret user inputs as desired robot behaviors, addressing challenges of sparse feedback and distributional shifts.",
    "type": {
      "value": "empirical",
      "justification": "The paper investigates the implementation and evaluation of the ASHA system through user studies and empirical testing in simulated environments.",
      "quote": "We evaluate our method primarily through a user study with 12 participants who perform tasks in three simulated robotic manipulation domains."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The primary focus of the paper is on developing a reinforcement learning approach for assistive teleoperation.",
        "quote": "We propose a hierarchical solution that learns efficiently from sparse user feedback: we use offline pre-training..."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Human-Computer Interaction",
          "justification": "The paper addresses interaction between humans and machines, especially with inputs like gaze.",
          "quote": "We aim to train an interface that enables the user to control the robot at test time and perform different tasks..."
        },
        "aliases": [
          "HCI"
        ]
      },
      {
        "name": {
          "value": "Robotics",
          "justification": "The application domain involves controlling robotic arms using innovative interfaces.",
          "quote": "...to perform tasks in three simulated robotic manipulation domains using a webcam and their eye gaze..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The study uses computer vision techniques to interpret webcam images for gaze tracking.",
          "quote": "...using a webcam and their eye gaze to perform tasks..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ASHA",
          "justification": "ASHA is the proposed model developed in the paper for assistive teleoperation using reinforcement learning.",
          "quote": "We call this algorithm ASsistive teleoperation via HumAn-in-the-loop reinforcement learning (ASHA)."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "ASHA is introduced as a novel solution by the authors to address the problem of teleoperation.",
          "quote": "We call this algorithm ASsistive teleoperation via HumAn-in-the-loop reinforcement learning (ASHA)."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper describes the implementation and execution of ASHA in simulated environments.",
          "quote": "We evaluate our method primarily through a user study with 12 participants..."
        },
        "is_compared": {
          "value": true,
          "justification": "ASHA is compared against baseline methods in various user studies described in the paper.",
          "quote": "ASHA increased success rates for the majority of users, compared to a non-adaptive baseline interface."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "ASHA is a new model proposed in this paper itself, so there is no referenced paper title.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Assistive Gym",
          "justification": "Assistive Gym is mentioned as a source of assets for simulating manipulation domains during experiments.",
          "quote": "...tasks in three simulated manipulation domains implemented with the PyBullet real-time physics simulator [44] using assets from Assistive Gym [45]..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Assistive Gym: A physics simulation framework for assistive robotics",
          "justification": "The dataset is used and its referenced paper is mentioned in the citations.",
          "quote": "...using assets from Assistive Gym [45]..."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyBullet",
          "justification": "PyBullet is used in the paper for physics simulation in the experiments.",
          "quote": "...tasks in three simulated manipulation domains implemented with the PyBullet real-time physics simulator [44]..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyBullet, a Python module for physics simulation for games, robotics and machine learning",
          "justification": "The library's referenced paper is mentioned in the citations.",
          "quote": "...implemented with the PyBullet real-time physics simulator [44]..."
        }
      },
      {
        "name": {
          "value": "iTracker",
          "justification": "iTracker is used to process webcam images for gaze tracking in the study.",
          "quote": "...input to a pre-trained iTracker model..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Eye Tracking for Everyone",
          "justification": "The library's referenced paper is mentioned in the citations.",
          "quote": "...feed these as input to a pre-trained iTracker model [62]..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 996,
    "prompt_tokens": 24409,
    "total_tokens": 25405,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}