{
  "paper": "8858dbee4574118b9d520004f41063e1.txt",
  "words": 8299,
  "extractions": {
    "title": {
      "value": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
      "justification": "The authors present a novel method for enhancing Graph Neural Networks (GNNs) using tensor decomposition based pooling and this title directly encapsulates their proposed methodology.",
      "quote": "We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture relying on tensor decomposition to model high-order non-linear node interactions."
    },
    "description": "The paper proposes the Tensorized Graph Neural Network (tGNN), an advanced Graph Neural Network architecture that enhances pooling operations by incorporating tensor decomposition, specifically leveraging symmetric CP decomposition to effectively model high-order non-linear interactions among nodes. The authors provide both theoretical grounding and empirical evidence of tGNN's superior effectiveness on node and graph classification tasks, particularly highlighting improvements on OGB datasets.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes experimental results on real-world datasets to evaluate the performance of the proposed model, indicating an empirical nature to test their theoretical contributions.",
      "quote": "We evaluate tGNN on both node and graph classification tasks. Experimental results on real-world large-scale datasets show that our proposed architecture outperforms or can compete with existing state-of-the-art approaches."
    },
    "primary_research_field": {
      "name": {
        "value": "Graph Neural Networks",
        "justification": "The research is focused on improving the capabilities of Graph Neural Networks through enhanced pooling methods.",
        "quote": "Graph Neural Networks (GNNs) are attracting growing attention due to their effectiveness and flexibility in modeling a variety of graph-structured data."
      },
      "aliases": [
        "GNNs"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Tensor Networks",
          "justification": "The paper leverages tensor decomposition methods to enhance Graph Neural Networks, thus connecting to research in tensor networks.",
          "quote": "We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture relying on tensor decomposition to model high-order non-linear node interactions."
        },
        "aliases": [
          "Tensor Decomposition"
        ]
      },
      {
        "name": {
          "value": "Node Classification",
          "justification": "One of the tasks evaluated using tGNN is node classification, making it a significant subfield of study in this paper.",
          "quote": "Theoretical and empirical analysis on both node and graph classification tasks show the superiority of tGNN over competitive baselines."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Graph Classification",
          "justification": "The paper evaluates the performance of their proposed architecture on graph classification tasks, using large-scale datasets.",
          "quote": "We evaluate tGNN on both node and graph classification tasks."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GCN",
          "justification": "GCN is mentioned as part of the comparison of existing GNN architectures.",
          "quote": "Many GNN architectures (e.g., GCN [26], GAT [45], MPNN [16]) have been proposed."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The model is mentioned as part of the existing models for comparison purposes, not contributed by the paper.",
          "quote": "Existing GNN architectures usually adopt simple pooling operations."
        },
        "is_executed": {
          "value": false,
          "justification": "GCN is not executed by the authors but is used as a comparative baseline.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GCN."
        },
        "is_compared": {
          "value": true,
          "justification": "GCN was explicitly compared to the tGNN model.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GCN."
        },
        "referenced_paper_title": {
          "value": "Semi-supervised classification with graph convolutional networks",
          "justification": "The acronym GCN corresponds to the model introduced in 'Semi-supervised classification with graph convolutional networks'.",
          "quote": "GCN [26] successfully define convolutions on graph-structured data by averaging node information in a neighborhood."
        }
      },
      {
        "name": {
          "value": "GAT",
          "justification": "GAT is listed among the existing architectures for graph neural networks, which the paper compares with their proposed model.",
          "quote": "Many GNN architectures (e.g., GCN [26], GAT [45], MPNN [16]) have been proposed."
        },
        "aliases": [
          "Graph Attention Networks"
        ],
        "is_contributed": {
          "value": false,
          "justification": "GAT is used for comparison, not an original contribution of this work.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GAT."
        },
        "is_executed": {
          "value": false,
          "justification": "GAT is not executed directly but referenced for baseline comparison.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GAT."
        },
        "is_compared": {
          "value": true,
          "justification": "GAT is used as a comparative baseline model against tGNN.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GAT."
        },
        "referenced_paper_title": {
          "value": "Graph attention networks",
          "justification": "GAT stands for Graph Attention Networks, introduced in the paper titled 'Graph attention networks'.",
          "quote": "GAT [45] successfully define convolutions on graph-structured data by averaging node information in a neighborhood."
        }
      },
      {
        "name": {
          "value": "GraphSAGE",
          "justification": "GraphSAGE is among the models discussed in the context of graph representation learning for comparison.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GraphSAGE."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GraphSAGE is a pre-existing model used for comparison.",
          "quote": "We compare tGNN with several classic baseline models... and GraphSAGE."
        },
        "is_executed": {
          "value": false,
          "justification": "GraphSAGE was not executed in the author's experiments, only referenced for comparison.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GraphSAGE."
        },
        "is_compared": {
          "value": true,
          "justification": "GraphSAGE is explicitly compared to the tGNN model.",
          "quote": "We compare tGNN with classic baseline models under the same training setting, including GraphSAGE."
        },
        "referenced_paper_title": {
          "value": "Inductive Representation Learning on Large Graphs",
          "justification": "GraphSAGE refers to the method introduced and studied in 'Inductive Representation Learning on Large Graphs'.",
          "quote": "GraphSAGE [19] applies inductive representation learning on large graphs."
        }
      },
      {
        "name": {
          "value": "tGNN",
          "justification": "tGNN stands for Tensorized Graph Neural Network, which is the primary contribution of the paper.",
          "quote": "We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture relying on tensor decomposition to model high-order non-linear node interactions."
        },
        "aliases": [
          "Tensorized Graph Neural Network"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The model, tGNN, is introduced and empirically tested in this paper.",
          "quote": "We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture."
        },
        "is_executed": {
          "value": true,
          "justification": "The tGNN model was executed and tested on various datasets within the study.",
          "quote": "We evaluate tGNN on both node and graph classification tasks."
        },
        "is_compared": {
          "value": true,
          "justification": "tGNN is compared with various classic baseline models to demonstrate its effectiveness.",
          "quote": "We compare tGNN with classic baseline models under the same training setting."
        },
        "referenced_paper_title": {
          "value": "High-Order Pooling for Graph Neural Networks with Tensor Decomposition",
          "justification": "tGNN is the model introduced by the paper itself.",
          "quote": "We propose the Tensorized Graph Neural Network (tGNN), a highly expressive GNN architecture."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Cora",
          "justification": "Cora dataset is mentioned in the context of evaluating the proposed model, tGNN, on real-world data for node-level tasks.",
          "quote": "In this work, we conduct experiments on three citation networks (Cora, Citeseer, Pubmed) and three OGB datasets (PRODUCTS, ARXIV, PROTEINS) for node-level tasks."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Comprehensive Survey on Graph Neural Networks",
          "justification": "The dataset's usage is not accompanied by reference to a specific paper; it is well-known as a benchmark dataset for graph-based learning tasks.",
          "quote": "In this work, we conduct experiments on three citation networks (Cora, Citeseer, Pubmed) for node-level tasks."
        }
      },
      {
        "name": {
          "value": "Citeseer",
          "justification": "Citeseer is used for evaluating the model's performance in node-level tasks.",
          "quote": "In this work, we conduct experiments on three citation networks (Cora, Citeseer, Pubmed) and three OGB datasets for node-level tasks."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Comprehensive Survey on Graph Neural Networks",
          "justification": "The dataset's usage is standard in graph-based learning communities and was mentioned without specific reference.",
          "quote": "In this work, we conduct experiments on three citation networks (Cora, Citeseer, Pubmed) for node-level tasks."
        }
      },
      {
        "name": {
          "value": "Pubmed",
          "justification": "Part of the three citation networks used for testing tGNN, focusing on node-level tasks, emphasizing its common use for this purpose.",
          "quote": "In this work, we conduct experiments on three citation networks (Cora, Citeseer, Pubmed) for node-level tasks."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Comprehensive Survey on Graph Neural Networks",
          "justification": "It is implied that Pubmed is a common benchmark dataset, therefore not directly referenced to a specific paper in this study.",
          "quote": "In this work, we conduct experiments on three citation networks (Cora, Citeseer, Pubmed) for node-level tasks."
        }
      },
      {
        "name": {
          "value": "OGB Datasets",
          "justification": "OGB datasets including PRODUCTS, ARXIV, and PROTEINS are mentioned as part of the node-level task experiments demonstrating the dataset's role in testing model efficiency.",
          "quote": "For node-level tasks, one OGB dataset (MolHIV) and three OGB datasets (PRODUCTS, ARXIV, PROTEINS) were used."
        },
        "aliases": [
          "Open Graph Benchmark"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
          "justification": "The OGB datasets are utilized widely and are referenced by papers dealing with these datasets.",
          "quote": "For node-level tasks, one OGB dataset (MolHIV) and three OGB datasets (PRODUCTS, ARXIV, PROTEINS) were used."
        }
      },
      {
        "name": {
          "value": "MolHIV",
          "justification": "MolHIV is used in the context of evaluating the model performance on graph-level tasks highlighting its importance for this purpose.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
          "justification": "MolHIV is part of the Open Graph Benchmark, signifying its use in the graph-focused segment of the study.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        }
      },
      {
        "name": {
          "value": "ZINC",
          "justification": "ZINC is specifically mentioned when addressing graph-level tasks for performance evaluation of tGNN.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking Graph Neural Networks",
          "justification": "ZINC dataset is included in standard datasets for testing graph neural networks.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        }
      },
      {
        "name": {
          "value": "CIFAR10",
          "justification": "CIFAR10 is included as part of the graph-level task evaluation datasets for benchmarking the proposed model.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking Graph Neural Networks",
          "justification": "CIFAR10 is part of the benchmark datasets used in this study for graph-level tasks.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        }
      },
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST appears as a dataset within graph-level experimental evaluation, illustrating its application in testing the architecture's efficiency.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Benchmarking Graph Neural Networks",
          "justification": "MNIST is referenced as a dataset for evaluating graph neural networks in graph-level tasks.",
          "quote": "For graph-level tasks, one OGB dataset (MolHIV) and three benchmarking datasets (ZINC, CIFAR10, MNIST) were used."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2806,
    "prompt_tokens": 15874,
    "total_tokens": 18680,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}