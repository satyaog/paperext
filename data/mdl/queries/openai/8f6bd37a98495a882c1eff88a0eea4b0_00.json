{
  "paper": "8f6bd37a98495a882c1eff88a0eea4b0.txt",
  "words": 6948,
  "extractions": {
    "title": {
      "value": "Perfectly Accurate Membership Inference by a Dishonest Central Server in Federated Learning",
      "justification": "The title is explicitly indicated at the beginning of the document.",
      "quote": "Perfectly Accurate Membership Inference by a Dishonest Central Server in Federated Learning"
    },
    "description": "The paper discusses a membership inference attack algorithm for a dishonest central server in federated learning, leveraging models with ReLU activations for perfect accuracy. It evaluates this method on visual classification tasks using MNIST, CIFAR10, CIFAR100, and CelebA datasets, achieving perfect accuracy in identifying training samples.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves empirical evaluation of the membership inference attack algorithm on datasets such as MNIST, CIFAR10, CIFAR100, and CelebA.",
      "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets show that our method provides perfect accuracy..."
    },
    "primary_research_field": {
      "name": {
        "value": "Federated Learning",
        "justification": "The research primarily focuses on privacy issues and membership inference attacks within the framework of Federated Learning.",
        "quote": "We are interested in the privacy aspect of this setup from the client’s point of view. In particular, we want to study the membership inference problem, where the CS wants to learn whether a particular training sample is present in the training data."
      },
      "aliases": [
        "FL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Privacy",
          "justification": "The focus on privacy in federated learning is evident from the frequent mention of privacy guarantees and threats.",
          "quote": "Federated Learning is expected to provide strong privacy guarantees... In this work, we study the privacy risk for a participant in a FL system, that results from a dishonest CS."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The empirical evaluation involves visual classification tasks, typical of the field of Computer Vision.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ReLU Neural Networks",
          "justification": "ReLU activations are employed in their models, crucial to the attack strategy discussed.",
          "quote": "Our strategy is applicable to models with ReLU activations and uses the properties of this activation function to achieve perfect accuracy."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The focus is more on utilizing existing models with ReLU activations rather than contributing a new model.",
          "quote": "Our strategy is applicable to models with ReLU activations..."
        },
        "is_executed": {
          "value": false,
          "justification": "The execution details regarding CPU or GPU usage are not discussed in the paper.",
          "quote": "Our strategy is applicable to models with ReLU activations..."
        },
        "is_compared": {
          "value": false,
          "justification": "There is no mention of any numerical comparison of this model with others.",
          "quote": "Our strategy is applicable to models with ReLU activations..."
        },
        "referenced_paper_title": {
          "value": "Rectified Linear Units Improve Restricted Boltzmann Machines",
          "justification": "ReLU is a well-known concept which commonly references the paper introducing ReLU for RBMs.",
          "quote": "Our method crucially relies on Assumption 1, i.e., it is possible to choose parameters θ of f(x, θ), such that the network depicted in Fig. 1 can be realized inside f."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is explicitly mentioned as one of the datasets used in the empirical evaluation.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Gradient-Based Learning Applied to Document Recognition",
          "justification": "This is the original paper introducing the MNIST dataset.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST..."
        }
      },
      {
        "name": {
          "value": "CIFAR10",
          "justification": "CIFAR10 is one of the datasets used for demonstrating the model's performance.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "This is the original paper where the CIFAR datasets were published.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100..."
        }
      },
      {
        "name": {
          "value": "CIFAR100",
          "justification": "CIFAR100 is mentioned as part of the visual classification tasks evaluated in the paper.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "This is the original paper where the CIFAR datasets were published.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100..."
        }
      },
      {
        "name": {
          "value": "CelebA",
          "justification": "CelebA is used in the empirical evaluation showing the performance of the membership inference attack.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deep learning face attributes in the wild",
          "justification": "This publication details the release and application of the CelebA dataset.",
          "quote": "Empirical evaluation on visual classification tasks with MNIST, CIFAR10, CIFAR100 and CelebA datasets..."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Flower",
          "justification": "Flower is mentioned as the federated learning framework used in the experiments.",
          "quote": "We train a simple network from the tutorial of the FL framework flower..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Flower: A Friendly Federated Learning Research Framework",
          "justification": "Flower framework was introduced and elaborated in this publication.",
          "quote": "We train a simple network from the tutorial of the FL framework flower..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1283,
    "prompt_tokens": 13300,
    "total_tokens": 14583,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}