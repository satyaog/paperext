{
  "paper": "2306.10374.txt",
  "words": 23298,
  "extractions": {
    "title": {
      "value": "A Survey of Contextual Optimization Methods for Decision-Making under Uncertainty",
      "justification": "It is the title provided at the top of the research paper.",
      "quote": "A Survey of Contextual Optimization Methods for Decision-Making under Uncertainty"
    },
    "description": "This survey paper reviews the literature on combining prediction algorithms and optimization techniques to solve decision-making problems under uncertainty, a field known as contextual optimization. It provides a general presentation of various problems, frameworks for learning policies from data, and existing models and methods under uniform notation and terminology. The objective is to strengthen understanding and stimulate advancements in integrating machine learning and stochastic programming.",
    "type": {
      "value": "empirical",
      "justification": "The paper reviews and categorizes various empirical methods found in the literature to strengthen the understanding of the field and propose further research directions.",
      "quote": "Our objective with this survey is to both strengthen the general understanding of this active field of research and stimulate further theoretical and algorithmic advancements in integrating ML and stochastic programming."
    },
    "primary_research_field": {
      "name": {
        "value": "Contextual Optimization",
        "justification": "The paper focuses on modeling and solving decision-making problems under uncertainty using contextual information. This is a sub-field that combines elements of operations research and machine learning.",
        "quote": "This gave rise to the field of contextual optimization, under which data-driven procedures are developed to prescribe actions to the decision-maker that make the best use of the most recently updated information."
      },
      "aliases": [
        "Data-Driven Optimization",
        "Prescriptive Optimization",
        "Predictive Stochastic Programming"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Operations Research",
          "justification": "The paper discusses at length the relevance of contextual optimization in operations research and provides solutions and models that cater to such problems.",
          "quote": "Recently there has been a surge of interest in operations research (OR) and the machine learning (ML) community in combining prediction algorithms and optimization techniques to solve decision-making problems in the face of uncertainty."
        },
        "aliases": [
          "OR"
        ]
      },
      {
        "name": {
          "value": "Machine Learning",
          "justification": "The paper delves into combining optimization techniques with machine learning algorithms to solve problems in contextual optimization.",
          "quote": "This gave rise to the field of contextual optimization, under which data-driven procedures are developed to prescribe actions to the decision-maker that make the best use of the most recently updated information."
        },
        "aliases": [
          "ML"
        ]
      },
      {
        "name": {
          "value": "Stochastic Programming",
          "justification": "The paper deals extensively with optimization under uncertainty, which is the core of stochastic programming.",
          "quote": "In contextual optimization, a decision-maker faces a decision-making problem with uncertainty where the distribution of uncertain parameters that affect the objective and the constraints is unknown."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "SPOT",
          "justification": "The SPOT model is specifically described as a model that constructs decision trees based on the SPO loss function, demonstrating its relevance to the study.",
          "quote": "Elmachtoub et al. (2020) propose a model (SPOT) to construct decision trees that segment the covariates based on the SPO loss function while retaining the interpretability in the end-to-end learning framework."
        },
        "aliases": [
          "SPOT"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The SPOT model is not contributed by this paper but is instead cited as part of the existing literature.",
          "quote": "Elmachtoub et al. (2020) propose a model (SPOT) to construct decision trees that segment the covariates based on the SPO loss function while retaining the interpretability in the end-to-end learning framework."
        },
        "is_executed": {
          "value": 0,
          "justification": "There's no mention in the paper that the SPOT model was executed as part of this study. It has been referenced for its methodology and results from other studies.",
          "quote": "Their model outperforms classification and regression trees (CART) in the numerical experiments on a news recommendation problem using a real-world dataset and on the shortest path problem with synthetic data."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the SPOT model with other models and methodologies.",
          "quote": "Their model outperforms classification and regression trees (CART) in the numerical experiments on a news recommendation problem using a real-world dataset and on the shortest path problem with synthetic data."
        },
        "referenced_paper_title": {
          "value": "Decision trees for decision-making under the predict-then-optimize framework",
          "justification": "This title captures the referenced work for the SPOT model and is provided in citation of Elmachtoub et al. (2020).",
          "quote": "Elmachtoub et al. (2020) propose a model (SPOT) to construct decision trees that segment the covariates based on the SPO loss function while retaining the interpretability in the end-to-end learning framework."
        }
      },
      {
        "name": {
          "value": "QPTL",
          "justification": "The QPTL model is referenced in the context of solving LP-representable combinatorial optimization problems, making it relevant to the discussion of contextual optimization methodologies.",
          "quote": "Wilder et al. (2019a) solve LP-representable combinatorial optimization problems and LP relaxations of combinatorial problems during the training phase. Their model, referred to as QPTL (Quadratic Programming Task Loss), adds a quadratic penalty term to the objective function of the linear problem."
        },
        "aliases": [
          "QPTL"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The QPTL model is referenced rather than contributed by this paper.",
          "quote": "Wilder et al. (2019a) solve LP-representable combinatorial optimization problems and LP relaxations of combinatorial problems during the training phase. Their model, referred to as QPTL (Quadratic Programming Task Loss), adds a quadratic penalty term to the objective function of the linear problem."
        },
        "is_executed": {
          "value": 0,
          "justification": "There's no indication in the paper that the QPTL model was executed for experiments.",
          "quote": "Mandi and Guns (2020) propose IntOpt based on the interior point method to solve LPs that adds a log barrier term to the objective function and differentiates the homogeneous self-dual formulation of the LP. Their experimental analyses show that this approach performs better on energy cost-aware scheduling problems than QPTL using the data from Ifrim et al. (2012)."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the QPTL model with other models and methodologies.",
          "quote": "Mandi et al. (2020) show that for weighted and unweighted knapsack problems as well as energy-cost aware scheduling problems (CSPLib, Problem 059, Simonis et al. 2014), SPO-relax results in faster convergence and similar performance compared to SPO+ loss. Also, SPO-relax provides low regret solutions and faster convergence compared to QPTL in the aforementioned three problems, except in the weighted knapsack problem with low capacity."
        },
        "referenced_paper_title": {
          "value": "Melding the data-decisions pipeline: Decision-focused learning for combinatorial optimization",
          "justification": "This title captures the referenced work for the QPTL model and is provided in citation of Wilder et al. (2019a).",
          "quote": "Wilder et al. (2019a) solve LP-representable combinatorial optimization problems and LP relaxations of combinatorial problems during the training phase."
        }
      },
      {
        "name": {
          "value": "DBB",
          "justification": "The DBB model is discussed as a method for approximating the true loss function using an interpolation controlled in a way that balances informativeness of the gradient and faithfulness to the original function.",
          "quote": "Vlastelica et al. (2019) propose a differentiable black-box (DBB) approach to tackle the issue that the Jacobian of z ∗ (x, gθ ) is zero almost everywhere by approximating the true loss function using an interpolation controlled in a way that balances between “informativeness of the gradient” and “faithfulness to the original function”."
        },
        "aliases": [
          "DBB"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The DBB model is referenced from previous literature and not contributed by this paper.",
          "quote": "Vlastelica et al. (2019) propose a differentiable black-box (DBB) approach to tackle the issue that the Jacobian of z ∗ (x, gθ ) is zero almost everywhere by approximating the true loss function using an interpolation controlled in a way that balances between “informativeness of the gradient” and “faithfulness to the original function”."
        },
        "is_executed": {
          "value": 0,
          "justification": "There's no mention that the DBB model was executed in this study. It is discussed as a part of the reviewed literature.",
          "quote": "Vlastelica et al. (2019) propose a differentiable black-box (DBB) approach to tackle the issue that the Jacobian of z ∗ (x, gθ ) is zero almost everywhere by approximating the true loss function using an interpolation controlled in a way that balances between “informativeness of the gradient” and “faithfulness to the original function”."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper discusses the DBB model in comparison with other models.",
          "quote": "Mulamba et al. (2021) note that ILO for combinatorial problems can be viewed as a learning-to-rank problem. They propose surrogate loss functions, with closed-form expressions for gradients, that are used to train to rank feasible points in terms of performance on the downstream optimization problem. Unlike Mulamba et al. (2021), Kong et al. (2022) tackles the partition function challenge by employing a self-normalized importance sampler that provides a discrete approximation. To avoid overfitting, the authors also introduce a regularization that penalizes the KL divergence between the perturbed optimizer distribution and a subjective posterior distribution over perturbed optimal hindsight actions P(z̃ ε (x, y)|y)."
        },
        "referenced_paper_title": {
          "value": "Differentiation of blackbox combinatorial solvers",
          "justification": "This title captures the referenced work for the DBB model and is provided in citation of Vlastelica et al. (2019).",
          "quote": "Vlastelica et al. (2019) propose a differentiable black-box (DBB) approach to tackle the issue that the Jacobian of z ∗ (x, gθ ) is zero almost everywhere by approximating the true loss function using an interpolation controlled in a way that balances between “informativeness of the gradient” and “faithfulness to the original function”."
        }
      },
      {
        "name": {
          "value": "ProjectNet",
          "justification": "The ProjectNet model is discussed in the context of solving uncertain constrained linear programs by training an optimal policy network.",
          "quote": "Cristian et al. (2022) introduce the ProjectNet model to solve uncertain constrained linear programs in an end-to-end framework by training an optimal policy network, which employs a differentiable approximation of the step of projection to feasibility."
        },
        "aliases": [
          "ProjectNet"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The ProjectNet model is not contributed by this paper but is instead cited as part of the existing literature.",
          "quote": "Cristian et al. (2022) introduce the ProjectNet model to solve uncertain constrained linear programs in an end-to-end framework by training an optimal policy network."
        },
        "is_executed": {
          "value": 0,
          "justification": "There's no mention of executing the ProjectNet model in this paper. It is cited for its methodology.",
          "quote": "Cristian et al. (2022) introduce the ProjectNet model to solve uncertain constrained linear programs in an end-to-end framework by training an optimal policy network."
        },
        "is_compared": {
          "value": 0,
          "justification": "The paper does not provide any explicit numerical comparisons with the ProjectNet model.",
          "quote": "Cristian et al. (2022) introduce the ProjectNet model to solve uncertain constrained linear programs in an end-to-end framework by training an optimal policy network."
        },
        "referenced_paper_title": {
          "value": "End-to-end learning via constraint-enforcing approximators for linear programs with applications to supply chains",
          "justification": "This title captures the referenced work for the ProjectNet model and is provided in citation of Cristian et al. (2022).",
          "quote": "Cristian et al. (2022) introduce the ProjectNet model to solve uncertain constrained linear programs in an end-to-end framework."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CSPLib Problem 059",
          "justification": "CSPLib Problem 059 is specifically cited as a dataset used for analyzing energy-cost aware scheduling problems.",
          "quote": "Mandi et al. (2020) show that for weighted and unweighted knapsack problems as well as energy-cost aware scheduling problems (CSPLib, Problem 059, Simonis et al. 2014), SPO-relax results in faster convergence and similar performance compared to SPO+ loss."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "CSPLib Problem 059: Energy-cost aware scheduling",
          "justification": "The title refers to the dataset used, as cited in the paper mentioning Simonis et al. (2014).",
          "quote": "CSPLib Problem 059, Simonis et al. 2014"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyEPO",
          "justification": "PyEPO is a library mentioned in the paper for end-to-end learning frameworks for linear and integer programming.",
          "quote": "Tang and Khalil (2022) introduce an open-source software package called PyEPO (Pytorch-based End-to-End Predict-then-Optimize) implemented in Python for ILO of problems that are linear in uncertain parameters."
        },
        "aliases": [
          "Pytorch-based End-to-End Predict-then-Optimize"
        ],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "PyEPO: A PyTorch-based end-to-end predict-then-optimize library for linear and integer programming",
          "justification": "The title provided gives the referenced context for the PyEPO library as described in the paper.",
          "quote": "Tang and Khalil (2022) introduce an open-source software package called PyEPO (Pytorch-based End-to-End Predict-then-Optimize) implemented in Python for ILO of problems that are linear in uncertain parameters."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2909,
    "prompt_tokens": 39380,
    "total_tokens": 42289
  }
}