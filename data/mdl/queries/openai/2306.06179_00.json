{
  "paper": "2306.06179.txt",
  "words": 18746,
  "extractions": {
    "title": {
      "value": "Hidden Symmetries of ReLU Networks",
      "justification": "It is the official title of the paper.",
      "quote": "Hidden Symmetries of ReLU Networks"
    },
    "description": "This paper conducts both a theoretical and empirical investigation into the symmetries of ReLU neural networks, focusing on when no hidden symmetries exist and how the functional dimension of different network architectures can contain or avoid such symmetries.",
    "type": {
      "value": "theoretical",
      "justification": "The paper primarily focuses on proving theorems and providing formal definitions related to the symmetries in ReLU networks.",
      "quote": "In this work, we prove that, for any network architecture where no layer is narrower than the input, there exist parameter settings with no hidden symmetries."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning Theory",
        "justification": "The paper's investigations are focused on the theoretical facets of neural networks, particularly regarding their symmetries.",
        "quote": "A number of works have explicitly considered which symmetries are admitted by different ReLU networks."
      },
      "aliases": [
        "DL Theory",
        "Neural Network Theory"
      ]
    },
    "sub_research_fields": [],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 300,
    "prompt_tokens": 29914,
    "total_tokens": 30214
  }
}