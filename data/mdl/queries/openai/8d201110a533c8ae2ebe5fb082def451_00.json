{
  "paper": "8d201110a533c8ae2ebe5fb082def451.txt",
  "words": 9962,
  "extractions": {
    "title": {
      "value": "Towards Fair Federated Recommendation Learning: Characterizing the Inter-Dependence of System and Data Heterogeneity",
      "justification": "The title prominently features the key focus areas of the research, which include federated recommendation learning and the inter-dependence between system and data heterogeneity.",
      "quote": "Towards Fair Federated Recommendation Learning: Characterizing the Inter-Dependence of System and Data Heterogeneity"
    },
    "description": "The paper explores the inter-dependence of system and data heterogeneity in federated learning for recommender systems. It introduces a framework called RF² to model and evaluate the impact of system-induced data heterogeneity on model quality and fairness. The study highlights how ignoring system-induced data heterogeneity can magnify fairness issues and demonstrates the need for realistic simulations in federated learning evaluations.",
    "type": {
      "value": "empirical",
      "justification": "The research involves real-world data analysis and introduces an empirical framework (RF²) for simulating system-induced data heterogeneity, emphasizing practical evaluation over purely theoretical development.",
      "quote": "This paper takes a data-driven approach to show the inter-dependence of data and system heterogeneity in real-world data and quantifies its impact on the overall model quality and fairness."
    },
    "primary_research_field": {
      "name": {
        "value": "Federated Learning",
        "justification": "The paper's core subject matter revolves around federated learning, specifically for recommendation systems, addressing challenges related to system and data heterogeneity.",
        "quote": "Federated learning (FL) is an effective mechanism for data privacy in recommender systems by running machine learning model training on-device."
      },
      "aliases": [
        "FL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Recommender Systems",
          "justification": "The research specifically addresses federated learning in the context of recommender systems.",
          "quote": "Recommender systems are a fundamental building block of modern internet services, empowering day-to-day applications."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Fairness in Machine Learning",
          "justification": "The impact on fairness is a significant part of the research, as the study examines fairness issues in federated recommendation learning.",
          "quote": "We demonstrate that the impact on fairness can be severe under realistic heterogeneity scenarios."
        },
        "aliases": [
          "Fairness in ML"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "DLRM",
          "justification": "DLRM is explicitly mentioned as one of the models evaluated in the research.",
          "quote": "We evaluated two state-of-the-art deep recommender models, DLRM [28, 61] and DIN [26]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper uses DLRM as a model for evaluation rather than contributing it as new research.",
          "quote": "We evaluated two state-of-the-art deep recommender models, DLRM [28, 61] and DIN [26]."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is part of the empirical evaluation conducted using the RF² framework.",
          "quote": "RF² supports FL simulation for state-of-the-art, commonly-used recommender models and datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "DLRM is compared with another model, DIN, as part of the fairness and accuracy evaluations.",
          "quote": "The best-accuracy optimization is not always the best-fairness optimization"
        },
        "referenced_paper_title": {
          "value": "Deep learning recommendation model for personalization and recommendation systems",
          "justification": "Reference [28] in the research paper corresponds to the referenced paper title for DLRM.",
          "quote": "DLRM [28, 61] is a model developed by Meta."
        }
      },
      {
        "name": {
          "value": "DIN",
          "justification": "DIN is explicitly mentioned as one of the models evaluated in the research.",
          "quote": "We evaluated two state-of-the-art deep recommender models, DLRM [28, 61] and DIN [26]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper uses DIN as a model for evaluation rather than contributing it as new research.",
          "quote": "We evaluated two state-of-the-art deep recommender models, DLRM [28, 61] and DIN [26]."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is part of the empirical evaluation conducted using the RF² framework.",
          "quote": "RF² supports FL simulation for state-of-the-art, commonly-used recommender models and datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "DIN is compared with another model, DLRM, as part of the fairness and accuracy evaluations.",
          "quote": "The best-accuracy optimization is not always the best-fairness optimization"
        },
        "referenced_paper_title": {
          "value": "Deep Interest Network for Click-Through Rate Prediction",
          "justification": "Reference [26] in the research paper corresponds to the referenced paper title for DIN.",
          "quote": "DIN [26] is a model proposed by Alibaba."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Taobao Ad Display/Click Data",
          "justification": "The dataset is explicitly used in the paper for the evaluation of federated learning models.",
          "quote": "RF² also currently supports two commonly-used open-source datasets, Taobao Ad Display/Click Data [55] and MovieLens-20M [56]."
        },
        "aliases": [
          "Taobao dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ad click data on Taobao.com",
          "justification": "Reference [55] in the research paper corresponds to the referenced paper title for the Taobao dataset.",
          "quote": "The Taobao dataset shows 26 million interactions (click/non-click) between 1.14 million users and 847 thousand item ads across an 8-day period."
        }
      },
      {
        "name": {
          "value": "MovieLens-20M",
          "justification": "The dataset is explicitly used in the paper for the evaluation of federated learning models.",
          "quote": "RF² also currently supports two commonly-used open-source datasets, Taobao Ad Display/Click Data [55] and MovieLens-20M [56]."
        },
        "aliases": [
          "MovieLens dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "MovieLens 20M dataset",
          "justification": "Reference [56] in the research paper corresponds to the referenced paper title for the MovieLens dataset.",
          "quote": "The MovieLens dataset provides 20 million movie ratings for 27 thousand movies from 138 thousand users."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "DeepCTR-Torch",
          "justification": "DeepCTR-Torch is the open-source codebase used to build RF², enabling evaluation with multiple recommender models.",
          "quote": "RF², on the other hand, is compatible with a large body of popular recommender models, by being built on top of DeepCTR-Torch [54]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "DeepCTR-Torch",
          "justification": "Reference [54] in the research paper corresponds to the reference for the DeepCTR-Torch library used in the evaluation framework.",
          "quote": "...being built on top of DeepCTR-Torch [54], an open-source codebase that implements 19 recommender models..."
        }
      },
      {
        "name": {
          "value": "AdaGrad",
          "justification": "AdaGrad is mentioned as a server-side optimizer used in the RF² framework for improved learning stability.",
          "quote": "Using full-batch SGD on the clients and advanced optimizers, e.g., AdaGrad, on the server [33] improves the learning stability significantly."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Field Guide to Federated Optimization",
          "justification": "Reference [33] in the research paper corresponds to the reference for AdaGrad used as an optimizer.",
          "quote": "... and advanced optimizers, e.g., AdaGrad, on the server [33] improves the learning stability significantly."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1581,
    "prompt_tokens": 18432,
    "total_tokens": 20013,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}