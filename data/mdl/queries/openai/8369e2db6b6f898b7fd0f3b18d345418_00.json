{
  "paper": "8369e2db6b6f898b7fd0f3b18d345418.txt",
  "words": 18591,
  "extractions": {
    "title": {
      "value": "QU-BraTS: MICCAI BraTS 2020 Challenge on Quantifying Uncertainty in Brain Tumor Segmentation - Analysis of Ranking Scores and Benchmarking Results",
      "justification": "The title of the paper is located at the beginning of the document and clearly identifies the primary focus of the research.",
      "quote": "QU-BraTS: MICCAI BraTS 2020 Challenge on Quantifying Uncertainty in Brain Tumor Segmentation - Analysis of Ranking Scores and Benchmarking Results"
    },
    "description": "The paper explores and evaluates an uncertainty quantification score developed during the BraTS 2019 and 2020 challenges to assess brain tumor segmentation. It benchmarks the segmentation uncertainties generated by 14 independent participating teams, highlighting the importance and complementary value that uncertainty estimates provide to segmentation algorithms in medical image analyses.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents an empirical study by evaluating the performance of different uncertainty measures and comparing them using empirical data from multiple teams participating in the BraTS challenges.",
      "quote": "In this study, we explore and evaluate a score developed during the BraTS 2019 and BraTS 2020 task on uncertainty quantification (QU-BraTS) and designed to assess and rank uncertainty estimates for brain tumor multi-compartment segmentation."
    },
    "primary_research_field": {
      "name": {
        "value": "Medical Image Analysis",
        "justification": "The paper focuses on uncertainty quantification in brain tumor segmentation, a task within the medical image analysis domain.",
        "quote": "Deep learning (DL) models have provided state-of-the-art performance in various medical imaging benchmarking challenges, including the Brain Tumor Segmentation (BraTS) challenges."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Uncertainty Quantification",
          "justification": "A major aspect of the paper is developing and evaluating uncertainty quantification methods for brain tumor segmentation.",
          "quote": "Quantifying the reliability of DL model predictions in the form of uncertainties could enable clinical review of the most uncertain regions, thereby building trust and paving the way toward clinical translation."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Brain Tumor Segmentation",
          "justification": "The paper's main application area is brain tumor segmentation as evidenced by its focus on the BraTS challenge.",
          "quote": "The availability of the dataset, and the challenge itself, have permitted the development of many new successful deep learning based approaches such as the DeepMedic and the nnU-Net."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DeepSCAN",
          "justification": "The DeepSCAN model was mentioned as being used by Team SCAN in the uncertainty quantification task.",
          "quote": "The method uses the DeepSCAN (McKinley et al., 2019) model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The model was used by Team SCAN and was not newly introduced in this paper.",
          "quote": "The method uses the DeepSCAN (McKinley et al., 2019) model."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was actively used by Team SCAN in the task.",
          "quote": "An ensemble of the networks was utilized in the final output..."
        },
        "is_compared": {
          "value": true,
          "justification": "The results and performance of DeepSCAN were part of the evaluations and benchmarking of the different teams.",
          "quote": "In total, 14 teams participated in the QU-BraTS 2020 challenge. All teams utilized a Convolutional Neural Network (CNN) based approach for the tumor segmentation task."
        },
        "referenced_paper_title": {
          "value": "Triplanar ensemble of 3D-to-2D CNNs with label-uncertainty for brain tumor segmentation",
          "justification": "The DeepSCAN model is referenced as McKinley et al., 2019 in the paper.",
          "quote": "The method uses the DeepSCAN (McKinley et al., 2019) model."
        }
      },
      {
        "name": {
          "value": "3D U-Net",
          "justification": "A modified 3D U-Net architecture is mentioned in the experimental setup.",
          "quote": "A modified 3D U-Net architecture (Çiçek et al., 2016; Mehta and Arbel, 2018) generates the segmentation outputs and corresponding uncertainties."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The 3D U-Net is a well-known architecture and was used in experiments but not newly introduced by this paper.",
          "quote": "A modified 3D U-Net architecture (Çiçek et al., 2016; Mehta and Arbel, 2018) generates the segmentation outputs and corresponding uncertainties."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was modified and executed to generate results in the experiments described.",
          "quote": "A modified 3D U-Net architecture..."
        },
        "is_compared": {
          "value": false,
          "justification": "While used in experiments, the specific performance of 3D U-Net compared to other models is not detailed.",
          "quote": "Experiments were devised to show the functioning of the derived uncertainty evaluations and rankings."
        },
        "referenced_paper_title": {
          "value": "3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation",
          "justification": "The 3D U-Net is referenced as Çiçek et al., 2016, indicating this is the primary paper introducing it.",
          "quote": "A modified 3D U-Net architecture (Çiçek et al., 2016; Mehta and Arbel, 2018)..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "BraTS 2020",
          "justification": "The BraTS 2020 dataset is central to the experiments and evaluations conducted in this paper.",
          "quote": "This work focuses on the publicly available BraTS challenge dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)",
          "justification": "The BraTS dataset is referenced repeatedly, including past years' benchmarks, indicating its foundational role.",
          "quote": "The BraTS 2020 challenge dataset..."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1234,
    "prompt_tokens": 35673,
    "total_tokens": 36907,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}