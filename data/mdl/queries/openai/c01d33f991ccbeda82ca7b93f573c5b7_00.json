{
  "paper": "c01d33f991ccbeda82ca7b93f573c5b7.txt",
  "words": 9544,
  "extractions": {
    "title": {
      "value": "Rhythmic information sampling in the brain during visual recognition",
      "justification": "The title of the paper is explicitly stated at the beginning of the text.",
      "quote": "Rhythmic information sampling in the brain during visual recognition"
    },
    "description": "This paper investigates rhythmic information sampling in the brain during visual recognition tasks using magnetoencephalography (MEG) to record participants' brain activity. It explores how the brain processes visual information over time and identifies oscillatory patterns in early visual areas.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves experimental research with human participants performing visual recognition tasks and analyzing brain activity using MEG, which is characteristic of empirical research.",
      "quote": "We recorded the brain activity of five neurotypical adults over five days each with MEG."
    },
    "primary_research_field": {
      "name": {
        "value": "Neuroscience",
        "justification": "The primary research field is neuroscience, as the study focuses on brain activity and visual processing.",
        "quote": "Oscillatory sampling was mostly visible in early visual areas, at theta and low beta frequencies."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Cognitive Neuroscience",
          "justification": "The paper is related to cognitive neuroscience because it studies brain processes involved in cognitive functions like visual recognition.",
          "quote": "These results advance our understanding of the oscillatory neural dynamics associated with visual processing."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "Karolinska Directed Emotional Faces",
          "justification": "This dataset was explicitly mentioned as being used for face image stimuli.",
          "quote": "Two hundred and sixty-four color images of faces were selected from the image database Karolinska Directed Emotional Faces."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Karolinska Directed Emotional Faces: A validation study",
          "justification": "The referenced paper validates the dataset used in the current study for experimental stimuli.",
          "quote": "Goeleven, E., De Raedt, R., Leyman, L., & Verschuere, B. (2008). The Karolinska Directed Emotional Faces: A validation study."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Psychophysics Toolbox",
          "justification": "The library was explicitly mentioned as being used to conduct the experiments in the study.",
          "quote": "The experimental program ran on a Dell Precision computer with Windows XP in the Matlab environment, using custom scripts and functions from the Psychophysics Toolbox."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Psychophysics Toolbox.",
          "justification": "The referenced paper describes the library used for visual stimuli presentation in the study.",
          "quote": "Brainard, D. H. (1997). The Psychophysics Toolbox. Spatial Vision, 10(4), 433â€“436."
        }
      },
      {
        "name": {
          "value": "SHINE toolbox",
          "justification": "The library was used for normalizing visual stimuli used in the study.",
          "quote": "The mean luminance and contrast of all masked faces were equalized, separately for each color channel, using the SHINE toolbox."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Controlling low-level image properties: the SHINE toolbox.",
          "justification": "This paper describes the SHINE toolbox, which was used in the study to manipulate visual stimuli properties.",
          "quote": "Willenbockel, V., Sadr, J., Fiset, D., Horne, G. O., Gosselin, F., & Tanaka, J. W. (2010). Controlling low-level image properties: the SHINE toolbox."
        }
      },
      {
        "name": {
          "value": "Brainstorm toolbox",
          "justification": "The toolbox was used for MEG data preprocessing and analysis.",
          "quote": "All further preprocessing was conducted using functions from the Brainstorm toolbox."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Brainstorm: a user-friendly application for MEG/EEG analysis.",
          "justification": "The referenced paper is about the Brainstorm toolbox, which was used for MEG analysis in the study.",
          "quote": "Tadel, F., Baillet, S., Mosher, J. C., Pantazis, D., & Leahy, R. M. (2011). Brainstorm: a user-friendly application for MEG/EEG analysis. Computational Intelligence and Neuroscience, 2011(3):879716."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 890,
    "prompt_tokens": 17177,
    "total_tokens": 18067,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}