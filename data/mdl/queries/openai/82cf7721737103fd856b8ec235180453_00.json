{
  "paper": "82cf7721737103fd856b8ec235180453.txt",
  "words": 10488,
  "extractions": {
    "title": {
      "value": "Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects",
      "justification": "The title is provided at the top of the document, before the abstract, and typically summarizes the main topic and focus of the research paper.",
      "quote": "Voices Unheard: NLP Resources and Models for Yorùbá Regional Dialects"
    },
    "description": "The paper introduces the YORÙLECT dataset, a high-quality parallel text and speech corpus for several Yorùbá dialects. It focuses on developing NLP technologies for these dialects, including machine translation, automatic speech recognition, and speech-to-text translation. The research highlights the performance disparities between standard Yorùbá and other dialects, offering solutions to close these gaps through dialect-adaptive finetuning. The authors aim to support the development of NLP tools for underrepresented African dialects.",
    "type": {
      "value": "empirical",
      "justification": "The paper describes experiments conducted using the YORÙLECT dataset, including measuring model performance and finetuning on machine translation, automatic speech recognition, and speech-to-text tasks.",
      "quote": "Using our newly created corpus, we conducted extensive experiments on (text) machine translation, automatic speech recognition, and speech-to-text translation."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on developing NLP resources for Yerùbá dialects and addresses tasks like machine translation and speech recognition, which are classic NLP tasks.",
        "quote": "Recent efforts to develop NLP technologies for African languages have focused on their standard dialects, resulting in disparities for dialects and varieties for which there are little to no resources or tools."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Translation",
          "justification": "The paper discusses experiments and performance regarding machine translation tasks performed on the YORÙLECT dataset.",
          "quote": "We first conduct extensive experiments evaluating the zero-shot performance of recent state-of-the-art models for MT, ASR, and S2TT (§4, §5)."
        },
        "aliases": [
          "MT"
        ]
      },
      {
        "name": {
          "value": "Automatic Speech Recognition",
          "justification": "The paper includes experiments on automatic speech recognition systems, comparing their performance across different dialects.",
          "quote": "With Whisper, the case is different: while the WER is generally very high, we see that only Ifè. is substantially better across all dialects."
        },
        "aliases": [
          "ASR"
        ]
      },
      {
        "name": {
          "value": "Speech-to-Text Translation",
          "justification": "Speech-to-text translation is explicitly discussed as one of the main experiments conducted using the YORÙLECT dataset.",
          "quote": "SeamlessM4T is a multilingual and multimodal model that translates and transcribes across speech and text...our focus here is ASR and S2TT."
        },
        "aliases": [
          "S2TT"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "M2M-100",
          "justification": "The M2M-100 is explicitly mentioned as one of the multilingual MT models evaluated on the Yorùbá dialects.",
          "quote": "MT-Specific Models We evaluate M2M-100 (Fan et al., 2020), NLLB (Costa-jussà et al., 2022), and MENYO-20k (Adelani et al., 2021a)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "M2M-100 is a pre-existing model referenced in the context of performance evaluation in the paper.",
          "quote": "MT-Specific Models We evaluate M2M-100 (Fan et al., 2020)"
        },
        "is_executed": {
          "value": true,
          "justification": "M2M-100 was evaluated for its performance on the new dataset as part of the experiments conducted in the paper.",
          "quote": "MT-Specific Models We evaluate M2M-100..."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares the performance of M2M-100 with other MT models on dialectal translation tasks.",
          "quote": "Zero-shot MT evaluation across all models"
        },
        "referenced_paper_title": {
          "value": "Beyond english-centric multilingual machine translation",
          "justification": "This title is given in the reference to Fan et al. relating to the M2M-100 model.",
          "quote": "MT-Specific Models We evaluate M2M-100 (Fan et al., 2020)"
        }
      },
      {
        "name": {
          "value": "NLLB-600M",
          "justification": "NLLB-600M is mentioned as a multilingual MT model evaluated and fine-tuned for translation tasks on the YORÙ LECT dataset.",
          "quote": "MT-Specific Models We evaluate M2M-100 (Fan et al., 2020), NLLB (Costa-jussà et al., 2022)"
        },
        "aliases": [
          "No Language Left Behind 600M"
        ],
        "is_contributed": {
          "value": false,
          "justification": "NLLB-600M is a known model from previous research, used in this paper for evaluation purposes.",
          "quote": "MT-specific models use an encoder-decoder architecture and are trained on large amounts of parallel data."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was part of MT-specific models evaluated for translation performance in the experiments detailed in the paper.",
          "quote": "We evaluate machine translation models, specifically MT-specific models like M2M-100, NLLB-600M."
        },
        "is_compared": {
          "value": true,
          "justification": "NLLB-600M's performance is compared with other machine translation models in the zero-shot and fine-tuned scenarios.",
          "quote": "Zero-shot MT evaluation across all models. Google Translate outperforms other systems..."
        },
        "referenced_paper_title": {
          "value": "No language left behind: Scaling human-centered machine translation",
          "justification": "This is the paper associated with the development of the NLLB model as cited in the paper.",
          "quote": "NLLB (Costa-jussà et al., 2022)"
        }
      },
      {
        "name": {
          "value": "MENYO-20k",
          "justification": "MENYO-20k is introduced as a Yoruba-to-English-specific model used for MT evaluation in the paper.",
          "quote": "MENYO-20k’s model is trained with the MENYO-20k dataset, a curated multi-domain standard Yorùbá dataset with proper orthography."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The model is a referenced pre-existing model, utilized within the paper for purposes of comparison and evaluation.",
          "quote": "MENYO-20k is a Yorùbá-to-English-specific model fine-tuned on top of the multilingual pretrained mT5 model."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper involves experiments where MENYO-20k is tested for its translation capabilities.",
          "quote": "MENYO-20k is a Yorùbá-to-English-specific model fine-tuned on top of the multilingual pretrained mT5 model."
        },
        "is_compared": {
          "value": true,
          "justification": "Its performance is specifically compared with other MT and S2TT models evaluated within the study.",
          "quote": "Zero-shot MT evaluation across all models. Google Translate outperforms other systems..."
        },
        "referenced_paper_title": {
          "value": "The effect of domain and diacritics in Yoruba–English neural machine translation",
          "justification": "This paper appears to have discussed or developed MENYO-20k, as cited when MENYO-20k is mentioned.",
          "quote": "MENYO-20k is a Yorùbá-to-English-specific model fine-tuned on top of the multilingual pretrained mT5 model (Xue et al., 2021). MENYO-20k’s model is trained with the MENYO-20k dataset, a curated multi-domain standard Yorùbá dataset with proper orthography."
        }
      },
      {
        "name": {
          "value": "Whisper",
          "justification": "Whisper is evaluated for automatic speech recognition (ASR) in the paper.",
          "quote": "We evaluate three models: Whisper (Radford et al., 2022), SeamlessM4T (Communication et al., 2023), and MMS."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Whisper is not a new model contributed by the paper but rather an existing model that was evaluated.",
          "quote": "Whisper is an end-to-end ASR model, implemented as an encoder-decoder transformer."
        },
        "is_executed": {
          "value": true,
          "justification": "Whisper is explicitly assessed for its performance in ASR tasks across various dialects in the experiments.",
          "quote": "With Whisper, the case is different: while the WER is generally very high, we see that only Ifè. is substantially better across all dialects."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper describes the comparative performance of Whisper and other ASR models.",
          "quote": "Zero-shot performance on automatic speech recognition and speech translation."
        },
        "referenced_paper_title": {
          "value": "Robust speech recognition via large-scale weak supervision",
          "justification": "This is the research cited for Whisper when it is introduced and evaluated in the paper.",
          "quote": "Whisper (Radford et al., 2022)"
        }
      },
      {
        "name": {
          "value": "SeamlessM4T",
          "justification": "SeamlessM4T is assessed for ASR and S2TT tasks and its results are compared in the study.",
          "quote": "SeamlessM4T is a multilingual and multimodal model that also translates and transcribes across speech and text."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The SeamlessM4T model is sourced from existing research, as used for evaluation in this paper.",
          "quote": "SeamlessM4T (Communication et al., 2023)"
        },
        "is_executed": {
          "value": true,
          "justification": "The paper involves running experiments using SeamlessM4T for both ASR and S2TT.",
          "quote": "Zero-shot performance on automatic speech recognition and speech translation."
        },
        "is_compared": {
          "value": true,
          "justification": "SeamlessM4T's performance in ASR and S2TT is compared to other models like Whisper in the paper.",
          "quote": "Zero-shot performance on automatic speech recognition and speech translation."
        },
        "referenced_paper_title": {
          "value": "SeamlessM4T: Massively multilingual & multimodal machine translation",
          "justification": "This is the reference within the paper where SeamlessM4T is cited for its evaluation.",
          "quote": "SeamlessM4T (Communication et al., 2023)"
        }
      },
      {
        "name": {
          "value": "MMS",
          "justification": "The MMS model is evaluated for automatic speech recognition tasks in the document.",
          "quote": "We evaluate three models: Whisper (Radford et al., 2022), SeamlessM4T (Communication et al., 2023), and MMS."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "MMS is mentioned as a previously established model, not a new contribution from this paper.",
          "quote": "MMS is an ASR-only model finetuned on top of wav2vec 2.0 (Baevski et al., 2020) models."
        },
        "is_executed": {
          "value": true,
          "justification": "MMS is used within the paper for zero-shot ASR tasks to measure performance particularly on Yorùbá dialects.",
          "quote": "We report word error rate (WER) with the models MMS, SeamlessM4T, and Whisper."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper lists and compares the performance of MMS against other models in ASR tasks for different dialects.",
          "quote": "Performance is generally poor across all models, with MMS performing the best."
        },
        "referenced_paper_title": {
          "value": "Scaling speech technology to 1,000+ languages",
          "justification": "This research paper by Pratap et al. is likely the foundational work describing the development of MMS.",
          "quote": "MMS (Pratap et al., 2024)"
        }
      },
      {
        "name": {
          "value": "XLSR-Wav2Vec2",
          "justification": "XLSR-Wav2Vec2 is used for fine-tuning experiments in ASR for Yorùbá dialects, as mentioned in the document.",
          "quote": "We finetune MMS (Pratap et al., 2024) and XLSR-Wav2Vec2 (Baevski et al., 2020)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "XLSR-Wav2Vec2 is already an existing model being utilized for evaluation in new contexts in the study.",
          "quote": "XLSR-Wav2Vec2 (Baevski et al., 2020)"
        },
        "is_executed": {
          "value": true,
          "justification": "The model is actively evaluated for its performance in ASR tasks through fine-tuning on dialectal data.",
          "quote": "Finetuning XLSR and MMS with two different model sizes..."
        },
        "is_compared": {
          "value": true,
          "justification": "XLSR-Wav2Vec2's performance is compared after fine-tuning with other models to assess adaptation efficacy.",
          "quote": "We compare performance after finetuning XLSR and MMS with two different model sizes each."
        },
        "referenced_paper_title": {
          "value": "wav2vec 2.0: A framework for self-supervised learning of speech representations",
          "justification": "The work by Baevski et al. on wav2vec 2.0 is cited, which is foundational for XLSR-Wav2Vec2 development.",
          "quote": "XLSR-Wav2Vec2 (Baevski et al., 2020)"
        }
      },
      {
        "name": {
          "value": "Google Translate (GMNMT)",
          "justification": "The study references Google Translate as a comparative baseline for machine translation performance.",
          "quote": "Finally, we include Google Translate (GM-NMT) due to its widespread commercial use."
        },
        "aliases": [
          "GMNMT"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Google Translate is not a new model or technology introduced by this study, but an existing service used as a baseline for comparison.",
          "quote": "Finally, we include Google Translate (GM-NMT) due to its widespread commercial use."
        },
        "is_executed": {
          "value": true,
          "justification": "Google Translate's API was used in this research for assessing its translation quality against other models.",
          "quote": "We request the NMT model through the API, and cannot control any other aspects of its usage."
        },
        "is_compared": {
          "value": true,
          "justification": "It is compared to other models, particularly noting where it sets a high benchmark for translation performance.",
          "quote": "Zero-shot MT evaluation across all models. Google Translate outperforms other systems and is more robust to dialectal variation."
        },
        "referenced_paper_title": {
          "value": "n/a",
          "justification": "As Google Translate is a widely known service, there is no specific reference paper given in the source text.",
          "quote": "Finally, we include Google Translate (GM-NMT) due to its widespread commercial use."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "YORÙLECT",
          "justification": "YORÙLECT is introduced as the new dataset created for parallel speech and text across Yorùbá dialects, central to the research paper.",
          "quote": "We take steps towards bridging this gap by introducing a new high-quality parallel text and speech corpus Y ORÙ L ECT across three domains and four regional Yorùbá dialects."
        },
        "aliases": [
          "YORÙ L ECT"
        ],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "n/a",
          "justification": "The dataset is a contribution of the current paper, not referenced from another paper.",
          "quote": "We take steps towards bridging this gap by introduc-ing a new high-quality parallel text and speech corpus Y ORÙ L ECT."
        }
      },
      {
        "name": {
          "value": "MENYO-20k",
          "justification": "MENYO-20k is referenced in the context of an established dataset used to train MT models, mentioned consistently in relation to MENYO-20k model.",
          "quote": "MENYO-20k is a Yorùbá-to-English-specific model fine-tuned on top of the multilingual pretrained mT5 model."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "The effect of domain and diacritics in Yoruba–English neural machine translation",
          "justification": "This dataset was originally introduced in relation to MENYO-20k model training, as referenced here.",
          "quote": "MENYO-20k’s model is trained with the MENYO-20k dataset, a curated multi-domain standard Yorùbá dataset with proper orthography."
        }
      },
      {
        "name": {
          "value": "MAFT Corpus",
          "justification": "The MAFT corpus was used as a source for the text data collected for building the YORÙLECT corpus.",
          "quote": "We collected textual Standard Yorùbá data from... (iii) Yorùbá news articles within the MAFT corpus (Alabi et al., 2022)."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "Adapting pre-trained language models to African languages via multilingual adaptive fine-tuning",
          "justification": "The paper by Alabi et al. is cited in conjunction with the MAFT corpus used for YORÙLECT text data sourcing.",
          "quote": "Yorùbá news articles within the MAFT corpus (Al-abi et al., 2022)."
        }
      },
      {
        "name": {
          "value": "TED Talks",
          "justification": "TED Talks is among the data sources for the textual content in the YORÙLECT corpus collection.",
          "quote": "Yorùbá portion of MTTT, a collection of multitarget bitexts based on TED Talks (Duh, 2018)"
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "The multitarget ted talks task",
          "justification": "The TED Talks as explained in the paper is integrated into the YORÙLECT dataset formulation and referenced in association with Duh (2018).",
          "quote": "Yorùbá portion of MTTT, a collection of multitarget bitexts based on TED Talks (Duh, 2018)"
        }
      },
      {
        "name": {
          "value": "Bible study manuals",
          "justification": "Bible study manuals were mentioned as a text source for Yorùbá data collection within the study for the YORÙLECT corpus.",
          "quote": "We collected textual Standard Yorùbá data from the following sources: (i) Bible study manuals; ^{4}"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "n/a",
          "justification": "Bible study manuals are generally used text sources without a specific academic paper referenced.",
          "quote": "We collected textual Standard Yorùbá data from the following sources: (i) Bible study manuals; ^{4}"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "YorubaVoice Recorder app",
          "justification": "The YorubaVoice Recorder app is mentioned as the tool used for the recording process during dataset creation.",
          "quote": "Recording is conducted using the speech recorder application designed by the YorubaVoice project (Ogunremi et al., 2024)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ìròyìnspeech: A multi-purpose yorùbá speech corpus",
          "justification": "The recorder app's development is part of prior work by Ogunremi et al. (2024), making it an essential tool referenced for the data collection phase.",
          "quote": "Recording is conducted using the speech recorder application designed by the YorubaVoice project (Ogunremi et al., 2024)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 4011,
    "prompt_tokens": 21737,
    "total_tokens": 25748,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}