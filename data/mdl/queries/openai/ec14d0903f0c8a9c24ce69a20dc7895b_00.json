{
  "paper": "ec14d0903f0c8a9c24ce69a20dc7895b.txt",
  "words": 13026,
  "extractions": {
    "title": {
      "value": "Reproducibility Study on Adversarial Attacks Against Robust Transformer Trackers",
      "justification": "The title is clearly mentioned at the beginning of the document, aligning with the focus on the reproducibility of adversarial attacks against transformer-based trackers.",
      "quote": "Reproducibility Study on Adversarial Attacks Against Robust Transformer Trackers"
    },
    "description": "This paper evaluates the effectiveness and robustness of different adversarial attacks on both transformer-based and non-transformer object trackers. The study is empirical, involving experiments to test various attacks on models like TransT and ROMTrack using datasets such as VOT2022ST and GOT10k. It investigates how these trackers handle adversarial perturbations and suggests the need for new attack methods for recent transformer trackers. The research is supported by practical experiments and aims to offer insights into the adversarial robustness of these models.",
    "type": {
      "value": "empirical",
      "justification": "The study conducts a series of experiments involving different adversarial attacks on object tracking models and evaluates their performances, which is characteristic of empirical research.",
      "quote": "We conducted a series of experiments to evaluate the effectiveness of existing adversarial attacks on object trackers with transformer and non-transformer backbones."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The primary focus of the paper is on object tracking, a key area of Computer Vision, as it deals with adversarial attacks on visual object trackers.",
        "quote": "In this context, transformer-based networks have surpassed other deep learning-based trackers, showing a very robust performance on the state-of-the-art benchmarks."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Adversarial Machine Learning",
          "justification": "The study is centered on understanding adversarial attacks—a core topic within adversarial machine learning—against transformer trackers.",
          "quote": "This paper focuses on understanding how transformer trackers behave under adversarial attacks and how different attacks perform on tracking datasets as their parameters change."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Transformer Networks",
          "justification": "The study targets transformer-based networks, exploring their performance and robustness under adversarial attacks.",
          "quote": "New transformer networks have been integrated into object tracking pipelines and have demonstrated strong performance on the latest benchmarks."
        },
        "aliases": [
          "Transformers"
        ]
      },
      {
        "name": {
          "value": "Object Tracking",
          "justification": "The research revolves around transformer trackers, a specific application under object tracking within computer vision.",
          "quote": "Our empirical study focuses on evaluating adversarial robustness of object trackers based on bounding box versus binary mask predictions, and attack methods at different levels of perturbations."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "TransT",
          "justification": "TransT is mentioned as a transformer-based object tracker used in the experiments to test adversarial attacks.",
          "quote": "The first transformer tracker, TransT, used the cross-attention and self-attention blocks to mix features of the moving target and the search region of the tracker."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "TransT is a pre-existing model used for experimentation rather than a contribution of this paper.",
          "quote": "The first transformer tracker, TransT, used the cross-attention and self-attention blocks to mix features of the moving target and the search region of the tracker."
        },
        "is_executed": {
          "value": true,
          "justification": "TransT was one of the models experimented upon in the study to assess adversarial robustness.",
          "quote": "...we applied a set of attacks against TransT..."
        },
        "is_compared": {
          "value": true,
          "justification": "TransT was compared in performance to other transformers during the experiments.",
          "quote": "We tested a set of transformer and non-transformer trackers before and after applying the adversarial attacks."
        },
        "referenced_paper_title": {
          "value": "Transformer Tracking",
          "justification": "The reference for TransT is given, confirming the model's implementation in prior research.",
          "quote": "The first transformer tracker, TransT (Chen et al., 2021), used the cross-attention and self-attention blocks..."
        }
      },
      {
        "name": {
          "value": "MixFormer",
          "justification": "MixFormer is mentioned as a transformer-based architecture involved in the experiments to test adversarial attacks.",
          "quote": "The MixFormer coupled with the AlphaRefine network has been proposed for the VOT2022 challenge as MixFormerM."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "MixFormer was used in experiments, not introduced in this paper.",
          "quote": "The MixFormer coupled with the AlphaRefine network has been proposed for the VOT2022 challenge as MixFormerM."
        },
        "is_executed": {
          "value": true,
          "justification": "MixFormer was executed during the testing of adversarial robustness.",
          "quote": "In our experiments, we tested both MixFormer and MixFormerM trackers."
        },
        "is_compared": {
          "value": true,
          "justification": "MixFormer was compared to other models in terms of performance under adversarial attacks.",
          "quote": "We have conducted a baseline experiment for the VOT2022 short-term sub-challenge in two cases:..."
        },
        "referenced_paper_title": {
          "value": "Mixformer: End-to-end tracking with iterative mixed attention",
          "justification": "The referenced paper describes MixFormer, detailing its contribution to object tracking.",
          "quote": "The MixFormer coupled with the AlphaRefine network has been proposed for the VOT2022 challenge as MixFormerM."
        }
      },
      {
        "name": {
          "value": "ROMTrack",
          "justification": "ROMTrack is used as one of the primary models for testing adversarial attacks in the study.",
          "quote": "The Robust Object Modeling Tracker (ROMTrack) proposed variation tokens to capture and preserve the object deformation across frames."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ROMTrack is an existing model used within the study.",
          "quote": "The Robust Object Modeling Tracker (ROMTrack) proposed variation tokens to capture and preserve the object deformation across frames."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper conducts experimental evaluation on ROMTrack against adversarial attacks.",
          "quote": "For instance, using RTAA, the adversarial search regions are generated in ROMTrack."
        },
        "is_compared": {
          "value": true,
          "justification": "ROMTrack's performance was compared to other models within the study.",
          "quote": "The ROMTrack and MixFormer bounding box predictions were harmed by the IoU method up to 18.11 %..."
        },
        "referenced_paper_title": {
          "value": "Robust Object Modeling for Visual Tracking",
          "justification": "The study references prior work on ROMTrack, highlighting its object modeling capabilities for tracking.",
          "quote": "The Robust Object Modeling Tracker (ROMTrack) proposed variation tokens..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "VOT2022ST",
          "justification": "VOT2022ST is explicitly used for evaluating attack performance in experiments.",
          "quote": "Our study found that altering the perturbation level may not significantly affect the overall object tracking results... on VOT2022ST"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "The tenth visual object tracking VOT2022 challenge results",
          "justification": "The paper cites the VOT2022 results as a benchmark for their experiments.",
          "quote": "The VOT2022 Short-term dataset and protocol..."
        }
      },
      {
        "name": {
          "value": "UAV123",
          "justification": "UAV123 was specifically utilized for evaluation and testing in the study.",
          "quote": "...the performance of TransT under RTAA and SPARK attacks with different perturbation levels on UAV123 dataset."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A benchmark and simulator for UAV tracking",
          "justification": "UAV123 is cited in conjunction with its original study as the source of dataset usage.",
          "quote": "...using the UAV123 dataset and protocol."
        }
      },
      {
        "name": {
          "value": "GOT10k",
          "justification": "GOT10k is noted as one of the datasets used in testing object trackers' robustness.",
          "quote": "...we tested against 4 recent attack methods to assess their performance and robustness on VOT2022ST, UAV123 and GOT10k datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "GOT-10k: A large high-diversity benchmark for generic object tracking in the wild",
          "justification": "The referenced paper for GOT10k underpins its benchmark status in object tracking, referenced in experiments.",
          "quote": "...and GOT10k."
        }
      },
      {
        "name": {
          "value": "DAVIS2016",
          "justification": "DAVIS2016 is partly used for visualizing video sequences impacted by adversarial attacks.",
          "quote": "For visualization usage, we employed some video sequences from DAVIS2016."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A benchmark dataset and evaluation methodology for video object segmentation",
          "justification": "DAVIS2016 is a well-cited dataset for segmentation tasks as indicated by the reference.",
          "quote": "For visualization usage, we employed some video sequences from DAVIS2016 (Perazzi et al., 2016) dataset."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1833,
    "prompt_tokens": 22041,
    "total_tokens": 23874,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}