{
  "paper": "ab6fd4d76d2982a7539fd0ca3cb9fad2.txt",
  "words": 16517,
  "extractions": {
    "title": {
      "value": "Reinforcement Learning for Freight Booking Control Problems",
      "justification": "The title is prominently mentioned at the beginning of the paper, and it is formatted in a distinct way that indicates it is the main title of the research.",
      "quote": "R EINFORCEMENT L EARNING FOR F REIGHT B OOKING C ONTROL P ROBLEMS"
    },
    "description": "The paper addresses freight booking control problems faced in revenue management where the decision to accept or reject a booking is made to maximize profitability. It proposes a two-phase approach where first, a supervised learning model predicts operational problems, followed by deploying simulation-based reinforcement learning algorithms. The paper evaluates the method on distributional logistics and airline cargo management, showing improvements over existing methods.",
    "type": {
      "value": "theoretical",
      "justification": "The paper is focused on proposing a new approach based on theoretical formulations, such as Markov Decision Processes (MDP), to improve booking control problems using reinforcement learning.",
      "quote": "This problem can be formulated as a finite-horizon stochastic dynamic program..."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper proposes and uses reinforcement learning methods to address freight booking control problems, aiming to leverage these techniques for improved decision-making processes.",
        "quote": "...this allows one to leverage the recent advances in reinforcement learning..."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Revenue Management",
          "justification": "The paper focuses on problems related to booking control in revenue management, specifically in the freight and airline industries.",
          "quote": "Booking control problems are sequential decision-making problems that occur in the domain of revenue management."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Supervised Learning",
          "justification": "The method involves training a supervised learning model as part of the solution to predict operational problems before applying reinforcement learning.",
          "quote": "...we first train a supervised learning model to predict the objective of the operational problem..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Deep Q-learning (DQN)",
          "justification": "The paper refers to using Deep Q-learning methods to implement control policies for booking problems, which is a specific type of reinforcement learning model.",
          "quote": "We select the Q-learning algorithm Watkins and Dayan (1992). Its performance has been well documented... More specifically, we focus on Deep Q-learning (DQN)."
        },
        "aliases": [
          "DQN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper utilizes and applies DQN as a part of its proposed methodology but does not claim to have developed or contributed the model itself.",
          "quote": "We select the Q-learning algorithm Watkins and Dayan (1992)... More specifically, we focus on Deep Q-learning (DQN)."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper discusses the evaluation of DQN through experiments on various booking problems, suggesting its execution as part of the study.",
          "quote": "We implement two variants of DQN. The first is DQN-L..."
        },
        "is_compared": {
          "value": true,
          "justification": "DQN is compared against several other methods and benchmarks within the study, demonstrating its effectiveness in the described control problems.",
          "quote": "Our work is of high practical importance... In contrast, existing work rely on simplifications... Our methodology is relatively easy to use in practice... Also, our approach performs comparably with a strong problem-specific algorithm in ACM."
        },
        "referenced_paper_title": {
          "value": "Human-level control through deep reinforcement learning",
          "justification": "The reference to Mnih et al. (2015) suggests this is the pivotal work on Deep Q-learning that underpins the model used in the paper.",
          "quote": "...deep RL algorithms in particular as they have a high capacity, and are known to produce well-performing policies without an explicit model of system dynamics (e.g., Mnih et al. 2015)."
        }
      },
      {
        "name": {
          "value": "Booking Limit Policy",
          "justification": "The Booking Limit Policy is used as a benchmark in the paper's evaluation of different approaches for booking control problems.",
          "quote": "The DLP-based approach of Giallombardo et al. (2022) constitutes the state-of-the-art for the DiL booking control problem. They formulate a profit-maximizing MILP which is given by...(BLP)..."
        },
        "aliases": [
          "BLP"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The Booking Limit Policy is referenced as an existing approach, not one newly introduced by the authors.",
          "quote": "The DLP-based approach of Giallombardo et al. (2022) constitutes the state-of-the-art for the DiL booking control problem. They formulate a profit-maximizing MILP which is given by...(BLP)..."
        },
        "is_executed": {
          "value": true,
          "justification": "Both the paper's methodology and the Booking Limit Policy are executed and compared in their effectiveness for solving booking control problems.",
          "quote": "We compare with BLP and BLPR as described in Section 3.1.2, and for ACM we compare with DLP and DPD as described in Section 3.2.2."
        },
        "is_compared": {
          "value": true,
          "justification": "BLP serves as a baseline method against which the proposed models' performances are compared.",
          "quote": "We compare with BLP and BLPR as described in Section 3.1.2..."
        },
        "referenced_paper_title": {
          "value": "Dynamic bid prices in revenue management",
          "justification": "Since the paper by Adelman (2007) is referenced in a similar context, it alludes to the models and methodology comparable to or drawing from established work, likely including BLP methods.",
          "quote": "Due to the curse of dimensionality, solving this recursive formulation is intractable for problems of practical relevance (e.g., Adelman 2007)."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1187,
    "prompt_tokens": 27826,
    "total_tokens": 29013,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}