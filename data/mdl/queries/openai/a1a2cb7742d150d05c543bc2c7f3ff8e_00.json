{
  "paper": "a1a2cb7742d150d05c543bc2c7f3ff8e.txt",
  "words": 27198,
  "extractions": {
    "title": {
      "value": "A Survey on Fairness Without Demographics",
      "justification": "The title is prominently displayed at the beginning of the paper.",
      "quote": "A Survey on Fairness Without Demographics"
    },
    "description": "This paper provides a comprehensive survey on fairness in machine learning when sensitive demographic attributes are missing. It reviews recent efforts, presents a taxonomy of methods, and discusses challenges and future directions for research on ML fairness in such settings.",
    "type": {
      "value": "theoretical",
      "justification": "The paper is a survey that reviews existing research efforts, taxonomy, and theoretical advancements in fairness without demographic data.",
      "quote": "This survey reviews recent research efforts to enforce fairness when sensitive attributes are missing."
    },
    "primary_research_field": {
      "name": {
        "value": "Fairness in Machine Learning",
        "justification": "The paper focuses on fairness issues in machine learning, specifically in scenarios where demographic information is not fully available.",
        "quote": "The issue of bias in Machine Learning (ML) models is a significant challenge for the machine learning community."
      },
      "aliases": [
        "Algorithmic Fairness"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Bias Mitigation",
          "justification": "The paper discusses various methods and approaches to mitigate biases in the absence of demographic data.",
          "quote": "This survey reviews recent research efforts to enforce fairness when sensitive attributes are missing..."
        },
        "aliases": [
          "Bias Reduction"
        ]
      },
      {
        "name": {
          "value": "Privacy-Preserving Machine Learning",
          "justification": "The paper explores how privacy concerns impact fairness in machine learning and discusses methods to handle this.",
          "quote": "This survey reviews recent research efforts to enforce fairness when sensitive attributes are missing due to privacy restrictions."
        },
        "aliases": [
          "Privacy in AI"
        ]
      }
    ],
    "models": [],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "Pytorch",
          "justification": "Pytorch is mentioned as a library used for developing some of the discussed methods or frameworks in the survey.",
          "quote": "Pytorch is used in the development of many methods that aim at learning fairness without accessing demographic attributes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Pytorch: Tensors and Dynamic neural networks in Python with strong GPU acceleration",
          "justification": "Pytorch is a well-known library used in many ML applications, corroborated by the name mentioned.",
          "quote": "Pytorch is used in the development of many methods that aim at learning fairness without accessing demographic attributes."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 470,
    "prompt_tokens": 42947,
    "total_tokens": 43417,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}