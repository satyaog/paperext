{
  "paper": "e57c0cabfd462478c18616ab368dd2fb.txt",
  "words": 9889,
  "extractions": {
    "title": {
      "value": "UTG: Towards a Unified View of Snapshot and Event Based Models for Temporal Graphs",
      "justification": "The title is explicitly mentioned at the beginning of the text and also highlighted in repeated headers throughout the paper.",
      "quote": "UTG: Towards a Unified View of Snapshot and Event Based Models for Temporal Graphs"
    },
    "description": "The paper introduces the Unified Temporal Graph (UTG) framework, integrating snapshot-based and event-based machine learning models for temporal graphs to enhance cross-model application and comparison. It also presents a novel UTG training procedure to improve snapshot-based models' performance in streaming settings and provides benchmarking across various temporal graph datasets.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical evaluations, training methods, and comparisons between models, as indicated by experimental setups and results sections.",
      "quote": "We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task."
    },
    "primary_research_field": {
      "name": {
        "value": "Graph Neural Networks",
        "justification": "The research focuses on Graph Neural Networks (GNNs), evaluating their performance on temporal graphs, which indicates its primary placement in the field.",
        "quote": "Recently, Graph Neural Networks (GNNs) and Graph Transformers have achieved remarkable success in various tasks for static graphs."
      },
      "aliases": [
        "GNNs"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Temporal Graphs",
          "justification": "The paper establishes a framework specifically for temporal graphs and conducts experiments on temporal datasets, reflecting this focus.",
          "quote": "In this paper, we introduce Unified Temporal Graph (UTG), a framework that unifies snapshot-based and event-based machine learning models under a single umbrella."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Graph Transformers",
          "justification": "Graph Transformers are mentioned as part of the successful models along with GNNs for tasks related to graphs.",
          "quote": "Graph Neural Networks (GNNs) and Graph Transformers have achieved remarkable success in various tasks for static graphs."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "TGN (Temporal Graph Network)",
          "justification": "TGN is mentioned as a benchmark event-based model to which `UTG` training is compared.",
          "quote": "second, snapshot-based models are at least an order of magnitude faster than most event-based models during inference. Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs."
        },
        "aliases": [
          "Temporal Graph Network",
          "TGN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "TGN is not a new contribution of this paper but rather an existing model used for comparison.",
          "quote": "event-based models such as TGN and GraphMixer."
        },
        "is_executed": {
          "value": true,
          "justification": "TGN is experimentally evaluated in this study, implying it was executed.",
          "quote": "We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task."
        },
        "is_compared": {
          "value": true,
          "justification": "TGN is numerically compared with other models in the evaluations.",
          "quote": "Our main findings are threefold:... snapshot-based models can perform competitively with event-based models such as TGN and GraphMixer even on event datasets."
        },
        "referenced_paper_title": {
          "value": "Temporal Graph Networks for Deep Learning on Dynamic Graphs",
          "justification": "The referenced paper title for TGN in the citations is 'Temporal Graph Networks for Deep Learning on Dynamic Graphs'.",
          "quote": "Rossi et al. [15] introduce Temporal Graph Networks (TGNs)"
        }
      },
      {
        "name": {
          "value": "GraphMixer",
          "justification": "GraphMixer is another event-based model compared in the benchmark studies presented in the paper.",
          "quote": "Second, snapshot-based models are at least an order of magnitude faster than most event-based models during inference. Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GraphMixer is used for comparison in experiments, not as a novel model proposed by this research.",
          "quote": "event-based models such as TGN and GraphMixer."
        },
        "is_executed": {
          "value": true,
          "justification": "Like other models mentioned, GraphMixer is evaluated in the experiments, reflecting execution.",
          "quote": "We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task."
        },
        "is_compared": {
          "value": true,
          "justification": "GraphMixer is compared against other models in the study as indicated by benchmarking and evaluation.",
          "quote": "Our main findings are threefold:... snapshot-based models can perform competitively with event-based models such as TGN and GraphMixer."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The referenced paper specifically for GraphMixer isn't mentioned directly in the provided text.",
          "quote": "Do we really need complicated model architectures for temporal networks? In The Eleventh International Conference on Learning Representations, 2022."
        }
      },
      {
        "name": {
          "value": "NAT (Neighborhood-aware temporal network)",
          "justification": "NAT is highlighted as one of the event-based models significantly outperforming snapshot-based methods.",
          "quote": "Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs."
        },
        "aliases": [
          "NAT"
        ],
        "is_contributed": {
          "value": false,
          "justification": "NAT is not introduced as a new model in this paper but mentioned as a model for comparison.",
          "quote": "event-based models such as TGN and GraphMixer...event-based methods such as NAT and DyGFormer outperforms snapshot-based methods."
        },
        "is_executed": {
          "value": true,
          "justification": "NAT is part of the models analyzed in the experiments, indicating execution.",
          "quote": "We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task."
        },
        "is_compared": {
          "value": true,
          "justification": "The model is compared in terms of performance to other models, evident from result discussions.",
          "quote": "Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs."
        },
        "referenced_paper_title": {
          "value": "Neighborhood-aware scalable temporal network representation learning",
          "justification": "The paper by Luo and Li on NAT is listed in the references indicating the referenced work.",
          "quote": "Yuhong Luo and Pan Li. Neighborhood-aware scalable temporal network representation learning."
        }
      },
      {
        "name": {
          "value": "DyGFormer",
          "justification": "DyGFormer is identified as an event-based model used for comparative analysis, showing higher performance.",
          "quote": "event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "DyGFormer is utilized as part of performance comparison, not developed in this work.",
          "quote": "event-based models such as TGN and GraphMixer...event-based methods such as NAT and DyGFormer outperforms snapshot-based methods."
        },
        "is_executed": {
          "value": true,
          "justification": "DyGFormer is involved in the benchmark tests, indicating it was executed as part of the study.",
          "quote": "We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task."
        },
        "is_compared": {
          "value": true,
          "justification": "The model is used as a benchmark in the comparison study, providing numerical performance results.",
          "quote": "Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs."
        },
        "referenced_paper_title": {
          "value": "Towards better dynamic graph learning: New architecture and unified library",
          "justification": "Yu et al.'s work on DyGFormer is cited, providing the referenced paper title.",
          "quote": "Le Yu, Leilei Sun, Bowen Du, and Weifeng Lv. Towards better dynamic graph learning: New architecture and unified library."
        }
      },
      {
        "name": {
          "value": "GCLSTM",
          "justification": "GCLSTM is featured as a snapshot-based model, included in evaluations presenting its performance under the new UTG methodology.",
          "quote": "In comparison, GCLSTM learns the graph structure via a GCN while capturing temporal dependencies with an LSTM network [21]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper describes GCLSTM as an established method and examines its performance rather than introducing it newly.",
          "quote": "GCLSTM [13] learns the graph structure via a GCN while capturing temporal dependencies with an LSTM network."
        },
        "is_executed": {
          "value": true,
          "justification": "GCLSTM is applied and tested within the experiments under the UTG framework.",
          "quote": "By leveraging the UTG framework, we conduct the first systematic comparison between snapshot and event-based models on both CTDG and DTDG datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "It is compared within the scope of snapshot-based models against event-based counterparts in the study.",
          "quote": "HTGN, a snapshot-based model is able to outperform widely-used TGN and GraphMixer model. This shows that learning from the discretized snapshots can be effective even on CTDG datasets."
        },
        "referenced_paper_title": {
          "value": "GC-LSTM: Graph Convolution Embedded LSTM for Dynamic Network Link Prediction",
          "justification": "The referenced study by Chen et al. integrates deep learning for dynamic networks, cited during GCLSTM discussion.",
          "quote": "GC-LSTM: Graph convolution embedded LSTM for dynamic network link prediction. Applied Intelligence, pages 1–16, 2022."
        }
      },
      {
        "name": {
          "value": "EGCN (EvolveGCN)",
          "justification": "EGCN is one of the snapshot-based models analyzed through UTG.",
          "quote": "EGCN [14] employs a Recurrent Neural Network (RNN) to evolve the parameters of a GCN over time. "
        },
        "aliases": [
          "EvolveGCN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "EGCN is utilized for comparison and isn't new to the paper.",
          "quote": "EGCN [14] employs a Recurrent Neural Network (RNN) to evolve the parameters of a GCN over time."
        },
        "is_executed": {
          "value": true,
          "justification": "EGCN is implemented in the comparative evaluations as mentioned.",
          "quote": "By leveraging the UTG framework, we conduct the first systematic comparison between snapshot and event-based models on both CTDG and DTDG datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "EGCN's performance is evaluated relative to both snapshot-based and event-based models.",
          "quote": "While event-based methods such as NAT and DyGFormer outperform snapshot-based methods on both CTDGs and DTDGs..."
        },
        "referenced_paper_title": {
          "value": "EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs",
          "justification": "The related work by Pareja et al. on EGCN is cited for dynamic graph context.",
          "quote": "EvolveGCN: Evolving graph convolutional networks for dynamic graphs."
        }
      },
      {
        "name": {
          "value": "HTGN",
          "justification": "HTGN is a snapshot-based method cited in this paper for its use of hyperbolic geometry, analyzed under new UTG training.",
          "quote": "HTGN [12] utilizes hyperbolic geometry to better capture the complex and hierarchical nature of the evolving networks."
        },
        "aliases": [
          "Hyperbolic Temporal Graph Network"
        ],
        "is_contributed": {
          "value": false,
          "justification": "HTGN pre-exists this research and is used as a benchmark.",
          "quote": "HTGN [12] utilizes hyperbolic geometry to better capture the complex and hierarchical nature of the evolving networks."
        },
        "is_executed": {
          "value": true,
          "justification": "The execution of HTGN is suggested as it forms part of evaluated models using UTG.",
          "quote": "By leveraging the UTG framework, we conduct the first systematic comparison between snapshot and event-based models on both CTDG and DTDG datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "HTGN's results are compared to those of other models in the assessments.",
          "quote": "HTGN, a snapshot-based model is able to outperform widely-used TGN and GraphMixer model."
        },
        "referenced_paper_title": {
          "value": "Discrete-Time Temporal Network Embedding via Implicit Hierarchical Learning in Hyperbolic Space",
          "justification": "The related work by Yang et al. establishes the HTGN framework for temporal learning.",
          "quote": "Discrete-time temporal network embedding via implicit hierarchical learning in hyperbolic space."
        }
      },
      {
        "name": {
          "value": "ROLAND-GRU",
          "justification": "ROLAND-GRU, a snapshot-based model employing GRU mechanisms, is part of the model evaluation series under new training novels like UTG.",
          "quote": "HTGN (UTG) [12], GCLSTM (UTG) [13], EGCNo (UTG) [14], and ROLAND-GRU [18]."
        },
        "aliases": [
          "ROLAND"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The model has been included in comparative studies and referred to in cited papers, not as a new contribution.",
          "quote": "ROLAND-GRU [18]."
        },
        "is_executed": {
          "value": true,
          "justification": "ROLAND-GRU is executed within the study and is central to empirical results.",
          "quote": "By leveraging the UTG framework, we conduct the first systematic comparison between snapshot and event-based models on both CTDG and DTDG datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "ROLAND-GRU is numerically compared with other temporal models as outlined in the paper.",
          "quote": "HTGN (UTG) [12], GCLSTM (UTG) [13], EGCNo (UTG) [14], and ROLAND-GRU [18]."
        },
        "referenced_paper_title": {
          "value": "ROLAND: Graph Learning Framework for Dynamic Graphs",
          "justification": "The listing by You et al. solidifies ROLAND as a benchmark model for these investigations.",
          "quote": "ROLAND: graph learning framework for dynamic graphs."
        }
      },
      {
        "name": {
          "value": "GCN (Graph Convolutional Network)",
          "justification": "Standard GCN is mentioned as a basic model executed under UTG for showcasing UTG's adaptability.",
          "quote": "Lastly, we adapt a common 2-layer (static) GCN [1] under the UTG framework to demonstrate the flexibility of UTG (without a recurrent module)."
        },
        "aliases": [
          "Graph Convolutional Network"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Standard GCN is a pre-existing model framework used to establish baseline UTG solution assessments.",
          "quote": "Lastly, we adapt a common 2-layer (static) GCN [1] under the UTG framework."
        },
        "is_executed": {
          "value": true,
          "justification": "The execution is demonstrated by mentioning GCN evaluations under UTG.",
          "quote": "By leveraging the UTG framework, we conduct the first systematic comparison between snapshot and event-based models on both CTDG and DTDG datasets."
        },
        "is_compared": {
          "value": true,
          "justification": "GCN functions in comparative assessments within the study to highlight UTG training efficiency.",
          "quote": "Interestingly, even the simple GCN with UTG training can achieve second place performance on the Social Evo. dataset."
        },
        "referenced_paper_title": {
          "value": "Semi-supervised classification with graph convolutional networks",
          "justification": "The original development of GCN discussed in the reference provides background to the model's utilization.",
          "quote": "Kipf and Max Welling. Semi-supervised classification with graph convolutional networks."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MOOC",
          "justification": "MOOC is listed among the datasets for benchmarking CTDG and DTDG models in experiments presented in the paper.",
          "quote": "see Table 1: Dataset statistics."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "No specific reference title is given for MOOC in the provided excerpts.",
          "quote": "MOOC"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch Geometric Temporal",
          "justification": "Type-specific for temporal GNNs, PyTorch Geometric Temporal is specifically noted as the setting for modified snapshot model training in this study.",
          "quote": "The standard training for snapshot-based models, e.g., with Pytorch Geometric Temporal [33], are designed for tasks such as graph regression or node classification."
        },
        "aliases": [
          "PyG Temporal"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models",
          "justification": "cite made available in reference lists the formal research article explaining PyTorch Geometric Temporal framework approach.",
          "quote": "Panicomputer Ropublik Continuamente. Editorial Española en Crisis"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3426,
    "prompt_tokens": 17345,
    "total_tokens": 20771,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}