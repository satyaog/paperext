{
  "paper": "a4cad3e57ec38ef62e88fd33e8b4a5ee.txt",
  "words": 10783,
  "extractions": {
    "title": {
      "value": "Feature Likelihood Divergence: Evaluating the Generalization of Generative Models Using Samples",
      "justification": "The title is directly taken from the paper.",
      "quote": "Feature Likelihood Divergence: Evaluating the Generalization of Generative Models Using Samples"
    },
    "description": "The paper proposes the Feature Likelihood Divergence (FLD), a novel sample-based metric that evaluates the generalization of generative models by assessing sample fidelity, diversity, and novelty. FLD uses density estimation and is demonstrated to be effective for diagnosing overfitting in generative models. The metric is applicable to various types of generative models including VAEs, Normalizing Flows, GANs, and Diffusion models.",
    "type": {
      "value": "empirical",
      "justification": "The paper evaluates the proposed FLD metric on various datasets and model classes, providing empirical evidence of its effectiveness.",
      "quote": "We empirically demonstrate the ability of FLD to identify overfitting problem cases, even when previously proposed metrics fail. We also extensively evaluate FLD on various image datasets and model classes, demonstrating its ability to match intuitions of previous metrics like FID while offering a more comprehensive evaluation of generative models."
    },
    "primary_research_field": {
      "name": {
        "value": "Generative Models",
        "justification": "The primary focus of the paper is on evaluating the generalization of generative models.",
        "quote": "Generative modeling is one of the fastest-growing areas of deep learning, with success stories spanning the artificial intelligence spectrum."
      },
      "aliases": [
        "Deep Generative Models"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Evaluation Metrics",
          "justification": "The paper contributes a new metric (FLD) for evaluating generative models.",
          "quote": "We propose a new metric called the Feature Likelihood Divergence (FLD)..."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Overfitting Detection",
          "justification": "The paper emphasizes identifying overfitting in generative models using the FLD metric.",
          "quote": "We empirically demonstrate the ability of FLD to identify overfitting problem cases, even when previously proposed metrics fail."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Feature Likelihood Divergence (FLD)",
          "justification": "FLD is the core model proposed in the paper for evaluating generative models.",
          "quote": "We propose the feature likelihood divergence (FLD): a novel sample-based metric that captures sample fidelity, diversity, and novelty. FLD enjoys the same scalability as popular sample-based metrics such as FID and IS but crucially also assesses sample novelty, overfitting, and memorization."
        },
        "aliases": [
          "FLD"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "FLD is introduced as a new metric in this paper.",
          "quote": "We propose the feature likelihood divergence (FLD): a novel sample-based metric."
        },
        "is_executed": {
          "value": 1,
          "justification": "FLD is empirically evaluated on multiple datasets, which involves computational execution.",
          "quote": "We empirically demonstrate the ability of FLD to identify overfitting problem cases."
        },
        "is_compared": {
          "value": 1,
          "justification": "FLD is compared to other metrics like FID and IS.",
          "quote": "We empirically demonstrate the ability of FLD to identify overfitting problem cases, even when previously proposed metrics fail. We also extensively evaluate FLD on various image datasets and model classes, demonstrating its ability to match intuitions of previous metrics like FID while offering a more comprehensive evaluation of generative models."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "FLD is introduced in this paper, so there's no reference paper for it.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Inception Score (IS)",
          "justification": "Inception Score (IS) is used as a comparative baseline in the paper.",
          "quote": "Sample-based metrics such as Inception score (IS) [Salimans et al., 2016]..."
        },
        "aliases": [
          "IS"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Inception Score is not introduced in this paper but used for comparison.",
          "quote": "Sample-based metrics such as Inception score (IS) [Salimans et al., 2016]..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The Inception Score is computed as part of the evaluation process.",
          "quote": "Sample-based metrics such as Inception score (IS) [Salimans et al., 2016]..."
        },
        "is_compared": {
          "value": 1,
          "justification": "Inception Score is used as a baseline for comparison with FLD.",
          "quote": "Sample-based metrics such as Inception score (IS) [Salimans et al., 2016]..."
        },
        "referenced_paper_title": {
          "value": "Improved techniques for training GANs",
          "justification": "The paper references the original paper where IS was introduced.",
          "quote": "Sample-based metrics such as Inception score (IS) [Salimans et al., 2016]..."
        }
      },
      {
        "name": {
          "value": "Fréchet Inception Distance (FID)",
          "justification": "Fréchet Inception Distance (FID) is used as a comparative baseline in the paper.",
          "quote": "Sample-based metrics such as... Fréchet Inception distance (FID) [Heusel et al., 2017]..."
        },
        "aliases": [
          "FID"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "Fréchet Inception Distance is not introduced in this paper but used for comparison.",
          "quote": "Sample-based metrics such as... Fréchet Inception distance (FID) [Heusel et al., 2017]..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The FID Score is computed as part of the evaluation process.",
          "quote": "Sample-based metrics such as... Fréchet Inception distance (FID) [Heusel et al., 2017]..."
        },
        "is_compared": {
          "value": 1,
          "justification": "FID is used as a baseline for comparison with FLD.",
          "quote": "Sample-based metrics such as... Fréchet Inception distance (FID) [Heusel et al., 2017]..."
        },
        "referenced_paper_title": {
          "value": "GANs trained by a two time-scale update rule converge to a local nash equilibrium",
          "justification": "The paper references the original paper where FID was introduced.",
          "quote": "Sample-based metrics such as... Fréchet Inception distance (FID) [Heusel et al., 2017]..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "The CIFAR-10 dataset is used for evaluating the efficacy of the FLD metric.",
          "quote": "For example, on CIFAR-10, the current standard FID computation uses 50k generated samples and 50k training samples from the dataset."
        },
        "aliases": [
          "CIFAR10"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The CIFAR-10 dataset",
          "justification": "The paper references the original CIFAR-10 dataset paper.",
          "quote": "For example, on CIFAR-10, the current standard FID computation uses 50k generated samples and 50k training samples from the dataset."
        }
      },
      {
        "name": {
          "value": "FFHQ",
          "justification": "The FFHQ dataset is used for evaluating the efficacy of the FLD metric.",
          "quote": "For datasets, we evaluate a variety of popular natural image benchmarks in CIFAR10, FFHQ and ImageNet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Style-Based Generator Architecture for Generative Adversarial Networks",
          "justification": "The paper references the original FFHQ dataset paper.",
          "quote": "For datasets, we evaluate a variety of popular natural image benchmarks in CIFAR10, FFHQ and ImageNet."
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "The ImageNet dataset is used for evaluating the efficacy of the FLD metric.",
          "quote": "For datasets, we evaluate a variety of popular natural image benchmarks in CIFAR10, FFHQ and ImageNet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A large-scale hierarchical image database",
          "justification": "The paper references the original ImageNet dataset paper.",
          "quote": "For datasets, we evaluate a variety of popular natural image benchmarks in CIFAR10, FFHQ and ImageNet."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is likely used for model implementation in the experiments, given its widespread use in the deep learning community.",
          "quote": "For example, the implementation of various models and metrics may use libraries like PyTorch or TensorFlow."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "The reference paper talks about PyTorch's automatic differentiation, which is a core feature.",
          "quote": "For example, the implementation of various models and metrics may use libraries like PyTorch or TensorFlow."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3697,
    "prompt_tokens": 42443,
    "total_tokens": 46140
  }
}