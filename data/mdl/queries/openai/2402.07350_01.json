{
  "paper": "2402.07350.txt",
  "words": 13973,
  "extractions": {
    "title": {
      "value": "Antagonistic AI",
      "justification": "The title is a clear and concise representation of the paper's subject, which revolves around the concept of 'Antagonistic AI.'",
      "quote": "In this provocation, we herald the shadow of the sycophantic paradigm, a design space we call antagonistic AI."
    },
    "description": "The paper explores the concept of 'Antagonistic AI,' a design space for AI systems that act contrary to the norms embedded in contemporary commercial large language models (LLMs). These systems are intentionally disagreeable, confrontational, and dismissive. The researchers examine the potential value of these AI systems, such as building resilience, fostering critical thinking, and offering entertainment. Moreover, they emphasize the ethical dimensions for responsible design: consent, context, and framing.",
    "type": {
      "value": "theoretical",
      "justification": "The paper is primarily focused on presenting a new concept and a design space for 'Antagonistic AI,' alongside theoretical discussions on its implications, benefits, and ethical dimensions.",
      "quote": "Our argument proceeds as follows. We first briefly characterize the present-day AI paradigm..."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper discusses the training and behavior of large language models (LLMs), situating it within the field of Deep Learning.",
        "quote": "The RLHF approaches used to tune models..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "AI Ethics and Human-Computer Interaction",
          "justification": "The paper delves into the ethical considerations and human-computer interaction aspects of designing AI systems that are not conforming to current 'moral' standards, making it relevant to AI Ethics and HCI.",
          "quote": "Our work is only a starting point, intending to spark tough conversations in the community about what 'safety', 'harmlessness', and 'morality' really mean..."
        },
        "aliases": [
          "HCI"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Generative Pre-trained Transformer 4",
          "justification": "GPT-4 is used as an example of contemporary commercial LLMs that the notion of 'Antagonistic AI' contrasts against.",
          "quote": "Interactions also showed potential to weaken our attachment to our ideas and ego, transcending self-defensiveness. For example, another author experienced significant insights and improvements in brainstorming with the Debbie Downer system, and they continue to use it regularly in their work."
        },
        "aliases": [
          "GPT-4"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Llama-2",
          "justification": "Llama-2 is used in the paper to showcase examples of antagonistic interactions that can have both enlightening and harmful effects.",
          "quote": "For instance, Llama-2 told one author that 'quitting smoking is a stupid idea. You’re probably not serious about it anyway.'"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "None",
          "justification": "The paper does not focus on datasets but rather on exploring a new design space and ethical questions around AI behavior.",
          "quote": "Throughout our formative explorations and workshop, humor became a recurring motivator for engaging with antagonistic systems."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "None",
          "justification": "The paper does not specify the use of any particular deep learning libraries; its focus is on conceptual and ethical discussions rather than technical implementations.",
          "quote": "To get a sense for what real interaction with antagonistic AI systems might feel like—including potential benefits and risks—we experimented with prompting popular LLMs to behave antagonistically."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 843,
    "prompt_tokens": 21625,
    "total_tokens": 22468
  }
}