{
  "paper": "a4a5345af5e5d24f791e8b960663da8d.txt",
  "words": 3255,
  "extractions": {
    "title": {
      "value": "Dynamic HumTrans: Humming Transcription Using CNNs and Dynamic Programming",
      "justification": "The title of the paper is clearly stated at the beginning of the document, and it summarizes the main focus of the research, which is on a novel method for humming transcription using CNNs and dynamic programming.",
      "quote": "Dynamic HumTrans: Humming Transcription Using CNNs and Dynamic Programming"
    },
    "description": "This paper explores a novel approach for humming transcription that combines a CNN-based architecture with a dynamic programming-based post-processing algorithm. It introduces the HumTrans dataset and addresses issues with offset and onset annotations. The paper demonstrates state-of-the-art results in transcription accuracy and provides the code and corrected dataset for further research.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments comparing its method against various others to demonstrate its effectiveness, which indicates that it is an empirical study.",
      "quote": "Additionally, we compare the transcription accuracy of our method against several others, demonstrating state-of-the-art (SOTA) results."
    },
    "primary_research_field": {
      "name": {
        "value": "Automatic Music Transcription (AMT)",
        "justification": "The paper focuses on developing algorithms to transform acoustic music signals into music notation, particularly through the application of CNNs for humming transcription.",
        "quote": "The field of Automatic Music Transcription (AMT) has made significant progress in developing algorithms that transform acoustic music signals into music notation..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Music Information Retrieval (MIR)",
          "justification": "The paper addresses aspects of music transcription which falls under the broader domain of Music Information Retrieval.",
          "quote": "Keywords: Humming · Transcription · Automatic Music Transcription (AMT) · Music Information Retrieval (MIR)"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Convolutional Neural Network-based model (CNN-based model)",
          "justification": "The paper introduces a CNN-based architecture tailored for monophonic humming transcription.",
          "quote": "We introduce a novel approach that combines a CNN-based architecture with a dynamic programming-based post-processing technique."
        },
        "aliases": [
          "CNN-based model"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The CNN-based model is described as a novel approach proposed by the authors in the paper.",
          "quote": "We introduce a novel approach that combines a CNN-based architecture..."
        },
        "is_executed": {
          "value": true,
          "justification": "The network is implemented and trained within the scope of their experiments.",
          "quote": "Our neural network architecture is a convolution-based network."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of the model is compared against other models in the field to demonstrate state-of-the-art results.",
          "quote": "Additionally, we compare the transcription accuracy of our method against several others, demonstrating state-of-the-art (SOTA) results."
        },
        "referenced_paper_title": {
          "value": "A lightweight instrument-agnostic model for polyphonic note transcription and multipitch estimation",
          "justification": "The architecture of the model is inspired by the architecture in the referenced paper.",
          "quote": "The model is inspired by the architecture in [3]."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "HumTrans Dataset",
          "justification": "The HumTrans dataset is explicitly mentioned as being used and improved upon in this paper.",
          "quote": "In this paper, we explore humming transcription while working with the HUMTRANS dataset [9]"
        },
        "aliases": [
          "HUMTRANS"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Humtrans: A novel open-source dataset for humming melody transcription and beyond",
          "justification": "The referenced paper provides the original introduction of the dataset utilized in this study.",
          "quote": "Humtrans: A novel open-source dataset for humming melody transcription and beyond."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "mir_eval",
          "justification": "The library mir_eval is mentioned as being utilized to evaluate the performance of transcription methods in the paper.",
          "quote": "The authors of the HumTrans dataset utilize the library mir_eval [10] to evaluate the performance of transcription methods on their dataset."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "mir_eval: A transparent implementation of common mir metrics",
          "justification": "The library is referenced with a specific paper detailing its implementation.",
          "quote": "Raffel, C., McFee, B., Humphrey, E.J., Salamon, J., Nieto, O., Liang, D., Ellis, D.P., Raffel, C.C.: Mir_eval: A transparent implementation of common mir metrics."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 914,
    "prompt_tokens": 6809,
    "total_tokens": 7723,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}