{
  "paper": "c04d73e7e2b7df822098dcf7d8b26de3.txt",
  "words": 12117,
  "extractions": {
    "title": {
      "value": "Rethinking Machine Learning Benchmarks in the Context of Professional Codes of Conduct",
      "justification": "The title of the paper is provided at the beginning and in the ACM Reference Format section.",
      "quote": "Peter Henderson, Jieru Hu, Mona Diab, and Joelle Pineau. 2024. Rethinking\nMachine Learning Benchmarks in the Context of Professional Codes of\nConduct."
    },
    "description": "The paper discusses the limitations of current machine learning benchmarks, particularly in professional fields like law, and suggests that professional codes of conduct could better guide the evaluation of machine learning models, especially those used in critical domains such as legal settings. It highlights the gaps in current benchmarking efforts and proposes modifications that align more closely with real-world practices.",
    "type": {
      "value": "theoretical",
      "justification": "The paper focuses on proposing new theoretical frameworks for benchmarking machine learning models based on professional standards rather than solely providing empirical results.",
      "quote": "We suggest further refinements that would bring the two closer together, including requiring a measurement of uncertainty so that models opt out of uncertain translations."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper primarily deals with machine translation and natural language processing in legal systems.",
        "quote": "To highlight this gap and propose potential solutions, we focus on the more restricted domain of automated machine translation."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Translation",
          "justification": "The paper specifically discusses the challenges and proposals related to automated machine translation.",
          "quote": "The allure of using state-of-the-art machine translation is understandable."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-4",
          "justification": "The paper mentions GPT-4 in the context of passing professional exams like the bar exam.",
          "quote": "Scoring highly on this benchmark and other similarly situated ones, inevitably leads to eye-catching results like, “GPT-4 has passed the bar exam” [Katz et al. 2023]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GPT-4 is mentioned as an existing model, not a contribution of this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not detail running executions of GPT-4.",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not provide a comparative analysis involving GPT-4 against other models.",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "Gpt-4 passes the bar exam",
          "justification": "The paper cites a specific reference where GPT-4's performance on exams is discussed.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "NLLB (No Language Left Behind)",
          "justification": "NLLB is mentioned as a machine translation model providing proficiency for particular languages.",
          "quote": "such as on the website for a machine translation modeling effort called No Lanugage Left Behind (NLLB) [Costa-jussà et al. 2022]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "NLLB is discussed as an existing model and not a contribution from this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper mentions NLLB but does not describe executing the model.",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not compare NLLB against other models within the scope of the paper.",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "No Language Left Behind: Scaling Human-Centered Machine Translation",
          "justification": "The referenced paper discusses the NLLB model as indicated by the citation.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Google Translate",
          "justification": "The paper uses Google Translate as an example of machine translation tools used in legal contexts.",
          "quote": "In response to these mandates, many turn to automated systems, such as Google Translate, to make their websites multilingual."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Google Translate is an existing tool and not a contribution of this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not focus on executing Google Translate itself but discusses its implications.",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not provide a comparative analysis involving Google Translate.",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "Lost in Translation",
          "justification": "The paper references a discussion on automated translation systems, namely Google Translate, in government settings.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MMLU benchmark",
          "justification": "The MMLU benchmark is used to evaluate language foundation models, as discussed in the paper.",
          "quote": "many language foundation models are evaluated on the MMLU benchmark [Hendrycks et al. 2020]"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Measuring massive multitask language understanding",
          "justification": "The referenced paper by Hendrycks et al. 2020 is likely the paper that introduced or discussed the MMLU benchmark.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Flores 200",
          "justification": "Mentioned regarding language proficiency estimates for machine translation models like NLLB.",
          "quote": "which presents the estimated proficiency of the model for a particular language (based on the language performance on an accompanying benchmark)."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "No Language Left Behind: Scaling Human-Centered Machine Translation",
          "justification": "The Flores 200 dataset is connected to discussions on the NLLB model by the same referenced paper.",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "XGBoost",
          "justification": "The paper references XGBoost in the context of building prediction models.",
          "quote": "We then use another calibration method... an XGBoost model is fit to a hold-out calibration set."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Xgboost: A scalable tree boosting system",
          "justification": "The paper cites Chen and Guestrin (2016) which is a known reference for XGBoost.",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1275,
    "prompt_tokens": 20110,
    "total_tokens": 21385,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}