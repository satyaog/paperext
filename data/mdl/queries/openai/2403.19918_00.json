{
  "paper": "2403.19918.txt",
  "words": 11035,
  "extractions": {
    "title": {
      "value": "CtRL-Sim: Reactive and Controllable Driving Agents with Offline Reinforcement Learning",
      "justification": "This is the title of the paper as stated at the top of the document.",
      "quote": "CtRL-Sim: Reactive and Controllable Driving Agents with Offline Reinforcement Learning"
    },
    "description": "The paper proposes CtRL-Sim, a method for generating reactive and controllable traffic agents using return-conditioned offline reinforcement learning. It processes real-world driving data through the Nocturne simulator to create a diverse dataset and trains a multi-agent behavior model. This enables generation of various driving behaviors by modifying desired returns for reward components, allowing for fine-grained control over agent behaviors, including adversarial scenarios.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes experiments, comparisons with baselines, and performance evaluations, indicating it is an empirical study.",
      "quote": "We present experiments showing the effectiveness of CtRL-Sim at producing controllable and reactive behaviours, while maintaining competitive performance on the imitation task compared to baselines."
    },
    "primary_research_field": {
      "name": {
        "value": "Autonomous Driving",
        "justification": "The paper focuses on generating realistic traffic agents for use in autonomous vehicle simulation environments.",
        "quote": "realistic and diverse behaviours that are reactive to the AV, while being easily controllable..."
      },
      "aliases": [
        "Autonomous Vehicles",
        "Self-Driving Cars"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Offline Reinforcement Learning",
          "justification": "The paper uses return-conditioned offline reinforcement learning to train their behavior model.",
          "quote": "return-conditioned offline reinforcement learning to efficiently generate reactive and controllable traffic agents."
        },
        "aliases": [
          "Offline RL"
        ]
      },
      {
        "name": {
          "value": "Simulation",
          "justification": "The work heavily involves simulation of autonomous vehicle behaviors to test the effectiveness of the method.",
          "quote": "Simulation has emerged as a promising tool for efficiently validating the safety of autonomous vehicles (AVs) in these long-tail scenarios."
        },
        "aliases": [
          "Simulated Environments"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "CtRL-Sim",
          "justification": "The model introduced and used in the paper is CtRL-Sim.",
          "quote": "In this paper, we propose CtRL-Sim to address these limitations of prior work."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The main contribution of the paper is the introduction of the CtRL-Sim method.",
          "quote": "We propose CtRL-Sim, which is, to the best of our knowledge, the first framework applying return-conditioned offline RL for controllable and reactive behaviour simulation."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model is executed as part of the experiments and evaluations presented in the paper.",
          "quote": "We process scenes from the Waymo Open Motion Dataset through Nocturne to curate an offline RL dataset for training..."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares CtRL-Sim to multiple baseline models to demonstrate its effectiveness.",
          "quote": "We present experiments showing the effectiveness of CtRL-Sim at producing controllable and reactive behaviours, while maintaining competitive performance on the imitation task compared to baselines."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "CtRL-Sim is introduced in this paper and does not have a separate reference.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Waymo Open Motion Dataset",
          "justification": "The dataset used in the research is the Waymo Open Motion Dataset.",
          "quote": "process real-world driving data through a physics-enhanced Nocturne simulator... scenes from the Waymo Open Motion Dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Large Scale Interactive Motion Forecasting for Autonomous Driving : The Waymo Open Motion Dataset",
          "justification": "The referenced title of the dataset cited in the paper.",
          "quote": "Waymo Open Motion Dataset [14]"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Nocturne",
          "justification": "The simulator used in the research is Nocturne.",
          "quote": "The CtRL-Sim framework utilizes return-conditioned offline reinforcement learning (RL) to enable reactive, closed-loop, controllable, and probabilistic behaviour simulation within a physics-enhanced Nocturne environment."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Nocturne: A Scalable Driving Benchmark for Bringing Multi-Agent Learning One Step Closer to the Real World",
          "justification": "The referenced title of the library cited in the paper.",
          "quote": "Nocturne [13]"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 911,
    "prompt_tokens": 19286,
    "total_tokens": 20197
  }
}