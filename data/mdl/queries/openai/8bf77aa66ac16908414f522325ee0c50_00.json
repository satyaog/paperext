{
  "paper": "8bf77aa66ac16908414f522325ee0c50.txt",
  "words": 12682,
  "extractions": {
    "title": {
      "value": "DyG2Vec: Efficient Representation Learning for Dynamic Graphs",
      "justification": "The title is clearly stated at the beginning of the paper.",
      "quote": "DyG2Vec: Efficient Representation Learning for Dynamic\nGraphs"
    },
    "description": "This paper introduces DyG2Vec, an efficient encoder-decoder model for continuous-time dynamic graphs, leveraging a window-based architecture and non-contrastive self-supervised learning to outperform state-of-the-art baseline models in future link prediction tasks, with significantly less computational time.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents experimental results and compares its proposed model, DyG2Vec, with state-of-the-art models across 7 benchmark datasets. This indicates an empirical research focus.",
      "quote": "Experimental results on 7 benchmark datasets indicate..."
    },
    "primary_research_field": {
      "name": {
        "value": "Representation Learning",
        "justification": "The primary focus is on developing efficient representation learning techniques for dynamic graphs.",
        "quote": "In this work, we propose DyG2Vec, a novel efficient encoder-decoder model for continuous-time dynamic\ngraphs that benefits from a window-based architecture that acts as a regularizer to avoid over-fitting."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Dynamic Graphs",
          "justification": "The paper focuses on representation learning specifically for dynamic graphs.",
          "quote": "Continuous-time dynamic graphs (Kazemi et al., 2020) are graphs in which each edge has a continuous\ntimestamp and can be naturally found in many real-world applications such as social networks and finance."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper proposes a non-contrastive self-supervised learning approach within its model.",
          "quote": "We propose a joint-embedding architecture using non-contrastive SSL to learn rich temporal embeddings without labels."
        },
        "aliases": [
          "SSL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "DyG2Vec",
          "justification": "DyG2Vec is the main model proposed in this paper for efficient representation learning in dynamic graphs.",
          "quote": "In this work, we propose DyG2Vec, a novel efficient encoder-decoder model for continuous-time dynamic\ngraphs..."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The paper introduces and describes DyG2Vec as a contribution of this research.",
          "quote": "In this work, we propose DyG2Vec, a novel efficient encoder-decoder model..."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper includes experimental results and evaluations using DyG2Vec.",
          "quote": "Our results on 7 benchmark datasets indicate that on average, DyG2Vec outperforms the SoTA baseline CaW..."
        },
        "is_compared": {
          "value": true,
          "justification": "DyG2Vec is compared with several state-of-the-art models as part of the evaluation.",
          "quote": "...our model outperforms SoTA baselines on the future link prediction task by 4.23%..."
        },
        "referenced_paper_title": {
          "value": "Not Applicable",
          "justification": "DyG2Vec is the original contribution of this paper, thus not directly referencing another paper for its title.",
          "quote": "Not Applicable"
        }
      },
      {
        "name": {
          "value": "CaW",
          "justification": "CaW is consistently used as a benchmark to compare DyG2Vec's performance on tasks.",
          "quote": "...DyG2Vec outperforms the SoTA baseline CaW (Wang et al., 2021b) on the future link prediction task..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "CaW is not the contribution of this paper but is a baseline for comparison.",
          "quote": "...our model outperforms the SoTA baseline CaW (Wang et al., 2021b)..."
        },
        "is_executed": {
          "value": false,
          "justification": "CaW is primarily used as a baseline model for performance comparison, not executed within this paper's experiments.",
          "quote": "...our model outperforms the SoTA baseline CaW..."
        },
        "is_compared": {
          "value": true,
          "justification": "CaW's performance is compared with DyG2Vec in experimental results.",
          "quote": "...DyG2Vec outperforms the SoTA baseline CaW..."
        },
        "referenced_paper_title": {
          "value": "Not Defined",
          "justification": "CaW is referenced multiple times but without a specific paper title indicated.",
          "quote": "CaW (Wang et al., 2021b) extracts temporal patterns..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Reddit",
          "justification": "The Reddit dataset is used for evaluating the model's performance in prediction tasks.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Temporal Graph Networks for Deep Learning on Dynamic Graphs",
          "justification": "This dataset was previously used in related work, particularly in Xu et al. 2020.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        }
      },
      {
        "name": {
          "value": "Wikipedia",
          "justification": "The Wikipedia dataset is used for evaluating the model's performance in prediction tasks.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Temporal Graph Networks for Deep Learning on Dynamic Graphs",
          "justification": "This dataset was previously used in related work, particularly in Xu et al. 2020.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        }
      },
      {
        "name": {
          "value": "MOOC",
          "justification": "The MOOC dataset is used for evaluating the model's performance in prediction tasks.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not Defined",
          "justification": "",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        }
      },
      {
        "name": {
          "value": "LastFM",
          "justification": "The LastFM dataset is used for evaluating the model's performance in prediction tasks.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Not Defined",
          "justification": "",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019)..."
        }
      },
      {
        "name": {
          "value": "Enron",
          "justification": "The Enron dataset is mentioned in both the experimental evaluation and dataset description.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Inductive representation learning in temporal networks via causal anonymous walks",
          "justification": "This dataset was previously used in related work, particularly in Wang et al. 2021b.",
          "quote": "Datasets: We use 7 real-world datasets... SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "UCI",
          "justification": "The UCI dataset is used for evaluating the model's performance in prediction tasks.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Inductive representation learning in temporal networks via causal anonymous walks",
          "justification": "This dataset was previously used in related work, particularly in Wang et al. 2021b.",
          "quote": "Datasets: We use 7 real-world datasets... SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      },
      {
        "name": {
          "value": "SocialEvolution",
          "justification": "The SocialEvolution dataset is used for evaluating the model's performance in prediction tasks.",
          "quote": "Datasets: We use 7 real-world datasets: Wikipedia, Reddit, MOOC, and LastFM (Kumar et al., 2019); SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Inductive representation learning in temporal networks via causal anonymous walks",
          "justification": "This dataset was previously used in related work, particularly in Wang et al. 2021b.",
          "quote": "Datasets: We use 7 real-world datasets... SocialEvolution, Enron, and UCI (Wang et al., 2021b)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch Geometric",
          "justification": "PyTorch Geometric is mentioned as a framework used for implementing the dynamic graph data and GNN encoder architecture.",
          "quote": "The dynamic graph data and GNN encoder architecture are implemented using Pytorch Geometric (Fey & Lenssen, 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fast graph representation learning with PyTorch Geometric",
          "justification": "The paper PyTorch Geometric by Fey & Lenssen, 2019 is frequently referenced for this library.",
          "quote": "Fast graph representation learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2090,
    "prompt_tokens": 21919,
    "total_tokens": 24009,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}