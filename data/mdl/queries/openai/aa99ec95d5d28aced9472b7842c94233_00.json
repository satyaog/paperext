{
  "paper": "aa99ec95d5d28aced9472b7842c94233.txt",
  "words": 9365,
  "extractions": {
    "title": {
      "value": "End-to-end Conditional Robust Optimization",
      "justification": "The title is clearly mentioned at the beginning of the paper, which typically names the paper.",
      "quote": "End-to-end Conditional Robust Optimization"
    },
    "description": "This paper introduces a novel end-to-end framework for conditional robust optimization (CRO) that integrates contextual uncertainty quantification and optimization. It proposes an end-to-end training algorithm to produce contextual uncertainty sets for the CRO problem, enhancing conditional coverage while improving robustness. It empirically demonstrates its superior performance compared to traditional Estimate Then Optimize approaches, especially in high-stakes applications like portfolio optimization.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes empirical demonstrations and comparisons of the end-to-end approach with other methods using synthetic and real-world datasets.",
      "quote": "We demonstrate through a set of synthetic environments that our end-to-end approach surpasses ETO approaches at the CRO task while achieving comparable if not superior conditional coverage with its learned contextual set"
    },
    "primary_research_field": {
      "name": {
        "value": "Optimization in Machine Learning",
        "justification": "The paper focuses on integrating machine learning with optimization processes specifically in the context of decision making under uncertainty, which is a key aspect of optimization in machine learning.",
        "quote": "The field of Contextual Optimization (CO) integrates machine learning and optimization to solve decision making problems under uncertainty."
      },
      "aliases": [
        "CO"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Conditional Robust Optimization",
          "justification": "The paper centers around Conditional Robust Optimization (CRO), a variant of contextual optimization dealing with uncertainty quantification and robust optimization.",
          "quote": "Conditional Robust Optimization (CRO), combines uncertainty quantification with robust optimization in order to promote safety and reliability in high stake applications."
        },
        "aliases": [
          "CRO"
        ]
      },
      {
        "name": {
          "value": "Portfolio Optimization",
          "justification": "The paper specifically demonstrates its approach using a portfolio optimization problem as an application example.",
          "quote": "We show empirically how our end-to-end learning approach outperforms other state-of-the-art methods on a portfolio optimization problem using real world data from the US stock market"
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "End-to-End Conditional Robust Optimization Model",
          "justification": "The paper proposes a new model aimed at improving Conditional Robust Optimization through an end-to-end learning framework.",
          "quote": "We propose for the first time an end-to-end training algorithm to produce contextual uncertainty sets, U(ψ) that lead to reduced risk exposure for the solution of the down-stream CRO problem"
        },
        "aliases": [
          "ECRO"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The proposed model is a novel contribution by the authors that integrates the training algorithm to the CRO framework.",
          "quote": "Our contributions can be described as follows: We propose for the first time an end-to-end training algorithm..."
        },
        "is_executed": {
          "value": true,
          "justification": "The model's performance is empirically validated using synthetic datasets and real-world portfolio optimization tasks.",
          "quote": "We demonstrate through a set of synthetic environments that our end-to-end approach surpasses ETO approaches..."
        },
        "is_compared": {
          "value": true,
          "justification": "The model's performance is compared against traditional ETO approaches in terms of CVaR performance and coverage.",
          "quote": "We conduct a comparative analysis between our two end-to-end approaches, TbS and DTbS, and three state-of-the-art ETO approaches..."
        },
        "referenced_paper_title": {
          "value": "Data-driven conditional robust optimization",
          "justification": "The reference paper for CRO is likely this, as it is mentioned together with the mention of CRO in the introduction of the paper.",
          "quote": "A natural risk averse variant of integrated learning and optimization takes the form of Conditional Robust Optimization (CRO) (see Chenreddy et al. [2022])"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "US Stock Market Data",
          "justification": "The dataset is used in the empirical evaluation of the portfolio optimization problem presented in the paper.",
          "quote": "We show empirically how our end-to-end learning approach outperforms other state-of-the-art methods on a portfolio optimization problem using real world data from the US stock market"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Data-driven conditional robust optimization",
          "justification": "The paper mentions a similar portfolio optimization problem using stock market data in prior work by the authors, likely referencing this paper.",
          "quote": "A natural risk averse variant of integrated learning and optimization takes the form of Conditional Robust Optimization (CRO) (see Chenreddy et al. [2022])"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Auto-differentiation",
          "justification": "Auto-differentiation is mentioned in the context of obtaining gradients, important for the end-to-end training framework in the paper.",
          "quote": "Given that ∇ xc(x),∇θμθ(ψ), and ∇θΣθ(ψ) can be readily obtained using auto-differentiation..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Auto-differentiating linear algebra",
          "justification": "Auto-differentiation methods were cited from Seeger et al. [2017] in the context of this technical requirement.",
          "quote": "Given that ∇ xc(x),∇θμθ(ψ), and ∇θΣθ(ψ) can be readily obtained using auto-differentiation Seeger et al. [2017]"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1097,
    "prompt_tokens": 18065,
    "total_tokens": 19162,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}