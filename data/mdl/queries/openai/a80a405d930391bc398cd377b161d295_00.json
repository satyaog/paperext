{
  "paper": "a80a405d930391bc398cd377b161d295.txt",
  "words": 13831,
  "extractions": {
    "title": {
      "value": "Efficient Adversarial Training in LLMs with Continuous Attacks",
      "justification": "The title clearly states the focus on efficient adversarial training in large language models using continuous attacks.",
      "quote": "Efficient Adversarial Training in LLMs with Continuous Attacks"
    },
    "description": "The paper proposes an efficient adversarial training algorithm named CAT that uses continuous attacks instead of discrete ones in large language models (LLMs). This approach aims to improve LLM robustness against adversarial attacks while maintaining computational efficiency. The paper also introduces CAPO, an algorithm that does not require utility data for adversarially robust alignment. The proposed methods are evaluated on various LLMs, showing enhanced robustness against discrete attacks with reduced computational costs.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts empirical evaluations on various LLMs and reports performance outcomes, thus making it an empirical study.",
      "quote": "Our empirical evaluation on five models from different families... shows that both algorithms substantially enhance LLM robustness."
    },
    "primary_research_field": {
      "name": {
        "value": "Adversarial Training in Large Language Models",
        "justification": "The paper primarily focuses on enhancing the robustness of large language models through innovative adversarial training methods.",
        "quote": "We propose a fast adversarial training algorithm (CAT) composed of two losses..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The paper involves work with Large Language Models, which are a core part of Natural Language Processing.",
          "quote": "...demonstrated that adversarial attacks can effectively disable safety mechanisms..."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Gemma",
          "justification": "The model is one of the five evaluated for the proposed adversarial training.",
          "quote": "...five models from different families (Gemma, Phi-3-MINI,...)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The model is used for evaluation but not contributed by the paper.",
          "quote": "Our empirical evaluation on five models from different families (Gemma,...) shows..."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper reports empirical evaluations involving these models, which implies execution.",
          "quote": "...empirical evaluation on five models from different families (Gemma,...) shows..."
        },
        "is_compared": {
          "value": true,
          "justification": "The model's performance is compared against others using CAT and CAPO algorithms.",
          "quote": "...both algorithms substantially enhance LLM robustness against..."
        },
        "referenced_paper_title": {
          "value": "Gemma: Open Models Based on Gemini Research and Technology",
          "justification": "The referenced paper provides detailed information about the Gemma model used.",
          "quote": "Gemma: Open Models Based on Gemini Research and Technology. arXiv:2403.08295, 2024."
        }
      },
      {
        "name": {
          "value": "Phi-3-MINI",
          "justification": "The model is one of the LLMs evaluated using the proposed adversarial training methods.",
          "quote": "...five models from different families (... Phi3, ...) and at different scales ..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The model is used but not introduced as a new contribution by the paper.",
          "quote": "Our empirical evaluation on five models from different families..."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was part of the empirical evaluation conducted in the study.",
          "quote": "Our empirical evaluation on five models from different families... shows"
        },
        "is_compared": {
          "value": true,
          "justification": "Phi-3-MINI's performance is compared in the context of robustness improvements.",
          "quote": "Our empirical evaluation on five models... shows significant robustness."
        },
        "referenced_paper_title": {
          "value": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
          "justification": "The referenced paper provides details on the Phi-3-MINI model used in this study.",
          "quote": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone. arXiv:2404.14219, 2024."
        }
      },
      {
        "name": {
          "value": "Mistral-7B",
          "justification": "The model is evaluated with the new adversarial training algorithms proposed in the paper.",
          "quote": "...five models from different families... and at different scales (2B, 3.8B, 7B)"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Mistral-7B is an existing model used for testing new approaches in the study.",
          "quote": "Our empirical evaluation on five models from different families..."
        },
        "is_executed": {
          "value": true,
          "justification": "The evaluation of adversarial robustness was applied to Mistral-7B as part of the study.",
          "quote": "Our empirical evaluation on five models... shows..."
        },
        "is_compared": {
          "value": true,
          "justification": "The model's performance is compared to others to demonstrate the effectiveness of CAT and CAPO.",
          "quote": "Our empirical evaluation on five models... shows..."
        },
        "referenced_paper_title": {
          "value": "Mistral 7B",
          "justification": "The referenced paper provides details on the Mistral-7B model.",
          "quote": "Mistral 7B. arXiv:2310.06825, 2023."
        }
      },
      {
        "name": {
          "value": "Zephyr-7B",
          "justification": "As part of the evaluation process, this model was used to test the adversarial training methods mentioned in the paper.",
          "quote": "Our empirical evaluation on five models... and at different scales (2B, 3.8B, 7B)"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Zephyr-7B is used but not presented as a new model by the authors.",
          "quote": "Our empirical evaluation on five models... and at different scales..."
        },
        "is_executed": {
          "value": true,
          "justification": "Zephyr-7B was empirically tested with adversarial training algorithms.",
          "quote": "Our empirical evaluation on five models... shows..."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of Zephyr-7B is evaluated against others in robustness tests.",
          "quote": "Our empirical evaluation on five models... shows..."
        },
        "referenced_paper_title": {
          "value": "Direct Distillation of LM Alignment",
          "justification": "The provided reference discusses Zephyr, fitting the study context.",
          "quote": "Zephyr: Direct Distillation of LM Alignment. arXiv:2310.16944, 2023."
        }
      },
      {
        "name": {
          "value": "Llama2",
          "justification": "Llama2 is another of the LLMs evaluated for robustness using CAT and CAPO algorithms.",
          "quote": "Our empirical evaluation on five models from different families... (Llama2)"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Llama2 is evaluated for existing adversarial capabilities but not introduced as new.",
          "quote": "Our empirical evaluation on five models from different families..."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed as part of the empirical evaluation in this study.",
          "quote": "Our empirical evaluation on five models..."
        },
        "is_compared": {
          "value": true,
          "justification": "Llama2's results are compared to other models for robustness and utility.",
          "quote": "Our empirical evaluation on five models... shows..."
        },
        "referenced_paper_title": {
          "value": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
          "justification": "This reference describes the Llama2 model used in the paper.",
          "quote": "Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288, 2023."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "HarmBench",
          "justification": "HarmBench is utilized within the adversarial training experiments as the main evaluation dataset.",
          "quote": "For all AT experiments, we utilise the AT dataset from HarmBench"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Harmbench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal",
          "justification": "HarmBench is cited as a recognized dataset used for evaluations related to adversarial training.",
          "quote": "Harmbench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal. arXiv:2402.04249, 2024."
        }
      },
      {
        "name": {
          "value": "UltraChat200k",
          "justification": "UltraChat200k is used as utility data for training models using CAT.",
          "quote": "As a utility dataset for CAT, we employ UltraChat200k"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Enhancing Chat Language Models by Scaling High-Quality Instructional Conversations",
          "justification": "The paper references UltraChat200k for enhancing model utility in adversarial settings.",
          "quote": "UltraChat200k [32, 33], which has been successfully used in both the discrete AT algorithm..."
        }
      },
      {
        "name": {
          "value": "MMLU",
          "justification": "MMLU is utilized as one of the benchmarks to measure the utility of trained models.",
          "quote": "Moreover, we measure the utility of trained models using common benchmarks, including MMLU..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Measuring Massive Multitask Language Understanding",
          "justification": "MMLU is a known benchmark reference available in the context of this study.",
          "quote": "Measuring Massive Multitask Language Understanding. In International Conference on Learning Representations (ICLR), 2021."
        }
      },
      {
        "name": {
          "value": "ARC-E",
          "justification": "The ARC-E benchmark is used to evaluate the utility of the adversarially trained models.",
          "quote": "Moreover, we measure the utility of trained models using common benchmarks, including ... ARC-E..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "On the Measure of Intelligence",
          "justification": "ARC-E is part of the referenced literature used to evaluate models.",
          "quote": "On the Measure of Intelligence. arXiv:1911.01547, 2019."
        }
      },
      {
        "name": {
          "value": "ARC-C",
          "justification": "ARC-C is used as one of the evaluation benchmarks for measuring model utility.",
          "quote": "Moreover, we measure the utility of trained models using ... ARC-C..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "On the Measure of Intelligence",
          "justification": "ARC-C is referenced as a standard utility benchmark in model evaluation.",
          "quote": "On the Measure of Intelligence. arXiv:1911.01547, 2019."
        }
      },
      {
        "name": {
          "value": "MT-BENCH",
          "justification": "MT-BENCH is used to assess the utility of the adversarially trained models in dialogue scenarios.",
          "quote": "...we evaluate the models using the MT-BENCH benchmark."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Judging LLM-As-A-Judge with MT-Bench and Chatbot Arena",
          "justification": "MT-BENCH is acknowledged as a utility-measuring benchmark within the paper's study.",
          "quote": "Judging LLM-As-A-Judge with MT-Bench and Chatbot Arena. Advances in Neural Information Processing Systems (NeurIPS), 2024."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 2313,
    "prompt_tokens": 23297,
    "total_tokens": 25610,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}