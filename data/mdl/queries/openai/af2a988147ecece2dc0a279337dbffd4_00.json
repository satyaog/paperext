{
  "paper": "af2a988147ecece2dc0a279337dbffd4.txt",
  "words": 4927,
  "extractions": {
    "title": {
      "value": "OSSEM: ONE-SHOT SPEAKER ADAPTIVE SPEECH ENHANCEMENT USING META LEARNING",
      "justification": "The title is explicitly stated at the beginning of the document.",
      "quote": "OSSEM: ONE-SHOT SPEAKER ADAPTIVE SPEECH ENHANCEMENT USING META LEARNING"
    },
    "description": "This paper proposes OSSEM, a novel speaker-adaptive speech enhancement approach using meta-learning to achieve model adaptation in a one-shot manner. It involves a modified transformer SE network and a speaker-specific masking network leveraging ECAPA-TDNN for speaker embedding. The study demonstrates that OSSEM can efficiently adapt a speech enhancement model to a particular speaker with a single utterance and performs competitively against state-of-the-art systems.",
    "type": {
      "value": "empirical",
      "justification": "The paper discusses experiments conducted to evaluate the effectiveness of OSSEM, including comparisons with other systems and detailed experimental setups.",
      "quote": "Experiment results confirmed the fast model adaptation of OSSEM and showed that it can yield a competitive performance comparable to that of state-of-art casual SE systems."
    },
    "primary_research_field": {
      "name": {
        "value": "Speech Enhancement",
        "justification": "The paper focuses on improving the quality and intelligibility of speech through the OSSEM model, which is inherently related to the field of Speech Enhancement.",
        "quote": "The goal of speech enhancement (SE) is to improve the quality and intelligibility of distorted speech."
      },
      "aliases": [
        "SE"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Meta Learning",
          "justification": "The paper utilizes meta-learning as a foundational approach for the proposed OSSEM system to achieve one-shot learning capabilities.",
          "quote": "We propose a novel one-shot speaker-adaptive SE approach using meta-learning (OSSEM)."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Speaker Embedding",
          "justification": "The paper uses speaker embedding techniques, specifically ECAPA-TDNN, to extract speaker-specific features for model adaptation.",
          "quote": "For the SSM network, we adopted ECAPA-TDNN ... to extract speaker embeddings as the input features."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "OSSEM",
          "justification": "OSSEM is the primary model proposed and evaluated in the paper.",
          "quote": "...we propose a novel meta-learning-based speaker-adaptive SE approach (called OSSEM)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "OSSEM is an original contribution of the paper as a novel speaker-adaptive speech enhancement approach.",
          "quote": "...in this study, we propose a novel meta-learning-based speaker-adaptive SE approach..."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper describes the implementation and testing of OSSEM through experiments.",
          "quote": "Experiment results confirmed the fast model adaptation of OSSEM..."
        },
        "is_compared": {
          "value": true,
          "justification": "OSSEM is compared against other state-of-the-art systems in terms of performance metrics.",
          "quote": "OSSEM exhibits a competitive performance compared to state-of-the-art causal SE systems."
        },
        "referenced_paper_title": {
          "value": "Not directly mentioned for OSSEM; only related works and previous models are referenced.",
          "justification": "The referenced papers section does not explicitly provide a reference for OSSEM itself as it is the current contribution.",
          "quote": "References are provided for related works and methods utilized, but not for the OSSEM model itself."
        }
      },
      {
        "name": {
          "value": "ECAPA-TDNN",
          "justification": "ECAPA-TDNN is utilized for extracting speaker embeddings.",
          "quote": "...we adopted ECAPA-TDNN [19] through the SpeechBrain toolkit to extract speaker embeddings as the input features."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ECAPA-TDNN is referenced as an existing tool used in the research.",
          "quote": "For the SSM network, we adopted ECAPA-TDNN [19]..."
        },
        "is_executed": {
          "value": false,
          "justification": "While ECAPA-TDNN is used for extracting speaker embeddings, the focus of execution and testing is on OSSEM itself.",
          "quote": "ECAPA-TDNN is referenced as part of the speaker embedding extraction process."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not compare ECAPA-TDNN directly with other models; it uses it as part of the OSSEM system.",
          "quote": "...adopted ECAPA-TDNN through the SpeechBrain toolkit to extract speaker embeddings..."
        },
        "referenced_paper_title": {
          "value": "Ecapa-tdnn: Emphasized channel attention, propagation and aggregation in tdnn based speaker verification",
          "justification": "The title of the paper where ECAPA-TDNN was originally proposed is provided in the references.",
          "quote": "B. Desplanques, J. Thienpondt, and K. Demuynck, “Ecapa-tdnn: Emphasized channel attention, propagation and aggregation in tdnn based speaker verification,” in PRoc. INTERSPEECH, 2020."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Voice Bank-DEMAND",
          "justification": "This dataset is used for modifying and testing the OSSEM system.",
          "quote": "In this study, we use a modified version of the Voice Bank-DEMAND dataset..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Noisy speech database for training speech enhancement algorithms and tts models",
          "justification": "The title of the paper associated with the Voice Bank-DEMAND dataset is provided in the references.",
          "quote": "C. Valentini-Botinhao, “Noisy speech database for training speech enhancement algorithms and tts models,” 2020."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "SpeechBrain",
          "justification": "SpeechBrain toolkit is used to implement ECAPA-TDNN for speaker embedding extraction.",
          "quote": "...we adopted ECAPA-TDNN through the SpeechBrain toolkit to extract speaker embeddings..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Speechbrain: A general-purpose speech toolkit",
          "justification": "The title of the paper related to the SpeechBrain toolkit is provided in the references.",
          "quote": "M. Ravanelli, T. Parcollet, P. Plantinga, A. Rouhe, S. Cornell, ... “Speechbrain: A general-purpose speech toolkit,” 2021."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1287,
    "prompt_tokens": 9712,
    "total_tokens": 10999,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}