{
  "paper": "ccb2b044e476b39277efa1f30ce8d463.txt",
  "words": 10818,
  "extractions": {
    "title": {
      "value": "In-Simulation Testing of Deep Learning Vision Models in Autonomous Robotic Manipulators",
      "justification": "The document explicitly mentions the title at the beginning and in the ACM reference format section.",
      "quote": "In-Simulation Testing of Deep Learning Vision Models in Autonomous Robotic Manipulators"
    },
    "description": "The paper presents the MARTENS framework, which integrates NVIDIA Isaac Sim simulator with evolutionary search, to test and enhance deep learning vision models in autonomous robotic manipulators. It focuses on uncovering design flaws and improving model performance by generating critical test scenarios in a simulated environment, demonstrating improved detection accuracy and system robustness.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves practical experiments and evaluations conducted through industrial case studies to assess the MARTENS framework, showing empirical evidence of improved detection accuracy and system robustness.",
      "quote": "Evaluation of two industrial case studies demonstrated that MARTENS effectively reveals robotic manipulator system failures, detecting 25% to 50% more failures with greater diversity compared to random test generation."
    },
    "primary_research_field": {
      "name": {
        "value": "Robotics",
        "justification": "The research is centered on testing and improving deep learning models used in autonomous robotic manipulator systems, which is a specific application within the field of Robotics.",
        "quote": "Testing autonomous robotic manipulators is challenging due to the complex software interactions between vision and control components."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The research uses deep learning models for object detection, a key area in Computer Vision, to improve vision capabilities in robotic manipulators.",
          "quote": "A crucial element of modern robotic manipulators is the deep learning based object detection model."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The research involves improving deep learning modelsâ€™ performance and robustness using synthetic data and evolutionary search approaches.",
          "quote": "The current techniques primarily focus on using synthetic data to train deep neural networks (DNNs) and identifying failures through offline or online simulation-based testing."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Simulation",
          "justification": "The MARTENS framework is built around simulation testing, leveraging photorealistic environments to test and improve deep learning models in robotics.",
          "quote": "We propose the MARTENS (Manipulator Robot Testing and Enhancement in Simulation) framework, which integrates a photorealistic NVIDIA Isaac Sim simulator."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "YOLOv8",
          "justification": "The paper specifies using YOLOv8 for object detection tasks, emphasizing its role in bounding box detection and enhancement through the MARTENS framework.",
          "quote": "This information can be inferred from the 2D images using YOLOv8 that natively supports the oriented bounding box detection."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "YOLOv8 is used as an existing model within the MARTENS framework rather than a novel contribution of the paper itself.",
          "quote": "Using the Isaac Replicator API, we propose generating annotated synthetic images by randomizing environmental parameters within specified distributions... Such labelled datasets can be used to train YOLOv8 for oriented bounding box detection."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is trained and tested within the MARTENS framework to perform object detection in simulation and real-world setups.",
          "quote": "For each of the use cases, we trained a dedicated vision DL model using 1200 synthetic images... An example of the model output predictions are shown in Figure 4."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper discusses various metrics such as mAP and F1 scores to compare the YOLOv8 model's performance before and after repair and tuning.",
          "quote": "Then, we used either M o or M f as a pre-trained DNN to train the vision model for detecting cardboard boxes in the real-world environment, referring to the resulting models as M or and M o f, respectively. As a baseline, we train a YOLOv8 model using its standard pre-trained weights exclusively on the real-world training dataset, denoted as M r ."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no specific paper cited for YOLOv8 within the given text.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Synthetic Dataset from NVIDIA Isaac Sim",
          "justification": "The dataset mentioned is specifically created within the simulation environment for training and improving the model, as described in the paper.",
          "quote": "Using NVIDIA Isaac Sim, we created a photorealistic simulation environment for ARM applications, enabling the collection of synthetic 2D annotated images for training the DL vision models."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "The dataset is specifically contributed by the authors for the purpose of the experiments in their framework, hence no external reference is applicable.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Real-World Dataset",
          "justification": "The real-world dataset is described as being collected for evaluating the performance of the trained models on actual scenarios.",
          "quote": "We collect and label two limited datasets, consisting of approximately 100 images each, from the actual production environments that conform to the simulation for both use cases."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "The dataset usage is described in the context of the paper's experiments without citing a specific external reference paper.",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "NVIDIA Isaac Sim",
          "justification": "This library is used extensively for creating the simulation environment in which the MARTENS framework operates.",
          "quote": "We propose the MARTENS (Manipulator Robot Testing and Enhancement in Simulation) framework, which integrates a photorealistic NVIDIA Isaac Sim simulator."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no specific reference to a paper about NVIDIA Isaac Sim in the given text.",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1200,
    "prompt_tokens": 17775,
    "total_tokens": 18975,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}