{
  "paper": "de5e15516bc9b421bb687dd352cf8a87.txt",
  "words": 13736,
  "extractions": {
    "title": {
      "value": "WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks",
      "justification": "The title is directly taken from the beginning of the paper where it is prominently displayed.",
      "quote": "WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks"
    },
    "description": "This paper introduces WorkArena++, a benchmark designed to evaluate the capabilities of web agents in performing common knowledge work tasks. It consists of 682 tasks that test skills such as planning, problem-solving, and information retrieval in enterprise settings. The paper also presents empirical studies comparing the performance of state-of-the-art AI models and human workers on these tasks.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical studies comparing AI models and humans on a newly proposed benchmark, indicating that it is empirical in nature.",
      "quote": "Our empirical studies across state-of-the-art LLMs and vision-language models (VLMs), as well as human workers, reveal several challenges for such models to serve as useful assistants in the workplace."
    },
    "primary_research_field": {
      "name": {
        "value": "Artificial Intelligence",
        "justification": "The research focuses on autonomous agents and their ability to perform tasks using AI models, fitting within the field of Artificial Intelligence.",
        "quote": "The ability of large language models (LLMs) to mimic human-like intelligence has led to a surge in LLM-based autonomous agents."
      },
      "aliases": [
        "AI"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The research involves large language models (LLMs), which are a core topic within Natural Language Processing.",
          "quote": "The ability of large language models (LLMs) to mimic human-like intelligence has led to a surge in LLM-based autonomous agents."
        },
        "aliases": [
          "NLP"
        ]
      },
      {
        "name": {
          "value": "Human-Computer Interaction",
          "justification": "The research involves agents interacting with user interfaces, which is a topic within Human-Computer Interaction.",
          "quote": "One major application is software control, with a large body of work focused on using LLMs to interact via Application Programming Interfaces (APIs)."
        },
        "aliases": [
          "HCI"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Chain-of-Thought",
          "justification": "The Chain-of-Thought model is explicitly mentioned as part of the background and literature review, indicating its prominence.",
          "quote": "Recent advances in the reasoning and planning capacities of large language models (LLMs), with developments such as Chain-of-Thought [Wei et al., 2022a]."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper references Chain-of-Thought as an existing model, not as a contribution of this paper.",
          "quote": "Recent advances in the reasoning and planning capacities of large language models (LLMs), with developments such as Chain-of-Thought [Wei et al., 2022a]."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not specify execution details for Chain-of-Thought.",
          "quote": "Recent advances in the reasoning and planning capacities of large language models (LLMs), with developments such as Chain-of-Thought [Wei et al., 2022a]."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not include numerical comparisons specifically involving Chain-of-Thought.",
          "quote": "Recent advances in the reasoning and planning capacities of large language models (LLMs), with developments such as Chain-of-Thought [Wei et al., 2022a]."
        },
        "referenced_paper_title": {
          "value": "Chain-of-thought prompting elicits reasoning in large language models",
          "justification": "The referenced paper by Wei et al., 2022a, corresponds to the title related to Chain-of-Thought prompting.",
          "quote": "Recent advances in the reasoning and planning capacities of large language models (LLMs), with developments such as Chain-of-Thought [Wei et al., 2022a]."
        }
      },
      {
        "name": {
          "value": "ReAct",
          "justification": "The ReAct model is mentioned as part of the discussion on existing literature and models, indicating its relevance.",
          "quote": "...with developments such as Chain-of-Thought [Wei et al., 2022a], ReAct [Yao et al., 2023]..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ReAct is referenced as part of the existing work in the field, not contributed by this paper.",
          "quote": "...with developments such as Chain-of-Thought [Wei et al., 2022a], ReAct [Yao et al., 2023]..."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not provide details of implementing or executing ReAct specifically.",
          "quote": "...with developments such as Chain-of-Thought [Wei et al., 2022a], ReAct [Yao et al., 2023]..."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not contain specific numerical comparisons involving ReAct.",
          "quote": "...with developments such as Chain-of-Thought [Wei et al., 2022a], ReAct [Yao et al., 2023]..."
        },
        "referenced_paper_title": {
          "value": "ReAct: Synergizing reasoning and acting in language models",
          "justification": "The referenced work by Yao et al., 2023, matches the title related to the ReAct model.",
          "quote": "...with developments such as Chain-of-Thought [Wei et al., 2022a], ReAct [Yao et al., 2023]..."
        }
      },
      {
        "name": {
          "value": "Tree-of-Thought",
          "justification": "Tree-of-Thought is discussed as part of the comparison and overview of reasoning models.",
          "quote": "...and Tree-of-Thought [Yao et al., 2024] (see [Huang et al., 2024, Wang et al., 2024b] for a review) suggest..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper references Tree-of-Thought as part of prior work.",
          "quote": "...and Tree-of-Thought [Yao et al., 2024] (see [Huang et al., 2024, Wang et al., 2024b] for a review) suggest..."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no description of Tree-of-Thought being executed or implemented in the paper.",
          "quote": "...and Tree-of-Thought [Yao et al., 2024] (see [Huang et al., 2024, Wang et al., 2024b] for a review) suggest..."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not provide specific numerical comparisons for Tree-of-Thought.",
          "quote": "...and Tree-of-Thought [Yao et al., 2024] (see [Huang et al., 2024, Wang et al., 2024b] for a review) suggest..."
        },
        "referenced_paper_title": {
          "value": "Tree of thoughts: Deliberate problem solving with large language models",
          "justification": "The paper by Yao et al., 2024, is directly aligned with the Tree-of-Thoughts model discussion.",
          "quote": "...and Tree-of-Thought [Yao et al., 2024] (see [Huang et al., 2024, Wang et al., 2024b] for a review) suggest..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Mind2Web",
          "justification": "Mind2Web is referenced in context of datasets related to web agents, fitting the theme of the paper.",
          "quote": "Deng et al. [2023] proposed Mind2Web, a large-scale collection of 2,000 web interactions from 137 websites curated by human annotators."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "Mind2Web: Towards a generalist agent for the web",
          "justification": "The dataset is referenced with this title by Deng et al., 2023, in the context of a similar field.",
          "quote": "Deng et al. [2023] proposed Mind2Web, a large-scale collection of 2,000 web interactions from 137 websites curated by human annotators."
        }
      },
      {
        "name": {
          "value": "WebLINX",
          "justification": "WebLINX is mentioned as a relevant dataset in the field of web interaction tasks, related to the paper's focus.",
          "quote": "Similarly, Lù et al. [2024] introduced WebLINX, a curated dataset of web interactions with 2337 expert demonstrations from 155 different real-world websites."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "WebLINX: Real-world website navigation with multi-turn dialogue",
          "justification": "The dataset WebLINX is referenced in context with this title by Lù et al., 2024.",
          "quote": "Similarly, Lù et al. [2024] introduced WebLINX, a curated dataset of web interactions with 2337 expert demonstrations from 155 different real-world websites."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "BrowserGym",
          "justification": "The paper integrates WorkArena++ with BrowserGym to facilitate design and evaluation of web agents.",
          "quote": "WorkArena++ is integrated into BrowserGym [Drouin et al., 2024] (Fig. 2b), a gym environment that facilitates the design and evaluation of web agents."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Workarena: How capable are web agents at solving common knowledge work tasks?",
          "justification": "BrowserGym's integration with WorkArena is part of the methodological contribution from Drouin et al., 2024.",
          "quote": "WorkArena++ is integrated into BrowserGym [Drouin et al., 2024] (Fig. 2b), a gym environment that facilitates the design and evaluation of web agents."
        }
      },
      {
        "name": {
          "value": "Hugging Face’s Text Generation Inference (TGI)",
          "justification": "Hugging Face's TGI library is used for deploying evaluated models on GPUs, underscoring its utility in this research.",
          "quote": "These model are deployed using Hugging Face’s Text Generation Inference (TGI) library on 4 A100 GPUs."
        },
        "aliases": [
          "Hugging Face TGI"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Mixtral of experts",
          "justification": "The library is discussed in the context of deploying Mixtral models, which is research by Jiang et al., 2024.",
          "quote": "These model are deployed using Hugging Face’s Text Generation Inference (TGI) library on 4 A100 GPUs."
        }
      },
      {
        "name": {
          "value": "Playwright",
          "justification": "Playwright is used as part of the oracle function to solve tasks in WorkArena++ and to generate traces, highlighting its role in the methodologies.",
          "quote": "WorkArena++ implements an \"oracle\" function that solves them step-by-step with Playwright code."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Playwright for Python documentation",
          "justification": "The use of Playwright is consistently referenced in the documentation and implementation context as a primary tool.",
          "quote": "WorkArena++ implements an \"oracle\" function that solves them step-by-step with Playwright code."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2326,
    "prompt_tokens": 22353,
    "total_tokens": 24679,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}