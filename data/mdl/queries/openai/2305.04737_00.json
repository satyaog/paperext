{
  "paper": "2305.04737.txt",
  "words": 9850,
  "extractions": {
    "title": {
      "value": "SkillQG: Learning to Generate Question for Reading Comprehension Assessment",
      "justification": "The title is explicitly mentioned in the research paper.",
      "quote": "SkillQG: Learning to Generate Question for Reading Comprehension Assessment"
    },
    "description": "This research paper presents SkillQG, a framework for generating questions tailored to different comprehension types. The framework uses a hierarchical skill-based schema inspired by Bloom’s Taxonomy, leveraging pretrained language models to improve generation controllability. The empirical results demonstrate SkillQG's superiority over other baselines in quality, relevance, and skill-controllability while boosting performance in downstream question answering tasks.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes empirical results and performance evaluations demonstrating the superiority of SkillQG over baseline methods.",
      "quote": "Empirical results demonstrate that SkillQG outperforms baselines in terms of quality, relevance, and skill-controllability while showing a promising performance boost in downstream question answering task."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research paper's main focus is on generating questions for reading comprehension, which falls under the domain of Natural Language Processing (NLP).",
        "quote": "We present SkillQG: a question generation framework with controllable comprehension types for assessing and improving machine reading comprehension models."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Question Generation",
          "justification": "The paper's main contribution is SkillQG, a question generation framework.",
          "quote": "We present SkillQG: a question generation framework with controllable comprehension types for assessing and improving machine reading comprehension models."
        },
        "aliases": [
          "QG"
        ]
      },
      {
        "name": {
          "value": "Machine Reading Comprehension",
          "justification": "The paper aims to assess and improve machine reading comprehension models using the questions generated by SkillQG.",
          "quote": "SkillQG is able to tailor a fine-grained assessment and improvement to the capabilities of question answering models built on it."
        },
        "aliases": [
          "MRC"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "SkillQG",
          "justification": "The paper introduces SkillQG as a novel question generation model.",
          "quote": "SkillQG: a question generation framework with controllable comprehension types."
        },
        "aliases": [
          "QG",
          "SkillQG"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "SkillQG is the primary contribution of the paper.",
          "quote": "We present SkillQG: a question generation framework with controllable comprehension types for assessing and improving machine reading comprehension models."
        },
        "is_executed": {
          "value": 1,
          "justification": "The model was trained and evaluated in various experiments using GPUs.",
          "quote": "Our experimental results show that SkillQG can produce more relevant and skill-controllable questions compared to baseline QG models."
        },
        "is_compared": {
          "value": 1,
          "justification": "The performance of SkillQG is compared against baseline QG models in the experiments.",
          "quote": "Our experimental results show that SkillQG can produce more relevant and skill-controllable questions compared to baseline QG models, and boost the QA performance significantly."
        },
        "referenced_paper_title": {
          "value": "not referenced",
          "justification": "SkillQG is a novel contribution introduced in this paper.",
          "quote": "not explicitly referenced"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "FairytaleQA",
          "justification": "The FairytaleQA dataset is used for training and evaluating the SkillQG model.",
          "quote": "We employ the official train and dev splits of FairytaleQA dataset (Xu et al., 2022) to train our SkillQG."
        },
        "aliases": [
          "FairytaleQA"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "FairytaleQA – an authentic dataset for narrative comprehension",
          "justification": "The dataset is referenced under the title 'FairytaleQA – an authentic dataset for narrative comprehension' by Xu et al., 2022.",
          "quote": "We employ the official train and dev splits of FairytaleQA dataset (Xu et al., 2022) to train our SkillQG."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "HuggingFace Transformers",
          "justification": "The HuggingFace Transformers library is used for initializing and fine-tuning the models.",
          "quote": "The question generator of our SkillQG is built on the basis of a BART-base model (Lewis et al., 2020)... initialized by the pre-trained parameters of the HuggingFace Transformers package (Wolf et al., 2020)."
        },
        "aliases": [
          "Transformers"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Transformers: State-of-the-art natural language processing",
          "justification": "The library is referenced in the paper under the title 'Transformers: State-of-the-art natural language processing' by Wolf et al., 2020.",
          "quote": "initialized by the pre-trained parameters of the HuggingFace Transformers package (Wolf et al., 2020)."
        }
      },
      {
        "name": {
          "value": "Spacy",
          "justification": "The Spacy NLP library is used for named entity recognition tasks in the pipeline.",
          "quote": "We resort to the Spacy tool (Honnibal and Montani, 2017) to extract named entities as the candidate answers."
        },
        "aliases": [
          "Spacy"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing",
          "justification": "The library is referenced under the title 'Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing' by Honnibal and Montani, 2017.",
          "quote": "We resort to the Spacy tool (Honnibal and Montani, 2017) to extract named entities as the candidate answers."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1149,
    "prompt_tokens": 17148,
    "total_tokens": 18297
  }
}