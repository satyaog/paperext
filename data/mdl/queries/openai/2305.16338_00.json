{
  "paper": "2305.16338.txt",
  "words": 9242,
  "extractions": {
    "title": {
      "value": "Think Before You Act: Decision Transformers with Internal Working Memory",
      "justification": "This value is the title of the paper as mentioned in the provided text.",
      "quote": "Think Before You Act: Decision Transformers with Internal Working Memory"
    },
    "description": "The paper proposes a novel architecture, Decision Transformers with Memory (DT-Mem), which introduces an internal working memory module to improve training efficiency and generalization for large language model-based decision-making agents. The working memory module helps manage and organize multiple skills efficiently, mitigating the forgetting phenomenon. Evaluation results demonstrate that DT-Mem improves performance in Atari games and Meta-World object manipulation tasks while reducing the number of parameters and training time required.",
    "type": {
      "value": "empirical",
      "justification": "The paper proposes a new model (DT-Mem) and evaluates its performance experimentally on Atari games and Meta-World environments, showing improved generalization and efficiency.",
      "quote": "Evaluation results show that the proposed method improves training efficiency and generalization in both Atari games and meta-world object manipulation tasks."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research focuses on improving the efficiency and generalization of large language model-based decision-making agents, which falls under the umbrella of Deep Learning.",
        "quote": "Large language model (LLM)-based decision-making agents have shown the ability to generalize across multiple tasks."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The paper's proposed model, DT-Mem, is applied to reinforcement learning settings, including Atari games and Meta-World environments, addressing issues specific to RL such as generalization and adaptability.",
          "quote": "Recently, with the tremendous success of large language model-based (LLM-based) foundation models [5, 27, 12, 33], an increasing number of researchers have focused on LLM-based decision-making agents."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DT-Mem",
          "justification": "The main contribution of the paper is the Decision Transformers with Memory (DT-Mem), which is introduced as a new model to enhance training efficiency and generalization.",
          "quote": "Thus motivated, we propose Decision Transformers with Memory (DT-Mem)."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "contributed"
        },
        "is_executed": {
          "value": true,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "trained"
        },
        "is_compared": {
          "value": true,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Multi-game DT",
          "justification": "Multi-game Decision Transformer (MDT) is referenced in the paper as a pre-trained model that DT-Mem relies on for its generalization capacity.",
          "quote": "For example, in Multi-game DT [22] and Hyper-DT [38], and this pre-training enables them to capture broad knowledge that is transferable across tasks."
        },
        "aliases": [
          "MDT"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "pre-trained"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Hyper-DT",
          "justification": "Hyper-Decision Transformer (HDT) is another pre-trained model referenced in the paper to highlight the generalization capabilities of Transformer-based models.",
          "quote": "For example, in Multi-game DT [22] and Hyper-DT [38], and this pre-training enables them to capture broad knowledge that is transferable across tasks."
        },
        "aliases": [
          "HDT"
        ],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "referenced"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "pre-trained"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Atari Games",
          "justification": "The paper evaluates DT-Mem using Atari games to demonstrate its improved training efficiency and generalization capabilities.",
          "quote": "Evaluation results show that the proposed method improves training efficiency and generalization in both Atari games and meta-world object manipulation tasks."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Meta-World",
          "justification": "The Meta-World environment is used to evaluate DT-Mem's performance in object manipulation tasks, showing its adaptability and generalization.",
          "quote": "To validate our approach, we evaluate DT-Mem on Atari games, as used in Multi-game Decision Transformer (MDT) [22], and Meta-World environments, as used in Prompt Decision Transformer (PDT) [37] and Hyper-Decision Transformer (HDT) [38]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "LoRA",
          "justification": "The LoRA (Low-Rank Adaptation) method is used in conjunction with the memory module to modulate its output and enhance adaptability to new tasks.",
          "quote": "In particular, we use the low-rank adaptation (LoRA) [18] method in conjunction with a small set of adaptation parameters to modulate the memory moduleâ€™s output."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1089,
    "prompt_tokens": 15032,
    "total_tokens": 16121
  }
}