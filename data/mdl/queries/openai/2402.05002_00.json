{
  "paper": "2402.05002.txt",
  "words": 19254,
  "extractions": {
    "title": {
      "value": "Randomized Confidence Bounds for Stochastic Partial Monitoring",
      "justification": "The paper is introduced with this title, which encapsulates its primary focus on the creation of randomized strategies for stochastic partial monitoring games.",
      "quote": "Randomized Confidence Bounds for Stochastic Partial Monitoring"
    },
    "description": "This paper presents new strategies for dealing with stochastic partial monitoring problems, where feedback is incomplete during sequential decision-making processes. It introduces randomized versions of the Confidence Bounds for Partial Monitoring (CBP) strategy, named RandCBP and RandCBPside⋆, and demonstrates their empirical success in reducing cumulative regret in comparison to deterministic and other stochastic approaches. The paper also provides a use case for monitoring the error rate of classification systems, highlighting the practical benefits of these strategies.",
    "type": {
      "value": "empirical",
      "justification": "The work involves empirical analyses, including experiments comparing proposed models with existing strategies and real-world applications of the introduced models.",
      "quote": "Our experiments show that the proposed RandCBP and RandCBPside⋆ strategies improve state-ofthe-art baselines in PM games."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper discusses strategies and frameworks specifically tailored for sequential learning problems with incomplete feedback, placing it within the broader field of Machine Learning.",
        "quote": "The partial monitoring (PM) framework provides a theoretical formulation of sequential learning problems with incomplete feedback."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Sequential Learning",
          "justification": "The primary focus on strategies dealing with sequential decision-making and learning problems classifies this work under Sequential Learning.",
          "quote": "The partial monitoring (PM) framework provides a theoretical formulation of sequential learning problems with incomplete feedback."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Decision Making",
          "justification": "The strategies developed are for optimizing decision making under uncertainty, a core aspect of this subfield.",
          "quote": "A partial monitoring (PM) game is played between a learning agent and the environment over multiple rounds."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Partial Monitoring",
          "justification": "Partial monitoring is explicitly addressed as both a framework and problem setting for the strategies developed in the paper.",
          "quote": "Partial monitoring (Bartók et al., 2014) is a framework tailored for online learning problems with partially informative feedback."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "RandCBP",
          "justification": "RandCBP is the proposed model that extends CBP with randomized confidence bounds to improve empirical performance.",
          "quote": "Our experiments show that the proposed RandCBP and RandCBPside⋆ strategies improve state-of-the-art baselines in PM games."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "RandCBP is newly introduced in this paper as a randomized extension to existing PM strategies.",
          "quote": "We show that it is possible to randomize CBP-based strategies, and obtain sub-linear regret guarantees for the resulting randomized strategies."
        },
        "is_executed": {
          "value": true,
          "justification": "Experiments conducted with this model are reported, indicating it was executed within the study.",
          "quote": "Our experiments show that the proposed RandCBP and RandCBPside⋆ strategies improve state-of-the-art baselines in PM games."
        },
        "is_compared": {
          "value": true,
          "justification": "RandCBP is compared against several other stochastic and deterministic PM strategies, as detailed in the empirical study results within the paper.",
          "quote": "Our experiments show that the proposed RandCBP and RandCBPside⋆ strategies improve state-of-the-art baselines in PM games."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "RandCBP is introduced in the current paper, so there is no previous reference paper title for it.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "RandCBPside⋆",
          "justification": "RandCBPside⋆ is the contextual variant of RandCBP developed to handle more complex PM problems.",
          "quote": "Our proposed RandCBP and RandCBPside⋆ establish state-of-the-art performance in multiple settings while maintaining regret guarantees."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "RandCBPside⋆ is a contribution of this paper, extending the CBPside to achieve better empirical and theoretical results.",
          "quote": "We then propose RandCBPside⋆ , a stochastic counterpart of CBPside⋆ , that enjoys regret guarantees on both easy and hard games in the linear setting, while empirically outperforming its deterministic counterpart."
        },
        "is_executed": {
          "value": true,
          "justification": "Empirical evaluations were conducted with RandCBPside⋆, demonstrating its execution in the scope of the paper.",
          "quote": "RandCBP and RandCBPside⋆ empirically outperforms CBP on the horizon T."
        },
        "is_compared": {
          "value": true,
          "justification": "RandCBPside⋆ is evaluated against other baseline strategies in the empirical study described in the paper.",
          "quote": "Our proposed RandCBP and RandCBPside⋆ establish state-of-the-art performance in multiple settings while maintaining regret guarantees."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "RandCBPside⋆ is also newly introduced in this paper, so it does not reference a prior paper.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Apple Tasting (AT)",
          "justification": "The Apple Tasting game is utilized to evaluate the proposed strategies in the study.",
          "quote": "We run the experiment 96 times on a T = 20k horizon. We consider the deterministic PMDMED and CBP as baselines, as well as the stochastic BPM-Least, TSPM, and TSPM-Gaussian (in the settings where they have a guarantee)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Apple Tasting",
          "justification": "The baseline Apple Tasting game is referenced and utilized to demonstrate and compare the effectiveness of the PM strategies.",
          "quote": "Apple tasting. Information and Computation, 161(2):85–139, 2000."
        }
      },
      {
        "name": {
          "value": "Label Efficient (LE)",
          "justification": "The Label Efficient game is utilized for testing the performance of the proposed strategies in the paper.",
          "quote": "The wellknown Apple Tasting (AT) (Helmbold et al., 2000) and Label Efficient (LE) (Helmbold et al., 1997) games."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Some label efficient learning results",
          "justification": "The Label Efficient game is cited as a baseline comparison for contextual learning tests in the paper.",
          "quote": "Some label efficient learning results. In In Proc. CoLT, 1997."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1373,
    "prompt_tokens": 34922,
    "total_tokens": 36295,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}