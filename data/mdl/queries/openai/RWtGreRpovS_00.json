{
  "paper": "RWtGreRpovS.txt",
  "words": 15362,
  "extractions": {
    "title": {
      "value": "Simplicial Embeddings in Self-Supervised Learning and Downstream Classification",
      "justification": "The title is explicitly stated at the beginning and end of the abstract, matching the focal topic of the paper.",
      "quote": "S IMPLICIAL E MBEDDINGS IN S ELF -S UPERVISED L EARNING AND D OWNSTREAM C LASSIFICATION"
    },
    "description": "This research paper introduces Simplicial Embeddings (SEM), a novel type of representation for self-supervised learning (SSL). Using a softmax operation, SEM projects representations into L simplices of V dimensions each. The approach improves generalization on natural image datasets like CIFAR-100 and ImageNet and enhances downstream classification performance by inducing sparsity in learned features.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts empirical studies to demonstrate the improved generalization of SEM on datasets like CIFAR-100 and ImageNet.",
      "quote": "Furthermore, we empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR100 and ImageNet."
    },
    "primary_research_field": {
      "name": {
        "value": "Self-Supervised Learning",
        "justification": "The primary focus is on enhancing self-supervised learning methods using Simplicial Embeddings (SEM).",
        "quote": "Self-supervised learning (SSL) is an emerging family of methods that aim to learn representations of data without manual supervision, such as class labels."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Representation Learning",
          "justification": "The paper discusses learning representations and how Simplicial Embeddings project them into simplices.",
          "quote": "Simplicial Embeddings (SEM) are representations learned through self-supervised learning (SSL), wherein a representation is projected into L simplices of V dimensions each using a softmax operation."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Simplicial Embeddings (SEM)",
          "justification": "The paper introduces and builds on the concept of Simplicial Embeddings.",
          "quote": "Simplicial Embeddings (SEM) are representations learned through self-supervised learning (SSL), wherein a representation is projected into L simplices of V dimensions each using a softmax operation."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "SEM is introduced and validated within this paper.",
          "quote": "In this work, we show that SSL may be used to learn discrete, sparse and overcomplete representations... We refer to this embedding as Simplicial Embeddings (SEM)"
        },
        "is_executed": {
          "value": 1,
          "justification": "SEM models are run on GPUs for empirical validation as mentioned in the compute resource details.",
          "quote": "For all our CIFAR-100 training, we used 1 RTX-8000 per experiment. For our ImageNet experiments, we used parallel training with 2 40GB A100 for the training with ResNet-50 and ResNet-50-x2 and 4 40GB A100 for the training with ResNet-50-x4."
        },
        "is_compared": {
          "value": 1,
          "justification": "SEM's performance is compared with several baseline models using CIFAR-100 and ImageNet datasets.",
          "quote": "We compare the semantic coherence of BYOL+SEM with the control experiments on BYOL: regular BYOL, BYOL with an embedding of the same size as BYOL+SEM but without the normalization and BYOL to which we applied linear ICA (Hyv√§rinen & Oja, 2000) in an attempt to disentangle the features."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "SEM is an original contribution of the paper and doesn't refer to another paper.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is one of the primary datasets used to empirically validate the SEM approach.",
          "quote": "We empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR100 and ImageNet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The referenced paper for CIFAR-100 is cited by the authors as Krizhevsky, 2009",
          "quote": "We empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR100 and ImageNet."
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is another primary dataset used to validate the effectiveness of SEM.",
          "quote": "We empirically demonstrate that SSL methods trained with SEMs have improved generalization on natural image datasets such as CIFAR100 and ImageNet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet: A large-scale hierarchical image database",
          "justification": "The referenced paper for ImageNet is cited by the authors as Deng et al., 2009",
          "quote": "When training a SSL method with SEM on ImageNet we also observe improvements on in-distribution compared to the baseline"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is used for implementing the models and running the experiments in the paper.",
          "quote": "Finally, this project would not have been possible without the contribution of the following open source projects: Pytorch (Paszke et al., 2019)"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The referenced paper for PyTorch is cited by the authors as Paszke et al., 2019",
          "quote": "Finally, this project would not have been possible without the contribution of the following open source projects: Pytorch (Paszke et al., 2019)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1189,
    "prompt_tokens": 27931,
    "total_tokens": 29120
  }
}