{
  "paper": "add2c69962b45ed77f90c5697f14eb31.txt",
  "words": 12829,
  "extractions": {
    "title": {
      "value": "The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks",
      "justification": "The title names both the pitfalls and potential of conformal inference when facing adversarial attacks, which corresponds with the paper's investigation into the performance and efficiency of conformal prediction (CP) methods under these conditions.",
      "quote": "The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks"
    },
    "description": "This paper investigates the performance and efficiency of conformal prediction (CP) methods under adversarial attacks. It identifies shortcomings in existing CP methods, especially when applied to non-robust models or in conjunction with certain adversarial training (AT) techniques. The authors propose an uncertainty-reducing adversarial training (AT-UR) method to improve CP efficiency. The paper provides both theoretical and empirical insights, validating the effectiveness of the proposed methods across multiple datasets.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes an empirical study that tests the effectiveness of the proposed AT-UR method on four image classification datasets and measures CP efficiency against adversarial attacks.",
      "quote": "Moreover, our empirical study on four image classification datasets across three popular AT baselines validates the effectiveness of the proposed Uncertainty-Reducing AT (AT-UR)."
    },
    "primary_research_field": {
      "name": {
        "value": "Adversarial Machine Learning",
        "justification": "The primary focus of the paper is on assessing and improving conformal prediction (CP) methods under adversarial conditions in machine learning.",
        "quote": "To address this gap, this study investigates the uncertainty of deep learning models by examining the performance of conformal prediction (CP) in the context of standard adversarial attacks within the adversarial defense community."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Conformal Prediction",
          "justification": "The paper investigates and proposes improvements for conformal prediction techniques under adversarial attacks, directly indicating its relevance.",
          "quote": "Our paper next demonstrates that the prediction set size (PSS) of CP using adversarially trained models with AT variants is often worse than using standard AT, inspiring us to research into CP-efficient AT for improved PSS."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Adversarial Training",
          "justification": "The study specifically explores adversarial training methods and their impact on the efficiency of CP under attack scenarios.",
          "quote": "This key observation inspires us to develop the uncertainty-reducing AT (AT-UR) to learn an adversarially robust model with improved CP-efficiency."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "TRADES",
          "justification": "The TRADES model is mentioned in the paper as one of the popular adversarial training methods analyzed for conformal prediction efficiency.",
          "quote": "Next, we show the CP performance of three popular AT methods, finding that advanced AT methods like TRADES (Zhang et al., 2019) and MART (Wang et al., 2019) substantially increase the PSS in CP even though they improve the Top-1 robust accuracy."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "TRADES is referenced as an existing model utilized in the paper's study rather than a contribution from this research.",
          "quote": "Next, we show the CP performance of three popular AT methods, finding that advanced AT methods like TRADES (Zhang et al., 2019) and MART (Wang et al., 2019)."
        },
        "is_executed": {
          "value": false,
          "justification": "The execution of the model in a specific hardware environment (i.e., GPU or CPU) is not explicitly discussed in the provided text.",
          "quote": "(Not explicitly stated)"
        },
        "is_compared": {
          "value": true,
          "justification": "The TRADES model's CP efficiency is compared to other adversarial training methods, mentioning its impact on prediction set size and accuracy.",
          "quote": "Next, we show the CP performance of three popular AT methods, finding that advanced AT methods like TRADES (Zhang et al., 2019) and MART (Wang et al., 2019) substantially increase the PSS in CP even though they improve the Top-1 robust accuracy."
        },
        "referenced_paper_title": {
          "value": "Theoretically principled trade-off between robustness and accuracy",
          "justification": "The reference is clearly attributed in the text discussing TRADES as one of the methods.",
          "quote": "TRADES (Zhang et al., 2019) substantially increase the PSS in CP even though they improve the Top-1 robust accuracy."
        }
      },
      {
        "name": {
          "value": "MART",
          "justification": "MART is one of the models evaluated in the paper for its impact on CP efficiency and robustness.",
          "quote": "Next, we show the CP performance of three popular AT methods, finding that advanced AT methods like TRADES (Zhang et al., 2019) and MART (Wang et al., 2019) substantially increase the PSS in CP even though they improve the Top-1 robust accuracy."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "MART is an existing model used to measure CP efficiency; it is not introduced as a new model in this paper.",
          "quote": "Next, we show the CP performance of three popular AT methods, finding that advanced AT methods like TRADES (Zhang et al., 2019) and MART (Wang et al., 2019)."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no specific mention of MART being executed on GPU or CPU directly in the text provided.",
          "quote": "(Not explicitly stated)"
        },
        "is_compared": {
          "value": true,
          "justification": "MART is numerically compared with other adversarial training methods regarding their CP efficiency impacts.",
          "quote": "finding that advanced AT methods like TRADES (Zhang et al., 2019) and MART (Wang et al., 2019) substantially increase the PSS in CP."
        },
        "referenced_paper_title": {
          "value": "Improving adversarial robustness requires revisiting misclassified examples",
          "justification": "The referenced title is provided in connection with the MART model within the text.",
          "quote": "MART (Wang et al., 2019) substantially increase the PSS in CP even though they improve the Top-1 robust accuracy."
        }
      },
      {
        "name": {
          "value": "AT-UR (Adversarial Training Uncertainty-Reducing)",
          "justification": "AT-UR is introduced as a novel approach in the paper, designed to improve CP efficiency against adversarial attacks.",
          "quote": "This key observation inspires us to develop the uncertainty-reducing AT (AT-UR) to learn an adversarially robust model with improved CP-efficiency."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "AT-UR is a new method proposed by the authors to address the identified issues in CP efficiency.",
          "quote": "To address this gap, this study investigates the uncertainty of deep learning models by examining the performance of conformal prediction (CP) in the context of standard adversarial attacks within the adversarial defense community."
        },
        "is_executed": {
          "value": false,
          "justification": "The specifics about whether AT-UR is executed on GPUs or CPUs are not provided in the text.",
          "quote": "(Not explicitly stated)"
        },
        "is_compared": {
          "value": true,
          "justification": "AT-UR's performance is empirically validated and compared against other models such as TRADES and MART.",
          "quote": "Moreover, our empirical study on four image classification datasets across three popular AT baselines validates the effectiveness of the proposed Uncertainty-Reducing AT (AT-UR)."
        },
        "referenced_paper_title": {
          "value": "(No specific referenced paper)",
          "justification": "AT-UR is a novel proposition within this paper, so there is no previous paper referenced for it.",
          "quote": "(Proposed method in the current paper)"
        }
      },
      {
        "name": {
          "value": "APS (Adaptive Prediction Sets)",
          "justification": "APS is one of the CP methods evaluated in the study for its efficiency under adversarial conditions.",
          "quote": "We test the performance of three conformal prediction methods, i.e., APS (Adaptive Prediction Sets) (Romano et al., 2020), RAPS (Regularized Adaptive Prediction Sets) (Angelopoulos et al., 2020) and RSCP (Randomly Smoothed Conformal Prediction) (Gendler et al., 2021), under standard adversarial attacks."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "APS is referenced from existing literature and used to assess CP efficiency; it is not a new method contributed by this paper.",
          "quote": "We test the performance of three conformal prediction methods, i.e., APS (Adaptive Prediction Sets) (Romano et al., 2020)."
        },
        "is_executed": {
          "value": false,
          "justification": "The execution details regarding hardware specifics for APS are not mentioned in the text.",
          "quote": "(Not explicitly stated)"
        },
        "is_compared": {
          "value": true,
          "justification": "APS is numerically evaluated against other CP methods like RAPS and RSCP under adversarial conditions.",
          "quote": "The performance of three representative CP methods using non-robust models under standard adversarial attacks in the adversarial defense community."
        },
        "referenced_paper_title": {
          "value": "Classification with valid and adaptive coverage",
          "justification": "APS is attributed to its original paper within the research paper.",
          "quote": "APS (Adaptive Prediction Sets) (Romano et al., 2020)"
        }
      },
      {
        "name": {
          "value": "RAPS (Regularized Adaptive Prediction Sets)",
          "justification": "RAPS is discussed in the context of its performance under adversarial attacks as a CP method.",
          "quote": "We test the performance of three conformal prediction methods, i.e., APS (Adaptive Prediction Sets) (Romano et al., 2020), RAPS (Regularized Adaptive Prediction Sets) (Angelopoulos et al., 2020) and RSCP (Randomly Smoothed Conformal Prediction) (Gendler et al., 2021), under standard adversarial attacks."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "RAPS is an existing method being analyzed rather than contributed in the paper.",
          "quote": "We test the performance of three conformal prediction methods, i.e., APS (Adaptive Prediction Sets) (Romano et al., 2020), RAPS (Regularized Adaptive Prediction Sets) (Angelopoulos et al., 2020) and RSCP (Randomly Smoothed Conformal Prediction) (Gendler et al., 2021)"
        },
        "is_executed": {
          "value": false,
          "justification": "There are no details specifying whether RAPS was executed on specific hardware like GPU/CPU.",
          "quote": "(Not explicitly stated)"
        },
        "is_compared": {
          "value": true,
          "justification": "RAPS is part of the CP comparison study under adversarial attacks, evaluated alongside APS and RSCP.",
          "quote": "The performance of three representative CP methods using non-robust models under standard adversarial attacks in the adversarial defense community."
        },
        "referenced_paper_title": {
          "value": "Uncertainty sets for image classifiers using conformal prediction",
          "justification": "The paper cites the origin of RAPS in its analysis of conformal methods under attack scenarios.",
          "quote": "RAPS (Regularized Adaptive Prediction Sets) (Angelopoulos et al., 2020)"
        }
      },
      {
        "name": {
          "value": "RSCP (Randomly Smoothed Conformal Prediction)",
          "justification": "RSCP is analyzed for its CP performance under adversarial settings in this paper.",
          "quote": "We test the performance of three conformal prediction methods, i.e., APS (Adaptive Prediction Sets) (Romano et al., 2020), RAPS (Regularized Adaptive Prediction Sets) (Angelopoulos et al., 2020) and RSCP (Randomly Smoothed Conformal Prediction) (Gendler et al., 2021), under standard adversarial attacks."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "RSCP is referenced as an existing method in the context of the paper's conformal prediction tests.",
          "quote": "We test the performance of three conformal prediction methods, i.e., APS (Adaptive Prediction Sets) (Romano et al., 2020), RAPS (Regularized Adaptive Prediction Sets) (Angelopoulos et al., 2020) and RSCP (Randomly Smoothed Conformal Prediction) (Gendler et al., 2021)."
        },
        "is_executed": {
          "value": false,
          "justification": "The execution specifics for RSCP, such as GPU/CPU usage, are not provided in the text.",
          "quote": "(Not explicitly stated)"
        },
        "is_compared": {
          "value": true,
          "justification": "RSCP's numeric performance is compared with APS and RAPS under adversarial conditions.",
          "quote": "The performance of three representative CP methods using non-robust models under standard adversarial attacks in the adversarial defense community."
        },
        "referenced_paper_title": {
          "value": "Adversarially robust conformal prediction",
          "justification": "The paper references RSCP to its original work in the context of adversarial robustness.",
          "quote": "RSCP (Randomly Smoothed Conformal Prediction) (Gendler et al., 2021)"
        }
      },
      {
        "name": {
          "value": "PGD Attack",
          "justification": "PGD Attack is used as a method to evaluate adversarial robustness and CP efficiency in the paper.",
          "quote": "For example, (Gendler et al., 2021) and (Ghosh et al., 2023) only consider l2-norm bounded adversarial perturbations with a small attack budget, e.g., ε = 0.125 for the CIFAR dataset (Krizhevsky et al., 2009)."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "PGD Attack is a known existing method and not contributed by the authors.",
          "quote": "For example, (Gendler et al., 2021) and (Ghosh et al., 2023) only consider l2-norm bounded adversarial perturbations with a small attack budget, e.g., ε = 0.125 for the CIFAR dataset (Krizhevsky et al., 2009)."
        },
        "is_executed": {
          "value": true,
          "justification": "PGD Attack is utilized to generate adversarial examples in the empirical study.",
          "quote": "In all adversarial training of this paper, we generate adversarial perturbations using PGD attack."
        },
        "is_compared": {
          "value": false,
          "justification": "PGD Attack itself is a method used for testing and is not a subject of comparison with other models in the paper.",
          "quote": "(Not applicable as it is not compared)"
        },
        "referenced_paper_title": {
          "value": "Towards deep learning models resistant to adversarial attacks",
          "justification": "The reference makes clear mention of PGD attack origins for adversarial training usage.",
          "quote": "The most effective approach to defending against adversarial attacks is adversarial training (AT) (Madry et al., 2018)."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is explicitly mentioned as one of the datasets used in the empirical study.",
          "quote": "For example, (Gendler et al., 2021) and (Ghosh et al., 2023) only consider l2-norm bounded adversarial perturbations with a small attack budget, e.g., ε = 0.125 for the CIFAR dataset (Krizhevsky et al., 2009)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-10 dataset is attributed to its original reference in the context of its usage in the experiments.",
          "quote": "For example, (Gendler et al., 2021) and (Ghosh et al., 2023) only consider l2-norm bounded adversarial perturbations with a small attack budget, e.g., ε = 0.125 for the CIFAR dataset (Krizhevsky et al., 2009)."
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is used within the presented experiments to test the proposed methods.",
          "quote": "We test three popular adversarial training methods, i.e., AT (Madry et al., 2018), TRADES (Zhang et al., 2019) and MART (Wang et al., 2019), using APS as the conformal prediction method under a commonly used adversarial attack, AutoAttack with l ∞ -norm and ε = 8/255 = 0.0314."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features from Tiny Images",
          "justification": "The CIFAR-100 dataset references its foundational paper clearly.",
          "quote": "The CIFAR dataset (Krizhevsky et al., 2009)"
        }
      },
      {
        "name": {
          "value": "Caltech-256",
          "justification": "Caltech-256 is listed among the datasets utilized for evaluating the new AT-UR methods under adversarial conditions.",
          "quote": "Dataset. Four datasets are used to evaluate our method, i.e., CIFAR10, CIFAR100 (Krizhevsky et al., 2009), Caltech-256 (Griffin et al., 2007) and Caltech-UCSD Birds-200-2011 (CUB200) (Wah et al., 2011)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Caltech-256 Object Category Dataset",
          "justification": "The paper credits the dataset's original creators when calling it out for experimental procedures.",
          "quote": "Dataset. Four datasets are used to evaluate our method, i.e., CIFAR10, CIFAR100 (Krizhevsky et al., 2009), Caltech-256 (Griffin et al., 2007) and Caltech-UCSD Birds-200-2011 (CUB200) (Wah et al., 2011)."
        }
      },
      {
        "name": {
          "value": "Caltech-UCSD Birds-200-201",
          "justification": "The paper explicitly lists CUB-200 as part of its image classification dataset lineup used for experimentation.",
          "quote": "Dataset. Four datasets are used to evaluate our method, i.e., CIFAR10, CIFAR100 (Krizhevsky et al., 2009), Caltech-256 (Griffin et al., 2007) and Caltech-UCSD Birds-200-2011 (CUB200) (Wah et al., 2011)."
        },
        "aliases": [
          "CUB-200"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The Caltech-UCSD Birds-200-2011 Dataset",
          "justification": "Reference to CUB-200 is made alongside its development paper in describing the chosen datasets.",
          "quote": "Dataset. Four datasets are used to evaluate our method, i.e., CIFAR10, CIFAR100 (Krizhevsky et al., 2009), Caltech-256 (Griffin et al., 2007) and Caltech-UCSD Birds-200-2011 (CUB200) (Wah et al., 2011)."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "NumPy",
          "justification": "NumPy is mentioned in the paper in connection with the creation of CP curves for analysis.",
          "quote": "The CP curve in Fig. 5 is obtained by using different threshold values, for instance, using the linspace function in numpy (Harris et al., 2020) with np.linspace(0.9,1.1,200)×τ̂ cal generates 200 different (coverage, PSS) points."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Array programming with numpy",
          "justification": "The reference for NumPy is clearly connected to its usage in the computation tasks of the paper.",
          "quote": "using the linspace function in numpy (Harris et al., 2020) with np.linspace(0.9,1.1,200)×τ̂ cal generates 200 different (coverage, PSS) points."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 4166,
    "prompt_tokens": 27518,
    "total_tokens": 31684,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}