{
  "paper": "2401.03069.txt",
  "words": 16065,
  "extractions": {
    "title": {
      "value": "Towards Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study",
      "justification": "The title is directly mentioned at the beginning of the paper and in the header.",
      "quote": "Towards Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study"
    },
    "description": "This paper explores the reproducibility of deep learning bugs, identifies key factors that can improve bugs' reproducibility, and demonstrates these findings through an empirical study.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts an empirical study involving the reproduction of deep learning bugs.",
      "quote": "In this paper, we conduct an empirical study to better understand the challenges in reproducing deep learning bugs."
    },
    "primary_research_field": {
      "name": {
        "value": "Software Engineering",
        "justification": "The main focus of the paper is on the empirical study of deep learning bug reproducibility, a topic primarily in the field of Software Engineering.",
        "quote": "Towards Enhancing the Reproducibility of Deep Learning Bugs: An Empirical Study"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Deep Learning",
          "justification": "The paper centers around the challenges in reproducing deep learning bugs, indicating Deep Learning as a relevant sub-field.",
          "quote": "Deep learning has achieved remarkable progress in various domains. However, like any software system, deep learning systems contain bugs."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Bug Reproducibility",
          "justification": "The paper specifically deals with the reproducibility of bugs within deep learning systems, indicating this as a sub-field.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "CNN",
          "justification": "CNN is listed as one of the model architectures covered in the study.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "CNN is a commonly known model architecture used in the study, not a contribution of the paper.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper focuses on reproducibility of bugs rather than executing these models.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper doesn't primarily focus on comparing execution or performance of models like CNN.",
          "quote": "Next, Section 4 presents the findings by answering our three research questions."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "A referenced paper provided knowledge on model architectures used in the study, indicating ‘An Empirical Study on Deep Learning Bug Characteristics’.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "LSTM",
          "justification": "LSTM is mentioned as one of the model architectures in the study.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "LSTM is a well-known architecture used within the study context, not contributed by the paper.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "is_executed": {
          "value": false,
          "justification": "The model itself is discussed in terms of architecture, execution details on performance aren't provided.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "Focus is not on performance comparison of LSTM with other models.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "This paper provides a context for models analyzed in bug reproducibility studies, referencing ‘An Empirical Study on Deep Learning Bug Characteristics’.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "AutoEncoder",
          "justification": "The paper mentions AutoEncoder as one of the architectures evaluated.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "AutoEncoder is a pre-existing model architecture mentioned among those studied.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "is_executed": {
          "value": false,
          "justification": "The study refers to functional and architectural perspectives of these models rather than execution.",
          "quote": "Next, Section 4 presents the findings by answering our three research questions."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not focus on numerical comparisons of model performances like AutoEncoders.",
          "quote": "Our work attempts to fill this important gap in the literature."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "The referenced research provides a foundational understanding of the characteristics of bugs that occur in neural network architectures including Autoencoders.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "MLP",
          "justification": "MLP is mentioned as one of several architectures investigated within the empirical study.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "MLP is a standard neural network architecture featured among the models investigated.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "is_executed": {
          "value": false,
          "justification": "Execution particulars for MLP regarding bugs aren't elaborated in terms of performance outputs.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "Model comparison, in terms of numerical significance, is not a core paper activity.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "This title encapsulates research on deep learning bug characteristics within widely-used architectures like MLP.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "RCNN",
          "justification": "RCNN is listed as one of the architectures included in the study.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The use of RCNN is within the scope of testing rather than introducing new contributions.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "is_executed": {
          "value": false,
          "justification": "RCNNs are part of the architectural landscape included in the study, rather than being executed for their own comparison.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "Comparative analysis on RCNN isn't a focus in terms of model benchmarks.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "Referencing other papers aids comprehending varying models and how bugs manifest, such as in RCNN architectures.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "ResNet",
          "justification": "ResNet is highlighted among the models assessed for understanding deep learning bugs.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ResNet as a model itself isn't a novel contribution of the paper but a referenced architecture type.",
          "quote": "Model Architectures Covered CNN, LSTM, AutoEncoder, MLP, RCNN, ResNet."
        },
        "is_executed": {
          "value": false,
          "justification": "ResNet's role is discussed more in conceptual terms about bugs rather than active framework executions.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "No numerical comparison involving ResNet is highlighted.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "An empirical study on ResNet can extend current knowledge on characteristics of bugs within such complex models.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "GAN",
          "justification": "Generative Adversarial Network (GAN) is mentioned as one of the architectures used in the study.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GAN is a pre-existing model architecture included in the study, not an original contribution of the paper.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet"
        },
        "is_executed": {
          "value": false,
          "justification": "The focus is on comprehending architecture roles rather than executing GANs in application terms.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "No numerical comparisons of GAN performance are discussed with other models.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "This paper offers insights on bugs across diverse architectures, providing a fundamental understanding like in GANs.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "Logistic Regression",
          "justification": "Logistic Regression appears within the models whose bugs the study addresses.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper incorporates Logistic Regression, a standard statistical model.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet"
        },
        "is_executed": {
          "value": false,
          "justification": "Execution details specific to Logistic Regressions in context of bugs aren't focal.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "Numerical comparisons for these models are not indicated as significant objectives.",
          "quote": "Next, Section 4 presents the findings by answering our three research questions."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "Investigating widely used methodologies like Logistic Regression highlights the bug characteristics in fundamental learning architectures.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "Variational RNN",
          "justification": "Referenced among the architectures discussed, representing a variation used for bug testing.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet, Variational RNN"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Variational RNN is brought in as a common architecture rather than a novel creation by the paper.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet, Variational RNN"
        },
        "is_executed": {
          "value": false,
          "justification": "The paper does not emphasize executing these models for extensive analysis on performance outputs.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "Comparison outcomes on specific tasks or metrics are not a paper's priority.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "An empirical understanding of bug manifestation in architectures like Variational RNN is rooted in referenced studies.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "Transformer",
          "justification": "Transformers are included in the list of architectures covered in the study.",
          "quote": "VGG16, Transformers"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Including Transformers serves the study scope, not an innovative contribution from this particular work.",
          "quote": "VGG16, Transformers"
        },
        "is_executed": {
          "value": false,
          "justification": "Execution detail for Transformers focuses on bug ramifications rather than detailed performance testing.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "Numerical comparison on Transformers is not emphasized.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "Common understanding on architecture-related bugs within Transformers aligns with empirical research like the cited paper.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "BERT",
          "justification": "BERT is referred to as one of the architectures used in the study.",
          "quote": "CNN, BERT, CNN, GAN, Logistic Regression"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "BERT is acknowledged for its role in different scenarios within the bug reproducibility exploration.",
          "quote": "CNN, BERT, CNN, GAN, Logistic Regression"
        },
        "is_executed": {
          "value": false,
          "justification": "Discussion on BERT remains non-specific on execution dynamics for active bug reproduction.",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper places no emphasis on comparing BERT with other models in terms of results.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "The study refers to a broader empirical understanding of different architectures including BERT in the context of bugs.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "VGG16",
          "justification": "VGG16 is listed as one of the neural network models assessed for bug reproducibility.",
          "quote": "VGG16, Transformers"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "VGG16 is not introduced as novel estimation in this work context, rather included within analytical framework.",
          "quote": "VGG16, Transformers"
        },
        "is_executed": {
          "value": false,
          "justification": "Testing models on execution aspects focus slightly more on bug relevance versus application",
          "quote": "The remainder of the paper is organized as follows. Section 2 presents a motivating example that highlights the challenges in reproducing deep learning bugs using existing techniques."
        },
        "is_compared": {
          "value": false,
          "justification": "No quantitative focus on result comparison among architectures is highlighted.",
          "quote": "Our work attempts to fill this important gap in the literature."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "An empirical reference offers context on VGG16’s bug encounter scenarios within larger neural frameworks.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      },
      {
        "name": {
          "value": "VGG19",
          "justification": "VGG19 is named as one of the model architectures covering bug reproducibility aspects in the paper.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet, VGG19"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper mentions VGG19 among customary models used for this type of analysis.",
          "quote": "CNN, GAN, Logistic Regression, MLP, ResNet, VGG19"
        },
        "is_executed": {
          "value": false,
          "justification": "Investigation does not heavily pursue executional testing or comparison for models like VGG19.",
          "quote": "Our research addresses the critical issue of deep learning bug reproducibility."
        },
        "is_compared": {
          "value": false,
          "justification": "Reference to VGG19 does not imply direct competitive analysis in this paper.",
          "quote": "Our work attempts to fill this important gap in the literature."
        },
        "referenced_paper_title": {
          "value": "An Empirical Study on Deep Learning Bug Characteristics",
          "justification": "An understanding for bug presence across multi-layer architectures like VGG19 is reflected in the mentioned study.",
          "quote": "A comprehensive study on deep learning bug characteristics."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Defects4ML",
          "justification": "Defects4ML is clearly mentioned as a benchmark dataset used in the study.",
          "quote": "First, we construct a dataset of 668 deep learning bugs from Stack Overflow and Defects4ML across three frameworks and 22 architectures."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Bugs in Machine Learning-based Systems: A Faultload Benchmark",
          "justification": "The paper uses Defects4ML as a reference and makes use of its dataset in their empirical study.",
          "quote": "Moravati et al. [12] constructed a benchmark dataset containing 100 deep learning bugs collected from StackOverflow and GitHub; they reproduced each of them."
        }
      },
      {
        "name": {
          "value": "Stack Overflow",
          "justification": "Stack Overflow is an essential data source used for collecting deep learning bugs for the study.",
          "quote": "We collect a total of 568 DL bugs from Stack Overflow posts."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Reproducibility of Programming-related Issues in Stack Overflow Questions",
          "justification": "Stack Overflow serves as a source for acquiring bug data for deep learning systems in this study.",
          "quote": "Rahman et al. [14] conduct a multi-modal study to understand the factors behind the non-reproducibility of software bugs."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "TensorFlow",
          "justification": "TensorFlow is mentioned as one of the frameworks from which data was collected for the study.",
          "quote": "To gather relevant posts from Stack Overflow, we use the Stack Exchange Data Explorer platform1 . We employ multiple filters to capture relevant posts discussing deep learning bugs. First, we select the recent posts (i.e., submitted between May 2020 and May 2023) with the following tags: ‘tensorflow’, ‘keras’, and ‘pytorch’."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "On Testing Machine Learning Programs",
          "justification": "TensorFlow serves as a primary framework, and the reference paper provides foundational insights into machine learning program testing.",
          "quote": "Humbatova et al. [16] introduces new testing techniques and the handling of various Types, specifically in the context of deep learning."
        }
      },
      {
        "name": {
          "value": "Keras",
          "justification": "Keras is explicitly mentioned as a deep learning library used in the studies of bug reproducibility.",
          "quote": "First, we select the recent posts (i.e., submitted between May 2020 and May 2023) with the following tags: ‘tensorflow’, ‘keras’, and ‘pytorch’."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A Guide to Deep Learning in Healthcare",
          "justification": "Keras is primarily used in the context of building and testing deep learning systems, drawing upon insights from this referenced paper.",
          "quote": "Esteva, Robicquet et al. [6] provide an overview of deep learning in healthcare including various libraries such as Keras, used in different frameworks."
        }
      },
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is enumerated among the known libraries from which bug data was harvested for empirical analysis.",
          "quote": "We employ multiple filters to capture relevant posts discussing deep learning bugs. First, we select the recent posts (i.e., submitted between May 2020 and May 2023) with the following tags: ‘tensorflow’, ‘keras’, and ‘pytorch’."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deep Learning in Medical Image Analysis",
          "justification": "The reference provides insights into applications like PyTorch in research areas such as medical imaging, paralleling the study usage.",
          "quote": "Shen et al. did a detailed review across domains using PyTorch to facilitate experiments and analysis."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 4349,
    "prompt_tokens": 23401,
    "total_tokens": 27750,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}