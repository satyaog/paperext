{
  "paper": "2212.14530.txt",
  "words": 13999,
  "extractions": {
    "title": {
      "value": "POMRL: No-Regret Learning-to-Plan with Increasing Horizons",
      "justification": "Title of the paper",
      "quote": "POMRL: No-Regret Learning-to-Plan with Increasing Horizons"
    },
    "description": "The paper proposes an algorithm for planning under model uncertainty in an online meta-reinforcement learning setting. The algorithm meta-learns the structure across tasks and utilizes it to plan in each task. It provides theoretical guarantees on regret and validates the findings empirically.",
    "type": {
      "value": "theoretical",
      "justification": "The paper provides a theoretical study with mathematical proofs and theoretical guarantees on regret for the proposed algorithm.",
      "quote": "We propose an algorithm to meta-learn the underlying structure across tasks, utilize it to plan in each task, and upper-bound the regret of the planning loss. Our bound suggests that the average regret over tasks decreases as the number of tasks increases and as the tasks are more similar."
    },
    "primary_research_field": {
      "name": {
        "value": "Meta-Reinforcement Learning",
        "justification": "The paper focuses on meta-reinforcement learning where an agent learns to plan across a sequence of related tasks.",
        "quote": "We study the problem of planning under model uncertainty in an online meta-reinforcement learning (RL) setting where an agent is presented with a sequence of related tasks with limited interactions per task."
      },
      "aliases": [
        "Meta-RL",
        "Meta Learning in Reinforcement Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Planning with Uncertainty",
          "justification": "The research deals with planning in scenarios with uncertain models.",
          "quote": "We study the problem of planning under model uncertainty in an online meta-reinforcement learning (RL) setting where an agent is presented with a sequence of related tasks with limited interactions per task."
        },
        "aliases": [
          "Planning under model uncertainty"
        ]
      },
      {
        "name": {
          "value": "Online Learning",
          "justification": "The meta-learning framework used in the paper involves online learning as the agent accumulates knowledge sequentially.",
          "quote": "Online meta-learning considers a sequential setting, where the agent progressively accumulates knowledge and uses past experience to learn good priors and to quickly adapt within each task Finn et al. (2019); Denevi et al. (2019)."
        },
        "aliases": [
          "Online meta-learning"
        ]
      }
    ],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 460,
    "prompt_tokens": 24828,
    "total_tokens": 25288
  }
}