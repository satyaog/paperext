{
  "paper": "8785318a3cbf58d6e2a345d43237f658.txt",
  "words": 11582,
  "extractions": {
    "title": {
      "value": "On the Scalability of Certified Adversarial Robustness with Generated Data",
      "justification": "The paper's title is directly mentioned at the beginning of the document.",
      "quote": "On the Scalability of Certified Adversarial Robustness with Generated Data"
    },
    "description": "The paper investigates how the scalability of certified adversarial robustness can be improved by using data generated by diffusion models in training. It demonstrates that this approach significantly enhances the robustness certificates for threat models on CIFAR-10 and CIFAR-100 datasets, providing recommendations for scaling certified training approaches.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves experiments and empirical analysis to evaluate the scalability of certified adversarial robustness using generated data, testing different training configurations.",
      "quote": "In our empirical study, we analyze models trained to be robust against l ∞ and models trained to be robust against l 2 norm attacks."
    },
    "primary_research_field": {
      "name": {
        "value": "Adversarial Robustness",
        "justification": "The paper primarily focuses on certified adversarial robustness using generated data to improve model security against adversarial attacks.",
        "quote": "Certified defenses against adversarial attacks offer formal guarantees on the robustness of a model, making them more reliable than empirical methods."
      },
      "aliases": [
        "Adversarial Security"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Certified Robustness",
          "justification": "The paper deals with certified methods of robustness that provide formal security guarantees.",
          "quote": "Unlike empirical methods, certified methods yield robustness guarantees, thereby eliminating possible vulnerabilities to future attacks."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Data Augmentation",
          "justification": "The paper employs data generation methods to augment training datasets, improving robustness.",
          "quote": "Gowal et al. and Wang et al. have shown that generating additional training data using state-of-the-art diffusion models can considerably improve the robustness of adversarial training."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "SortNet",
          "justification": "SortNet is analyzed in the experiments, specifically in the context of training with auxiliary data.",
          "quote": "We find that by removing the dropout from SortNet we can improve certified accuracy from 41.32% to 41.78% when using auxiliary data."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "SortNet is a model referenced and used in the paper but not introduced as a new model.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l 2 (GloroNet [9] and LOT [17]) and l ∞ threat models (SortNet [18] and l ∞ -dist Net [27])."
        },
        "is_executed": {
          "value": true,
          "justification": "Experiments were explicitly conducted with SortNet, assessing its robustness improvements.",
          "quote": "For the (l ∞ , ε = 8/255) threat model on CIFAR-10 we can increase the robustness of the existing SortNet [18]."
        },
        "is_compared": {
          "value": true,
          "justification": "SortNet's performance is numerically compared in terms of certified and clean accuracy improvements.",
          "quote": "Full results are given in Tab. 1 for both SortNet and l ∞ -dist Net, as well as Tab. 2 for LOT and Tab. 3 for GloroNet."
        },
        "referenced_paper_title": {
          "value": "Rethinking Lipschitz Neural Networks and Certified Robustness: A Boolean Function Perspective",
          "justification": "SortNet model is referenced from the paper by Zhang et al., which discusses Lipschitz neural networks and certified robustness.",
          "quote": "SortNet [18] and l ∞ -dist Net [27]"
        }
      },
      {
        "name": {
          "value": "GloroNet",
          "justification": "GloroNet is used in experiments for robustness testing against l2 threat models.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l 2 (GloroNet [9] and LOT [17]) and l ∞ threat models."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "GloroNet is not a new model contribution but rather a referenced and used model in the study.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l 2 (GloroNet [9] and LOT [17]) and l ∞ threat models."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed in the experiments, as evidenced by its results and comparison against others.",
          "quote": "Tables 1 to 3 demonstrate that scaling the model size can increase the certified robustness for both LOT and GloroNet."
        },
        "is_compared": {
          "value": true,
          "justification": "GloroNet's performance was compared in terms of clean and certified accuracy results.",
          "quote": "Full results are given in Tab. 1 for both SortNet and l ∞ -dist Net, as well as Tab. 2 for LOT and Tab. 3 for GloroNet."
        },
        "referenced_paper_title": {
          "value": "Unlocking Deterministic Robustness Certification on ImageNet",
          "justification": "The referenced paper focuses on deterministic robustness certification methods, which is relevant to GloroNet's usage in the paper.",
          "quote": "GloroNet [9]"
        }
      },
      {
        "name": {
          "value": "LOT",
          "justification": "LOT is another model among the top-performing architectures used to test certified robustness.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l2 (GloroNet [9] and LOT [17]) and l∞ threat models."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The LOT model is used from existing research and not a contribution of this paper.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l2 (GloroNet [9] and LOT [17]) and l∞ threat models."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper performed experiments with LOT, analyzing its performance improvements.",
          "quote": "Tables 1 to 3 demonstrate that scaling the model size can increase the certified robustness for both LOT and GloroNet."
        },
        "is_compared": {
          "value": true,
          "justification": "LOT's performance was compared against other models in terms of certified accuracy.",
          "quote": "The proposed approach improves robustness for both the (l ∞ , ε = 8/255) and (l 2 , ε = 36/255) threat models on CIFAR-10, improving upon the previous results in the literature."
        },
        "referenced_paper_title": {
          "value": "LOT: Layer-wise Orthogonal Training on Improving l2 Certified Robustness",
          "justification": "LOT is referenced from the paper by Xu et al., focusing on robust training techniques.",
          "quote": "LOT [17]"
        }
      },
      {
        "name": {
          "value": "l ∞ -dist Net",
          "justification": "This model was utilized to assess the (l ∞ , ε = 8/255) threat model's robustness improvement.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l 2 (GloroNet [9] and LOT [17]) and l ∞ threat models (SortNet [18] and l ∞ -dist Net [27])."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "l ∞ -dist Net is used from existing research and is not a new model introduced in this paper.",
          "quote": "For our experiments, we select the two best architectures from the popular certified robustness leaderboard introduced by Li et al. [10] for both the l 2 (GloroNet [9] and LOT [17]) and l ∞ threat models (SortNet [18] and l ∞ -dist Net [27])."
        },
        "is_executed": {
          "value": true,
          "justification": "This model was part of the conducted experiments evaluating its robustness metrics.",
          "quote": "Table 1: Clean and certified test accuracy (%) on CIFAR-10 (l ∞ , ε = 8/255) for l ∞ -dist Net and SortNet with dropout rate."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of l ∞ -dist Net was compared to other models such as SortNet, in terms of certification gains.",
          "quote": "Full results are given in Tab. 1 for both SortNet and l ∞ -dist Net."
        },
        "referenced_paper_title": {
          "value": "Boosting the Certified Robustness of L-infinity Distance Nets",
          "justification": "The paper discusses advancing the robustness of L-infinity distance networks, from which l ∞ -dist Net is cited.",
          "quote": "l ∞ -dist Net [27]"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is a primary dataset used in experiments for evaluating model robustness.",
          "quote": "Our approach achieves state-of-the-art deterministic robustness certificates on CIFAR-10 for the l 2 (ε = 36/255) and l ∞ (ε = 8/255) threat models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "CIFAR-10 is based on the paper by Krizhevsky and Hinton, which describes the dataset creation.",
          "quote": "CIFAR-10 [22]"
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is used for additional experiments extending the analysis beyond CIFAR-10.",
          "quote": "Further experiments show that the same approach considerably improves certified accuracy on CIFAR-100 as well."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "CIFAR-100, like CIFAR-10, is also a dataset established in the same paper by Krizhevsky and Hinton.",
          "quote": "CIFAR-100 [22]"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The experiments likely utilized PyTorch for neural network implementations, a common choice for such research even though not explicitly quoted.",
          "quote": "All our experiments are done on a single Nvidia A100 graphics card (40GB of VRAM) without distributed training."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "While not directly quoted in the paper, PyTorch is inferred to be used for the experimental setup involving deep learning models.",
          "quote": "All our experiments are done on a single Nvidia A100 graphics card (40GB of VRAM) without distributed training."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2249,
    "prompt_tokens": 20123,
    "total_tokens": 22372,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}