{
  "paper": "d0b01dd93756e4453aa17978aca23d10.txt",
  "words": 10781,
  "extractions": {
    "title": {
      "value": "RAIDAR: Generative AI Detection via Rewriting",
      "justification": "The title clearly states the focus of the paper on AI detection through a rewriting approach.",
      "quote": "We dubbed our geneRative AI Detection viA Rewriting method Raidar."
    },
    "description": "This paper presents a novel method called Raidar that detects AI-generated text by prompting large language models (LLMs) to rewrite text and calculating the editing distance. The method is shown to improve detection performance in several domains and remains robust even against adversarial inputs.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments and applies the proposed method to multiple datasets to evaluate its effectiveness.",
      "quote": "Visualizations, empirical experiments show that our simple rewriting-based algorithm Raidar significantly improves detection for several established paragraph-level detection benchmarks."
    },
    "primary_research_field": {
      "name": {
        "value": "Artificial Intelligence",
        "justification": "The paper deals with the detection of AI-generated content, indicating that its primary concern is within the domain of Artificial Intelligence.",
        "quote": "The increasing deployment and accessibility of those LLM also pose serious risks (Bergman et al., 2022; Mirsky et al., 2022)."
      },
      "aliases": [
        "AI"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "Since the paper involves detection of AI-generated text, it falls under the natural language processing subfield.",
          "quote": "Detecting and auditing those machine-generated text will thus be crucial to mitigate the potential downside of LLMs."
        },
        "aliases": [
          "NLP"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-3.5",
          "justification": "This LLM is used for generating text and for rewriting in the experiments.",
          "quote": "We use GPT-3.5-Turbo as the LLM to rewrite the input text."
        },
        "aliases": [
          "GPT 3.5 Turbo"
        ],
        "is_contributed": {
          "value": false,
          "justification": "GPT-3.5 is used in the study but was not developed in this research.",
          "quote": "We use GPT-3.5-Turbo as the LLM to rewrite the input text."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is actively used for text rewriting in the experiments conducted in this study.",
          "quote": "We use GPT-3.5-Turbo as the LLM to rewrite the input text."
        },
        "is_compared": {
          "value": true,
          "justification": "The performance of this model in rewriting is part of the evaluation for detecting AI-generated content.",
          "quote": "Our data and code is available at https://github.com/cvlab-columbia/RaidarLLMDetect.git."
        },
        "referenced_paper_title": {
          "value": "Language Models are Few-Shot Learners",
          "justification": "GPT-3.5 is a continuation and improvement from the original GPT-3 model described in the referenced paper.",
          "quote": "Brown et al., 2020; Chowdhery et al., 2022"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Creative Writing Dataset",
          "justification": "Used in the experiments to evaluate the detection method across different types of text.",
          "quote": "Creative Writing Dataset is a language dataset based on the subreddit WritingPrompts, which is creative writing by a community based on the prompts."
        },
        "aliases": [
          "WritingPrompts"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ghostbuster: Detecting text ghostwritten by large language models",
          "justification": "The paper references this dataset as part of evaluating detection methods for AI text generation.",
          "quote": "We use the dataset generated by Verma et al. (2023)."
        }
      },
      {
        "name": {
          "value": "News Dataset",
          "justification": "This dataset is used to test the detection method's effectiveness on news text.",
          "quote": "News Dataset is based on the Reuters 50-50 authorship identification dataset."
        },
        "aliases": [
          "Reuters 50-50"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ghostbuster: Detecting text ghostwritten by large language models",
          "justification": "The paper references this dataset as part of evaluating detection methods for AI text generation.",
          "quote": "News Dataset is based on the Reuters 50-50 authorship identification dataset."
        }
      },
      {
        "name": {
          "value": "Student Essay Dataset",
          "justification": "This dataset is utilized to assess the detection method on essay-type texts, representative of educational content.",
          "quote": "Student Essay Dataset The dataset is based on the British Academic Written English corpus and generated by Verma et al. (2023)."
        },
        "aliases": [
          "British Academic Written English"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ghostbuster: Detecting text ghostwritten by large language models",
          "justification": "The paper references this dataset as part of evaluating detection methods for AI text generation.",
          "quote": "Student Essay Dataset The dataset is based on the British Academic Written English corpus and generated by Verma et al. (2023)."
        }
      },
      {
        "name": {
          "value": "Code Dataset",
          "justification": "The dataset is used to evaluate the detection on AI-generated code, representing a relevant application in education.",
          "quote": "We adopt the HumanEval dataset (Chen et al., 2021) as the human-written code, and ask GPT-3.5-turbo to perform the same task and generate the code."
        },
        "aliases": [
          "HumanEval"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Evaluating Large Language Models Trained on Code",
          "justification": "The dataset relates to evaluating models on code generation, aligning with the referenced paper's context.",
          "quote": "We adopt the HumanEval dataset (Chen et al., 2021) as the human-written code."
        }
      },
      {
        "name": {
          "value": "Yelp Review Dataset",
          "justification": "This dataset is involved to test detection methods on shorter form reviews from the Yelp platform.",
          "quote": "Yelp Review Dataset. Yelp reviews tend to be short and challenging to detect."
        },
        "aliases": [
          "Yelp"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ghostbuster: Detecting text ghostwritten by large language models",
          "justification": "The paper references this dataset as part of evaluating detection methods for AI text generation.",
          "quote": "We use the first 2000 human reviews from the Yelp Review Dataset."
        }
      },
      {
        "name": {
          "value": "ArXiv Dataset",
          "justification": "This dataset tests detection capability on academic texts, showing AI-generated abstract evaluation.",
          "quote": "ArXiv Paper Abstract. We investigate if we can detect GPT written paragraphs in academic papers."
        },
        "aliases": [
          "ICLR papers"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Ghostbuster: Detecting text ghostwritten by large language models",
          "justification": "The paper references this dataset as part of evaluating detection methods for AI text generation.",
          "quote": "Our dataset contains 350 abstracts from ICLR papers from 2015 to 2021."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1377,
    "prompt_tokens": 18768,
    "total_tokens": 20145,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}