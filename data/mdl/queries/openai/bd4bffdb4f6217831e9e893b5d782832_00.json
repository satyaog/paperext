{
  "paper": "bd4bffdb4f6217831e9e893b5d782832.txt",
  "words": 8225,
  "extractions": {
    "title": {
      "value": "Characterizing Idioms: Conventionality and Contingency",
      "justification": "The title explicitly states the focus of the paper, which is on idioms and their nature in terms of conventionality and contingency.",
      "quote": "Title of the paper"
    },
    "description": "This paper explores idioms, specifically in terms of whether their unique properties of non-canonical meanings and word contingency require special theoretical machinery for their understanding. The study uses two language models, BERT and XLNet, to implement measures of conventionality and contingency to understand idioms' placement within these dimensions. It challenges existing theories by suggesting idioms do not require special handling methods. The researchers also construct a novel dataset of idiomatic and non-idiomatic English phrases for their analysis.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments using language models BERT and XLNet, and constructs a dataset to measure the properties of idiomatic expressions, which classify it as empirical research.",
      "quote": "We define two measures that correspond to the properties above, and we implement them using BERT (Devlin et al., 2019) and XLNet (Yang et al., 2019)."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research focuses on idioms which is a topic under natural language understanding, a subfield of Natural Language Processing.",
        "quote": "This lack of homogeneity among idiomatic phrases has been recognized as a challenge in the domain of NLP, with Sag et al. (2002) suggesting that a variety of techniques are needed to deal with different kinds of multi-word expressions."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Linguistics",
          "justification": "The paper investigates linguistic theories about idioms and their meanings.",
          "quote": "Linguistic theories differ on whether these properties depend on one another, as well as whether special theoretical machinery is needed to accommodate idioms."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Language Model",
          "justification": "BERT and XLNet are used as language models to implement the measures of conventionality and contingency.",
          "quote": "Our implementations make use of the pre-trained language models BERT (Devlin et al., 2019) and XLNet (Yang et al., 2019)."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computational Linguistics",
          "justification": "The study involves computational evaluation of idiom properties which aligns with computational linguistics.",
          "quote": "This lack of homogeneity among idiomatic phrases has been recognized as a challenge in the domain of NLP, with Sag et al. (2002) suggesting that a variety of techniques are needed to deal with different kinds of multi-word expressions."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "BERT",
          "justification": "BERT is used to obtain contextualized embeddings for the words in the dataset, measuring conventionality.",
          "quote": "Our measure makes use of the language model BERT (Devlin et al., 2019) to obtain contextualized embeddings for the words in our dataset."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "BERT itself is not contributed by this paper, but rather utilized as a language model for experiments.",
          "quote": "BERT (Devlin et al., 2019)"
        },
        "is_executed": {
          "value": true,
          "justification": "BERT is actively used for calculating contextualized embeddings in the study.",
          "quote": "Our measure makes use of the language model BERT (Devlin et al., 2019) to obtain contextualized embeddings for the words in our dataset."
        },
        "is_compared": {
          "value": false,
          "justification": "BERT is not compared against other models; instead, it is used in conjunction with XLNet.",
          "quote": "Our measure makes use of the language model BERT (Devlin et al., 2019)"
        },
        "referenced_paper_title": {
          "value": "BERT: Pre-training of deep bidirectional transformers for language understanding",
          "justification": "The referenced paper title for BERT aligns with its original publication.",
          "quote": "BERT (Devlin et al., 2019)"
        }
      },
      {
        "name": {
          "value": "XLNet",
          "justification": "XLNet is used to estimate conditional probabilities of words, allowing for the measurement of contingency in idioms.",
          "quote": "To estimate the contingency of a phrase, we use word probabilities given by XLNet (Yang et al., 2019)"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "XLNet is utilized within this study but not developed by it.",
          "quote": "XLNet (Yang et al., 2019)"
        },
        "is_executed": {
          "value": true,
          "justification": "XLNet is actively employed to compute probabilities and contingency measures for the study.",
          "quote": "To estimate the contingency of a phrase, we use word probabilities given by XLNet (Yang et al., 2019)"
        },
        "is_compared": {
          "value": false,
          "justification": "Although multiple models are mentioned, they are not directly compared to each other in terms of performance within the paper.",
          "quote": "To estimate the contingency of a phrase, we use word probabilities given by XLNet (Yang et al., 2019)"
        },
        "referenced_paper_title": {
          "value": "XLNet: Generalized autoregressive pretraining for language understanding",
          "justification": "The referenced paper title for XLNet where it is originally proposed.",
          "quote": "XLNet (Yang et al., 2019)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "British National Corpus (BNC)",
          "justification": "The BNC is the source of the sentences used in the corpus for the study of idioms and non-idioms.",
          "quote": "all gathered from the British National Corpus (BNC; Burnard, 2000)"
        },
        "aliases": [
          "BNC"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "The British National Corpus Users Reference Guide",
          "justification": "The referenced paper provides the guide for the British National Corpus, used in this study for sentence sourcing.",
          "quote": "British National Corpus (BNC; Burnard, 2000)"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1249,
    "prompt_tokens": 14501,
    "total_tokens": 15750,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}