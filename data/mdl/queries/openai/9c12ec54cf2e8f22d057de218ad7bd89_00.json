{
  "paper": "9c12ec54cf2e8f22d057de218ad7bd89.txt",
  "words": 14124,
  "extractions": {
    "title": {
      "value": "Harnessing small projectors and multiple views for efficient vision pretraining",
      "justification": "The title directly corresponds to the title provided in the paper's header, just after the authors' names.",
      "quote": "Harnessing small projectors and multiple views for\nefficient vision pretraining"
    },
    "description": "The paper presents a study on improving self-supervised learning (SSL) in visual representation by developing theoretically grounded recommendations for more efficient and effective feature learning. The focus is on using small projector dimensionalities and multiple augmentations to optimize SSL frameworks. Authors perform empirical verification on benchmark datasets to support their theoretical findings, suggesting the reduction of dataset size while maintaining accuracy.",
    "type": {
      "value": "theoretical",
      "justification": "The paper develops recommendations based on theoretical results and performs theoretical analysis on SSL frameworks and optimization dynamics.",
      "quote": "we build on recent analytical results to design practical recommendations for competitive and efficient SSL that are grounded in theory."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The paper deals with visual self-supervised learning, focusing on image augmentations and training frameworks in the field of computer vision.",
        "quote": "Unsupervised representation learning, i.e., learning features without human-annotated labels, is\ncritical for progress in computer vision."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The paper specifically focuses on self-supervised learning frameworks and their optimization.",
          "quote": "Recent progress in self-supervised (SSL) visual representation learning has led to the development of several different proposed frameworks that rely on augmenta-\ntions of images..."
        },
        "aliases": [
          "SSL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet",
          "justification": "The paper mentions using a ResNet-backbone in their empirical studies, which is a well-known deep learning model architecture.",
          "quote": "we empirically verify our findings on CIFAR, STL and Imagenet datasets, wherein we demonstrate an improved linear\nreadout performance when training a ResNet-backbone using our theoretically grounded recommendations."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ResNet is a pre-existing architecture and is not contributed by this paper.",
          "quote": "when training a ResNet-backbone using our theoretically grounded recommendations."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper uses the ResNet model in their experiments to verify theoretical findings.",
          "quote": "we empirically verify our findings...when training a ResNet-backbone"
        },
        "is_compared": {
          "value": true,
          "justification": "The ResNet model's performance is compared to baseline performance and different configurations.",
          "quote": "we empirically demonstrate that low-dimensional projector heads are sufficient and that using more augmentations leads\nto learning better representations."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "This is the seminal paper introducing the ResNet architecture, which is highly likely to be the reference given the wide use and context.",
          "quote": "Reference not explicitly provided, assumed based on model description."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR",
          "justification": "CIFAR is one of the datasets used in the empirical verification of the theoretical recommendations in this paper.",
          "quote": "verify our theoretically grounded recommendations using the popular ResNet backbone on benchmark datasets: CIFAR, STL and Imagenet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning multiple layers of features from tiny images",
          "justification": "The CIFAR dataset is widely referenced in deep learning literature with this title by Alex Krizhevsky, who initially introduced it.",
          "quote": "Reference not explicitly provided, assumed based on dataset description."
        }
      },
      {
        "name": {
          "value": "STL",
          "justification": "STL is mentioned alongside other benchmark datasets used in the empirical analysis of the paper.",
          "quote": "verify our theoretically grounded recommendations using the popular ResNet backbone on benchmark datasets: CIFAR, STL and Imagenet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "An Analysis of Single-Layer Networks in Unsupervised Feature Learning",
          "justification": "This is one of the main references for the STL dataset by Adam Coates and others.",
          "quote": "Reference not explicitly provided, assumed based on dataset description."
        }
      },
      {
        "name": {
          "value": "ImageNet",
          "justification": "ImageNet is used as a benchmark dataset in the experiments conducted to validate theoretical aspects.",
          "quote": "verify our theoretically grounded recommendations using the popular ResNet backbone on benchmark datasets: CIFAR, STL and Imagenet."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "ImageNet large scale visual recognition challenge",
          "justification": "ImageNet is widely cited with this title authored by Olga Russakovsky and others in 2015.",
          "quote": "Reference not explicitly provided, assumed based on dataset description."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "FastSSL",
          "justification": "The paper mentions using FastSSL for implementation and releasing their code in this framework.",
          "quote": "Our code base is publicly available on github."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "Not provided",
          "justification": "The library is presented along with implementation details and contribution is mentioned in the paper.",
          "quote": "provided in the public github repo, FastSSL"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1076,
    "prompt_tokens": 24019,
    "total_tokens": 25095,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}