{
  "paper": "2212.09631.txt",
  "words": 10383,
  "extractions": {
    "title": {
      "value": "Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation",
      "justification": "The title is explicitly mentioned at the beginning of the paper.",
      "quote": "Optimal Transport for Unsupervised Hallucination Detection in Neural Machine Translation"
    },
    "description": "The paper addresses the problem of hallucination detection in neural machine translation (NMT) using an optimal transport formulation. It proposes a fully unsupervised, plug-in detector that can be applied to any attention-based NMT model. The detector outperforms previous model-based detectors and is competitive with external models trained for related tasks such as quality estimation and cross-lingual sentence similarity.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents an experimental analysis to demonstrate the performance of the proposed hallucination detector.",
      "quote": "Experimental results show that our detector not only outperforms all previous model-based detectors..."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper primarily deals with machine translation, a subfield of Natural Language Processing.",
        "quote": "Neural machine translation (NMT) has become the de-facto standard in real-world machine translation applications."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Translation",
          "justification": "The paper focuses on neural machine translation, addressing the specific issue of hallucinations in NMT models.",
          "quote": "In this paper, we address the problem of hallucination detection in NMT."
        },
        "aliases": [
          "NMT"
        ]
      },
      {
        "name": {
          "value": "Anomaly Detection",
          "justification": "The paper frames hallucination detection as an anomaly detection problem using optimal transport.",
          "quote": "We approach the problem of hallucination detection as a problem of anomaly detection with an optimal transport (OT) formulation."
        },
        "aliases": [
          "Anomaly"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Transformer",
          "justification": "The paper utilizes an encoder-decoder Transformer model for the experiments.",
          "quote": "...we focus on models parameterized by an encoder-decoder transformer model (Vaswani et al., 2017)"
        },
        "aliases": [
          "Transformer model"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The Transformer model is not contributed by this paper but used for evaluation purposes.",
          "quote": "...we focus on models parameterized by an encoder-decoder transformer model (Vaswani et al., 2017)"
        },
        "is_executed": {
          "value": true,
          "justification": "The Transformer model is executed as part of the experiments conducted in the study.",
          "quote": "In this work, we focus on models parameterized by an encoder-decoder transformer model..."
        },
        "is_compared": {
          "value": true,
          "justification": "The Detector's performance is compared against other methods, indirectly comparing the Transformer model's ability to handle hallucinations.",
          "quote": "Experimental results show that our detector not only outperforms all previous model-based detectors..."
        },
        "referenced_paper_title": {
          "value": "Attention is all you need",
          "justification": "This paper refers to the original Transformer model paper authored by Vaswani et al.",
          "quote": "...we focus on models parameterized by an encoder-decoder transformer model (Vaswani et al., 2017)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "WMT18 DE - EN",
          "justification": "The paper uses the WMT18 DE - EN dataset for experiments on hallucination detection.",
          "quote": "the authors released a dataset of 3415 translations for WMT18 DE - EN news translation data"
        },
        "aliases": [
          "WMT18 German-English"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Findings of the 2018 conference on machine translation (WMT18)",
          "justification": "This is the reference paper for the WMT18 dataset.",
          "quote": "WMT18 DE - EN data (Bojar et al., 2018)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "fairseq",
          "justification": "The library is explicitly mentioned as the toolkit used for training the NMT model.",
          "quote": "It was trained with the fairseq toolkit (Ott et al., 2019)"
        },
        "aliases": [
          "fairseq toolkit"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "fairseq: A fast, extensible toolkit for sequence modeling",
          "justification": "This is the reference paper for the fairseq toolkit.",
          "quote": "It was trained with the fairseq toolkit (Ott et al., 2019)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 895,
    "prompt_tokens": 18051,
    "total_tokens": 18946,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}