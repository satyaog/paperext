{
  "paper": "ceff61b89a6c159eb0acb9b145b913ed.txt",
  "words": 10632,
  "extractions": {
    "title": {
      "value": "Efficient Leverage Score Sampling for Tensor Train Decomposition",
      "justification": "The title is found at the beginning of the paper, clearly indicating the main focus of the research.",
      "quote": "Efficient Leverage Score Sampling for Tensor Train Decomposition"
    },
    "description": "This paper proposes an efficient algorithm to compute the Tensor Train (TT) decomposition using the Alternating Least Squares (ALS) algorithm with leverage score sampling. The authors introduce a data structure that enables efficient sampling with time complexity logarithmic in tensor size, enhancing the speed of the TT-ALS process while maintaining approximation accuracy. The paper demonstrates the proposed method's effectiveness through experiments on synthetic and real datasets.",
    "type": {
      "value": "empirical",
      "justification": "The paper includes experiments on synthetic and real datasets to demonstrate the effectiveness of the proposed method.",
      "quote": "Experiments on synthetic and real data on dense and sparse tensors demonstrate that our method outperforms SVD-based and ALS-based algorithms."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper discusses tensor decomposition, a topic commonly explored within the field of Machine Learning, particularly focusing on algorithm optimization and efficiency improvements.",
        "quote": "Tensor decomposition methods have recently found numerous applications in machine learning."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Tensor Decomposition",
          "justification": "The paper focuses on Tensor Train decomposition, a specific method under tensor decomposition techniques.",
          "quote": "Tensor Train (TT) decomposition is widely used in the machine learning and quantum physics communities."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "rTT-ALS",
          "justification": "The rTT-ALS model is specifically proposed by the authors as a new contribution in the paper.",
          "quote": "we propose a novel randomized variant of the TT-ALS algorithm relying on exact leverage score sampling."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The rTT-ALS is introduced as a new contribution for TT decomposition using leverage score sampling.",
          "quote": "Our Contributions. In this paper, we propose a new sampling-based ALS approach to compute the TT decomposition: rTT-ALS."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper details experiments and provides results using the rTT-ALS model.",
          "quote": "we provide experiments on synthetic and real massive sparse and dense tensors showing that rTT-ALS can achieve up to 26× speed-up compared to its non-randomized counterpart."
        },
        "is_compared": {
          "value": true,
          "justification": "The rTT-ALS is compared against existing methods such as TT-SVD and TT-ALS in terms of performance and speed.",
          "quote": "rTT-ALS is about 2× faster than TT-ALS and 3× faster than TT-SVD for I = 500."
        },
        "referenced_paper_title": {
          "value": "Adaptive randomized algorithm for tensor decomposition",
          "justification": "The referenced paper is listed in the citations as a foundational work related to randomized algorithms for tensor decomposition.",
          "quote": "Randomized variants of the TT-ALS approach have received little attention. In this work, we propose a novel randomized variant of the TT-ALS algorithm."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Pavia University",
          "justification": "The Pavia University dataset is used in the experiments for the real dense datasets.",
          "quote": "For the real data experiment, we consider four real images and video datasets (more details about datasets are given in Appendix C): (i) Pavia University is a hyper-spectral image dataset of size (610 × 340 × 103)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Hyperspectral image analysis with tensor decomposition",
          "justification": "The dataset is referenced as an example to demonstrate the proposed algorithm's capability.",
          "quote": "The Washington DC Mall dataset is downloaded from https://engineering.purdue.edu/Ëœbiehl/MultiSpec/hyperspectral.html."
        }
      },
      {
        "name": {
          "value": "MNIST",
          "justification": "The MNIST dataset is used in the experiments to validate the method's performance on real data.",
          "quote": "(iii) the MNIST dataset is of size (60000 × 28 × 28)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Deep learning using tensor decomposition",
          "justification": "This dataset is extensively used in deep learning literature and papers for testing methods.",
          "quote": "The MNIST dataset is reshaped into a tensor of size (280, 600, 28, 10) and is downloaded from https://www.kaggle.com/datasets/hojjatk/mnist-dataset"
        }
      },
      {
        "name": {
          "value": "Tabby Cat",
          "justification": "The Tabby Cat video dataset is used for testing the model on real-world scenarios.",
          "quote": "Tabby Cat dataset is reshaped to a tensor of size (286, 720, 40, 32)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adaptive approaches for video tensor trains",
          "justification": "The Tabby Cat dataset is used to demonstrate video data applicability.",
          "quote": "The video is in color and converted to grayscale by averaging the three color channels."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1055,
    "prompt_tokens": 19164,
    "total_tokens": 20219,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}