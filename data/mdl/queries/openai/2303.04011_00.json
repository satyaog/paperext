{
  "paper": "2303.04011.txt",
  "words": 7345,
  "extractions": {
    "title": {
      "value": "One-4-All: Neural Potential Fields for Embodied Navigation",
      "justification": "Title of the paper",
      "quote": "One-4-All: Neural Potential Fields for Embodied Navigation"
    },
    "description": "The paper introduces One-4-All (O4A), a method for end-to-end, graph-free, image-goal navigation in robotics. The system leverages self-supervised manifold learning to continuously minimize a neural potential function over image embeddings for real-world navigation tasks.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents a new methodology and evaluates its performance on both simulated and real-world tasks, making it an empirical study.",
      "quote": "We show that O4A can reach long-range goals in 8 simulated Gibson indoor environments and that resulting embeddings are topologically similar to ground truth maps, even if no pose is observed. We further demonstrate successful real-world navigation using a Jackal UGV platform."
    },
    "primary_research_field": {
      "name": {
        "value": "Robotics",
        "justification": "The paper addresses the task of navigation in robotics, proposing a new method for robot navigation using image-goals.",
        "quote": "A fundamental task in robotics is to navigate between two locations."
      },
      "aliases": [
        "Robotics"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Embodied Navigation",
          "justification": "The main focus of the paper is on embodied navigation, where robots navigate using high-dimensional image data.",
          "quote": "In particular, real-world navigation can require long-horizon planning using high-dimensional RGB images, which poses a substantial challenge for end-to-end learning-based approaches."
        },
        "aliases": [
          "Embodied Navigation"
        ]
      },
      {
        "name": {
          "value": "Self-Supervised Learning",
          "justification": "The method relies on self-supervised learning to train the models for navigation.",
          "quote": "O4A is trained offline using non-expert exploration sequences of RGB data and controls. We first rely on self-supervised learning to identify neighboring RGB observations."
        },
        "aliases": [
          "Self-Supervised Learning"
        ]
      },
      {
        "name": {
          "value": "Manifold Learning",
          "justification": "The training procedure includes a manifold learning objective for the geodesic regressor to predict shortest path lengths.",
          "quote": "we compute a graph to derive a manifold learning objective for our planning module, which we dub the geodesic regressor."
        },
        "aliases": [
          "Manifold Learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "One-4-All (O4A)",
          "justification": "One-4-All (O4A) is the core model proposed in the paper for navigation tasks.",
          "quote": "In this work, we present One-4-All (O4A), a method leveraging self-supervised and manifold learning to obtain a graph-free, end-to-end navigation pipeline in which the goal is specified as an image."
        },
        "aliases": [
          "O4A"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The model is novel and is introduced in this paper.",
          "quote": "In this work, we present One-4-All (O4A), a method leveraging self-supervised and manifold learning to obtain a graph-free, end-to-end navigation pipeline in which the goal is specified as an image."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed and evaluated in both simulated and real-world environments.",
          "quote": "We show that O4A can reach long-range goals in 8 simulated Gibson indoor environments and that resulting embeddings are topologically similar to ground truth maps, even if no pose is observed. We further demonstrate successful real-world navigation using a Jackal UGV platform."
        },
        "is_compared": {
          "value": true,
          "justification": "O4A has been compared with various other models to evaluate its performance in different settings.",
          "quote": "To assess the navigation performance of our method, we compare against the following baselines: Random Agent, Goal Conditioned Behavioral Cloning (GC-BC), SPTM, ViNG."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "This is the primary model of the paper and there is no referenced paper for this model.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Gibson Environment",
          "justification": "The Gibson Environment dataset is used in the simulated experiments.",
          "quote": "We perform our experiments using the Habitat simulator with the Gibson dataset."
        },
        "aliases": [
          "Gibson"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Xia, F., R. Zamir, Z. He, A. Sax, J. Malik, and S. Savarese. Gibson Env: Real-World Perception for Embodied Agents. In Proc. IEEE CVPR, pp. 9068-9079, 2018.",
          "justification": "The dataset is referenced in the paper and used for simulated navigation tasks.",
          "quote": "We perform our experiments using the Habitat simulator with the Gibson dataset [39]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Habitat",
          "justification": "The Habitat simulator was used for the simulation experiments in the paper.",
          "quote": "We perform our experiments using the Habitat simulator with the Gibson dataset."
        },
        "aliases": [
          "Habitat"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Savva, M., et al. Habitat: A Platform for Embodied AI Research. In Proc. ICCV, 2019.",
          "justification": "The Habitat simulator is referenced in the paper and used for simulated navigation experiments.",
          "quote": "We perform our experiments using the Habitat simulator with the Gibson dataset [38]."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1105,
    "prompt_tokens": 12819,
    "total_tokens": 13924
  }
}