{
  "paper": "2305.06897.txt",
  "words": 11755,
  "extractions": {
    "title": {
      "value": "AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages",
      "justification": "This is the title given at the beginning of the paper and encapsulates the key aspects of the research presented.",
      "quote": "AfriQA: Cross-lingual Open-Retrieval Question Answering for African Languages"
    },
    "description": "The paper introduces AfriQA, the first cross-lingual question answering (QA) dataset focused on African languages. AfriQA includes 12,000+ questions across 10 African languages and evaluates the performance of state-of-the-art QA models on this dataset.",
    "type": {
      "value": "empirical",
      "justification": "The research paper involves the creation of a dataset, conducting experiments, and evaluating the performance of models on these datasets, which is empirical in nature.",
      "quote": "In this work, we create AfriQA, the first cross-lingual QA dataset with a focus on African languages. [...] Our experiments demonstrate the poor performance of automatic translation and multilingual retrieval methods."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on creating a dataset and conducting experiments related to question answering, which is a core NLP task.",
        "quote": "In this work, we lay the foundation for research on QA systems for one of the most linguistically diverse regions by creating A FRI QA, the first QA dataset for 10 African languages."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Cross-lingual Information Retrieval",
          "justification": "The paper focuses on cross-lingual question answering and retrieval, emphasizing the use of information across different languages.",
          "quote": "A FRI QA focuses on open-retrieval QA where information-seeking questions2 are paired with retrieved documents in which annotators identify an answer if one is available [...] A FRI QA employs a cross-lingual setting."
        },
        "aliases": [
          "CLIR"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "BM25",
          "justification": "BM25 is used as one of the retrieval baselines in the experiments conducted in the paper.",
          "quote": "We present two baseline retrieval systems: translate–retrieve and cross-lingual baselines. In the translate–retrieve baseline, we first translate the queries using the translation systems described in §4.1. The translated queries are used to retrieve relevant passages using three different retrieval systems: BM25, multilingual Dense Passage Retriever (mDPR), and a hybrid combination of BM25 and mDPR."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "BM25 is a well-known retrieval model used as a baseline in this study.",
          "quote": ""
        },
        "is_executed": {
          "value": 1,
          "justification": "The BM25 model is executed as part of the retrieval baseline experiments.",
          "quote": "In the translate–retrieve baseline, we first translate the queries using the translation systems described in §4.1. The translated queries are used to retrieve relevant passages using three different retrieval systems: BM25, multilingual Dense Passage Retriever (mDPR), and a hybrid combination of BM25 and mDPR."
        },
        "is_compared": {
          "value": 1,
          "justification": "BM25 is compared to other retrieval systems like mDPR and their hybrid.",
          "quote": "We present two baseline retrieval systems: translate–retrieve and cross-lingual baselines. In the translate–retrieve baseline, we first translate the queries using the translation systems described in §4.1. The translated queries are used to retrieve relevant passages using three different retrieval systems: BM25, multilingual Dense Passage Retriever (mDPR), and a hybrid combination of BM25 and mDPR."
        },
        "referenced_paper_title": {
          "value": "The probabilistic relevance framework: BM25 and beyond",
          "justification": "This is the key paper that introduces the BM25 model, establishing its relevance and foundational principles.",
          "quote": "BM25. BM25 (Robertson and Zaragoza, 2009) is a classic term-frequency-based retrieval model that matches queries to relevant passages using the frequency of word occurrences in both queries and passages."
        }
      },
      {
        "name": {
          "value": "multilingual Dense Passage Retriever (mDPR)",
          "justification": "mDPR is used as part of the baseline retrieval systems. It is a multilingual adaptation of the Dense Passage Retriever model.",
          "quote": "We present two baseline retrieval systems: translate–retrieve and cross-lingual baselines. In the translate–retrieve baseline, we first translate the queries using the translation systems described in §4.1. The translated queries are used to retrieve relevant passages using three different retrieval systems: BM25, multilingual Dense Passage Retriever (mDPR), and a hybrid combination of BM25 and mDPR."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "mDPR is an existing model adapted for the multilingual retrieval task in this study.",
          "quote": ""
        },
        "is_executed": {
          "value": 1,
          "justification": "The mDPR model is executed as part of the retrieval baseline experiments.",
          "quote": "In the translate–retrieve baseline, we first translate the queries using the translation systems described in §4.1. The translated queries are used to retrieve relevant passages using three different retrieval systems: BM25, multilingual Dense Passage Retriever (mDPR), and a hybrid combination of BM25 and mDPR."
        },
        "is_compared": {
          "value": 1,
          "justification": "mDPR is compared to BM25 and their hybrid in the experiments.",
          "quote": "We present two baseline retrieval systems: translate–retrieve and cross-lingual baselines. In the translate–retrieve baseline, we first translate the queries using the translation systems described in §4.1. The translated queries are used to retrieve relevant passages using three different retrieval systems: BM25, multilingual Dense Passage Retriever (mDPR), and a hybrid combination of BM25 and mDPR."
        },
        "referenced_paper_title": {
          "value": "Dense passage retrieval for open-domain question answering",
          "justification": "This is the key paper that introduces the Dense Passage Retriever model, establishing its relevance and foundational principles.",
          "quote": "mDPR. We evaluate the performance of mDPR, a multilingual adaptation of the Dense Passage Retriever (DPR) model (Karpukhin et al., 2020)."
        }
      },
      {
        "name": {
          "value": "AfroXLM-R",
          "justification": "AfroXLM-R is used as a backbone model for extractive question answering from gold passages.",
          "quote": "To extract answer spans from the gold passages, we train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016) and fQuad (d’Hoffschmidt et al., 2020) using AfroXLM-R as a backbone."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "AfroXLM-R is used as a backbone model for the experiments but is not a new contribution in this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": 1,
          "justification": "AfroXLM-R is fine-tuned and executed as part of the extractive question-answering experiments.",
          "quote": "To extract answer spans from the gold passages, we train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016) and fQuad (d’Hoffschmidt et al., 2020) using AfroXLM-R as a backbone. We evaluated the models on the test queries and the annotated gold passages."
        },
        "is_compared": {
          "value": 1,
          "justification": "AfroXLM-R is compared with other reader models like mT5 in the extractive QA experiments.",
          "quote": "We now evaluate performance using retrieved passages. We present F1 and Exact Match results with different translation–retriever combinations in Table 8. We extract the answer spans from only the top-10 retrieved passages for each question using an extractive multilingual reader model (see §4.3)."
        },
        "referenced_paper_title": {
          "value": "Adapting pre-trained language models to African languages via multilingual adaptive fine-tuning",
          "justification": "This is the key paper that introduces AfroXLM-R, establishing its relevance and foundational principles.",
          "quote": "We train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016) and fQuad (d’Hoffschmidt et al., 2020) using AfroXLM-R as a backbone."
        }
      },
      {
        "name": {
          "value": "mT5-base",
          "justification": "mT5-base is used for generative question answering on gold passages.",
          "quote": "We fine-tuned multilingual pre-trained text-to-text transformer (mT5) (Xue et al., 2020) on Squad 2.0 (Rajpurkar et al., 2016) dataset to generate answers from the gold passages."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "mT5-base is used as a backbone model for generative QA experiments but is not a new contribution in this paper.",
          "quote": ""
        },
        "is_executed": {
          "value": 1,
          "justification": "mT5-base is fine-tuned and executed for the experiments on gold passages.",
          "quote": "We fine-tuned multilingual pre-trained text-to-text transformer (mT5) (Xue et al., 2020) on Squad 2.0 (Rajpurkar et al., 2016) dataset to generate answers from the gold passages."
        },
        "is_compared": {
          "value": 1,
          "justification": "mT5-base is compared with other extractive models like AfroXLM-R for QA tasks.",
          "quote": "We now evaluate performance using retrieved passages. We present F1 and Exact Match results with different translation–retriever combinations in Table 8. We extract the answer spans from only the top-10 retrieved passages for each question using an extractive multilingual reader model (see §4.3)."
        },
        "referenced_paper_title": {
          "value": "mT5: A massively multilingual pre-trained text-to-text transformer",
          "justification": "This is the key paper that introduces mT5, establishing its relevance and foundational principles.",
          "quote": "We fine-tuned multilingual pre-trained text-to-text transformer (mT5) (Xue et al., 2020) on Squad 2.0 (Rajpurkar et al., 2016) dataset to generate answers from the gold passages."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "AfriQA",
          "justification": "AfriQA is the newly created dataset introduced in this paper, containing QA pairs for African languages.",
          "quote": "To this end, we create A FRI QA, the first cross-lingual QA dataset with a focus on African languages. A FRI QA includes 12,000+ XOR QA examples across 10 African languages."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "SQuAD 2.0",
          "justification": "SQuAD 2.0 is used as a training dataset for fine-tuning models in the experiments.",
          "quote": "We train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "SQuAD: 100,000+ Questions for Machine Comprehension of Text",
          "justification": "This is the key paper that introduces the SQuAD 2.0 dataset.",
          "quote": "We train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016)..."
        }
      },
      {
        "name": {
          "value": "fQuad",
          "justification": "fQuad is used as one of the training datasets for fine-tuning models in the experiments.",
          "quote": "We train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016) and fQuad (d’Hoffschmidt et al., 2020)..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "FQuAD: French question answering dataset",
          "justification": "This is the key paper that introduces the fQuad dataset.",
          "quote": "We train extractive reader models on the training set of Squad 2.0 (Rajpurkar et al., 2016) and fQuad (d’Hoffschmidt et al., 2020)..."
        }
      },
      {
        "name": {
          "value": "Natural Questions",
          "justification": "The Natural Questions dataset is used to train the DPR retriever which is then adapted for multilingual tasks.",
          "quote": "We trained our model using the DPR retriever output on the training and development set of Natural questions and evaluated on the test set of A FRI QA in a zero-shot manner."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Natural Questions: a benchmark for question answering research",
          "justification": "This is the key paper that introduces the Natural Questions dataset.",
          "quote": "We trained our model using the DPR retriever output on the training and development set of Natural questions and evaluated on the test set of A FRI QA in a zero-shot manner."
        }
      },
      {
        "name": {
          "value": "AfriCLIRMatrix",
          "justification": "AfriCLIRMatrix is referenced for comparison with AfriQA regarding cross-lingual information retrieval datasets for African languages.",
          "quote": "To address the information scarcity of the typically used data sources for low-resource languages, cross-lingual datasets (Liu et al., 2019; Asai et al., 2021) emerged that translate between low-resource and high-resource languages, thus providing access to a larger information retrieval pool which decreases the fraction of unanswerable questions. Despite these efforts, however, the inclusion of African languages remains extremely rare...In recent years, efforts to create cross-lingual information retrieval datasets that include African languages have resulted in the creation of datasets such as AfriCLIRMatrix (Ogundepo et al., 2022)"
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "AfriCLIRMatrix: Enabling cross-lingual information retrieval for African languages",
          "justification": "This is the key paper that introduces the AfriCLIRMatrix dataset.",
          "quote": "In recent years, efforts to create cross-lingual information retrieval datasets that include African languages have resulted in the creation of datasets such as AfriCLIRMatrix (Ogundepo et al., 2022)"
        }
      },
      {
        "name": {
          "value": "XOR QA",
          "justification": "XOR QA is referenced for comparison as one of the cross-lingual open-domain QA datasets.",
          "quote": "A FRI QA employs a cross-lingual setting (Asai et al., 2021) where relevant passages are retrieved in a high-resource language spoken in the corresponding region and answers are translated into the source language."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "XOR QA: Cross-lingual open-domain question answering",
          "justification": "This is the key paper that introduces the XOR QA dataset.",
          "quote": "XOR QA (Asai et al., 2021)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Pyserini",
          "justification": "Pyserini is used to implement BM25 retrieval in the experiments.",
          "quote": "We use the BM25 implementation provided by Pyserini (Lin et al., 2021) with default hyperparameters k1 = 0.9, b = 0.4 for all languages."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Pyserini: A Python toolkit for reproducible information retrieval research with sparse and dense representations",
          "justification": "This is the key paper that introduces the Pyserini toolkit, establishing its relevance and utility.",
          "quote": "We use the BM25 implementation provided by Pyserini (Lin et al., 2021) with default hyperparameters k1 = 0.9, b = 0.4 for all languages."
        }
      },
      {
        "name": {
          "value": "Faiss",
          "justification": "Faiss is used for indexing and retrieval in the dense retriever implementation.",
          "quote": "Retrieval is performed using the Faiss flat index implementation provided by Pyserini."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3983,
    "prompt_tokens": 24246,
    "total_tokens": 28229
  }
}