{
  "paper": "rGN3X9jnEg.txt",
  "words": 18111,
  "extractions": {
    "title": {
      "value": "Formalizing locality for normative synaptic plasticity models",
      "justification": "The name derives directly from the paper's title and accurately depicts its content.",
      "quote": "Formalizing locality for normative synaptic plasticity models"
    },
    "description": "This paper addresses the lack of clarity in the concept of 'locality' in biologically plausible learning algorithms by proposing formal and operational definitions of locality. The framework can be used to guide claims of biological plausibility and identify means for experimentally falsifying proposed learning algorithms.",
    "type": {
      "value": "theoretical",
      "justification": "The paper primarily focuses on proposing formal and operational definitions and does not involve empirical experiments or data collection.",
      "quote": "we focus on formalizing this process. Our central contributions are as follows: 1. We develop an architecture-independent formal framework for locality that we term Sp-locality."
    },
    "primary_research_field": {
      "name": {
        "value": "Computational Neuroscience",
        "justification": "The paper focuses on normative synaptic plasticity models, which are a key topic in computational neuroscience.",
        "quote": "computational neuroscience researchers have proposed a variety of 'biologically plausible' models of synaptic plasticity."
      },
      "aliases": [
        "Computational Neural Science"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Synaptic Plasticity",
          "justification": "The paper investigates synaptic plasticity models and their locality in the brain.",
          "quote": "we focus on formalizing this process. Our central contributions are as follows: 1. We develop an architecture-independent formal framework for locality"
        },
        "aliases": [
          "Synaptic Adaptability"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "REINFORCE",
          "justification": "The paper explicitly discusses REINFORCE as a model it addresses within the scope of normative plasticity models.",
          "quote": "Theorem 3.1. If p(Θ) = ∏k p(Θk ), the REINFORCE estimator given by AR (p(R, X|Θ)) is Rp-local."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "REINFORCE is a pre-existing model and not a novel contribution of this paper.",
          "quote": "REINFORCE [13], also known as policy gradient learning, produces reward-modulated Hebbian parameter updates for neural networks. Here we will show that REINFORCE is Rp-local."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no mention of computational implementation or testing of REINFORCE within this paper.",
          "quote": "we develop… Rp-locality, meaning that it is Sp-local where S = {Sk = R ∀k}, which assumes each synapse has access to a global scalar reward signal R."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper focuses on formalizing locality and does not provide numerical comparisons between models.",
          "quote": "Our central contributions are as follows: 1. We develop an architecture-independent formal framework for locality ... 2. We use our framework to group existing plasticity models into different locality classes."
        },
        "referenced_paper_title": {
          "value": "Simple statistical gradient-following algorithms for connectionist reinforcement learning",
          "justification": "This paper is one of the foundational works on the REINFORCE algorithm, which is referenced as [13] in the study.",
          "quote": "REINFORCE [13], also known as policy gradient learning, produces reward-modulated Hebbian parameter updates for neural networks."
        }
      },
      {
        "name": {
          "value": "Wake-Sleep",
          "justification": "The paper discusses Wake-Sleep as a model it addresses within the scope of normative plasticity models.",
          "quote": "Theorem 3.2. If p(Θ, Θ(d) ) = ... the Wake-Sleep estimator given by AW S (p(X|Θ), pd (X|Θ(d) )) is γpmd -local."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Wake-Sleep is a pre-existing model and not a novel contribution of this paper.",
          "quote": "The Wake-Sleep algorithm has been used to model unsupervised learning [22]."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no mention of computational implementation or testing of Wake-Sleep within this paper.",
          "quote": "Interestingly, Wake-Sleep is not the only algorithm to obey this form of locality: several other normative plasticity models, including Boltzmann machine learning [26], equilibrium propagation [27], and impression learning [23] have essentially the same p-locality properties."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper focuses on formalizing locality and does not provide numerical comparisons between models.",
          "quote": "Our central contributions are as follows: 1. We develop an architecture-independent formal framework for locality ... 2. We use our framework to group existing plasticity models into different locality classes."
        },
        "referenced_paper_title": {
          "value": "The 'wake-sleep' algorithm for unsupervised neural networks",
          "justification": "This paper is one of the foundational works on the Wake-Sleep algorithm, which is referenced as [22] in the study.",
          "quote": "Wake-Sleep algorithm has been used to model unsupervised learning [22]."
        }
      },
      {
        "name": {
          "value": "e-prop",
          "justification": "The paper discusses e-prop as a model it addresses within the scope of normative plasticity models.",
          "quote": "The e-prop update [37] is nearly identical to the RTRL update, except we replace ei with an approximate credit assignment signal."
        },
        "aliases": [
          "Eligibility Propagation"
        ],
        "is_contributed": {
          "value": false,
          "justification": "e-prop is a pre-existing model and not a novel contribution of this paper.",
          "quote": "The e-prop update [37] is nearly identical to the RTRL update..."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no mention of computational implementation or testing of e-prop within this paper.",
          "quote": "For e-prop [37], we will also consider networks constructed according to Eq. E.39."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper focuses on formalizing locality and does not provide numerical comparisons between models.",
          "quote": "Our central contributions are as follows: 1. We develop an architecture-independent formal framework for locality ... 2. We use our framework to group existing plasticity models into different locality classes."
        },
        "referenced_paper_title": {
          "value": "A solution to the learning dilemma for recurrent networks of spiking neurons",
          "justification": "This paper is one of the foundational works on the e-prop algorithm, which is referenced as [37] in the study.",
          "quote": "The e-prop update [37] is nearly identical to the RTRL update..."
        }
      },
      {
        "name": {
          "value": "eRTRL",
          "justification": "The paper discusses eRTRL as a model it addresses within the scope of normative plasticity models.",
          "quote": "Q Theorem E.11. If p(Θ) = k p(Θk ) and p(X|Θ) is defined by Eq. E.39 (with X = r and Θ = W), the RTRL update for Wij with a loss L(r(T )), given by Aep (p(r|W), L(r)) is ei p-local,"
        },
        "aliases": [
          "Efficient Real-Time Recurrent Learning"
        ],
        "is_contributed": {
          "value": false,
          "justification": "eRTRL is a pre-existing model and not a novel contribution of this paper.",
          "quote": "For e-prop [37], we will also consider networks constructed according to Eq. E.39. The update is nearly identical to the RTRL update."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no mention of computational implementation or testing of eRTRL within this paper.",
          "quote": "For e-prop [37], we will also consider networks constructed according to Eq. E.39."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper focuses on formalizing locality and does not provide numerical comparisons between models.",
          "quote": "Our central contributions are as follows: 1. We develop an architecture-independent formal framework for locality ... 2. We use our framework to group existing plasticity models into different locality classes."
        },
        "referenced_paper_title": {
          "value": "A learning algorithm for continually running fully recurrent neural networks",
          "justification": "This paper is one of the foundational works on the eRTRL algorithm, which is referenced as [49] in the study.",
          "quote": "The update is nearly identical to the RTRL update."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1731,
    "prompt_tokens": 31568,
    "total_tokens": 33299
  }
}