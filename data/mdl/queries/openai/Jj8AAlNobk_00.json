{
  "paper": "Jj8AAlNobk.txt",
  "words": 13161,
  "extractions": {
    "title": {
      "value": "A Differentiable Sequence Model Perspective on Policy Gradients",
      "justification": "This is the full and accurate title of the paper.",
      "quote": "A Differentiable Sequence Model Perspective on Policy Gradients"
    },
    "description": "This paper explores the relationship between sequence modeling using deep learning and policy gradients in reinforcement learning. It demonstrates that better gradient propagation in neural network architectures can lead to improved policy gradient methods for sequential decision-making tasks. The authors introduce a framework using action-sequence models (ASMs) and theoretically and empirically show that modern architectures provide better policy gradients.",
    "type": {
      "value": "theoretical",
      "justification": "The paper primarily develops a theoretical framework and provides theoretical analysis regarding the relationship between sequence models and policy gradients.",
      "quote": "We leverage this connection to analyze, understand and improve policy gradient methods with tools that have been developed for deep sequence models, theoretically showing that modern architectures provably give better policy gradients."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper deals with improving policy gradient methods for reinforcement learning using advancements in sequence modeling.",
        "quote": "If we follow the parallel from sequence modelling to RL, a natural technique to learn a policy is to treat the computational graph created by the interaction between the agent and the dynamics of the environment in a similar way, and to compute a policy gradient by differentiating through it."
      },
      "aliases": [
        "RL",
        "Reinforcement Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Sequence Modeling",
          "justification": "The paper extends principles of sequence modeling to reinforcement learning.",
          "quote": "Progress in sequence modeling with deep learning has been driven by the advances in temporal credit assignment coming from better gradient propagation in neural network architectures."
        },
        "aliases": [
          "Sequence Models"
        ]
      },
      {
        "name": {
          "value": "Policy Gradient Methods",
          "justification": "The paper's main contribution is the theoretical and empirical improvement of policy gradient methods.",
          "quote": "We complement the theoretical findings with in-depth empirical investigations. We show that using appropriate neural network architectures for action-sequence models yields policy gradients that are accurate in the presence of a well-behaved environment."
        },
        "aliases": [
          "Policy Gradients"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Recurrent Neural Networks",
          "justification": "The paper mentions Recurrent Neural Networks (RNNs) as one of the principal sequence models used in the framework.",
          "quote": "We will mainly consider three types of sequence models: simple Recurrent Neural Networks (RNNs) (Werbos, 1974)."
        },
        "aliases": [
          "RNNs",
          "Recurrent Networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "RNNs are not introduced by this paper; they are used as part of the framework.",
          "quote": "We will mainly consider three types of sequence models: simple Recurrent Neural Networks (RNNs) (Werbos, 1974)."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments using RNNs.",
          "quote": "Training an ASM instantiated with an RNN to predict states using teacher forcing is equivalent to training its recurrent cell with the one-step loss function from Equation 1."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the performance and gradient propagation properties of RNNs with other models like LSTMs and transformers.",
          "quote": "we mainly consider three types of sequence models: simple Recurrent Neural Networks (RNNs) (Werbos, 1974), Long Short-Term Memory networks (LSTMs) (Hochreiter & Schmidhuber, 1997) and attention-based models (e.g., transformers (Vaswani et al., 2017))."
        },
        "referenced_paper_title": {
          "value": "Generalization of backpropagation with application to a recurrent gas market model",
          "justification": "The referenced paper is the foundational work for Recurrent Neural Networks (RNNs).",
          "quote": "We will mainly consider three types of sequence models: simple Recurrent Neural Networks (RNNs) (Werbos, 1974)."
        }
      },
      {
        "name": {
          "value": "Long Short-Term Memory networks",
          "justification": "The paper mentions LSTMs as one of the principal sequence models used in the framework.",
          "quote": "We will mainly consider three types of sequence models: Long Short-Term Memory networks (LSTMs) (Hochreiter & Schmidhuber, 1997)"
        },
        "aliases": [
          "LSTMs",
          "Long Short-Term Memory networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "LSTMs are not introduced by this paper; they are used as part of the framework.",
          "quote": "We will mainly consider three types of sequence models: Long Short-Term Memory networks (LSTMs) (Hochreiter & Schmidhuber, 1997)"
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes experiments using LSTMs.",
          "quote": "Training an ASM instantiated with an LSTM to predict states using teacher forcing is equivalent to training its recurrent cell with the one-step loss function from Equation 1."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the performance and gradient propagation properties of LSTMs with other models like RNNs and transformers.",
          "quote": "we mainly consider three types of sequence models: simple Recurrent Neural Networks (RNNs) (Werbos, 1974), Long Short-Term Memory networks (LSTMs) (Hochreiter & Schmidhuber, 1997) and attention-based models (e.g., transformers (Vaswani et al., 2017))."
        },
        "referenced_paper_title": {
          "value": "Long short-term memory",
          "justification": "The referenced paper is the foundational work for Long Short-Term Memory networks (LSTMs).",
          "quote": "We will mainly consider three types of sequence models: Long Short-Term Memory networks (LSTMs) (Hochreiter & Schmidhuber, 1997)"
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "Adam",
          "justification": "The paper uses the Adam optimizer for training neural networks within the experiments.",
          "quote": "All optimization is done using the Adam optimizer (Kingma & Ba, 2014)."
        },
        "aliases": [
          "Adam Optimizer"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Adam: A method for stochastic optimization",
          "justification": "The referenced paper is the foundational work describing the Adam optimizer.",
          "quote": "All optimization is done using the Adam optimizer (Kingma & Ba, 2014)."
        }
      },
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper uses PyTorch for implementing and training the sequence models.",
          "quote": "All implementation and training of the sequence models is done using PyTorch (Paszke et al., 2019)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The referenced paper is the foundational work describing the PyTorch library.",
          "quote": "All implementation and training of the sequence models is done using PyTorch (Paszke et al., 2019)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1441,
    "prompt_tokens": 23678,
    "total_tokens": 25119
  }
}