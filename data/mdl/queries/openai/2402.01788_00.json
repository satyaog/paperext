{
  "paper": "2402.01788.txt",
  "words": 6049,
  "extractions": {
    "title": {
      "value": "LitLLM: A Toolkit for Scientific Literature Review",
      "justification": "The title is explicitly mentioned at the beginning of the paper.",
      "quote": "LitLLM: A Toolkit for Scientific Literature Review"
    },
    "description": "The paper introduces LitLLM, a toolkit designed to assist researchers in conducting literature reviews using Retrieval Augmented Generation (RAG) principles. The system leverages Large Language Models (LLMs) for summarizing abstracts, retrieving and re-ranking relevant papers, and generating related work sections, aiming to reduce the time and effort required for literature reviews.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents a system, LitLLM, and provides implementation details, as well as user experiences and usage studies, indicating its empirical nature.",
      "quote": "As a preliminary study, we provided access to our user interface to 5 different researchers who worked through the demo to write literature reviews and validate the systemâ€™s efficacy."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on the use of LLMs and RAG techniques, which are core topics in the field of Natural Language Processing.",
        "quote": "Following recent advances in large language models (LLMs), a new set of systems provides even more advanced features."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Scientific Literature Review",
          "justification": "The paper specifically addresses the task of conducting literature reviews using NLP techniques.",
          "quote": "LitLLM is an interactive tool to help scientists write the literature review or related work section of a scientific paper starting from a user-provided abstract."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-3.5-turbo",
          "justification": "The paper mentions the use of GPT-3.5-turbo for generating results.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "GPT-4",
          "justification": "The paper mentions the use of GPT-4 for generating results.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Role:['contributed', 'used', 'referenced']",
          "quote": "used"
        },
        "is_executed": {
          "value": false,
          "justification": "ModelMode:['trained', 'fine-tuned', 'inference']",
          "quote": "inference"
        },
        "is_compared": {
          "value": false,
          "justification": "",
          "quote": ""
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "S2ORC",
          "justification": "The paper mentions using the Semantic Scholar API and its academic corpus for retrieving relevant papers, which includes datasets like S2ORC.",
          "quote": "We query the Semantic Scholar API available through the Semantic Scholar Open Data Platform to search for the relevant papers."
        },
        "aliases": [
          "Semantic Scholar Open Research Corpus"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "OpenAI API",
          "justification": "The paper mentions using the OpenAI API for generating results using GPT-3.5-turbo and GPT-4 models.",
          "quote": "In this work, we use OpenAI API to generate results for LLM using GPT-3.5-turbo and GPT-4 model."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Gradio",
          "justification": "The paper mentions using Gradio for building the system's user interface.",
          "quote": "We build our system using Gradio, which provides a nice interface to quickly and efficiently build system demos."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 793,
    "prompt_tokens": 10094,
    "total_tokens": 10887
  }
}