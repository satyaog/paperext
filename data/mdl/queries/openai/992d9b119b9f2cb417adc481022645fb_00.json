{
  "paper": "992d9b119b9f2cb417adc481022645fb.txt",
  "words": 6408,
  "extractions": {
    "title": {
      "value": "On the Effectiveness of Interpretable Feedforward Neural Network",
      "justification": "The title is explicitly provided at the beginning of the paper.",
      "quote": "On the Effectiveness of Interpretable Feedforward Neural Network"
    },
    "description": "This paper explores the generalization of an interpretable feedforward neural network (IFFNN) to multi-class classification and any type of feedforward neural networks, evaluating its classification performance and interpretability on interpretable datasets. The paper finds that the generalized IFFNNs achieve comparable classification performance to normal feedforward neural networks while providing meaningful interpretations, making this architecture practically useful.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves comprehensive experiments to evaluate the classification performance and interpretability of the IFFNNs on datasets like MNIST and INBEN.",
      "quote": "We conduct comprehensive experiments to evaluate the classification performance and interpretability of the IFFNNs."
    },
    "primary_research_field": {
      "name": {
        "value": "Interpretable Machine Learning",
        "justification": "The primary focus of the paper is on developing and evaluating interpretable neural networks, specifically an interpretable feedforward neural network (IFFNN).",
        "quote": "Thus, this kind of neural network architecture has great practical use."
      },
      "aliases": [
        "Explainable AI",
        "Interpretable AI"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Classification",
          "justification": "The paper deals with multi-class classification by generalizing an interpretable feedforward neural network.",
          "quote": "We propose ways to generalize the IFFNN to multi-class classification."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Model Interpretability",
          "justification": "The study extensively discusses the interpretability of machine learning models, proposing a generalized IFFNN architecture that provides meaningful interpretations.",
          "quote": "... evaluate its classification performance and interpretability on intrinsic interpretable datasets."
        },
        "aliases": [
          "Model Explainability"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Interpretable Feedforward Neural Network (IFFNN)",
          "justification": "The paper proposes the generalized IFFNN and examines its effectiveness in classification and interpretability.",
          "quote": "If the IFFNN can perform well in a more flexible and general form for other classification tasks while providing meaningful interpretations..."
        },
        "aliases": [
          "IFFNN"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The paper contributes to the research by generalizing the IFFNN to multi-class classification and different neural network architectures.",
          "quote": "In this paper, we propose a way to generalize the interpretable feedforward neural network to multi-class classification scenarios and any type of feedforward neural networks."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper mentions the execution of various experiments to evaluate the IFFNNs on datasets.",
          "quote": "We conduct comprehensive experiments to evaluate the classification performance and interpretability of the IFFNNs."
        },
        "is_compared": {
          "value": true,
          "justification": "The generalized IFFNNs are compared with their non-interpretable counterparts in terms of classification performance.",
          "quote": "We compare the classification accuracy of IFFNNs with their non-interpretable counterparts to show that they have similar classification performance."
        },
        "referenced_paper_title": {
          "value": "I-MAD: Interpretable Malware Detector Using Galaxy Transformers",
          "justification": "The referenced paper title found in the citations in relation to the IFFNN's previous work.",
          "quote": "(Li et al. 2021) propose an interpretable feedforward neural network (IFFNN) for malware detection."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "MNIST",
          "justification": "MNIST is explicitly mentioned as a dataset used for evaluating IFFNNs in image classification tasks.",
          "quote": "We evaluate the models on two datasets: MNIST and INBEN."
        },
        "aliases": [
          ""
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Gradient-based learning applied to document recognition",
          "justification": "The paper references LeCun et al. 1998 for the MNIST dataset.",
          "quote": "LeCun, Y.; Bottou, L.; Bengio, Y.; and Haffner, P. 1998. Gradient-based learning applied to document recognition."
        }
      },
      {
        "name": {
          "value": "INBEN",
          "justification": "INBEN, a dataset specifically created for this paper to evaluate the interpretability of IFFNNs.",
          "quote": "With our created dataset INBEN, the gold standard interpretations of the samples are known."
        },
        "aliases": [],
        "role": "contributed",
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no external reference for INBEN as it is introduced in this paper.",
          "quote": "We propose an INterpretablility BENchmark (INBEN) dataset."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is mentioned as the library used for implementing the models.",
          "quote": "We use Python 3.7.9 and PyTorch 1.6.0 (Paszke et al. 2017) to implement the models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "The paper references Paszke et al. 2017 for PyTorch.",
          "quote": "Paszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.; DeVito, Z.; Lin, Z.; Desmaison, A.; Antiga, L.; and Lerer, A. 2017. Automatic differentiation in PyTorch."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1113,
    "prompt_tokens": 12178,
    "total_tokens": 13291,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}