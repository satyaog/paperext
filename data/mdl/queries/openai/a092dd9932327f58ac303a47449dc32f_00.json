{
  "paper": "a092dd9932327f58ac303a47449dc32f.txt",
  "words": 11161,
  "extractions": {
    "title": {
      "value": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining",
      "justification": "The title captures the core focus of the research, which involves evaluating the faithfulness of importance measures in Natural Language Processing (NLP) by using a method of recursively masking important tokens and retraining the model.",
      "quote": "Title: Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining"
    },
    "description": "The paper proposes a novel metric, Recursive ROAR, to evaluate the faithfulness of importance measures in NLP models. This involves recursively masking allegedly important tokens in NLP tasks and retraining models to observe the impact on performance. The paper compares various importance measures across different models and tasks to determine how model and task dependent the faithfulness of these measures are.",
    "type": {
      "value": "empirical",
      "justification": "The paper primarily conducts experiments and evaluates different importance measures across various tasks and models, indicating it is an empirical study.",
      "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper focuses on evaluating importance measures and faithfulness specifically within the context of NLP models.",
        "quote": "To explain NLP models a popular approach is to use importance measures...However, an open question is how well these explanations accurately reflect a model’s logic, a property called faithfulness."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Interpretability",
          "justification": "The research paper deals with the evaluation of explanations or interpretability of NLP models, particularly looking at their faithfulness.",
          "quote": "A major challenge in the field of interpretability is ensuring that an explanation is faithful: “a faithful interpretation is one that accurately represents the reasoning process behind the model’s prediction”."
        },
        "aliases": [
          "Explainability",
          "Faithfulness"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "BiLSTM-Attention",
          "justification": "The paper uses BiLSTM-Attention as one of the architectures for evaluating importance measures.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "aliases": [
          "LSTM-Attention"
        ],
        "is_contributed": {
          "value": false,
          "justification": "This model is a well-known architecture and not a contribution of this paper.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "is_executed": {
          "value": true,
          "justification": "Experiments were conducted using this model to evaluate importance measures.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "is_compared": {
          "value": true,
          "justification": "The BiLSTM-Attention model is compared with the RoBERTa model in evaluating the importance measures.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "referenced_paper_title": {
          "value": "Attention is All You Need",
          "justification": "The paper builds upon concepts from the foundational 'Attention is All You Need' paper regarding the importance measures in attention-based models.",
          "quote": "Attention is often used as an explanation to provide insight into the logical process of a model (Belinkov and Glass, 2019)."
        }
      },
      {
        "name": {
          "value": "RoBERTa",
          "justification": "RoBERTa is used as another model architecture for evaluating importance measures in the study.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "RoBERTa is an existing model that is widely used in the NLP community.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed to evaluate the faithfulness of importance measures in NLP tasks.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "is_compared": {
          "value": true,
          "justification": "RoBERTa is compared with LSTM-attention models in the evaluation of importance measures.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        },
        "referenced_paper_title": {
          "value": "RoBERTa: A Robustly Optimized BERT Pretraining Approach",
          "justification": "The paper focuses on evaluating importance measures using the RoBERTa model, which is an extension of BERT.",
          "quote": "We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "SST (Stanford Sentiment Treebank)",
          "justification": "SST is used to evaluate the faithfulness of importance measures in sentiment analysis tasks.",
          "quote": "1. Two sentiment tasks: SST (Socher et al., 2013) and IMDB (Maas et al., 2011)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Parsing with compositional vector grammars",
          "justification": "SST is defined and originally used in the referenced paper by Socher et al. (2013).",
          "quote": "1. Stanford Sentiment Treebank (SST) (Socher et al., 2013) – Sentences are classified as positive or negative."
        }
      },
      {
        "name": {
          "value": "IMDB",
          "justification": "IMDB is another dataset used to analyze importance measures for sentiment classification.",
          "quote": "1. Two sentiment tasks: SST (Socher et al., 2013) and IMDB (Maas et al., 2011)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning word vectors for sentiment analysis",
          "justification": "The IMDB dataset is referenced from the study by Maas et al. (2011) on sentiment analysis.",
          "quote": "2. IMDB Movie Reviews (Maas et al., 2011) – Movie reviews are classified as positive or negative."
        }
      },
      {
        "name": {
          "value": "SNLI",
          "justification": "The SNLI dataset is employed to evaluate the faithfulness of importance measures in natural language inference tasks.",
          "quote": "5. Stanford Natural Language Inference (SNLI) (Bowman et al., 2015) – Inputs are premise and hypothesis."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A large annotated corpus for learning natural language inference",
          "justification": "The SNLI dataset was introduced in the referenced paper for natural language inference tasks.",
          "quote": "5. Stanford Natural Language Inference (SNLI) (Bowman et al., 2015)."
        }
      },
      {
        "name": {
          "value": "MIMIC-III",
          "justification": "The MIMIC-III dataset is used for healthcare-related NLP tasks such as detecting diabetes and anemia.",
          "quote": "3. MIMIC (Diabetes) (Johnson et al., 2016) – Uses health records to detect if a patient has Diabetes."
        },
        "aliases": [
          "MIMIC"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "MIMIC-III, a freely accessible critical care database",
          "justification": "MIMIC-III is referenced from Johnson et al. (2016), describing its use for critical care data analyses.",
          "quote": "3. MIMIC (Diabetes) (Johnson et al., 2016)."
        }
      },
      {
        "name": {
          "value": "bAbI",
          "justification": "bAbI dataset is used to evaluate on synthetic reasoning tasks in natural language processing, providing insights into model reasoning capabilities.",
          "quote": "6. bAbI (Weston et al., 2016) – A set of artificial text for understanding and reasoning."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Towards AI-complete question answering: A set of prerequisite toy tasks",
          "justification": "The bAbI dataset is a synthetic dataset for reasoning tasks created by Weston et al. (2016).",
          "quote": "6. bAbI (Weston et al., 2016) – A set of artificial text for understanding and reasoning."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1768,
    "prompt_tokens": 20366,
    "total_tokens": 22134,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}