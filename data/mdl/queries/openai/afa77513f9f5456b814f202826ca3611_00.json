{
  "paper": "afa77513f9f5456b814f202826ca3611.txt",
  "words": 19718,
  "extractions": {
    "title": {
      "value": "Performance-gated deliberation: A context-adapted strategy in which urgency is opportunity cost",
      "justification": "The title is directly provided at the beginning of the research paper and in the citation format.",
      "quote": "Citation: Puelma Touzel M, Cisek P, Lajoie G (2022) Performance-gated deliberation: A context-adapted strategy in which urgency is opportunity cost. PLoS Comput Biol 18(5): e1010080."
    },
    "description": "The paper proposes a decision-making strategy called Performance-Gated Deliberation (PGD) that balances the opportunity cost of time, particularly in decision-making scenarios where urgency plays a significant role. This strategy considers adaptive cost estimation in varying contexts and applies it to explain behavior in non-human primates during specific tasks.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents experimental results and simulations to support the proposed decision-making strategy, indicating that it is based on empirical data and observations.",
      "quote": "We show PGD outperforms AR-RL solutions in explaining behaviour and urgency of non-human primates in a context-varying random walk prediction task."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning in Decision Making",
        "justification": "The paper is centered around a strategy in decision-making using reinforcement learning principles, making this the primary research field.",
        "quote": "Average-reward reinforcement learning (AR-RL) was first proposed to extend the reward prediction error hypothesis for phasic dopamine to account also for the observed properties of tonic dopamine levels."
      },
      "aliases": [
        "AR-RL",
        "Average-Reward Reinforcement Learning"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Neuroscience",
          "justification": "The paper involves neural dynamics and behavioral neuroscience in decision-making tasks, linking neuroscience with reinforcement learning.",
          "quote": "Our work helps to integrate the neuroscience of reward representations and the brain dynamics associated with deliberation."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Animal Behavior",
          "justification": "The research includes experiments and observations on non-human primates, which relate to animal behavior studies.",
          "quote": "We show PGD outperforms AR-RL solutions in explaining behaviour and urgency of non-human primates in a context-varying random walk prediction task."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Performance-Gated Deliberation (PGD)",
          "justification": "The paper introduces PGD as a new model to optimize decision-making processes under different contexts, specifically focusing on the cost of deliberation and urgency.",
          "quote": "We use it in a simple decision-making heuristic based on average-reward reinforcement learning (AR-RL) that we call Performance-Gated Deliberation (PGD)."
        },
        "aliases": [
          "PGD",
          "Average-reward Reinforcement Learning heuristic"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The PGD model is introduced as a new contribution in the paper, extending the previous models with a novel heuristic for decision-making.",
          "quote": "We propose how the opportunity cost of deliberation can be estimated adaptively on multiple timescales to account for non-stationary contextual factors."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper includes simulations and examples where the PGD model is applied, indicating it is executed within the study.",
          "quote": "We show PGD outperforms AR-RL solutions in explaining behaviour and urgency of non-human primates in a context-varying random walk prediction task."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares PGD against AR-RL solutions, showing its advantages in specific tasks.",
          "quote": "PGD outperforms AR-RL solutions in explaining behaviour and urgency of non-human primates..."
        },
        "referenced_paper_title": {
          "value": "Unified neural dynamics of decisions and actions in the cerebral cortex and basal ganglia",
          "justification": "This paper discusses non-human primate experiments and neural implementations referenced alongside PGD.",
          "quote": "To illustrate how PGD applies in a specific continuing decision-making task, and to make the links to a neural implementation explicit, we analyze behavior and neural recordings collected over eight years from two non-human primates"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "tokens task dataset from non-human primates",
          "justification": "The paper references the use of a task-specific dataset involving non-human primates engaged in a task with varying contexts.",
          "quote": "To illustrate how PGD applies in a specific continuing decision-making task, and to make the links to a neural implementation explicit, we analyze behavior and neural recordings collected over eight years from two non-human primates."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Context-Dependent Urgency Influences Speed–Accuracy Trade-Offs in Decision-Making and Movement Execution",
          "justification": "The dataset used in this study is associated with experiments on non-human primates from previous work by the same authors.",
          "quote": "we analyze behavior and neural recordings collected over eight years from two non-human primates... References: [25] Thura D, Cos I, Trung J, Cisek P. Context-Dependent Urgency Influences Speed–Accuracy Trade-Offs in Decision-Making and Movement Execution."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Advances in Neural Information Processing Systems",
          "justification": "The paper references simulations and computational models described in this conference series, showing usage of related computational tools.",
          "quote": "In: Weiss Y, Schölkopf B, Platt J, editors. Advances in Neural Information Processing Systems. vol. 18. MIT Press."
        },
        "aliases": [
          "NIPS",
          "NeurIPS"
        ],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "A reinforcement learning method for maximizing undiscounted rewards",
          "justification": "The library or conference serves as a base for computational methods and theories discussed in the paper.",
          "quote": "Anton Schwartz. 1993. A reinforcement learning method for maximizing undiscounted rewards. In Proceedings of the Tenth International Conference on International Conference on Machine Learning (ICML'93). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, p. 298–305."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1244,
    "prompt_tokens": 34230,
    "total_tokens": 35474,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}