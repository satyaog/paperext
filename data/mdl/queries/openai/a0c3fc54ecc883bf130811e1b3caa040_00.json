{
  "paper": "a0c3fc54ecc883bf130811e1b3caa040.txt",
  "words": 7592,
  "extractions": {
    "title": {
      "value": "Tracking and predicting COVID‐19 radiological trajectory on chest X‐rays using deep learning",
      "justification": "The title explicitly states the focus of the research, which is about tracking and predicting the COVID-19 radiological trajectory on chest X-rays using deep learning techniques.",
      "quote": "Tracking and predicting COVID‐19 radiological trajectory on chest X‐rays using deep learning"
    },
    "description": "This paper explores the use of deep learning algorithms to track and predict the radiological trajectory of COVID-19 on chest X-rays, aiming to aid in disease severity evaluation and prognosis. The study utilizes a pre-trained model to extract radiological features and applies classical machine learning models for predicting radiological trajectory from these features.",
    "type": {
      "value": "empirical",
      "justification": "The study involves training and testing a deep learning model on datasets of chest X-rays to track and predict COVID-19 radiological trajectories, thus involving experimental and data-driven investigation.",
      "quote": "We trained a repurposed deep learning algorithm on the CheXnet open dataset... to perform immediate severity evaluation and prediction of future radiological trajectory."
    },
    "primary_research_field": {
      "name": {
        "value": "Medical Imaging",
        "justification": "The paper focuses on analyzing chest X-rays to track and predict COVID-19 radiological trajectories, which falls under the field of medical imaging.",
        "quote": "Radiological findings on chest X-ray (CXR) have shown to be essential for the proper management of COVID-19 patients."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "COVID-19 Analysis",
          "justification": "The study specifically applies deep learning for analyzing COVID-19 radiological features on chest X-rays.",
          "quote": "We hypothesize that deep learning can be harnessed to analyze CXRs and extract radiological features in a reproducible and quantitative manner."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Deep Learning",
          "justification": "Deep learning techniques are used for feature extraction and prediction of radiological trajectory.",
          "quote": "We trained a repurposed deep learning algorithm...to extract features that mapped to radiological labels."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Machine Learning",
          "justification": "Classical machine-learning algorithms were used on deep learning extracted features for the prediction tasks.",
          "quote": "Classical machine-learning algorithms were trained on the deep learning extracted features to perform immediate severity evaluation and prediction of future radiological trajectory."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "DenseNet121",
          "justification": "The DenseNet121 architecture was used for the experiments in this study, trained on CheXpert data for feature extraction.",
          "quote": "We used a DenseNet121 architecture for all our experiments as it was determined by Irving et al. to achieve the best results on the CheXpert dataset."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The model used, DenseNet121, is not a contribution of this paper but an existing architecture applied to this study's data.",
          "quote": "We used a DenseNet121 architecture for all our experiments."
        },
        "is_executed": {
          "value": true,
          "justification": "DenseNet121 was executed for feature extraction from the chest X-ray images, indicating its use in the experiments.",
          "quote": "We used a DenseNet121 architecture for all our experiments."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not mention numerical comparisons of DenseNet121 with other models, rather it uses it as a feature extractor for machine learning tasks.",
          "quote": "We used a DenseNet121 architecture for all our experiments."
        },
        "referenced_paper_title": {
          "value": "Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison",
          "justification": "The DenseNet121 model used in the paper references Irvin et al.'s work on the CheXpert dataset for its use and effectiveness.",
          "quote": "...as it was determined by Irving et al. to achieve the best results on the CheXpert dataset."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CheXpert",
          "justification": "CheXpert is the main dataset used for training the feature extraction model on chest X-ray images.",
          "quote": "We used as training set the open “CheXpert” chest X-ray dataset from Stanford Hospital."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison",
          "justification": "The CheXpert dataset's referenced paper by Irvin et al. is cited in relation to using this dataset for model training.",
          "quote": "We used as training set the open “CheXpert” chest X-ray dataset from Stanford Hospital, comprised of 224,316 X-ray images."
        }
      },
      {
        "name": {
          "value": "COVID-19 image data collection",
          "justification": "The dataset comprises COVID-19 patient chest X-rays and is used for training and testing.",
          "quote": "COVID‐19 image data collection. The open-access COVID-19 dataset was curated from a convenience sample of 77 patients with sequential AP CXRs."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Predicting COVID-19 pneumonia severity on chest X-ray with deep learning",
          "justification": "The referenced paper by Cohen J.P. et al. describes the COVID-19 image dataset utilized in this study.",
          "quote": "The COVID-19 image data collection was curated from a convenience sample of 77 patients."
        }
      },
      {
        "name": {
          "value": "COVID-19 ICU dataset",
          "justification": "This dataset includes imaging and clinical data from ICU-admitted COVID-19 patients, used for model evaluation.",
          "quote": "COVID-19 ICU dataset. We collected imaging and clinical data for all adult patients that were admitted at the ICU for confirmed COVID-19."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Factors associated with COVID-19-related death using OpenSAFELY",
          "justification": "The dataset on COVID-19 ICU patients references clinical studies such as OpenSAFELY describing factors and outcomes in ICU settings.",
          "quote": "The COVID-19 ICU dataset was collected from ICU admissions for confirmed COVID-19."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The PyTorch library was utilized for deep learning feature extraction in this study.",
          "quote": "Deep learning feature extraction was done in Python using the PyTorch library (version 1.4)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "The PyTorch library is commonly cited for its model training and automatic differentiation capabilities, assisting in this study’s deep learning tasks.",
          "quote": "Deep learning feature extraction was done in Python using the PyTorch library (version 1.4)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1359,
    "prompt_tokens": 13482,
    "total_tokens": 14841,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}