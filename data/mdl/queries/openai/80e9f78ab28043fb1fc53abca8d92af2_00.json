{
  "paper": "80e9f78ab28043fb1fc53abca8d92af2.txt",
  "words": 8673,
  "extractions": {
    "title": {
      "value": "P ATH OCL: P ATH -B ASED P ROMPT A UGMENTATION FOR OCL GENERATION WITH GPT-4",
      "justification": "The title is taken directly from the top of the document, matching the paper's given title format.",
      "quote": "P ATH OCL: P ATH -B ASED P ROMPT A UGMENTATION FOR OCL GENERATION WITH GPT-4"
    },
    "description": "This study introduces PathOCL, a novel path-based prompt augmentation technique designed to facilitate Object Constraint Language (OCL) generation using large language models, specifically GPT-4. PathOCL aims to address the challenges related to the token processing limits of LLMs and the complexity of large UML class models by segmenting the models into more manageable sub-models. The empirical evaluation shows that using PathOCL significantly improves the validity and correctness of OCL constraints compared to a full UML class model augmentation approach.",
    "type": {
      "value": "empirical",
      "justification": "The paper provides an empirical evaluation of the PathOCL prompting technique by comparing its effectiveness against traditional UML augmentation methods using specific metrics such as validity and correctness.",
      "quote": "In this study, we aim to empirically evaluate the effectiveness of providing a selective subset of UML classes as context (PathOCL), compared to augmenting the entire UML model (UML-Augmentation)."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The paper utilizes large language models, specifically focusing on prompt engineering and NLP techniques for generating OCL constraints.",
        "quote": "Prompt engineering is a systematic approach in designing prompts that effectively generate a response from LLMs."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Software Engineering",
          "justification": "The context of the study is heavily focused on software application development with AI, specifically using UML models and OCL constraints.",
          "quote": "Our study aims to empirically evaluate the effectiveness of providing a selective subset of UML classes as context (PathOCL), compared to augmenting the entire UML model (UML-Augmentation)."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-4",
          "justification": "The study specifically uses the GPT-4 model for generating OCL constraints as part of the PathOCL technique.",
          "quote": "We designed PathOCL as a three-step process... and generate OCL constraints using the GPT-4 model."
        },
        "aliases": [
          "Generative Pre-Trained Transformer 4",
          "GPT-4"
        ],
        "is_contributed": {
          "value": false,
          "justification": "GPT-4 is used as a tool in the study, not a contribution or development of the study itself.",
          "quote": "We designed PathOCL as a three-step process... and generate OCL constraints using the GPT-4 model."
        },
        "is_executed": {
          "value": true,
          "justification": "The GPT-4 model is actively used to generate OCL constraints, indicating execution.",
          "quote": "We designed PathOCL as a three-step process... and generate OCL constraints using the GPT-4 model."
        },
        "is_compared": {
          "value": false,
          "justification": "The GPT-4 model's results are analyzed, but no direct numerical comparison against other models is mentioned for the GPT-4 in the excerpts provided.",
          "quote": "In our hypotheses, we stated that there is no improvement in both the validity and correctness scores when using PathOCL..."
        },
        "referenced_paper_title": {
          "value": "GPT - OpenAI API",
          "justification": "This paper likely references the official documentation or paper on GPT-4 from OpenAI.",
          "quote": "[24] OpenAI. Gpt - openai api. https://platform.openai.com/docs/guides/gpt, 2023. [Online; accessed 23-October-2023]."
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "spaCy",
          "justification": "The spaCy library is used in the specification preprocessing step for natural language processing tasks such as tokenization and lemmatization.",
          "quote": "We use spaCy trained English pipeline “en_core_web_sm”, which includes the required components for extracting the UML elements."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "explosion/spaCy: v3.7.2: Fixes for APIs and requirements",
          "justification": "The version and repository of spaCy are likely cited for reproducibility.",
          "quote": "[22] Ines Montani, Matthew Honnibal, Matthew Honnibal, Adriane Boyd, Sofie Van Landeghem, and Henning Peters. explosion/spaCy: v3.7.2: Fixes for APIs and requirements, October 2023."
        }
      },
      {
        "name": {
          "value": "Sentence-BERT",
          "justification": "It is used to generate word embeddings for ranking simple paths.",
          "quote": "To generate the word embeddings, we employ the “all-MiniLM-L6-v2” model provided by Sentence-BERT [26]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Sentence-BERT: Sentence embeddings using siamese BERT-networks",
          "justification": "Referenced for its application in generating word embeddings in the study.",
          "quote": "[26] Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence embeddings using siamese BERT-networks, 2019."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1090,
    "prompt_tokens": 14181,
    "total_tokens": 15271,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}