{
  "paper": "d4c3f0f14db3c3786449cca0aed75258.txt",
  "words": 9696,
  "extractions": {
    "title": {
      "value": "Hallucinated but Factual! Inspecting the Factuality of Hallucinations in Abstractive Summarization",
      "justification": "The title is clearly stated on the first page of the research paper.",
      "quote": "Hallucinated but Factual! Inspecting the Factuality of Hallucinations in\nAbstractive Summarization"
    },
    "description": "This paper explores the phenomenon of hallucinations in state-of-the-art abstractive summarization systems, specifically identifying when these hallucinations contain factual information that is consistent with world knowledge. The authors propose a novel detection method to distinguish factual from non-factual hallucinated entities using pre-trained and fine-tuned masked language models. They demonstrate that this approach can improve the factuality of synthesized summaries in reinforcement learning frameworks.",
    "type": {
      "value": "empirical",
      "justification": "The paper discusses an empirical study involving experiments to detect factual hallucinations in text summarization, including performance evaluations against baselines and correlation with human judgments.",
      "quote": "Empirical results suggest that our approach outperforms five baselines and strongly correlates with human judgments."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research involves applying models and methods to tasks within Natural Language Processing, specifically focusing on text summarization.",
        "quote": "State-of-the-art abstractive summarization systems"
      },
      "aliases": [
        "NLP",
        "Text Summarization"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Abstractive Summarization",
          "justification": "The main focus of the paper is on abstractive summarization and the hallucination issues therein.",
          "quote": "State-of-the-art abstractive summarization systems"
        },
        "aliases": [
          "Abstractive Text Summarization"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "BART",
          "justification": "BART is mentioned as a state-of-the-art abstractive summarization model known to generate hallucinations.",
          "quote": "We annotate 800 summaries generated by BART, which is one of the state-of-the-art abstractive summarization models."
        },
        "aliases": [
          "BART model"
        ],
        "is_contributed": {
          "value": false,
          "justification": "BART is used as a baseline model in the experiments, not as a new contribution.",
          "quote": "We annotate 800 summaries generated by BART, which is one of the state-of-the-art abstractive summarization models."
        },
        "is_executed": {
          "value": true,
          "justification": "The experiments involve executing the BART model to generate summaries for analysis.",
          "quote": "We annotate 800 summaries generated by BART..."
        },
        "is_compared": {
          "value": true,
          "justification": "BART's performance and its hallucination characteristics are compared with other models and baselines in the study.",
          "quote": "Empirical results suggest that our approach outperforms five baselines"
        },
        "referenced_paper_title": {
          "value": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
          "justification": "The referenced title is found in the citation for the original BART paper.",
          "quote": "(Lewis et al., 2020)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "XSUM",
          "justification": "The XSUM dataset is extensively used for generating summaries and evaluating hallucination in the paper's experiments.",
          "quote": "Maynez et al. (2020) discovered that 64.1% of the summaries generated by a BERT-based abstractive summarization model on XSUM (Narayan et al., 2018a) contain hallucinations."
        },
        "aliases": [
          "XSUM Dataset"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization",
          "justification": "The paper by Narayan et al. is the reference work introducing the XSUM dataset.",
          "quote": "(Narayan et al., 2018a)"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is used as a library for implementing models and running experiments, as stated in the appendix on experimental setup.",
          "quote": "The Transformer encoder-decoder architecture from the Fairseq library (Ott et al., 2019) that is written in PyTorch (Paszke et al., 2017)."
        },
        "aliases": [
          "PyTorch Library"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in PyTorch",
          "justification": "This referenced title details PyTorch's capabilities, cited in the context of its use in the paper.",
          "quote": "Paszke et al., 2017"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 925,
    "prompt_tokens": 17113,
    "total_tokens": 18038,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}