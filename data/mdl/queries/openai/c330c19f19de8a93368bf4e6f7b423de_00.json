{
  "paper": "c330c19f19de8a93368bf4e6f7b423de.txt",
  "words": 21651,
  "extractions": {
    "title": {
      "value": "A protocol for trustworthy EEG decoding with neural networks",
      "justification": "The title explicitly states the focus of the paper is on developing a protocol for EEG decoding using neural networks.",
      "quote": "A protocol for trustworthy EEG decoding with neural networks"
    },
    "description": "This paper presents a comprehensive protocol for EEG decoding that explores hyperparameters characterizing the entire pipeline, including data pre-processing, network architecture, network training, and data augmentation. It emphasizes robust performance estimates using multi-seed initialization and is validated across multiple datasets involving various deep learning models.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves experiments conducted on EEG datasets to validate the proposed protocol.",
      "quote": "Our protocol is validated on 9 datasets about motor imagery, P300, SSVEP, including 204 participants and 26 recording sessions, and on different deep learning models."
    },
    "primary_research_field": {
      "name": {
        "value": "EEG Decoding",
        "justification": "The paper specifically focuses on EEG signal processing and decoding using neural networks.",
        "quote": "Deep learning solutions have rapidly emerged for EEG decoding, achieving state-of-the-art performance on a variety of decoding tasks."
      },
      "aliases": [
        "Electroencephalography Decoding"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Brain-Computer Interfaces",
          "justification": "The paper discusses applications related to BCIs, such as motor imagery, P300, and SSVEP paradigms.",
          "quote": "Machine learning and deep learning approaches are widely used to process the brain activity, often encompassing data recorded via electroencephalographic (EEG) signals, mainly for designing neural decoders in Brain–Computer Interfaces (BCIs)."
        },
        "aliases": [
          "BCI"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "EEGNet",
          "justification": "EEGNet is discussed as a primary model for EEG decoding within the paper.",
          "quote": "Among architectures, EEGNet (Lawhern et al., 2018) – in its original version and its variants – represents the most used one, providing a good trade-off between model compactness, model size, training time, and decoding accuracy."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper does not claim EEGNet as a newly developed model; it discusses its use within the proposed protocol.",
          "quote": "Among EEGNet-like variants, recent improvements regarded..."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is executed as part of the protocol validation over several datasets.",
          "quote": "Our protocol is validated on 9 datasets about motor imagery, P300, SSVEP, including... and on different deep learning models."
        },
        "is_compared": {
          "value": true,
          "justification": "EEGNet's performance is compared to other models and baselines within the study.",
          "quote": "Our protocol consistently outperformed baseline state-of-the-art pipelines, widely across datasets and models."
        },
        "referenced_paper_title": {
          "value": "EEGNet: A compact convolutional neural network for EEG-based brain–computer interfaces",
          "justification": "The referenced paper is acknowledged as the original proposal for EEGNet.",
          "quote": "EEGNet (Lawhern et al., 2018) – in its original version..."
        }
      },
      {
        "name": {
          "value": "ShallowConvNet",
          "justification": "ShallowConvNet is mentioned as another model used in the study for comparison.",
          "quote": "Crucially, it should be noted that for a more robust validation of the proposed decoding protocol, we applied it also with other CNNs, including... ShallowConvNet."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The paper does not contribute ShallowConvNet as a new model but uses it as an existing model for validation.",
          "quote": "...including one of the first successful CNNs proposed for decoding motor imagery from EEG (ShallowConvNet)..."
        },
        "is_executed": {
          "value": true,
          "justification": "It was executed to test against the proposed protocol.",
          "quote": "Crucially, it should be noted that for a more robust validation of the proposed decoding protocol, we applied it also with other CNNs, including one of the first successful CNNs..."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares its proposed protocol's results against baselines which include models like ShallowConvNet.",
          "quote": "Additionally, when designing new decoding pipelines, neuroscientists could exploit our suggestions about the key aspect affecting a decoding protocol."
        },
        "referenced_paper_title": {
          "value": "Deep learning with convolutional neural networks for EEG decoding and visualization",
          "justification": "This is the foundational paper detailing ShallowConvNet's design and usage.",
          "quote": "ShallowConvNet (Schirrmeister et al., 2017) is one of the first CNN proposed for motor imagery decoding..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "BNCI2014-001",
          "justification": "The dataset is used within the protocol validation involving motor imagery tasks.",
          "quote": "In this study, we used 9 multi-session MOABB datasets publicly available, covering: Motor imagery-based BCIs: BNCI2014-001 (Tangermann et al., 2012)"
        },
        "aliases": [
          "dataset IIa"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Review of the BCI competition IV",
          "justification": "The dataset is cited with its reference from the BCI competition IV review paper.",
          "quote": "BNCI2014-001... This dataset is also known as ‘dataset IIa’ from BCI competition IV (Tangermann et al., 2012)."
        }
      },
      {
        "name": {
          "value": "Lee2019-MI",
          "justification": "Used for validation in the protocol for motor imagery.",
          "quote": "Lee2019-MI (Lee et al., 2019). This dataset consists of 62-channel EEG recorded from 54 healthy participants across 2 recording sessions."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "EEG dataset and OpenBMI toolbox for three BCI paradigms: an investigation into BCI illiteracy",
          "justification": "The authors give proper credit citing the paper describing the dataset.",
          "quote": "Lee2019-MI (Lee et al., 2019). This dataset consists of 62-channel EEG..."
        }
      },
      {
        "name": {
          "value": "BNCI2014-009",
          "justification": "Dataset used for P300 evaluation in the protocol.",
          "quote": "BNCI2014-009 (Aricò et al., 2014). This dataset consists of 16-channel EEG recorded from 10 healthy participants across 3 recording sessions."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Influence of P300 latency jitter on event related potential-based brain–computer interface performance",
          "justification": "The paper references the dataset according to its original study.",
          "quote": "BNCI2014-009 (Aricò et al., 2014). This dataset consists of..."
        }
      },
      {
        "name": {
          "value": "Lee2019-SSVEP",
          "justification": "Utilized within the protocol for SSVEP paradigms.",
          "quote": "Lee2019-SSVEP (Lee et al., 2019). This dataset consists of 62-channel EEG recorded from 54 healthy participants across 2 recording sessions."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "EEG dataset and OpenBMI toolbox for three BCI paradigms: an investigation into BCI illiteracy",
          "justification": "The same paper that introduced Lee2019-MI also covers Lee2019-SSVEP.",
          "quote": "Lee2019-SSVEP (Lee et al., 2019). This dataset consists of 62-channel EEG..."
        }
      },
      {
        "name": {
          "value": "BI2015a",
          "justification": "The dataset is applied during the protocol validation for P300 BCIs.",
          "quote": "BI2015a (Korczowski et al., 2019). This dataset consists of 32-channel EEG recorded from 43 healthy participants across 3 recording sessions."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Brain invaders calibration-less P300-based BCI with modulation of flash duration dataset (bi2015a)",
          "justification": "The description of BI2015a is consistent with its reference for validation in BCI.",
          "quote": "BI2015a (Korczowski et al., 2019)..."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is explicitly mentioned as the library used for the decoding protocol implementation.",
          "quote": "The decoding protocol was implemented using the PyTorch (Paszke et al., 2019)-based library..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "Reference to PyTorch is made with the paper on its development by Paszke et al.",
          "quote": "...using the PyTorch (Paszke et al., 2019)-based library SpeechBrain..."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1828,
    "prompt_tokens": 40604,
    "total_tokens": 42432,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}