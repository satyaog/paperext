{
  "paper": "cae4402bb30576d5030f9a5d9dc8cf15.txt",
  "words": 21541,
  "extractions": {
    "title": {
      "value": "Beyond the Norms: Detecting Prediction Errors in Regression Models",
      "justification": "The title is clearly stated at the top of the document and mentioned multiple times in the text and headers.",
      "quote": "Beyond the Norms: Detecting Prediction Errors in Regression Models"
    },
    "description": "This paper addresses the challenge of detecting unreliable behavior in regression algorithms, specifically focusing on prediction errors due to intrinsic variability or model uncertainty. It introduces a metric to estimate discrepancy density and measure statistical diversity, thereby improving error detection across regression tasks. The paper demonstrates empirical improvements over baseline approaches in ensuring more reliable machine learning systems.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents empirical improvements and experimental results on various datasets, indicating an empirical research type.",
      "quote": "We show empirical improvements in error detection for multiple regression tasks, consistently outperforming popular baseline approaches..."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning Regression",
        "justification": "The paper focuses on improving the detection of prediction errors in regression models, making it primarily about regression techniques within machine learning.",
        "quote": "This paper tackles the challenge of detecting unreliable behavior in regression algorithms..."
      },
      "aliases": []
    },
    "sub_research_fields": [],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "energy",
          "justification": "The paper includes experimental results on the energy dataset, among others, as part of its empirical validation.",
          "quote": "In our extensive numerical evaluation, we consider six variations of the baselines and six variations of the algorithms... energy..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Fast calibrated additive quantile regression",
          "justification": "The paper refers to works by other authors, like in the context of quantile regression methods, which are applied to benchmark datasets.",
          "quote": "Fast calibrated additive quantile regression. Journal of the American Statistical Association, 2021."
        }
      },
      {
        "name": {
          "value": "wine",
          "justification": "The wine dataset is mentioned as one of the datasets used to evaluate the proposed methods.",
          "quote": "we consider 8 well-known UCI (Kelly et al.) regression datasets that have been extensively used in uncertainty quantification (Chung et al., 2021)... wine..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Beyond pinball loss: Quantile methods for calibrated uncertainty quantification",
          "justification": "The dataset is associated with works that discuss its usage in quantile methods, which are used in the paper's experiments.",
          "quote": "Beyond pinball loss: Quantile methods for calibrated uncertainty quantification. In Advances in Neural Information Processing Systems, 2021."
        }
      },
      {
        "name": {
          "value": "concrete",
          "justification": "The concrete dataset is among those utilized in the experiments to validate the proposed algorithms.",
          "quote": "we consider 8 well-known UCI (Kelly et al.) regression datasets that have been extensively used in uncertainty quantification (Chung et al., 2021)... concrete..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Beyond pinball loss: Quantile methods for calibrated uncertainty quantification",
          "justification": "References to the use of this dataset are found in cited works discussing methodologies also used in the paper.",
          "quote": "Beyond pinball loss: Quantile methods for calibrated uncertainty quantification. In Advances in Neural Information Processing Systems, 2021."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Simultaneous Quantile Regression (SQR)",
          "justification": "SQR is used extensively in the paper for estimating conditional distributions, playing a significant role in the experiments conducted.",
          "quote": "We then repeat the experiment for the same samples of X, but we estimate the distributions using Simultaneous Quantile Regression (Tagasovska & Lopez-Paz, 2019)."
        },
        "aliases": [
          "SQR"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Single-model uncertainties for deep learning",
          "justification": "The referenced work by Tagasovska and Lopez-Paz is cited for Simultaneous Quantile Regression, which is a key method employed in the paper.",
          "quote": "Simultaneous Quantile Regression (Tagasovska & Lopez-Paz, 2019)"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 846,
    "prompt_tokens": 57955,
    "total_tokens": 58801,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}