{
  "paper": "2305.00970.txt",
  "words": 10044,
  "extractions": {
    "title": {
      "value": "ArK: Augmented Reality with Knowledge Interactive Emergent Ability",
      "justification": "This is the official title as provided in the document.",
      "quote": "ArK: Augmented Reality with Knowledge Interactive Emergent Ability"
    },
    "description": "This paper discusses the development of an interactive AI system called ArK, which uses knowledge-memory from foundation models like GPT-4 and DALLE-2 to generate and edit high-quality 2D/3D scenes in both physical and virtual environments. The approach leverages an emergent mechanism, named Augmented Reality with Knowledge Inference Interaction (ArK), to enhance scene understanding and generation using knowledge-memory data.",
    "type": {
      "value": "empirical",
      "justification": "The paper focuses on developing and validating the performance of the ArK system through experiments and human evaluation.",
      "quote": "We validate the effectiveness of ArK on the scene generation and editing tasks. We show that our ArK approach, combined with large foundation models, significantly improves the quality of generated 2D/3D scenes, compared to baselines."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Vision",
        "justification": "The primary focus of the paper is on scene understanding and generation, which are core aspects of computer vision.",
        "quote": "This study focuses on developing an interactive AI agent for scene understanding and generation, powered by pre-trained foundation models (e.g., DALLE-2, Chat-GPT)."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The paper discusses the use of large language models like GPT-4 and Chat-GPT for improving scene generation tasks, which fall under NLP.",
          "quote": "In this study, we develop an infinite agent that learns to transfer knowledge-memory from general foundation models (e.g., GPT4, DALLE) to novel domains or scenarios for scene understanding and generation."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Augmented Reality",
          "justification": "The paper includes applications to augmented reality, highlighted by the development and validation of an augmented reality interaction mechanism named ArK.",
          "quote": "We present an AI dominating demonstration of a system that enables interactive generation and editing of a Gaming/AR environment using a knowledge-enhanced style projection."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "The paper uses reinforcement learning to improve the interactive AI agent for scene generation tasks.",
          "quote": "We show that the effectiveness of our infinite agent is attributed to the proposed ArK mechanism with reinforce learning (RL) that can understand and generate scenes in unseen settings."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Generative Models",
          "justification": "The paper focuses on generative models for creating 2D/3D scenes using knowledge from foundation models.",
          "quote": "We validate the effectiveness of ArK on the scene generation and editing tasks."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ArK",
          "justification": "This is the core model developed and validated in the paper.",
          "quote": "The heart of our approach is an emerging mechanism, dubbed Augmented Reality with Knowledge Inference Interaction (ArK), which leverages knowledge-memory to generate scenes in unseen physical world and virtual reality environments."
        },
        "aliases": [],
        "is_contributed": {
          "value": 1,
          "justification": "The model is a primary contribution of the research presented in this paper.",
          "quote": "In this study, we develop an infinite agent that learns to transfer knowledge-memory from general foundation models (e.g., GPT4, DALLE) to novel domains or scenarios for scene understanding and generation in the physical or virtual world."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper contains experimental results validating the performance of the ArK model.",
          "quote": "We validate the effectiveness of ArK on the scene generation and editing tasks."
        },
        "is_compared": {
          "value": 1,
          "justification": "The paper compares the performance of the ArK approach with other baseline models to show its effectiveness in improving the quality of generated scenes.",
          "quote": "We show that our ArK approach, combined with large foundation models, significantly improves the quality of generated 2D/3D scenes, compared to baselines."
        },
        "referenced_paper_title": {
          "value": "ArK: Augmented Reality with Knowledge Interactive Emergent Ability",
          "justification": "The model is primarily introduced in this paper.",
          "quote": "In this study, we develop an infinite agent that learns to transfer knowledge-memory from general foundation models (e.g., GPT4, DALLE) to novel domains or scenarios for scene understanding and generation in the physical or virtual world."
        }
      },
      {
        "name": {
          "value": "GPT-3.5",
          "justification": "This model is used in the ArK system for generating question-answer pairs with context.",
          "quote": "Following the KAT (Gui et al., 2022) and PICa model, for each image-question pair, we construct a carefully designed text prompt consisting of a general instruction sentence, the description of the image, the question, and a set of context-question-answer triplets taken from the training dataset that are similar to the current image-question pair. We then input this text prompt to the GPT-3.5 model in its frozen version and obtain the output from GPT-3.5 as the tentative answer candidate to the current image-question pair."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "GPT-3.5 is not contributed by this paper; it is used as part of the ArK system.",
          "quote": "Following the KAT (Gui et al., 2022) and PICa model, for each image-question pair, we construct a carefully designed text prompt consisting of a general instruction sentence, the description of the image, the question, and a set of context-question-answer triplets taken from the training dataset that are similar to the current image-question pair. We then input this text prompt to the GPT-3.5 model in its frozen version and obtain the output from GPT-3.5 as the tentative answer candidate to the current image-question pair."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper utilizes GPT-3.5 in its experiments for generating question-answer pairs.",
          "quote": "Following the KAT (Gui et al., 2022) and PICa model, for each image-question pair, we construct a carefully designed text prompt consisting of a general instruction sentence, the description of the image, the question, and a set of context-question-answer triplets taken from the training dataset that are similar to the current image-question pair. We then input this text prompt to the GPT-3.5 model in its frozen version and obtain the output from GPT-3.5 as the tentative answer candidate to the current image-question pair."
        },
        "is_compared": {
          "value": 0,
          "justification": "GPT-3.5 is not compared against other models; it is used within the system.",
          "quote": "To generate the 3D scene from knowledge prompt, we use GPT-4/ ChatGPT to output text code that is then rendered using a 3D rendering engine."
        },
        "referenced_paper_title": {
          "value": "Language models are unsupervised multitask learners.",
          "justification": "GPT-3.5 is referenced but not primarily contributed by this paper.",
          "quote": "Language models are unsupervised multitask learners. OpenAI Blog."
        }
      },
      {
        "name": {
          "value": "DALLE-2",
          "justification": "This model is utilized to generate images from textual descriptions as part of the ArK system.",
          "quote": "Text retrieval knowledge: large language models (GPT-3.5). Yang et al. (2022) propose to use GPT-3 for the outside knowledge-based visual question answering task OK-VQA. Instead of using explicit knowledge sources, they use GPT-3 as an implicit source of knowledge. They propose to feed the question and textual descriptions of the image to the GPT-3 model and query it to directly predict the answer."
        },
        "aliases": [],
        "is_contributed": {
          "value": 0,
          "justification": "DALLE-2 is not contributed by this paper; it is used as part of the ArK system.",
          "quote": "Text retrieval knowledge: large language models (GPT-3.5). Yang et al. (2022) propose to use GPT-3 for the outside knowledge-based visual question answering task OK-VQA. Instead of using explicit knowledge sources, they use GPT-3 as an implicit source of knowledge. They propose to feed the question and textual descriptions of the image to the GPT-3 model and query it to directly predict the answer."
        },
        "is_executed": {
          "value": 1,
          "justification": "DALLE-2 is explicitly used in generating images as part of the ArK experiments.",
          "quote": "Text retrieval knowledge: large language models (GPT-3.5). Yang et al. (2022) propose to use GPT-3 for the outside knowledge-based visual question answering task OK-VQA. Instead of using explicit knowledge sources, they use GPT-3 as an implicit source of knowledge. They propose to feed the question and textual descriptions of the image to the GPT-3 model and query it to directly predict the answer."
        },
        "is_compared": {
          "value": 0,
          "justification": "DALLE-2 is used for generating images but not compared to other models in terms of performance.",
          "quote": "We show that our ArK approach, combined with large foundation models, significantly improves the quality of generated 2D/3D scenes, compared to baselines."
        },
        "referenced_paper_title": {
          "value": "Hierarchical text-conditional image generation with clip latents",
          "justification": "DALLE-2 is mainly referenced in this paper",
          "quote": "Hierarchical text-conditional image generation with clip latents"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "COCO",
          "justification": "The dataset is used for training and evaluating image retrieval and generation tasks.",
          "quote": "Knowledge-memory retrieval system and evaluation. We first evaluate the performance of knowledge retrieval system on the WIT dataset (Srinivasan et al., 2021), Coco (Lin et al., 2014), Flicker 30K (Plummer et al., 2015), Sherlock (Hessel et al., 2022), and AOKVQA (Schwenk et al., 2022) on the knowledge-based image text retrieval and question answering task."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Microsoft coco: Common objects in context",
          "justification": "COCO is an external dataset used for evaluation and is not primarily contributed by this paper.",
          "quote": "Lin et al., 2014"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is a widely used deep learning library and mentioned in the implementation details.",
          "quote": "We use a cosine learning rate decay scheduler with a peak learning rate of 1e-5 and a linear warm-up of 10k steps. The weight decay is 0.05. More pre-training details of the Knowledge-Tensor CLIP model is in Section A of Appendix."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The paper references PyTorch as the deep learning framework used in the experiments.",
          "quote": "PyTorch: An imperative style, high-performance deep learning library"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 2296,
    "prompt_tokens": 17150,
    "total_tokens": 19446
  }
}