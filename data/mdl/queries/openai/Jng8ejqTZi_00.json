{
  "paper": "Jng8ejqTZi.txt",
  "words": 12675,
  "extractions": {
    "title": {
      "value": "Equivariance with Learned Canonicalization Functions",
      "justification": "The given text is the title section of the provided paper.",
      "quote": "Equivariance with Learned Canonicalization Functions"
    },
    "description": "Symmetry-based neural networks often constrain the architecture to achieve invariance or equivariance to a group of transformations. This paper proposes an alternative by learning to produce canonical representations of the data. The canonicalization functions are designed to be plugged into non-equivariant backbone architectures, with applications spanning image classification, N-body dynamics prediction, point cloud classification, and part segmentation. Experimental results show this approach is competitive across various tasks, offering insights and faster performance.",
    "type": {
      "value": "empirical",
      "justification": "The paper describes empirical results and presents experiments on images, physical dynamical systems, and point clouds.",
      "quote": "Our experiments show that learning the canonicalization function is competitive with existing techniques for learning equivariant functions across many tasks, including image classification, N-body dynamics prediction, point cloud classification and part segmentation, while being faster across the board."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper is focused on learning methodologies for achieving equivariance through canonicalization functions, which falls under the domain of Machine Learning.",
        "quote": "our hypothesis that learning a small neural network to perform canonicalization is better than using predefined heuristics."
      },
      "aliases": [
        "ML"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Computer Vision",
          "justification": "One of the primary applications of the proposed method is image classification, which falls under the domain of Computer Vision.",
          "quote": "Our experiments show that learning the canonicalization function is competitive with existing techniques for learning equivariant functions across many tasks, including image classification, N-body dynamics prediction, point cloud classification and part segmentation, while being faster across the board."
        },
        "aliases": [
          "CV"
        ]
      },
      {
        "name": {
          "value": "Physics",
          "justification": "The proposed model is used for N-body dynamics prediction, which pertains to the domain of Physics.",
          "quote": "Our experiments show that learning the canonicalization function is competitive with existing techniques for learning equivariant functions across many tasks, including image classification, N-body dynamics prediction, point cloud classification and part segmentation, while being faster across the board."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "3D Data Processing",
          "justification": "The proposed method is applied to point cloud classification and part segmentation, which are central problems in the field of 3D Data Processing.",
          "quote": "Our experiments show that learning the canonicalization function is competitive with existing techniques for learning equivariant functions across many tasks, including image classification, N-body dynamics prediction, point cloud classification and part segmentation, while being faster across the board."
        },
        "aliases": [
          "Point Cloud Processing"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "G-CNN (p4, =params)",
          "justification": "The paper describes the G-CNN variant with similar architecture to CNN (base) but with equal parameters, referred to as G-CNN (p4 & = params).",
          "quote": "For the pure G-CNN-based baseline, we provide the value reported by Cohen & Welling (2016a) and design a variant which has similar architecture to CNN (base) while matching the number of parameters of our CN(p4)-CNN. We call this G-CNN (p4 & = params)."
        },
        "aliases": [
          "G-CNN (p4 & = params)"
        ],
        "is_contributed": {
          "value": false,
          "justification": "This model is a baseline variant inspired by existing G-CNN models and not a novel contribution of this paper.",
          "quote": "For the pure G-CNN-based baseline, we provide the value reported by Cohen & Welling (2016a) and design a variant which has similar architecture to CNN (base) while matching the number of parameters of our CN(p4)-CNN. We call this G-CNN (p4 & = params)."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed as part of the experiments in the paper.",
          "quote": "For the pure G-CNN-based baseline, we provide the value reported by Cohen & Welling (2016a) and design a variant which has similar architecture to CNN (base) while matching the number of parameters of our CN(p4)-CNN."
        },
        "is_compared": {
          "value": true,
          "justification": "This model was compared numerically against other models like CN(p4)-CNN in the experiments.",
          "quote": "For the pure G-CNN-based baseline, we provide the value reported by Cohen & Welling (2016a) and design a variant which has similar architecture to CNN (base) while matching the number of parameters of our CN(p4)-CNN. We call this G-CNN (p4 & = params)."
        },
        "referenced_paper_title": {
          "value": "Group equivariant convolutional networks",
          "justification": "This is the referenced paper for the original G-CNN model.",
          "quote": "Cohen, T. and Welling, M. Group equivariant convolutional networks. pp. 2990–2999, 2016."
        }
      },
      {
        "name": {
          "value": "CN(p4)-CNN",
          "justification": "The paper introduces this model as one where the canonicalization function is learned end-to-end with a CNN as the prediction function and is equivariant to p4.",
          "quote": "For the canonicalization function, we choose a shallow G-CNN with three layers...We learn the canonicalization function end-to-end with a CNN as the prediction function (CN(pn)-CNN)."
        },
        "aliases": [
          "Canonical Network-CNN (p4)"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The CN(p4)-CNN is a novel contribution of this paper as it integrates the learned canonicalization function with a CNN.",
          "quote": "We learn the canonicalization function end-to-end with a CNN as the prediction function (CN(pn)-CNN)."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed as part of the experiments in the paper.",
          "quote": "We learn the canonicalization function end-to-end with a CNN as the prediction function (CN(pn)-CNN)."
        },
        "is_compared": {
          "value": true,
          "justification": "This model was numerically compared with other models like G-CNN and the baseline CNN.",
          "quote": "We learn the canonicalization function end-to-end with a CNN as the prediction function (CN(pn)-CNN)."
        },
        "referenced_paper_title": {
          "value": "Equivariance with Learned Canonicalization Functions",
          "justification": "The paper itself is the reference for this novel model.",
          "quote": "We learn the canonicalization function end-to-end with a CNN as the prediction function (CN(pn)-CNN)."
        }
      },
      {
        "name": {
          "value": "Deep Sets",
          "justification": "This model is used as the canonicalization network in the N-body dynamics prediction task.",
          "quote": "We use a Vector Neurons version of the Deep Sets architecture for the canonicalization network in this task."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The Deep Sets model is used but not introduced by this paper.",
          "quote": "We use a Vector Neurons version of the Deep Sets architecture for the canonicalization network in this task."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed as part of the experiments in the paper.",
          "quote": "We use a Vector Neurons version of the Deep Sets architecture for the canonicalization network in this task."
        },
        "is_compared": {
          "value": true,
          "justification": "Deep Sets is part of the architectural comparison in the N-body dynamics prediction task.",
          "quote": "We use a Vector Neurons version of the Deep Sets architecture for the canonicalization network in this task."
        },
        "referenced_paper_title": {
          "value": "Deep Sets",
          "justification": "The referenced paper for the Deep Sets model is the original paper introducing Deep Sets.",
          "quote": "Zaheer, M., Kottur, S., Ravanbakhsh, S., Poczos, B., Salakhutdinov, R. R., and Smola, A. J. Deep sets. In Guyon, I., Luxburg, U. V., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., and Garnett, R. (eds.), Advances in Neural Information Processing Systems 30, pp. 3391–3401. Curran Associates, Inc., 2017a."
        }
      },
      {
        "name": {
          "value": "GNN",
          "justification": "A Graph Neural Network (GNN) is used as the prediction function in the N-body dynamics prediction task.",
          "quote": "The prediction network is a 4-layer Graph Neural Network (GNN) with the same hyperparameters as the one used in (Satorras et al., 2021), and (Puny et al., 2022) for a fair comparison."
        },
        "aliases": [
          "Graph Neural Network"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The GNN is used but not introduced by this paper.",
          "quote": "The prediction network is a 4-layer Graph Neural Network (GNN) with the same hyperparameters as the one used in (Satorras et al., 2021), and (Puny et al., 2022) for a fair comparison."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was executed as part of the experiments in the paper.",
          "quote": "The prediction network is a 4-layer Graph Neural Network (GNN) with the same hyperparameters as the one used in (Satorras et al., 2021), and (Puny et al., 2022) for a fair comparison."
        },
        "is_compared": {
          "value": true,
          "justification": "The GNN was compared numerically with other models in the scope of the paper.",
          "quote": "The prediction network is a 4-layer Graph Neural Network (GNN) with the same hyperparameters as the one used in (Satorras et al., 2021), and (Puny et al., 2022) for a fair comparison."
        },
        "referenced_paper_title": {
          "value": "E (n) equivariant graph neural networks",
          "justification": "While not explicitly mentioned, this model appears to reference the method used in E(n) Equivariant Graph Neural Networks as the hyperparameters and architecture settings are aligned.",
          "quote": "Satorras, V. G., Hoogeboom, E., and Welling, M. E (n) equivariant graph neural networks. arXiv preprint arXiv:2102.09844, 2021."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Rotated MNIST",
          "justification": "The dataset Rotated MNIST is used as a benchmark for equivariant architectures in the image classification task.",
          "quote": "We first perform an empirical analysis of the proposed framework in the image domain. We selected the Rotated MNIST dataset (Larochelle et al., 2007), often used as a benchmark for equivariant architectures."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "An empirical evaluation of deep architectures on problems with many factors of variation",
          "justification": "The Rotated MNIST dataset was introduced in this paper.",
          "quote": "Larochelle, H., Erhan, D., Courville, A., Bergstra, J., and Bengio, Y. An empirical evaluation of deep architectures on problems with many factors of variation. In Proceedings of the 24th International Conference on Machine Learning, ICML ’07, pp. 473–480, 2007."
        }
      },
      {
        "name": {
          "value": "N-body dynamics prediction",
          "justification": "This dataset is used to evaluate the model in predicting the future positions of charged particles in the Physics domain.",
          "quote": "We evaluate our framework in this setting with the N -body dynamics prediction task proposed by (Kipf et al., 2018) and (Fuchs et al., 2020). In this task, the model has to predict the future positions of 5 charged particles interacting with Coulomb force given initial positions and velocities."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Neural relational inference for interacting systems",
          "justification": "The N-body dynamics prediction task was first proposed in this paper.",
          "quote": "Kipf, T., Fetaya, E., Wang, K.-C., Welling, M., and Zemel, R. Neural relational inference for interacting systems. In International Conference on Machine Learning, pp. 2688–2697. PMLR, 2018."
        }
      },
      {
        "name": {
          "value": "ModelNet40",
          "justification": "This dataset is used for the classification task in point cloud experiments. It consists of 40 classes of 3D models.",
          "quote": "We use the ModelNet40 (Wu et al., 2015) and ShapeNet (Chang et al., 2015) datasets for experiments on point clouds.\nThe ModelNet40 dataset consists of 40 classes of 3D models, with a total of 12,311 models. 9,843 models were used for training, and the remaining models were used for testing in the classification task."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "3D ShapeNets: A deep representation for volumetric shapes",
          "justification": "The ModelNet40 dataset was introduced in this paper.",
          "quote": "Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., and Xiao, J. 3d shapenets: A deep representation for volumetric shapes. pp. 1912–1920, 2015."
        }
      },
      {
        "name": {
          "value": "ShapeNet (ShapeNet-part subset)",
          "justification": "This dataset is used for the part segmentation task in point cloud experiments. It includes 16 categories of objects and more than 30,000 models.",
          "quote": "We use the ModelNet40 (Wu et al., 2015) and ShapeNet (Chang et al., 2015) datasets for experiments on point clouds...The ShapeNet dataset was used for part segmentation with the ShapeNet-part subset, which includes 16 categories of objects and more than 30,000 models."
        },
        "aliases": [
          "ShapeNet-part"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ShapeNet: An Information-Rich 3D Model Repository",
          "justification": "The ShapeNet dataset was introduced in this paper.",
          "quote": "Chang, A. X., Funkhouser, T., Guibas, L., Hanrahan, P., Huang, Q., Li, Z., Savarese, S., Savva, M., Song, S., Su, H., Xiao, J., Yi, L., and Yu, F. ShapeNet: An Information-Rich 3D Model Repository. Technical Report arXiv:1512.03012 [cs.GR], 2015."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch is used as part of the implementation for the experiments, as evidenced by the provided code snippet.",
          "quote": "Listing 1: Differentiable canonicalization for image inputs in PyTorch."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An imperative style, high-performance deep learning library",
          "justification": "The main reference paper for PyTorch is by Paszke et al., which describes the framework in detail.",
          "quote": "Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. Pytorch: An imperative style, high-performance deep learning library."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 3227,
    "prompt_tokens": 22426,
    "total_tokens": 25653
  }
}