{
  "paper": "93aad52ebe67880d9a8c24658d4ed8dd.txt",
  "words": 8076,
  "extractions": {
    "title": {
      "value": "Washing The Unwashable: On The (Im)possibility of Fairwashing Detection",
      "justification": "The title is explicitly mentioned at the beginning of the paper, which is commonly used as the primary identifier of the research work.",
      "quote": "Washing The Unwashable : On The (Im)possibility of Fairwashing Detection"
    },
    "description": "This paper investigates the issue of 'fairwashing', where model explanation techniques are manipulated to rationalize decisions made by unfair black-box models using deceptive surrogate models. It introduces FRAUD-Detect, a method for detecting fairwashing, and performs theoretical and empirical analysis demonstrating its effectiveness and robustness against adversaries.",
    "type": {
      "value": "theoretical",
      "justification": "The paper mostly focuses on theoretical analysis and formulation of fairwashing, and introduces a novel method for detection based on theoretical findings.",
      "quote": "Our primary contributions include (1) an extensive theoretical analysis of fairwashing and the fairness limitations in explanation techniques and (2) a novel approach for detecting, and thus deterring, fairwashing."
    },
    "primary_research_field": {
      "name": {
        "value": "Explainable Artificial Intelligence",
        "justification": "The research focuses on explaining model decisions and detecting deceptive explanations (fairwashing), which falls under the Explainable AI domain.",
        "quote": "One possible way to realize this is to approximate the black-box model using an inherently interpretable model (e.g., logistic regression or decision tree) whose decisions can be easily explained by design [27]."
      },
      "aliases": [
        "XAI",
        "Explainable AI"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Fairness in AI",
          "justification": "The paper attributes significant focus on fairness issues in AI models and the phenomenon of fairwashing.",
          "quote": "In this work, we investigate the issue of fairwashing, in which model explanation techniques are manipulated to rationalize decisions taken by an unfair black-box model using deceptive surrogate models."
        },
        "aliases": [
          "Fair AI"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Deep Neural Networks",
          "justification": "The paper mentions using Deep Neural Networks as black-box models for testing the proposed fairwashing detection method.",
          "quote": "We examine logistic regressors and decision trees as interpretable models with respect to black-box Deep Neural Networks, AdaBoost [24], Gradient Boosted Decision Trees [17] and Random Forests [13] on three benchmark datasets."
        },
        "aliases": [
          "DNN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper uses existing deep neural networks as part of its evaluation process and doesn't contribute a new model in this category.",
          "quote": "We examine logistic regressors and decision trees as interpretable models with respect to black-box Deep Neural Networks, AdaBoost [24], Gradient Boosted Decision Trees [17] and Random Forests [13] on three benchmark datasets."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper describes empirical evaluations using black-box Deep Neural Networks.",
          "quote": "We empirically demonstrate that this divergence is significantly larger in purposefully fairwashed interpretable models than in honest ones."
        },
        "is_compared": {
          "value": true,
          "justification": "Deep Neural Networks are part of the empirical comparison regarding fairwashing detection with other models.",
          "quote": "We evaluate the strength of our detector... on three benchmark datasets: COMPAS [5], Adult Income [22] and Bank Marketing [34]."
        },
        "referenced_paper_title": {
          "value": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization",
          "justification": "The referenced paper provides context for discussing explainability within deep networks.",
          "quote": "Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: visual explanations from deep networks via gradient-based localization."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "COMPAS",
          "justification": "The dataset is explicitly mentioned as one of the datasets used for empirical analysis in the paper.",
          "quote": "We examine logistic regressors and decision trees as interpretable models with respect to black-box Deep Neural Networks, AdaBoost [24], Gradient Boosted Decision Trees [17] and Random Forests [13] on three benchmark datasets: COMPAS [5], Adult Income [22] and Bank Marketing [34]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Machine Bias",
          "justification": "The referenced paper provides context for the dataset's relevance and background information.",
          "quote": "Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. Machine bias. ProPublica, (May 2016)."
        }
      },
      {
        "name": {
          "value": "Adult Income",
          "justification": "The dataset is explicitly mentioned as one of the datasets used for empirical analysis in the paper.",
          "quote": "We examine logistic regressors and decision trees as interpretable models with respect to black-box Deep Neural Networks, AdaBoost [24], Gradient Boosted Decision Trees [17] and Random Forests [13] on three benchmark datasets: COMPAS [5], Adult Income [22] and Bank Marketing [34]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "UCI Machine Learning Repository",
          "justification": "The dataset is a well-known benchmark dataset found in the UCI repository, referenced for its formal record.",
          "quote": "Dheeru Dua and Casey Graff. 2017. UCI machine learning repository. http://archive.ics.uci.edu/ml."
        }
      },
      {
        "name": {
          "value": "Bank Marketing",
          "justification": "The dataset is explicitly mentioned as one of the datasets used for empirical analysis in the paper.",
          "quote": "We examine logistic regressors and decision trees as interpretable models with respect to black-box Deep Neural Networks, AdaBoost [24], Gradient Boosted Decision Trees [17] and Random Forests [13] on three benchmark datasets: COMPAS [5], Adult Income [22] and Bank Marketing [34]."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "A data-driven approach to predict the success of bank telemarketing",
          "justification": "The referenced paper discusses the development and analysis relevant to the Bank Marketing dataset.",
          "quote": "Sérgio Moro, Paulo Cortez, and Paulo Rita. 2014. A data-driven approach to predict the success of bank telemarketing. Decision Support Systems, 62, 22–31."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "Scikit-learn",
          "justification": "The paper uses Scikit-learn for machine learning model implementations, as it is commonly used in empirical evaluations.",
          "quote": "Scikit-learn: machine learning in Python."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Scikit-learn: Machine Learning in Python",
          "justification": "The Scikit-learn library is referenced for its comprehensive capabilities in machine learning tasks.",
          "quote": "Fabian Pedregosa, Gaël Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, etc. 2011. Scikit-learn: machine learning in Python. Journal of Machine Learning Research, 12, 2825–2830."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1457,
    "prompt_tokens": 14500,
    "total_tokens": 15957,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}