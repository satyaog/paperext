{
  "paper": "f36e238cad8a0b6fd9f22a9561c19c0e.txt",
  "words": 5459,
  "extractions": {
    "title": {
      "value": "Linear Weight Interpolation Leads to Transient Performance Gains",
      "justification": "The extracted title matches the main focus of the introduction, abstract, and conclusion sections.",
      "quote": "We train copies of a neural network on different sets of SGD noise and find that linearly interpo-\nlating their weights can, remarkably, produce networks that perform significantly better than the\noriginal networks."
    },
    "description": "This paper investigates the effects of linearly interpolating neural network weights trained on different sets of SGD noise. The research finds that such interpolations can lead to transient performance gains, especially early in the training process, and discusses the implications of these findings on neural network optimization landscapes.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves conducting experiments with neural networks, analyzing the effects of interpolation during training.",
      "quote": "We train copies of a neural network on different sets of SGD noise..."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The paper focuses on neural network training dynamics and optimization, which are core topics in Deep Learning.",
        "quote": "We train copies of a neural network on different sets of SGD noise and find that linearly interpolating their weights can..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Training Dynamics",
          "justification": "The research specifically studies how network weight interpolation affects training performance and optimization.",
          "quote": "...our understanding of the properties of such networks and their optimization remains limited in more\ngeneral settings."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Computer Vision",
          "justification": "The experiments reference standard vision tasks and datasets like CIFAR-10 and CIFAR-100.",
          "quote": "We train copies of networks on different sets of SGD noise on standard vision tasks."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "ResNet20",
          "justification": "ResNet20 is specifically mentioned as a model used in experiments with CIFAR-10.",
          "quote": "We will show the results of our experiment on CIFAR-10 [15] with ResNet20 networks [11]..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ResNet20 is used as a well-established model for the experiments and is not introduced by this paper.",
          "quote": "We will show the results of our experiment on CIFAR-10 [15] with ResNet20 networks [11]..."
        },
        "is_executed": {
          "value": true,
          "justification": "The experiments using ResNet20 are executed to gather empirical data.",
          "quote": "We will show the results of our experiment on CIFAR-10 [15] with ResNet20 networks [11]..."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not compare ResNet20 against other models numerically; it uses it as part of experimentation.",
          "quote": "We will show the results of our experiment on CIFAR-10 [15] with ResNet20 networks [11]..."
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "ResNet models are widely recognized from this reference.",
          "quote": "Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016."
        }
      },
      {
        "name": {
          "value": "ResNet56",
          "justification": "ResNet56 is specifically mentioned as a model used in experiments with CIFAR-100.",
          "quote": "ResNet56 + CIFAR-100"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "ResNet56 is used as a well-established model for the experiments and is not introduced by this paper.",
          "quote": "ResNet56 + CIFAR-100"
        },
        "is_executed": {
          "value": true,
          "justification": "The experiments using ResNet56 are executed to gather empirical data.",
          "quote": "ResNet56 + CIFAR-100"
        },
        "is_compared": {
          "value": false,
          "justification": "The paper does not compare ResNet56 against other models numerically; it uses it as part of experimentation.",
          "quote": "ResNet56 + CIFAR-100"
        },
        "referenced_paper_title": {
          "value": "Deep Residual Learning for Image Recognition",
          "justification": "ResNet models are widely recognized from this reference.",
          "quote": "Deep Residual Learning for Image Recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016."
        }
      },
      {
        "name": {
          "value": "VGG-16",
          "justification": "VGG-16 is mentioned as part of the further appendices on experimental results, involving CIFAR-10.",
          "quote": "Appendix D. VGG-16 + CIFAR-10"
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "VGG-16 is used as a well-established model for the experiments and is not introduced by this paper.",
          "quote": "Appendix D. VGG-16 + CIFAR-10"
        },
        "is_executed": {
          "value": true,
          "justification": "The paper involves execution using VGG-16 for experiments in Appendix D.",
          "quote": "Appendix D. VGG-16 + CIFAR-10"
        },
        "is_compared": {
          "value": false,
          "justification": "There is no indication of numerical comparisons against other models for VGG-16.",
          "quote": "Appendix D. VGG-16 + CIFAR-10"
        },
        "referenced_paper_title": {
          "value": "Very Deep Convolutional Networks for Large-Scale Image Recognition",
          "justification": "VGG-16 is commonly attributed to this foundational paper.",
          "quote": "The experiments are adapted from VGG-16 networks."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "CIFAR-10",
          "justification": "CIFAR-10 is specifically mentioned and used for experiments with ResNet20 and other networks.",
          "quote": "We will show the results of our experiment on CIFAR-10 [15] with ResNet20 networks [11]..."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features From Tiny Images",
          "justification": "The CIFAR-10 dataset is associated with this reference by Alex Krizhevsky.",
          "quote": "CIFAR-10 [15]"
        }
      },
      {
        "name": {
          "value": "CIFAR-100",
          "justification": "CIFAR-100 is specifically mentioned and used with ResNet56 for experiments.",
          "quote": "ResNet56 + CIFAR-100"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Learning Multiple Layers of Features From Tiny Images",
          "justification": "The CIFAR-100 dataset is associated with this reference by Alex Krizhevsky.",
          "quote": "Appendix E. ResNet56 + CIFAR-100"
        }
      },
      {
        "name": {
          "value": "CINIC-10",
          "justification": "CINIC-10 is mentioned for use in Appendix F with ResNet20 networks.",
          "quote": "Appendix F. ResNet20 + CINIC-10"
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "CINIC-10 is not ImageNet or CIFAR-10",
          "justification": "This title is referenced in association with CINIC-10 dataset usage.",
          "quote": "CINIC-10 [3]"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1475,
    "prompt_tokens": 10742,
    "total_tokens": 12217,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}