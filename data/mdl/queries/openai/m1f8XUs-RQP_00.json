{
  "paper": "m1f8XUs-RQP.txt",
  "words": 10689,
  "extractions": {
    "title": {
      "value": "Minimal Value-Equivalent Partial Models for Scalable and Robust Planning in Lifelong Reinforcement Learning",
      "justification": "The complete title of the paper as provided.",
      "quote": "M INIMAL VALUE -E QUIVALENT PARTIAL M ODELS FOR S CALABLE AND ROBUST P LANNING IN L IFELONG R EINFORCEMENT L EARNING"
    },
    "description": "This paper introduces the concept of minimal value-equivalent partial models in the context of lifelong reinforcement learning (LRL). The paper presents both theoretical and empirical results to illustrate the scalability, robustness, and computational benefits of using these models for planning in LRL. It also provides heuristics for learning these models using deep learning architectures.",
    "type": {
      "value": "theoretical",
      "justification": "The paper focuses on theoretical constructs of minimal value-equivalent partial models, providing formal definitions, theoretical results, and some empirical validation.",
      "quote": "After providing the formal definitions of these models, we provide theoretical results..."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The paper is centered around the concept of learning models in the context of lifelong reinforcement learning (LRL).",
        "quote": "environment from pure interaction is often considered an essential component of building lifelong reinforcement learning agents..."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Model-Based Reinforcement Learning",
          "justification": "The paper discusses the limitations of traditional model-based reinforcement learning and introduces new concepts tailored for lifelong reinforcement learning scenarios.",
          "quote": "However, the common practice in model-based reinforcement learning is to learn models that model every aspect of the agent’s environment, regardless of whether they are important..."
        },
        "aliases": [
          "MBRL"
        ]
      },
      {
        "name": {
          "value": "Scalable Reinforcement Learning",
          "justification": "Scalability is a key focus of the paper, as it aims to make planning in large environments more manageable.",
          "quote": "Overall, both our theoretical and empirical results suggest that minimal value-equivalent partial models can provide significant benefits to performing scalable and robust planning..."
        },
        "aliases": [
          "Scalable RL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Minimal Value-Equivalent Partial Models",
          "justification": "The paper explicitly defines and focuses on minimal value-equivalent partial models as the primary model being proposed and evaluated.",
          "quote": "models that only model the relevant aspects of the environment, which we call minimal value-equivalent partial models"
        },
        "aliases": [
          "Minimal VE Models"
        ],
        "is_contributed": {
          "value": 1,
          "justification": "The model is introduced and developed as a new concept in this paper.",
          "quote": "we propose new kinds of models that only model the relevant aspects of the environment, which we call minimal value-equivalent partial models..."
        },
        "is_executed": {
          "value": 1,
          "justification": "The paper includes empirical validations which suggest that the model has been executed.",
          "quote": "perform experiments to empirically illustrate these theoretical results..."
        },
        "is_compared": {
          "value": 1,
          "justification": "The model is theoretically and empirically compared to conventional models.",
          "quote": "several experiments to empirically illustrate these theoretical results..."
        },
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "This is the original paper introducing the concept, so no referenced title is provided.",
          "quote": "N/A"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Squirrel’s World (SW)",
          "justification": "The SW environment is specifically mentioned as a dataset used in the paper's experiments.",
          "quote": "As an illustration of the models defined above, let us start by considering the Squirrel’s World (SW) environment..."
        },
        "aliases": [
          "SW"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Original environment designed for the purposes of this paper.",
          "quote": "N/A"
        }
      },
      {
        "name": {
          "value": "Two Rooms Dynamic Obstacles (2RDO)",
          "justification": "The 2RDO environment is used for additional experiments to validate the scalability and robustness of the proposed models.",
          "quote": "Environments. We perform experiments on both the SW environment and on variations of the Two Rooms Dynamic Obstacles (2RDO) environment..."
        },
        "aliases": [
          "2RDO"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Original environment designed for the purposes of this paper.",
          "quote": "N/A"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "It is mentioned in the code repositories and is a common library for implementing deep learning models.",
          "quote": "implementation uses PyTorch for neural network architectures..."
        },
        "aliases": [
          "Torch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "N/A",
          "justification": "Common deep learning library, no specific referenced paper required.",
          "quote": "N/A"
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 959,
    "prompt_tokens": 18190,
    "total_tokens": 19149
  }
}