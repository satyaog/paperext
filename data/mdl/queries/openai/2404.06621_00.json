{
  "paper": "2404.06621.txt",
  "words": 6969,
  "extractions": {
    "title": {
      "value": "What is Your Favorite Gender, MLM? Gender Bias Evaluation in Multilingual Masked Language Models",
      "justification": "The title clearly reflects the primary focus of the research, which is on evaluating gender bias in multilingual masked language models (MLMs).",
      "quote": "What is Your Favorite Gender, MLM? Gender Bias Evaluation in Multilingual Masked Language Models"
    },
    "description": "This paper addresses the evaluation of gender bias in multilingual Masked Language Models (MLMs) across five languages: Chinese, English, German, Portuguese, and Spanish. It proposes a multilingual approach to generate sentence pairs for assessing gender bias, using both lexicon-based and model-based methods. Three new scoring metrics are introduced to provide a more robust analysis compared to traditional methods.",
    "type": {
      "value": "empirical",
      "justification": "The paper focuses on creating datasets and using these to evaluate gender bias in models using empirical methods, including experiments and evaluation scores across several models.",
      "quote": "This paper improves the gender bias evaluation in multilingual MLMs by addressing the limitations of previous work."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research focuses on evaluating gender bias in language models, which is an aspect of Natural Language Processing.",
        "quote": "The advent of transformer models (Vaswani et al., 2017) and subsequent development of contextualized embedding encoders (Devlin et al., 2019; Liu et al., 2019) have led to the widespread deployment of large language models for crucial societal tasks."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Bias Analysis in Language Models",
          "justification": "The paper specifically deals with bias, particularly gender bias, in language models which require a specialized understanding of bias within NLP models.",
          "quote": "This paper proposes a multilingual approach to estimate gender bias in MLMs from 5 languages."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "BERT",
          "justification": "The paper explicitly mentions using BERT-based language-specific transformer encoders for evaluating gender bias.",
          "quote": "For our experiments, BERT-based language-specific transformer encoders are used for English (Devlin et al., 2019), German (Chan et al., 2020), Spanish (Ca√±ete et al., 2020), Portuguese (Souza et al., 2020), and Chinese (Cui et al., 2020)"
        },
        "aliases": [
          "Bidirectional Encoder Representations from Transformers"
        ],
        "is_contributed": {
          "value": false,
          "justification": "BERT is not a contribution of this paper; it is used as a tool for analysis.",
          "quote": "For our experiments, BERT-based language-specific transformer encoders are used."
        },
        "is_executed": {
          "value": true,
          "justification": "The experiments conducted in the paper use BERT, implying that it was executed to carry out the bias evaluation.",
          "quote": "For our experiments, BERT-based language-specific transformer encoders are used."
        },
        "is_compared": {
          "value": false,
          "justification": "While BERT is used in the experiments, there is no indication that it was numerically compared with other models.",
          "quote": "The entire evaluation process, which includes processing all sentence pairs in every language, is completed in about two hours with efficient performance."
        },
        "referenced_paper_title": {
          "value": "BERT: Pre-training of deep bidirectional transformers for language understanding",
          "justification": "The original BERT paper is referenced in explaining the models used.",
          "quote": "For our experiments, BERT-based language-specific transformer encoders are used for English (Devlin et al., 2019)"
        }
      },
      {
        "name": {
          "value": "Electra",
          "justification": "Electra is mentioned as a sophisticated model adapted for pretraining transformers.",
          "quote": "Despite efforts to enhance Masked Language Models (MLMs) (Clark et al., 2020; Tan and Bansal, 2019)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Electra is mentioned as part of the literature on enhancing MLMs, not a specific contribution of this research.",
          "quote": "Despite efforts to enhance Masked Language Models (MLMs) (Clark et al., 2020; Tan and Bansal, 2019)..."
        },
        "is_executed": {
          "value": false,
          "justification": "There is no specific mention of Electra being executed as part of the experiments.",
          "quote": "Despite efforts to enhance Masked Language Models (MLMs) (Clark et al., 2020; Tan and Bansal, 2019)..."
        },
        "is_compared": {
          "value": false,
          "justification": "There is no comparison involving Electra in terms of the experiments conducted.",
          "quote": "Despite efforts to enhance Masked Language Models (MLMs) (Clark et al., 2020; Tan and Bansal, 2019)..."
        },
        "referenced_paper_title": {
          "value": "Electra: Pre-training text encoders as discriminators rather than generators",
          "justification": "The referenced paper is an important work in the literature of transformer models, as cited in the paper.",
          "quote": "Despite efforts to enhance Masked Language Models (MLMs) (Clark et al., 2020; Tan and Bansal, 2019)..."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "TED2020 v1",
          "justification": "The paper describes using the TED2020 dataset to validate their multilingual gender lexicon and create evaluation datasets.",
          "quote": "We utilize the TED parallel corpus (Section 4.2) to build a comprehensive corpus for the evaluation of gender bias in the transformer-based multilingual language models."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Making monolingual sentence embeddings multilingual using knowledge distillation",
          "justification": "The TED2020 v1 dataset is associated with the work of Reimers and Gurevych, who are cited for providing the corpus.",
          "quote": "TED2020 v1: https://opus.nlpl.eu/TED2020.php"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1221,
    "prompt_tokens": 11589,
    "total_tokens": 12810,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}