{
  "paper": "a48bb120c1de345206094ac09e40a3eb.txt",
  "words": 13547,
  "extractions": {
    "title": {
      "value": "Stress-Testing Capability Elicitation With Password-Locked Models",
      "justification": "The paper introduces the concept of password-locked models and investigates fine-tuning-based elicitation conditions.",
      "quote": "To determine the safety of large language models (LLMs), AI developers must be able to assess their dangerous capabilities... In this paper, we investigate the conditions under which fine-tuning-based elicitation suffices to elicit capabilities."
    },
    "description": "The paper introduces a method to assess the safety of large language models (LLMs) by using password-locked models, which are fine-tuned to hide some capabilities unless a password is given. This study evaluates whether fine-tuning can fully elicit these hidden capabilities and compares its efficacy against other methods such as reinforcement learning.",
    "type": {
      "value": "empirical",
      "justification": "The paper presents experimental results on password-locked models and tests various elicitation techniques like fine-tuning and reinforcement learning.",
      "quote": "In this paper, we investigate the conditions under which fine-tuning-based elicitation suffices to elicit capabilities... We find that a few high-quality demonstrations are often sufficient to fully elicit password-locked capabilities."
    },
    "primary_research_field": {
      "name": {
        "value": "Machine Learning",
        "justification": "The paper focuses on techniques like fine-tuning and reinforcement learning within the machine learning space to elicit capabilities of large language models.",
        "quote": "To determine the safety of large language models (LLMs), AI developers must be able to assess their dangerous capabilities..."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The paper deals with large language models, which are a key component of Natural Language Processing.",
          "quote": "To determine the safety of large language models (LLMs), AI developers must be able to assess their dangerous capabilities."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Reinforcement Learning",
          "justification": "Reinforcement learning is explored as a method for capability elicitation in the study.",
          "quote": "Furthermore, when only evaluations, and not demonstrations, are available, approaches like reinforcement learning are still often able to elicit capabilities."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Deepseek 7B",
          "justification": "Deepseek 7B is a model used for code generation tasks and fine-tuned to exhibit specific behaviors for the research purposes.",
          "quote": "For code generation (right), when using a Deepseek 7B (Bi et al., 2024) model fine-tuned to imitate poor answers generated by Pythia-1B (Biderman et al., 2023), both supervised fine-tuning (SFT) on few demonstrations and reinforcement learning (RL) recover most of the coding capabilities of Deepseek 7B."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Deepseek 7B is a referenced model in the study, not introduced by the authors.",
          "quote": "For code generation (right), when using a Deepseek 7B (Bi et al., 2024) model..."
        },
        "is_executed": {
          "value": true,
          "justification": "The model was fine-tuned and executed in experiments related to code generation and testing capability elicitation.",
          "quote": "For code generation (right), when using a Deepseek 7B (Bi et al., 2024) model fine-tuned to imitate poor answers generated by Pythia-1B..."
        },
        "is_compared": {
          "value": true,
          "justification": "Model comparisons are made to determine the efficacy of different elicitation methods on Deepseek 7B's capabilities.",
          "quote": "both supervised fine-tuning (SFT) on few demonstrations and reinforcement learning (RL) recover most of the coding capabilities of Deepseek 7B."
        },
        "referenced_paper_title": {
          "value": "Deepseek LLM: Scaling Open-Source Language Models with Longtermism",
          "justification": "The reference paper title for Deepseek 7B is extracted from the citation.",
          "quote": "(Bi et al., 2024)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "APPS",
          "justification": "APPS is used in the study to generate coding tasks for evaluating models' performance.",
          "quote": "In our coding task, a model needs to generate solutions to coding problems from APPS (Hendrycks et al., 2021a) and MBPP (Austin et al., 2021) datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Measuring Coding Challenge Competence with APPS",
          "justification": "The referenced paper is cited in context of using the APPS dataset.",
          "quote": "(Hendrycks et al., 2021a)"
        }
      },
      {
        "name": {
          "value": "MBPP",
          "justification": "The MBPP dataset is utilized for code generation tasks in the research.",
          "quote": "In our coding task, a model needs to generate solutions to coding problems from APPS (Hendrycks et al., 2021a) and MBPP (Austin et al., 2021) datasets."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Program Synthesis with Large Language Models",
          "justification": "The referenced paper provides context for the MBPP dataset used in experiments.",
          "quote": "(Austin et al., 2021)"
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1085,
    "prompt_tokens": 24407,
    "total_tokens": 25492,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 0
    }
  }
}