{
  "paper": "2310.07814.txt",
  "words": 9742,
  "extractions": {
    "title": {
      "value": "Explorable Mesh Deformation Subspaces from Unstructured 3D Generative Models",
      "justification": "This is the title of the paper as provided by the user.",
      "quote": "Explorable Mesh Deformation Subspaces from Unstructured 3D Generative Models"
    },
    "description": "This paper presents a novel method for exploring variations among a set of input 3D shapes using a 2D exploration space. The method constructs a mapping to a sub-space of a pre-trained generative model's latent space that optimizes the smoothness of interpolations. This allows for transferring these variations to high-quality meshes while avoiding detail loss from the generator's unstructured output.",
    "type": {
      "value": "empirical",
      "justification": "The paper demonstrates a practical method validated through experiments with 3D shapes, comparison with other methods, and quantitative metrics.",
      "quote": "We test our method using SP-GAN trained on ShapeNet as our shape generator G [Chang et al. 2015]."
    },
    "primary_research_field": {
      "name": {
        "value": "Computer Graphics",
        "justification": "The paper focuses on shape deformation, generative models, and 3D shape generation, which are key topics in the field of Computer Graphics.",
        "quote": "• Computing methodologies → Shape analysis."
      },
      "aliases": [
        "Computer Graphics"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "3D Shape Generation",
          "justification": "The paper contributes to the field of 3D shape generation by proposing a new method for exploring 3D shape variations.",
          "quote": "Data-driven generative models have introduced revolutionary new capabilities to the practice of 3D shape design and exploration."
        },
        "aliases": [
          "3D Shape Generation"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "SP-GAN",
          "justification": "SP-GAN is a state-of-the-art point cloud GAN used as the shape generator in the study.",
          "quote": "For our generator G, we employ SP-GAN [Li et al. 2021], a state-of-the-art point cloud GAN."
        },
        "aliases": [
          "SP-GAN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "SP-GAN is utilized in the study but is not introduced by the authors.",
          "quote": "For our generator G, we employ SP-GAN [Li et al. 2021], a state-of-the-art point cloud GAN."
        },
        "is_executed": {
          "value": true,
          "justification": "SP-GAN was executed as part of the experiments in this paper.",
          "quote": "We test our method using SP-GAN trained on ShapeNet as our shape generator G [Chang et al. 2015]."
        },
        "is_compared": {
          "value": true,
          "justification": "SP-GAN's results are compared with ShapeFlow and other models in the evaluation section.",
          "quote": "We compare our results qualitatively and quantitatively with ShapeFlow. ... We specifically compare against ShapeFlow’s chair model, as other models were unavailable."
        },
        "referenced_paper_title": {
          "value": "SP-GAN: Sphere-Guided 3D Shape Generation and Manipulation",
          "justification": "This is the reference paper for the SP-GAN model.",
          "quote": "For our generator G, we employ SP-GAN [Li et al. 2021], a state-of-the-art point cloud GAN."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "ShapeNet",
          "justification": "ShapeNet is used to train the SP-GAN model in the study.",
          "quote": "We test our method using SP-GAN trained on ShapeNet as our shape generator G [Chang et al. 2015]."
        },
        "aliases": [
          "ShapeNet"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "ShapeNet: An Information-Rich 3D Model Repository",
          "justification": "This is the reference paper for the ShapeNet dataset.",
          "quote": "We test our method using SP-GAN trained on ShapeNet as our shape generator G [Chang et al. 2015]."
        }
      },
      {
        "name": {
          "value": "ShapeNet Manifold",
          "justification": "ShapeNet Manifold dataset is used for training and evaluation of the models in the study.",
          "quote": "We also use the ShapeNet Manifold dataset [Huang et al. 2018]."
        },
        "aliases": [
          "ShapeNet Manifold"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Robust Watertight Manifold Surface Generation Method for ShapeNet Models",
          "justification": "This is the reference paper for the ShapeNet Manifold dataset.",
          "quote": "We also use the ShapeNet Manifold dataset [Huang et al. 2018]."
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "PyTorch was used for implementation and optimization in the study.",
          "quote": "We use PyTorch and Adam for all optimization routines [Kingma and Ba 2014; Paszke et al. 2019]."
        },
        "aliases": [
          "PyTorch"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "PyTorch: An Imperative Style, High-Performance Deep Learning Library",
          "justification": "This is the reference paper for PyTorch.",
          "quote": "We use PyTorch and Adam for all optimization routines [Kingma and Ba 2014; Paszke et al. 2019]."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1056,
    "prompt_tokens": 17676,
    "total_tokens": 18732
  }
}