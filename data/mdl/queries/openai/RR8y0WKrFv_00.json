{
  "paper": "RR8y0WKrFv.txt",
  "words": 9765,
  "extractions": {
    "title": {
      "value": "ENSEMBLE DISTILLATION FOR UNSUPERVISED CONSTITUENCY PARSING",
      "justification": "The title captures the main contributions and focus of the paper, which is on ensemble distillation for unsupervised constituency parsing.",
      "quote": "ENSEMBLE DISTILLATION FOR UNSUPERVISED CONSTITUENCY PARSING"
    },
    "description": "This paper presents a method for unsupervised constituency parsing by proposing an ensemble method which leverages tree averaging and distillation into a student model to improve efficiency and performance. The ensemble approach utilizes multiple unsupervised parsers, and the knowledge is distilled into a recurrent neural network grammar model. The method is shown to be robust and effective across various datasets, including the Penn Treebank and SUSANNE.",
    "type": {
      "value": "empirical",
      "justification": "The paper conducts experiments to demonstrate the effectiveness of the ensemble distillation approach on datasets such as the Penn Treebank and SUSANNE.",
      "quote": "Experiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs, with different ensemble components, and under domain-shift conditions."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research pertains to syntactic structure prediction, a key task within the field of Natural Language Processing.",
        "quote": "Constituency parsing is a well-established task in natural language processing (NLP)..."
      },
      "aliases": [
        "NLP"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Unsupervised Parsing",
          "justification": "The core focus of the paper is on unsupervised methods for constituency parsing.",
          "quote": "We investigate the unsupervised constituency parsing task, which organizes words and phrases of a sentence into a hierarchical structure without using linguistically annotated data."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Compound PCFG",
          "justification": "Compound PCFG is listed among the unsupervised parsers used for ensemble distillation.",
          "quote": "The left table considers three heterogeneous models (Compound PCFG, DIORA, and S-DIORA)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "Compound PCFG was not developed in this paper as it is used as a baseline model.",
          "quote": "Our ensemble approach involves the following classic or state-of-the-art unsupervised parsers as our teachers, which are also baselines for comparison."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper performs experiments with Compound PCFG as part of the ensemble.",
          "quote": "The left table considers three heterogeneous models (Compound PCFG, DIORA, and S-DIORA)..."
        },
        "is_compared": {
          "value": true,
          "justification": "Compound PCFG is compared with other models in terms of F1 score.",
          "quote": "Experiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs..."
        },
        "referenced_paper_title": {
          "value": "Compound probabilistic context-free grammars for grammar induction",
          "justification": "The referenced paper title matches the Compound PCFG model discussed in the research paper.",
          "quote": "Kim, Y., Dyer, C., & Rush, A. (2019a). Compound probabilistic context-free grammars for grammar induction."
        }
      },
      {
        "name": {
          "value": "DIORA",
          "justification": "DIORA is one of the models used in the ensemble methods discussed in the paper.",
          "quote": "The left table considers three heterogeneous models (Compound PCFG, DIORA, and S-DIORA)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "DIORA was previously developed and is used as a baseline in this research.",
          "quote": "Our ensemble approach involves the following classic or state-of-the-art unsupervised parsers as our teachers, which are also baselines for comparison."
        },
        "is_executed": {
          "value": true,
          "justification": "DIORA is utilized in the experiments for the ensemble.",
          "quote": "The left table considers three heterogeneous models (Compound PCFG, DIORA, and S-DIORA)..."
        },
        "is_compared": {
          "value": true,
          "justification": "DIORA is compared in experiments based on F1 scores against other models.",
          "quote": "Experiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs..."
        },
        "referenced_paper_title": {
          "value": "Unsupervised latent tree induction with deep inside-outside recursive auto-encoders",
          "justification": "The referenced paper is cited as the source for the DIORA model.",
          "quote": "Drozdov, A., Verga, P., Yastrom, M., Cohen, S. (2019). Unsupervised latent tree induction with deep inside-outside recursive auto-encoders."
        }
      },
      {
        "name": {
          "value": "S-DIORA",
          "justification": "The S-DIORA model is included in the set of unsupervised parsers used for the ensemble.",
          "quote": "The left table considers three heterogeneous models (Compound PCFG, DIORA, and S-DIORA)..."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "S-DIORA is used as a baseline model in this paper.",
          "quote": "Our ensemble approach involves the following classic or state-of-the-art unsupervised parsers as our teachers, which are also baselines for comparison."
        },
        "is_executed": {
          "value": true,
          "justification": "S-DIORA is executed as part of the experimental setup.",
          "quote": "The left table considers three heterogeneous models (Compound PCFG, DIORA, and S-DIORA)..."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares S-DIORA's performance with other models.",
          "quote": "Experiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs..."
        },
        "referenced_paper_title": {
          "value": "Unsupervised parsing with S-DIORA: Single tree encoding for deep inside-outside recursive autoencoders",
          "justification": "The S-DIORA model description corresponds to this reference title.",
          "quote": "Drozdov, A., Rongali, S., Chen, Y.-P., O'Gorman, T., Iyyer, M., McCallum, A. (2020). Unsupervised parsing with S-DIORA: Single tree encoding for deep inside-outside recursive autoencoders."
        }
      },
      {
        "name": {
          "value": "Recurrent Neural Network Grammar (RNNG)",
          "justification": "The paper makes use of the RNNG model in combination with ensemble distillation.",
          "quote": "we choose the recurrent neural network grammar (RNNG; Dyer et al., 2016) with an unsupervised self-training procedure (URNNG; Kim et al., 2019b)"
        },
        "aliases": [
          "RNNG"
        ],
        "is_contributed": {
          "value": false,
          "justification": "RNNG is an existing model leveraged in the study.",
          "quote": "we choose the recurrent neural network grammar (RNNG; Dyer et al., 2016) with an unsupervised self-training procedure (URNNG; Kim et al., 2019b)"
        },
        "is_executed": {
          "value": true,
          "justification": "The RNNG model is used in experiments as part of the distillation process.",
          "quote": "we choose the recurrent neural network grammar (RNNG; Dyer et al., 2016) with an unsupervised self-training procedure (URNNG; Kim et al., 2019b)"
        },
        "is_compared": {
          "value": true,
          "justification": "RNNG performance is evaluated and reported in the context of ensemble distillation.",
          "quote": "Then, we evaluate the distillation stage of our approach, which is based on Run 1 of each model."
        },
        "referenced_paper_title": {
          "value": "Recurrent neural network grammars",
          "justification": "The RNNG's referenced title is consistent with the original paper description.",
          "quote": "Dyer, Chris, et al. (2016). Recurrent neural network grammars."
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Penn Treebank (PTB)",
          "justification": "The Penn Treebank is utilized for evaluating the parsing models in experiments.",
          "quote": "We evaluated our ensemble method on the Penn Treebank (PTB; Marcus et al., 1993)"
        },
        "aliases": [
          "PTB"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "Building a large annotated corpus of English: The Penn Treebank",
          "justification": "The referenced paper provides the original description of the Penn Treebank dataset.",
          "quote": "Marcus, Mitchell P., et al. (1993). Building a large annotated corpus of English: The Penn Treebank."
        }
      },
      {
        "name": {
          "value": "SUSANNE",
          "justification": "The SUSANNE dataset is used for evaluation in a domain-shift setting.",
          "quote": "In addition, we used the SUSANNE dataset (Sampson, 2002) to evaluate model performance in a domain-shift setting."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "English for the computer: The SUSANNE corpus and analytic scheme",
          "justification": "This title corresponds with the description of the SUSANNE dataset used in the paper.",
          "quote": "Sampson, Geoffrey. (2002). English for the computer: The SUSANNE corpus and analytic scheme."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1918,
    "prompt_tokens": 17598,
    "total_tokens": 19516,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}