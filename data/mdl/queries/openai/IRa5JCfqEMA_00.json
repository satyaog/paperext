{
  "paper": "IRa5JCfqEMA.txt",
  "words": 13894,
  "extractions": {
    "title": {
      "value": "BLOCK CONTEXTUAL MDPs FOR CONTINUAL LEARNING",
      "justification": "The title of the paper explicitly stated at the beginning of the document is 'B LOCK C ONTEXTUAL MDP S FOR C ONTINUAL L EARNING'.",
      "quote": "B LOCK C ONTEXTUAL MDP S FOR C ONTINUAL L EARNING"
    },
    "description": "This paper introduces a novel framework called Block Contextual MDP (BC-MDP) for addressing nonstationarity in reinforcement learning. The framework allows for modeling complex environments with changing dynamics and rewards, leveraging Lipschitz continuity to ensure generalization. The authors propose an algorithm named ZeUS for zero-shot adaptation to these continual environments and demonstrate its effectiveness through both theoretical bounds and empirical experiments.",
    "type": {
      "value": "theoretical",
      "justification": "The paper includes theoretical contributions such as the proposal of a new framework (BC-MDP), theoretical bounds on adaptation and generalization, and proofs of concept for the introduced ideas.",
      "quote": "We propose a representation learning algorithm to enable the use of the current RL algorithms (that rely on the prototypical MDP setting) in nonstationary environments. It works by constructing a context space that is Lipschitz with respect to the changes in dynamics and reward of the nonstationary environment. We show, both theoretically and empirically, that the trained agent generalizes well to unseen contexts."
    },
    "primary_research_field": {
      "name": {
        "value": "Reinforcement Learning",
        "justification": "The entire paper revolves around addressing challenges in reinforcement learning settings, specifically focusing on the nonstationary and continual learning aspects.",
        "quote": "In reinforcement learning (RL), when defining a Markov Decision Process (MDP), the environment dynamics is implicitly assumed to be stationary."
      },
      "aliases": [
        "RL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Continual Learning",
          "justification": "The paper discusses the continual reinforcement learning scenario, focusing on adaptation over sequences of tasks.",
          "quote": "In the continual reinforcement learning scenario, the sequence of tasks is another source of nonstationarity."
        },
        "aliases": [
          "Continual RL"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "ZeUS",
          "justification": "ZeUS is introduced as a novel algorithm in the paper for handling nonstationarity and performing zero-shot adaptation.",
          "quote": "We refer to our proposed method as Zero-shot adaptation to Unknown Systems (ZeUS)."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "ZeUS is proposed by the authors as a contribution to handle nonstationary environments in the context of their BC-MDP framework.",
          "quote": "We refer to our proposed method as Zero-shot adaptation to Unknown Systems (ZeUS)."
        },
        "is_executed": {
          "value": true,
          "justification": "The paper mentions empirical experiments which verify the effectiveness of the ZeUS algorithm, indicating it was executed during the research.",
          "quote": "We empirically verify the effectiveness of ZeUS..."
        },
        "is_compared": {
          "value": true,
          "justification": "ZeUS is compared to other methods and baselines in various experiments as described in the paper's experimental results section.",
          "quote": "In Figure 3, we compare ZeUSâ€™s performance with the baselines when the reward function varies across tasks."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no specific reference paper title given for ZeUS as it is introduced in this paper.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "The paper explicitly mentions using PyTorch for implementing algorithms used in the research.",
          "quote": "All the algorithms are implemented using PyTorch (Paszke et al., 2017)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Automatic differentiation in pytorch",
          "justification": "The PyTorch library is referenced in the context of implementation and is acknowledged with its reference paper.",
          "quote": "All the algorithms are implemented using PyTorch (Paszke et al., 2017)."
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 807,
    "prompt_tokens": 25241,
    "total_tokens": 26048,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}