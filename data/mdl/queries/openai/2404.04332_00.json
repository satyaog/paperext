{
  "paper": "2404.04332.txt",
  "words": 9338,
  "extractions": {
    "title": {
      "value": "Scope Ambiguities in Large Language Models",
      "justification": "The title of the paper is directly mentioned at the beginning of the provided text.",
      "quote": "Scope Ambiguities in Large Language Models Gaurav Kamathα,β Sebastian Schusterγ Sowmya Vajjalaδ Siva Reddyα,β,ϵ α"
    },
    "description": "The paper investigates how large language models handle sentences with scope ambiguities by comparing different versions of autoregressive language models to human judgments. It introduces new datasets and finds that some models align well with human-preferred interpretations.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves experiments and analysis of models' performance, indicating empirical research.",
      "quote": "we investigate how different versions of certain autoregressive language models—GPT2, GPT-3/3.5, Llama 2 and GPT-4—treat scope ambiguous sentences, and compare this with human judgments."
    },
    "primary_research_field": {
      "name": {
        "value": "Natural Language Processing",
        "justification": "The research involves how language models process sentences, a key area within NLP.",
        "quote": "Despite this, there has been little research into how modern large language models treat them. In this paper, we investigate how different versions of certain autoregressive language models—GPT2, GPT-3/3.5, Llama 2 and GPT-4—treat scope ambiguous sentences."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Linguistic Semantics",
          "justification": "The focus on scope ambiguities in semantic interpretation aligns with linguistic semantics.",
          "quote": "These ambiguities offer rich insights into the interaction between semantic structure and world knowledge in language processing."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "GPT-2",
          "justification": "GPT-2 is explicitly mentioned as one of the models studied for handling scope ambiguities.",
          "quote": "we investigate how different versions of certain autoregressive language models—GPT2, GPT-3/3.5, Llama 2 and GPT-4—treat scope ambiguous sentences."
        },
        "aliases": [
          "GPT2"
        ],
        "is_contributed": {
          "value": false,
          "justification": "GPT-2 is used as a model in experiments, rather than being a newly contributed model.",
          "quote": "we investigate how different versions of certain autoregressive language models—GPT2, GPT-3/3.5, Llama 2 and GPT-4—treat scope ambiguous sentences."
        },
        "is_executed": {
          "value": true,
          "justification": "The model is executed as part of the experiments to assess its responses to ambiguous sentences.",
          "quote": "we investigate how different versions of certain autoregressive language models—GPT2, GPT-3/3.5, Llama 2 and GPT-4—treat scope ambiguous sentences."
        },
        "is_compared": {
          "value": true,
          "justification": "The study involves comparing GPT-2's performance to other models and human judgments.",
          "quote": "we investigate how different versions of certain autoregressive language models—GPT2, GPT-3/3.5, Llama 2 and GPT-4—treat scope ambiguous sentences, and compare this with human judgments."
        },
        "referenced_paper_title": {
          "value": "Language models are unsupervised multitask learners",
          "justification": "The model GPT-2 is associated with the referenced paper title as per common knowledge.",
          "quote": "GPT-2 (Radford et al., 2019)"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "AnderBois et al. 2012 Dataset",
          "justification": "The dataset by AnderBois et al. 2012 is directly referenced as a starting point for data in the study.",
          "quote": "We build upon the quantifier scope dataset presented by AnderBois et al. (2012)."
        },
        "aliases": [],
        "role": "referenced",
        "referenced_paper_title": {
          "value": "The pragmatics of quantifier scope: A corpus study",
          "justification": "The referenced title corresponds to the dataset cited in the study.",
          "quote": "We build upon the quantifier scope dataset presented by AnderBois et al. (2012)."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 841,
    "prompt_tokens": 16417,
    "total_tokens": 17258,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}