{
  "paper": "2206.04270.txt",
  "words": 17472,
  "extractions": {
    "title": {
      "value": "A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis",
      "justification": "Extracted from the title of the paper.",
      "quote": "A G ENERAL F RAMEWORK F OR P ROVING T HE E QUIVARIANT S TRONG L OTTERY T ICKET H YPOTHESIS"
    },
    "description": "The paper explores the Strong Lottery Ticket Hypothesis (SLTH) in the context of equivariant networks, proving that any G-equivariant network can be approximated by a pruned overparameterized G-equivariant network. It provides optimal overparameterization strategies and validates the theories with experimental results.",
    "type": {
      "value": "theoretical",
      "justification": "The paper primarily presents theoretical results and proofs, focusing on the Strong Lottery Ticket Hypothesis for equivariant networks.",
      "quote": "In this paper, we develop a unifying framework to study and prove the existence of strong lottery tickets (SLTs) for general equivariant networks."
    },
    "primary_research_field": {
      "name": {
        "value": "Theoretical Machine Learning",
        "justification": "The research is focused on theoretical aspects of machine learning, such as hypothesis proof and mathematical optimization strategies.",
        "quote": "In this paper, we develop a unifying framework to study and prove the existence of strong lottery tickets (SLTs) for general equivariant networks."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Deep Learning Theory",
          "justification": "The paper provides theoretical insights specifically for deep learning models and their parameterization.",
          "quote": "We further prove that our prescribed overparameterization scheme is optimal and provides a lower bound on the number of effective parameters as a function of the error tolerance."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Equivariant Neural Networks",
          "justification": "The paper discusses G-equivariant networks and presents proofs related to their structure and capabilities.",
          "quote": "we generalize the SLTH to functions that preserve the action of the group G—i.e. G-equivariant network."
        },
        "aliases": [
          "G-equivariant networks"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "G-CNNs",
          "justification": "The paper references G-CNNs as a type of network that the theory can be applied to.",
          "quote": "Recent works by da Cunha et al. (2022b); Burkholz (2022a) demonstrate that the SLTH can be extended to translation equivariant networks—i.e. CNNs."
        },
        "aliases": [
          "G-equivariant CNNs",
          "translation equivariant networks"
        ],
        "is_contributed": {
          "value": 0,
          "justification": "The paper does not claim to have developed G-CNNs, but rather utilizes them for proving the SLTH.",
          "quote": "Recent works by da Cunha et al. (2022b); Burkholz (2022a) demonstrate that the SLTH can be extended to translation equivariant networks—i.e. CNNs."
        },
        "is_executed": {
          "value": 1,
          "justification": "The experiments in the paper were conducted on G-CNNs to validate the theory.",
          "quote": "Empirically, we verify our theory by pruning overparametrized E(2)-steerable CNNs, k-order GNNs, and message passing GNNs to match the performance of trained target networks."
        },
        "is_compared": {
          "value": 1,
          "justification": "Compared with other models like E(2)-steerable CNNs, k-order GNNs to validate the theory.",
          "quote": "Empirically, we verify our theory by pruning overparametrized E(2)-steerable CNNs, k-order GNNs, and message passing GNNs to match the performance of trained target networks."
        },
        "referenced_paper_title": {
          "value": "Proving the Strong Lottery Ticket Hypothesis for Convolutional Neural Networks",
          "justification": "This referenced paper focuses on CNNs and the SLTH, which is built upon in this paper.",
          "quote": "Proving the Strong Lottery Ticket Hypothesis for Convolutional Neural Networks"
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "RotMNIST",
          "justification": "The dataset is explicitly named as one of the benchmarks for evaluating E(2)-steerable CNNs.",
          "quote": "For E(2)-steerable, we experiment with Rotation and Flip-Rotation MNIST datasets which contain data augmentations from G ≤ SO(2)."
        },
        "aliases": [
          "Rotation MNIST"
        ],
        "role": "used",
        "referenced_paper_title": {
          "value": "General E(2)-equivariant Steerable CNNs",
          "justification": "This paper by Weiler and Cesa (2019) discusses E(2)-equivariant steerable CNNs which directly connects to the dataset's usage.",
          "quote": "General E(2)-equivariant Steerable CNNs"
        }
      }
    ],
    "libraries": [
      {
        "name": {
          "value": "PyTorch",
          "justification": "Common deep learning library likely used in implementing models and experiments described in the paper.",
          "quote": "Full details on our experimental setup, including hyperparameters choices, architectures, and the exact SUBSET-SUM problem being solved for pruning in Appendix G."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "Not applicable as no reference paper is explicitly stated for PyTorch.",
          "quote": ""
        }
      }
    ]
  },
  "usage": {
    "completion_tokens": 1060,
    "prompt_tokens": 31717,
    "total_tokens": 32777
  }
}