{
  "paper": "d88eadb0c7fac982d66c20a3741d078f.txt",
  "words": 11965,
  "extractions": {
    "title": {
      "value": "Scalable Hierarchical Self-Attention with Learnable Hierarchy for Long-Range Interactions",
      "justification": "This is the main title on the first page of the document, denoting the publication and topic of the research.",
      "quote": "Scalable Hierarchical Self-Attention with Learnable Hierarchy for Long-Range Interactions"
    },
    "description": "The paper proposes a model named Sequoia which introduces an efficient hierarchical self-attention scheme to handle long-range interactions in graphs and sequences. It aims to reduce computational complexity while maintaining performance compared to traditional transformers. Sequoia features an adaptive hierarchical clustering mechanism to optimize attention processes, demonstrating state-of-the-art or competitive results across various benchmarks.",
    "type": {
      "value": "empirical",
      "justification": "The paper provides empirical results from experiments on various datasets demonstrating the efficacy of the proposed model, Sequoia.",
      "quote": "Experimentally, we report state-of-the-art performance on long-range graph benchmarks while remaining computationally efficient."
    },
    "primary_research_field": {
      "name": {
        "value": "Deep Learning",
        "justification": "The research revolves around developing and evaluating a novel deep learning model (Sequoia) for enhanced performance on graphs and sequences.",
        "quote": "Our proposed model Sequoia provides a powerful inductive bias toward long-range interaction modeling, leading to better generalization."
      },
      "aliases": [
        "DL"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Graph Neural Networks",
          "justification": "The primary focus of the study is on modeling graph-structured data and improving graph neural networks using hierarchical attention.",
          "quote": "Self-attention models have made great strides toward accurately modeling a wide array of data modalities, including, more recently, graph-structured data."
        },
        "aliases": [
          "GNN"
        ]
      },
      {
        "name": {
          "value": "Sequence Modeling",
          "justification": "The paper evaluates the proposed model on sequence modeling tasks, indicating a significant emphasis on this subfield.",
          "quote": "Moving beyond graphs, we also display competitive performance on long-range sequence modeling."
        },
        "aliases": []
      }
    ],
    "models": [
      {
        "name": {
          "value": "Sequoia",
          "justification": "Sequoia is the primary model introduced in this paper, focusing on adaptive hierarchical attention mechanisms.",
          "quote": "Our model Sequoia decreases the computational cost by exploiting an adaptive task-informed hierarchical clustering of the graph."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "Sequoia is a novel contribution by the authors as indicated by them describing it as 'our proposed model'.",
          "quote": "Our proposed model Sequoia provides a powerful inductive bias toward long-range interaction modeling, leading to better generalization."
        },
        "is_executed": {
          "value": true,
          "justification": "Experiments are conducted using the Sequoia model as part of the empirical validation in the study.",
          "quote": "Experimentally, we report state-of-the-art performance on long-range graph benchmarks while remaining computationally efficient."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares the performance of Sequoia against other models across various benchmarks to demonstrate its effectiveness.",
          "quote": "Our model consistently outperforms other models in the benchmarks presented above."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No specific previous paper on Sequoia is referenced, as it is likely a novel contribution of this study.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "Long Range Graph Benchmark (LRGB)",
          "justification": "The LRGB is used to assess the performance of the Sequoia model on graph data.",
          "quote": "LRGB (Dwivedi et al., 2022c) is a long-range graph benchmark that is built on peptides and images."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Long range graph benchmark",
          "justification": "The dataset is originally introduced in 'Long range graph benchmark' by Dwivedi et al., 2022.",
          "quote": "LRGB (Dwivedi et al., 2022c) is a long-range graph benchmark that is built on peptides and images."
        }
      },
      {
        "name": {
          "value": "Polymer",
          "justification": "This dataset is used for evaluating the Sequoia model on molecular property prediction.",
          "quote": "Polymer (St. John et al., 2019) contains 54,000 molecules associated to polymer properties."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Message-passing neural networks for high-throughput polymer screening",
          "justification": "The dataset was introduced in the paper 'Message-passing neural networks for high-throughput polymer screening' by St. John et al., 2019.",
          "quote": "Polymer (St. John et al., 2019) contains 54,000 molecules associated to polymer properties."
        }
      },
      {
        "name": {
          "value": "Citation networks",
          "justification": "This dataset is employed to test Sequoia's performance on citation graphs, typical in benchmark analysis.",
          "quote": "Citation networks (Sen et al., 2008) is a benchmark comprising 3 subdatasets named Cora, Citeseer, and Pubmed."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Collective classification in network data",
          "justification": "The well-known Citation networks dataset is introduced in 'Collective classification in network data' by Sen et al., 2008.",
          "quote": "Citation networks (Sen et al., 2008) is a benchmark comprising 3 subdatasets named Cora, Citeseer, and Pubmed."
        }
      },
      {
        "name": {
          "value": "Long Range Arena (LRA)",
          "justification": "The LRA is used for sequence modeling tasks to evaluate the Sequoia.",
          "quote": "We evaluate Sequoia on Long Range Arena (Tay et al., 2020b) (sequence classification on multiple input modalities) to demonstrate the effectiveness of our model."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Long Range Arena: A Benchmark for Efficient Transformers",
          "justification": "The LRA dataset was introduced in the paper 'Long Range Arena: A Benchmark for Efficient Transformers' by Tay et al., 2020b.",
          "quote": "We evaluate Sequoia on Long Range Arena (Tay et al., 2020b) (sequence classification on multiple input modalities) to demonstrate the effectiveness of our model."
        }
      },
      {
        "name": {
          "value": "ModelNet40",
          "justification": "This dataset is utilized for 3D shape classification in assessing Sequoia's performance on point clouds.",
          "quote": "ModelNet40 (Wu et al., 2015) dataset is a classification dataset that contains 12,311 3D models categorised into 40 classes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "3D Shapenets: A Deep Representation for Volumetric Shapes",
          "justification": "ModelNet40 was introduced in the paper '3D Shapenets: A Deep Representation for Volumetric Shapes' by Wu et al., 2015.",
          "quote": "ModelNet40 (Wu et al., 2015) dataset is a classification dataset that contains 12,311 3D models categorised into 40 classes."
        }
      },
      {
        "name": {
          "value": "ShapeNetPart",
          "justification": "ShapeNetPart dataset is employed for segmentation tasks as part of the point cloud experiments.",
          "quote": "ShapeNetPart (Mo et al., 2019) dataset is a part segmentation dataset, which contains 16,881 synthetic point clouds from 16 classes."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding",
          "justification": "ShapeNetPart was introduced in 'PartNet: A Large-scale Benchmark for Fine-grained and Hierarchical Part-level 3D Object Understanding' by Mo et al., 2019.",
          "quote": "ShapeNetPart (Mo et al., 2019) dataset is a part segmentation dataset, which contains 16,881 synthetic point clouds from 16 classes."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1625,
    "prompt_tokens": 23632,
    "total_tokens": 25257,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}