{
  "paper": "2304.11737.txt",
  "words": 14039,
  "extractions": {
    "title": {
      "value": "Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features",
      "justification": "The title is taken from the beginning of the research paper.",
      "quote": "Sarah Frank-Wolfe: Methods for Constrained Optimization with Best Rates and Practical Features"
    },
    "description": "The paper presents two new variants of the Frank-Wolfe algorithms for stochastic finite-sum minimization with better convergence guarantees for both convex and non-convex objective functions. The algorithms do not require computing full gradients or large batches, making them more efficient for large datasets.",
    "type": {
      "value": "theoretical",
      "justification": "The paper primarily focuses on developing and analyzing the theoretical aspects of new optimization algorithms.",
      "quote": "In this paper, we present two new variants of the FW algorithms for stochastic finite-sum minimization. Our algorithms have the best convergence guarantees of existing stochastic FW approaches for both convex and non-convex objective functions."
    },
    "primary_research_field": {
      "name": {
        "value": "Optimization",
        "justification": "The paper focuses on optimization algorithms, specifically variants of the Frank-Wolfe method.",
        "quote": "The Frank-Wolfe (FW) method is a popular approach for solving optimization problems with structured constraints that arise in machine learning applications."
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Machine Learning",
          "justification": "The applications mentioned for the optimization algorithms include machine learning models such as regressions, support vector machines, and neural networks.",
          "quote": "Empirical risk minimization is a cornerstone for training supervised machine learning models such as various regressions, support vector machine, and neural networks."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Stochastic Optimization",
          "justification": "The paper specifically deals with stochastic versions of the Frank-Wolfe algorithm and their applications in optimization.",
          "quote": "In recent years, stochastic versions of FW have gained popularity, motivated by large datasets for which the computation of the full gradient is prohibitively expensive."
        },
        "aliases": []
      }
    ],
    "models": [],
    "datasets": [
      {
        "name": {
          "value": "LibSVM",
          "justification": "The experiments conducted in the paper use LibSVM datasets.",
          "quote": "We take LibSVM [Chang and Lin, 2011] datasets (see Table 2)."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "Libsvm: a library for support vector machines",
          "justification": "This is the referenced paper for the LibSVM datasets used in the experiments.",
          "quote": "We take LibSVM [Chang and Lin, 2011] datasets (see Table 2)."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 655,
    "prompt_tokens": 27035,
    "total_tokens": 27690
  }
}