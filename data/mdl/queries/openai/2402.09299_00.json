{
  "paper": "2402.09299.txt",
  "words": 16612,
  "extractions": {
    "title": {
      "value": "Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code",
      "justification": "The title clearly reflects the focus of the research, which is on detecting code inclusion in language models trained on code.",
      "quote": "Vahid Majdinasab, Amin Nikanjam, and Foutse Khomh. 2023. Trained Without My Consent: Detecting Code Inclusion In Language Models Trained on Code."
    },
    "description": "This paper presents TraWiC, a new approach to detect whether specific code was included in the training dataset of a Large Language Model (LLM). The authors compare TraWiC to traditional code clone detection approaches and highlight its efficiency and accuracy in detecting dataset inclusion, especially in light of code auditing challenges posed by LLMs.",
    "type": {
      "value": "empirical",
      "justification": "The study conducts experiments and compares the TraWiC method with existing methods, using empirical data for validation.",
      "quote": "To evaluate our approach, we constructed a large dataset of projects which were used to train an LLM. This dataset will act as the ground truth for inclusion detection and is comprised of over 9400 code files from 263 projects."
    },
    "primary_research_field": {
      "name": {
        "value": "Software Engineering",
        "justification": "The research focuses on challenges within software engineering, particularly related to code auditing in the context of LLMs.",
        "quote": "The recent advent of Large Language Models (LLMs) as coding assistants in the software development process poses new challenges for code auditing."
      },
      "aliases": [
        "SE"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Natural Language Processing",
          "justification": "The paper deals with Large Language Models which are a significant topic in Natural Language Processing.",
          "quote": "A significant development in ML is the recent rise of Large Language Models (LLM) which are now being used for various Software Engineering (SE) tasks."
        },
        "aliases": [
          "NLP"
        ]
      },
      {
        "name": {
          "value": "Machine Learning",
          "justification": "The paper involves using machine learning techniques to evaluate LLMs for code inclusion detection.",
          "quote": "Machine Learning (ML) models have been used in various industrial sectors ranging from healthcare to finance."
        },
        "aliases": [
          "ML"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "TraWiC",
          "justification": "TraWiC is the primary model introduced by the paper for detecting code inclusion in LLMs.",
          "quote": "To address this challenge, we propose a new approach, TraWiC; a model-agnostic and interpretable method based on membership inference for detecting code inclusion in an LLMâ€™s training dataset."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "TraWiC is proposed as a new methodology introduced by the authors as a contribution to the research field.",
          "quote": "We propose a model-agnostic, interpretable, and efficient approach for dataset inclusion detection for LLMs."
        },
        "is_executed": {
          "value": true,
          "justification": "TraWiC is evaluated using a large dataset and is executed for experiments.",
          "quote": "To evaluate our approach, we constructed a large dataset of projects which were used to train an LLM."
        },
        "is_compared": {
          "value": true,
          "justification": "TraWiC is numerically compared to other models like NiCad in terms of dataset inclusion detection accuracy.",
          "quote": "In our experiments, we observe that TraWiC is capable of detecting 83.87% of codes that were used to train an LLM. In comparison, the prevalent clone detection tool NiCad is only capable of detecting 47.64%."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "There is no specific reference to a prior paper for the TraWiC model since it is a novel contribution by the authors.",
          "quote": ""
        }
      }
    ],
    "datasets": [
      {
        "name": {
          "value": "TheStack",
          "justification": "TheStack is used as the reference dataset providing the training data for the LLM under study, SantaCoder.",
          "quote": "We selected TheStack. TheStack is a large dataset (3 terabytes) of code collected from GitHub by HuggingFace."
        },
        "aliases": [],
        "role": "used",
        "referenced_paper_title": {
          "value": "",
          "justification": "TheStack is referenced as a dataset created by HuggingFace, but no specific paper title is provided.",
          "quote": "TheStack is a large dataset (3 terabytes) of code collected from GitHub by HuggingFace2."
        }
      }
    ],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 893,
    "prompt_tokens": 28670,
    "total_tokens": 29563,
    "completion_tokens_details": {
      "accepted_prediction_tokens": null,
      "audio_tokens": 0,
      "reasoning_tokens": 0,
      "rejected_prediction_tokens": null
    },
    "prompt_tokens_details": {
      "audio_tokens": 0,
      "cached_tokens": 1152
    }
  }
}