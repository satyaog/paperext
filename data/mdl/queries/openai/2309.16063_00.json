{
  "paper": "2309.16063.txt",
  "words": 4645,
  "extractions": {
    "title": {
      "value": "Time Delay Cosmography with a Neural Ratio Estimator",
      "justification": "This is the title of the paper.",
      "quote": "Time Delay Cosmography with a Neural Ratio Estimator"
    },
    "description": "The paper explores the use of a Neural Ratio Estimator (NRE) to determine the Hubble constant (H0) in the context of time delay cosmography. The authors simulate various astronomical measurements and train the NRE to output the posterior distribution of H0. The NRE's performance is compared to traditional likelihood-based methods, showing similar accuracy and precision while being significantly faster.",
    "type": {
      "value": "empirical",
      "justification": "The paper involves empirical experiments and simulations to train Neural Ratio Estimators (NRE) and compares its results to traditional methods.",
      "quote": "We explore the use of a Neural Ratio Estimator (NRE) to determine the Hubble constant (H0 ) in the context of time delay cosmography.... Results are presented in section 5."
    },
    "primary_research_field": {
      "name": {
        "value": "Astrophysics",
        "justification": "The primary focus of the paper is on determining the Hubble constant (H0), which falls under the domain of Astrophysics.",
        "quote": "Time delay cosmography can provide an independent measurement of H0 with different systematics from existing methods."
      },
      "aliases": [
        "Astro"
      ]
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "Simulation-based Inference",
          "justification": "The paper discusses the simulation-based inference (SBI) framework and implements a Neural Ratio Estimator which falls under this sub-field.",
          "quote": "The simulation-based inference (SBI) framework allows handling complex, high-dimensional data and models that are difficult or intractable to analyze using traditional likelihood-based methods by only relying on the availability of a realistic simulation pipeline."
        },
        "aliases": []
      },
      {
        "name": {
          "value": "Machine Learning for Astrophysics",
          "justification": "The paper focuses on applying a Neural Ratio Estimator, a machine learning model, to solve problems in astrophysics.",
          "quote": "We explore the use of a Neural Ratio Estimator (NRE) to determine the Hubble constant (H0 ) in the context of time delay cosmography."
        },
        "aliases": [
          "ML for Astrophysics"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Neural Ratio Estimator",
          "justification": "The primary model discussed and used in the paper is the Neural Ratio Estimator (NRE).",
          "quote": "We explore the use of a Neural Ratio Estimator (NRE) to determine the Hubble constant (H0 ) in the context of time delay cosmography."
        },
        "aliases": [
          "NRE"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The main contribution of the paper is the application and analysis of the Neural Ratio Estimator.",
          "quote": "We explore the use of a Neural Ratio Estimator (NRE) to determine the Hubble constant (H0 ) in the context of time delay cosmography."
        },
        "is_executed": {
          "value": true,
          "justification": "The NRE model was executed as part of the study to infer Hubble's constant.",
          "quote": "We train the NRE to output the posterior distribution of H0 given the time delay measurements, the relative Fermat potentials (calculated from the modeled parameters and the measured image positions), the deflector redshift, and the source redshift."
        },
        "is_compared": {
          "value": true,
          "justification": "The results from the NRE were compared to those from traditional explicit likelihood methods.",
          "quote": "We compare the accuracy and precision of the NRE with traditional explicit likelihood methods in the limit where the latter is tractable and reliable."
        },
        "referenced_paper_title": {
          "value": "Approximating Likelihood Ratios with Calibrated Discriminative Classifiers",
          "justification": "This is a key paper referenced for Neural Ratio Estimators.",
          "quote": "Neural Ratio Estimators (NREs; Cranmer et al. 2015), a specific class of SBI methods"
        }
      },
      {
        "name": {
          "value": "Set Transformer",
          "justification": "The paper employs the Set Transformer architecture for the Neural Ratio Estimator (NRE).",
          "quote": "We use a Set Transformer architecture (Lee et al., 2019), which allows for the amortization over lensing systems with two or four lensed images by the same model."
        },
        "aliases": [],
        "is_contributed": {
          "value": false,
          "justification": "The Set Transformer is not a new contribution of this paper but a referenced architecture.",
          "quote": "We use a Set Transformer architecture (Lee et al., 2019), which allows for the amortization over lensing systems with two or four lensed images by the same model."
        },
        "is_executed": {
          "value": true,
          "justification": "The Set Transformer architecture was used to implement the Neural Ratio Estimator.",
          "quote": "We use a Set Transformer architecture (Lee et al., 2019), which allows for the amortization over lensing systems with two or four lensed images by the same model."
        },
        "is_compared": {
          "value": false,
          "justification": "The Set Transformer is not compared with other architectures in this paper.",
          "quote": "We use a Set Transformer architecture (Lee et al., 2019), which allows for the amortization over lensing systems with two or four lensed images by the same model."
        },
        "referenced_paper_title": {
          "value": "Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks",
          "justification": "This is the referenced paper for the Set Transformer architecture.",
          "quote": "We use a Set Transformer architecture (Lee et al., 2019)..."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "completion_tokens": 1386,
    "prompt_tokens": 9544,
    "total_tokens": 10930
  }
}