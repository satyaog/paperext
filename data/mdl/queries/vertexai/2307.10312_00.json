{
  "paper": "2307.10312.txt",
  "words": 16170,
  "extractions": {
    "title": {
      "value": "Beyond the ML Model: Applying Safety Engineering Frameworks to Text-to-Image Development",
      "justification": "This is the paper's title.",
      "quote": "Beyond the ML Model: Applying Safety Engineering Frameworks to Text-to-Image Development"
    },
    "description": "The paper discusses the application of safety engineering frameworks, specifically FMEA and STPA, to the development and deployment of text-to-image (T2I) models. The authors conducted a case study involving the use of T2I models by professional visual artists in their creative practice. The study aimed to identify potential social and ethical risks associated with these models at three stages of the ML product development pipeline: data processing, integration of a T2I model with other models, and use. The authors argue that safety engineering frameworks can be valuable tools for identifying and mitigating social and ethical risks in ML systems, even if these frameworks were not originally designed for this purpose.",
    "type": {
      "value": "empirical",
      "justification": "The authors conducted a case study, which is an empirical research method.",
      "quote": "We use a case study approach to explore our two research questions described in Section 1 for the following reasons [65]."
    },
    "primary_research_field": {
      "name": {
        "value": "Art Creation",
        "justification": "The paper focuses on the use of T2I models in the context of art creation.",
        "quote": "To illustrate, we conducted FMEA and STPA on a case study involving real-world users of a text-to-image (T2I) model user interface by professional visual artists in their creative practice."
      },
      "aliases": [
        "art creation",
        "creative practice"
      ]
    },
    "sub_research_fields": [],
    "models": [
      {
        "name": {
          "value": "Text-to-Image Model",
          "justification": "The paper focuses on text-to-image models in general.",
          "quote": "We focus on the application of FMEA and STPA at three stages of the ML development and deployment pipeline: (1) data processing for creating a training dataset, (2) integration of one ML model with other ML or non-ML algorithms in an ML-product, and (3) end use of the ML product. To illustrate, we conducted FMEA and STPA on a case study involving real-world users of a text-to-image (T2I) model user interface by professional visual artists in their creative practice."
        },
        "aliases": [
          "T2I",
          "text-to-image"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to a new text-to-image model.",
          "quote": "The analysis is solely illustrative and it captures a point-in-time snapshot and potential configuration of the development and deployment for the chosen ML application."
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute a specific T2I model.",
          "quote": "The analysis is solely illustrative and it captures a point-in-time snapshot and potential configuration of the development and deployment for the chosen ML application."
        },
        "is_compared": {
          "value": false,
          "justification": "The paper doesn't compare different T2I models.",
          "quote": "The analysis is solely illustrative and it captures a point-in-time snapshot and potential configuration of the development and deployment for the chosen ML application."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper doesn't reference a specific paper for this model.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "DALL-E",
          "justification": "DALL-E is the name of the model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "aliases": [
          "DALL-E"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to DALL-E.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute DALL-E.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "DALL-E is mentioned as an example of a T2I model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper references the DALL-E paper.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Parti",
          "justification": "Parti is the name of the model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "aliases": [
          "Parti"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to Parti.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute Parti.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "Parti is mentioned as an example of a T2I model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper references the Parti paper.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Stable Diffusion",
          "justification": "Stable Diffusion is the name of the model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "aliases": [
          "Stable Diffusion"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to Stable Diffusion.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute Stable Diffusion.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "Stable Diffusion is mentioned as an example of a T2I model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper references the Stable Diffusion paper.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Imagen",
          "justification": "Imagen is the name of the model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "aliases": [
          "Imagen"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to Imagen.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute Imagen.",
          "quote": ""
        },
        "is_compared": {
          "value": true,
          "justification": "Imagen is mentioned as an example of a T2I model.",
          "quote": "Such models, including DALL-E [58], Parti [84], Stable Diffusion [19], and Imagen [68] are generative T2I models."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper references the Imagen paper.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Input Prompt Classifier",
          "justification": "This is the name mentioned in the paper.",
          "quote": "From our interviews with T2I developers and existing literature [54, 64], we identified demos often include at least three types of models: (1) an input prompt classifier (which either block or filter the text prompt), (2) the T2I model, and (3) output image classifiers (which either block or filter the generated image)."
        },
        "aliases": [
          "input prompt classifier"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to the input prompt classifier.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute the input prompt classifier.",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "The input prompt classifier is mentioned as part of T2I demos, but not compared.",
          "quote": "From our interviews with T2I developers and existing literature [54, 64], we identified demos often include at least three types of models: (1) an input prompt classifier (which either block or filter the text prompt), (2) the T2I model, and (3) output image classifiers (which either block or filter the generated image)."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper doesn't reference a specific paper for this model.",
          "quote": ""
        }
      },
      {
        "name": {
          "value": "Output Image Classifier",
          "justification": "This is the name mentioned in the paper.",
          "quote": "From our interviews with T2I developers and existing literature [54, 64], we identified demos often include at least three types of models: (1) an input prompt classifier (which either block or filter the text prompt), (2) the T2I model, and (3) output image classifiers (which either block or filter the generated image)."
        },
        "aliases": [
          "output image classifiers"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The paper doesn't contribute to the output image classifier.",
          "quote": ""
        },
        "is_executed": {
          "value": false,
          "justification": "The paper doesn't execute the output image classifier.",
          "quote": ""
        },
        "is_compared": {
          "value": false,
          "justification": "The output image classifier is mentioned as part of T2I demos, but not compared.",
          "quote": "From our interviews with T2I developers and existing literature [54, 64], we identified demos often include at least three types of models: (1) an input prompt classifier (which either block or filter the text prompt), (2) the T2I model, and (3) output image classifiers (which either block or filter the generated image)."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper doesn't reference a specific paper for this model.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 27360
  }
}