{
  "paper": "1910.08650.txt",
  "words": 7405,
  "extractions": {
    "title": {
      "value": "Toward Metrics for Differentiating Out-of-Distribution Sets",
      "justification": "The title of the paper is extracted from the provided text.",
      "quote": "Toward Metrics for Differentiating Out-of-Distribution Sets"
    },
    "description": "The paper proposes a method for differentiating between out-of-distribution (OOD) sets for selecting the most effective one(s) that induce training calibrated CNNs with high detection rates on unseen OOD sets. The authors propose three novel computationally-efficient metrics for differentiating between OOD sets according to their “protection” level of in-distribution sub-manifolds. They empirically verify that the most protective OOD sets – selected according to their metrics – lead to A-CNNs with significantly lower generalization errors than the A-CNNs trained on the least protective ones. They also empirically show the effectiveness of a protective OOD set for training well-generalized confidence-calibrated vanilla CNNs.",
    "type": {
      "value": "empirical",
      "justification": "The paper proposes new metrics and conducts empirical evaluations, indicating an empirical approach.",
      "quote": "We empirically verify that the most protective OOD sets – selected according to our metrics – lead to A-CNNs with significantly lower generalization errors than the A-CNNs trained on the least protective ones."
    },
    "primary_research_field": {
      "name": {
        "value": "Out-of-Distribution Detection",
        "justification": "The main research area is Out-of-Distribution Detection",
        "quote": "Vanilla CNNs, as uncalibrated classifiers, suffer from classifying out-of-distribution (OOD) samples nearly as confidently as in-distribution samples. To tackle this challenge,\\nsome recent works have demonstrated the gains of leveraging available OOD sets for training end-to-end calibrated CNNs."
      },
      "aliases": [
        "OOD Detection"
      ]
    },
    "sub_research_fields": [],
    "models": [
      {
        "name": {
          "value": "A-CNN",
          "justification": "The paper refers to the model as A-CNN.",
          "quote": "Besides the confidence-calibrated vanilla CNN [24, 15, 19]\\nas end-to-end model for OOD detection task, the classical idea of adding an explicit rejection class [1, 2, 6, 11] is also an interesting end-to-end approach. Indeed, such augmented classifiers can directly reject OOD samples by classifying them to the extra class, while correctly classifying in-distribution samples. In addition to the calibrated vanilla CNN, we exploit A-CNN as an end-to-end model for OOD detection task."
        },
        "aliases": [
          "A-CNN",
          "Augmented-CNN"
        ],
        "is_contributed": {
          "value": false,
          "justification": "The authors use A-CNN as a model for OOD detection, which is an existing model.",
          "quote": "In addition to the calibrated vanilla CNN, we exploit A-CNN as an end-to-end model for OOD detection task."
        },
        "is_executed": {
          "value": true,
          "justification": "The authors train and evaluate A-CNNs on various datasets.",
          "quote": "In an extensive series of experiments on image and audio classification tasks, we empirically show that A-CNNs and calibrated vanilla CNNs trained on the most protective OOD set have higher detection rates (lower generalization error) on unseen OOD sets in comparison with those trained on the least protective OOD set."
        },
        "is_compared": {
          "value": true,
          "justification": "The authors compare A-CNN with vanilla CNNs.",
          "quote": "These results confirm that 1) all OOD sets are not equally effective for training well-performing end-to-end models (i.e., A-CNNs and calibrated CNNs) for OOD detection tasks and 2) the protection level of OOD sets is a viable factor for recognizing the most effective one."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No referenced paper explicitly introduces A-CNN.",
          "quote": ""
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 14199
  }
}