{
  "paper": "1910.13249.txt",
  "words": 8469,
  "extractions": {
    "title": {
      "value": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and Experiments",
      "justification": "This is the title of the paper.",
      "quote": "Navigation Agents for the Visually Impaired: A Sidewalk Simulator and Experiments"
    },
    "description": "Millions of blind and visually-impaired (BVI) people navigate urban environments everyday, using smartphones for high-level path-planning and white canes or guide dogs for local information. However, many BVI people still struggle to travel to new places. In our endeavour to create a navigation assistant for the BVI, we found that existing Reinforcement Learning (RL) environments were unsuitable for the task. This work introduces SEVN, a sidewalk simulation environment and a neural network-based approach to creating a navigation agent. SEVN contains panoramic images with labels for house numbers, doors, and street name signs, and formulations for several navigation tasks. We study the performance of an RL algorithm (PPO) in this setting. Our policy model fuses multi-modal observations in the form of variable resolution images, visible text, and simulated GPS data to navigate to a goal door. We hope that this dataset, simulator, and experimental results will provide a foundation for further research into the creation of agents that can assist members of the BVI community with outdoor navigation.\\nKeywords: outdoor navigation, computer vision, reinforcement learning, dataset",
    "type": {
      "value": "empirical",
      "justification": "The paper presents a novel simulation environment and experimental results.",
      "quote": "We study the performance of an RL algorithm (PPO) in this setting."
    },
    "primary_research_field": {
      "name": {
        "value": "Navigation Assistance",
        "justification": "The paper focuses on developing a navigation agent for visually impaired people, which involves computer vision and reinforcement learning.",
        "quote": "Keywords: outdoor navigation, computer vision, reinforcement learning, dataset"
      },
      "aliases": [
        "Computer Vision",
        "Reinforcement Learning"
      ]
    },
    "sub_research_fields": [],
    "models": [
      {
        "name": {
          "value": "PPO",
          "justification": "The authors name the model \\\"PPO\\\" in the paper.",
          "quote": "To train our model, we chose the PPO algorithm for its reliability without hyperparameter search7."
        },
        "aliases": [],
        "is_contributed": {
          "value": true,
          "justification": "The authors contribute a multimodal fusion model based on PPO.",
          "quote": "Our policy model fuses multi-modal observations in the form of variable resolution images, visible text, and simulated GPS data to navigate to a goal door."
        },
        "is_executed": {
          "value": true,
          "justification": "The authors train their proposed model with PPO.",
          "quote": "To train our model, we chose the PPO algorithm for its reliability without hyperparameter search7."
        },
        "is_compared": {
          "value": true,
          "justification": "The authors study the performance of PPO in the paper.",
          "quote": "We study the performance of an RL algorithm (PPO) in this setting."
        },
        "referenced_paper_title": {
          "value": "Proximal policy optimization algorithms",
          "justification": "This paper is cited as the source for PPO.",
          "quote": "J. Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov. Proximal policy optimization algorithms. CoRR, 2017. URL http://arxiv.org/abs/1707.06347."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 14085
  }
}