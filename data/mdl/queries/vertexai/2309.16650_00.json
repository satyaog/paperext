{
  "paper": "2309.16650.txt",
  "words": 10191,
  "extractions": {
    "title": {
      "value": "ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning",
      "justification": "The title of the paper is extracted from the provided text.",
      "quote": "ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning"
    },
    "description": "The paper introduces ConceptGraphs, a novel method for creating open-vocabulary 3D scene graphs for robot perception and planning. ConceptGraphs leverages 2D foundation models and fuses their output to 3D using multiview association. The resulting representations can understand novel semantic classes without needing large 3D datasets or model fine-tuning. The authors demonstrate ConceptGraphs",
    "type": {
      "value": "empirical",
      "justification": "The paper presents a novel method for robot perception and planning, making it empirical in nature.",
      "quote": "We propose ConceptGraphs, a 3D scene representation method for robot perception and planning that satisfies all the above requirements."
    },
    "primary_research_field": {
      "name": {
        "value": "Robot Perception and Planning in 3D Environments",
        "justification": "The paper focuses on enabling robots to understand and plan in 3D scenes using the novel ConceptGraphs representation.",
        "quote": "In this work, we propose ConceptGraphs, an open-vocabulary graph-structured representation for 3D scenes. ConceptGraphs is built by leveraging 2D foundation models and fusing their output to 3D by multiview association."
      },
      "aliases": [
        "Robot Perception",
        "Robot Planning",
        "3D Scene Understanding"
      ]
    },
    "sub_research_fields": [],
    "models": [],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 17950
  }
}