{
  "paper": "2403.13086.txt",
  "words": 6513,
  "extractions": {
    "title": {
      "value": "Listenable Maps for Audio Classifiers",
      "justification": "The title of the paper is \\\"Listenable Maps for Audio Classifiers\\\".",
      "quote": "Listenable Maps for Audio Classifiers"
    },
    "description": "This research paper presents Listenable Maps for Audio Classifiers (L-MAC), a novel method designed to enhance the interpretability of audio classifiers that utilize inputs such as mel-spectrograms. L-MAC generates listenable explanations by employing a decoder on top of a pretrained audio classifier. This decoder produces binary masks which highlight important segments within the input audio, making it easier for humans to understand the basis of the classifier’s predictions. The decoder is trained with a loss function that aims to maximize the confidence of the classifier’s decision on the masked-in audio portion while minimizing the probability of the model output for the masked-out portion. The authors conducted evaluations on both in-domain and out-of-domain data, demonstrating that L-MAC consistently generates more faithful interpretations compared to several other gradient and masking-based methods. Additionally, a user study confirmed that users generally prefer the interpretations generated by L-MAC. The paper provides a detailed methodology for L-MAC, including its architecture, masking objective, and the generation of listenable explanations. The effectiveness of L-MAC is further validated through experiments on the ESC-50 dataset, covering both single-label and multi-label classification tasks. The authors also performed sanity checks, including the Remove-and-retrain (ROAR) test and the cascading randomization test, to confirm the reliability and robustness of L-MAC’s interpretations.",
    "type": {
      "value": "empirical",
      "justification": "The research presented is empirical in nature, as it involves experiments and evaluation of the proposed method.",
      "quote": "In our experiments, we evaluate the faithfulness and understandability of the generated interpretations."
    },
    "primary_research_field": {
      "name": {
        "value": "audio classification",
        "justification": "Based on the paper's title and content, the primary research field is audio classification within the broader area of audio processing.",
        "quote": "Listenable Maps for Audio Classifiers"
      },
      "aliases": []
    },
    "sub_research_fields": [
      {
        "name": {
          "value": "interpretability",
          "justification": "The paper focuses on improving the interpretability of audio classifiers, making it a key sub-research field.",
          "quote": "Explainable Machine Learning is a research area that aims to render the models transparent concerning their decision-making mechanisms."
        },
        "aliases": [
          "interpretability",
          "explainable machine learning"
        ]
      }
    ],
    "models": [
      {
        "name": {
          "value": "Listenable Maps for Audio Classifiers",
          "justification": "The authors name their novel method \\\"Listenable Maps for Audio Classifiers\\\", often abbreviated as \\\"L-MAC\\\".",
          "quote": "This paper contributes to this emerging field by introducing a novel method called Listenable Maps for Audio Classifiers (L-MAC)."
        },
        "aliases": [
          "L-MAC",
          "Listenable Maps for Audio Classifiers"
        ],
        "is_contributed": {
          "value": true,
          "justification": "The authors introduce L-MAC as a novel method for generating listenable interpretations for audio classifiers.",
          "quote": "This paper contributes to this emerging field by introducing a novel method called Listenable Maps for Audio Classifiers (L-MAC)."
        },
        "is_executed": {
          "value": true,
          "justification": "The authors implement and evaluate L-MAC on the ESC-50 dataset, providing both quantitative and qualitative results.",
          "quote": "In our experiments, we evaluate the faithfulness and understandability of the generated interpretations. To achieve this, we considered two setups: i) Single-label classification under out-of-domain conditions, and ii) Multi-label classification. We utilized the ESC50 dataset (Piczak) which contains 50 environmental sound classes for both setups."
        },
        "is_compared": {
          "value": true,
          "justification": "The paper compares L-MAC with other methods such as gradient-based methods (standard saliency maps, SmoothGrad, IntegratedGradients, GuidedBackProp), decoder-based methods (Listen-to-Interpret (L2I)), and SHAP.",
          "quote": "To compare L-MAC with the literature, we used several gradient-based methods such as standard saliency maps (Simonyan et al., 2014), SmoothGrad (Smilkov et al., 2017), IntegratedGradients (Sundararajan et al., 2017), GuidedBackProp (Springenberg et al., 2015), and decoder based audio specific method, Listen-to-Interpret (L2I) (Parekh et al., 2022), and we also include SHAP (Lundberg & Lee, 2017)."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "No paper title provided for this model.",
          "quote": "No quote provided."
        }
      },
      {
        "name": {
          "value": "CNN14 classifier",
          "justification": "This model is referred to as \\\"CNN14 classifier\\\".",
          "quote": "In these experiments, we first train a CNN14 classifier (Kong et al., 2020) on the ESC-50 dataset (Piczak) augmented with WHAM! noise, to simulate real-world mixtures."
        },
        "aliases": [
          "CNN14"
        ],
        "is_contributed": {
          "value": false,
          "justification": "No mention is made that this model was developed in the paper.",
          "quote": "No quote provided."
        },
        "is_executed": {
          "value": true,
          "justification": "This model is used for audio classification on the ESC-50 dataset.",
          "quote": "In these experiments, we first train a CNN14 classifier (Kong et al., 2020) on the ESC-50 dataset (Piczak) augmented with WHAM! noise, to simulate real-world mixtures."
        },
        "is_compared": {
          "value": false,
          "justification": "No comparison is made with this model.",
          "quote": "No quote provided."
        },
        "referenced_paper_title": {
          "value": "",
          "justification": "The paper references Kong et al., 2020 in relation to the CNN14 model.",
          "quote": "In these experiments, we first train a CNN14 classifier (Kong et al., 2020) on the ESC-50 dataset (Piczak) augmented with WHAM! noise, to simulate real-world mixtures."
        }
      }
    ],
    "datasets": [],
    "libraries": []
  },
  "usage": {
    "cached_content_token_count": 0,
    "candidates_token_count": 0,
    "prompt_token_count": 0,
    "total_token_count": 14859
  }
}