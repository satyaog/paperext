High-Probability Bounds for Stochastic Optimization and
Variational Inequalities: the Case of Unbounded Variance

arXiv:2302.00999v2 [math.OC] ^{18} ^{Jul} ^{2023}

Abdurakhmon Sadiev ^{1} Marina Danilova ^{2} Eduard Gorbunov ^{3} Samuel Horváth ^{3} Gauthier Gidel ^{4} ^{5}
Pavel Dvurechensky ^{6} Alexander Gasnikov ^{2} ^{7} ^{8} Peter Richtárik ^{1}

1. Introduction

Abstract

Training of machine learning models is usually per-
formed via stochastic first-order optimization methods, e.g.,
Stochastic Gradient Descent (SGD) (Robbins & Monro,
1951)
x ^{k+1} = x ^{k} − γ∇f ξ k (x ^{k} ),
(1)

During recent years the interest of optimiza-
tion and machine learning communities in high-
probability convergence of stochastic optimiza-
tion methods has been growing. One of the main
reasons for this is that high-probability complex-
ity bounds are more accurate and less studied
than in-expectation ones. However, SOTA high-
probability non-asymptotic convergence results
are derived under strong assumptions such as
the boundedness of the gradient noise variance
or of the objective’s gradient itself. In this pa-
per, we propose several algorithms with high-
probability convergence results under less restric-
tive assumptions. In particular, we derive new
high-probability convergence results under the
assumption that the gradient/operator noise has
bounded central α-th moment for α ∈ (1, 2] in
the following setups: (i) smooth non-convex /
Polyak-Łojasiewicz / convex / strongly convex
/ quasi-strongly convex minimization problems,
(ii) Lipschitz / star-cocoercive and monotone /
quasi-strongly monotone variational inequalities.
These results justify the usage of the considered
methods for solving problems that do not fit stan-
dard functional classes studied in stochastic opti-
mization.

where ∇f ξ k (x ^{k} ) represents the stochastic gradient of the
objective/loss function f at point x ^{k} . Despite numerous
empirical studies and observations validating the good per-
formance of such methods, it is also important for the field
to understand their theoretical convergence properties, e.g.,
under what assumptions a method converges and what the
rate is. However, since the methods of interest are stochas-
tic, one needs to specify what type of convergence is con-
sidered before moving on to further questions.

Typically, the convergence of the stochastic methods is
studied only in expectation, i.e., for some performance met-
^{ric} ^{1} P(x), ^{upper} ^{bounds} ^{are} ^{derived} ^{for} ^{the} ^{number} ^{of} ^{iter-}
ations K needed to achieve E[P(x ^{K} )] ≤ ε, where x ^{K} is
the output of the method after K steps, ε is an optimization
error, and E[·] is the full expectation. These bounds can
be “blind” to some important properties like light-/heavy-
tailedness of the noise distribution and, as a result, such
guarantees do not accurately describe the methods’ conver-
gence in practice (Gorbunov et al., 2020). In contrast, high-
probability convergence guarantees are more sensitive to
the noise distribution and thus are more accurate. Such
results provide upper bounds for the number of iterations
K needed to achieve P{P(x ^{K} ) ≤ ε} ≥ 1 − β for some
confidence level β ∈ (0, 1], where P{·} denotes some prob-
ability measure determined by a setup.

1

King Abdullah University of Science and Technology,
KSA ^{2} Moscow Institute of Physics and Technology, Russia
3
Mohamed bin Zayed University of Artificial Intelligence, UAE
4
Université de Montréal and Mila, Canada ^{5} Canada CIFAR AI
Chair ^{6} Weierstrass Institute for Applied Analysis and Stochas-
tics, Germany ^{7} Skolkovo Institute of Science and Technol-
ogy, Russia ^{8} Institute for Information Transmission Problems
RAS, Russia. Correspondence to: Eduard Gorbunov <ed-
uard.gorbunov@mbzuai.ac.ae>.

With the ultimate goal of bridging the theory and practice of
stochastic methods, recent works on high-probability con-
vergence guarantees (Nazin et al., 2019; Davis et al., 2021;
Gorbunov et al., 2020; 2021; 2022a; Cutkosky & Mehta,
2021) focus on an important direction of the relaxing the as-
sumptions under which these guarantees are derived. Our

Proceedings of the 40 ^{th} International Conference on Machine
Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright
2023 by the author(s).

1

Examples of performance metrics for minimization of func-
tion f : P(x) = f (x) − f (x ^{∗} ), P(x) = k∇f (x)k ^{2} , P(x) =
kx − x ^{∗} k ^{2} , where x ^{∗} ∈ arg min x∈R d f (x).

1

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

(ii) for problem (3) E ξ∼D [F ξ (x)] = F (x) and

paper further extensively complements this line of works in
two main aspects: for a plethora of settings, we derive new
high-probability results allowing the variance of the noise
and the gradient of the objective to be unbounded.

α

E ξ∼D [kF ξ (x) − F (x)k ] ≤ σ ^{α} .

When α = 2, the above assumption recovers the standard
uniformly bounded variance assumption (Nemirovski et al.,
2009; Ghadimi & Lan, 2012; 2013). However, Assump-
tion 1.1 allows the variance of the estimator to be un-
bounded when α ∈ (1, 2), i.e., the noise can follow
some heavy-tailed distribution. For example, the distribu-
tion of the gradient noise in the training of large attention
models resembles Lévy α-stable distribution with α < 2
(Zhang et al., 2020b). There exist also other versions of
Assumption 1.1, see (Patel et al., 2022).

1.1. Technical Preliminaries

Before we move on to the main part of the paper, we intro-
duce the problems considered in the work and all necessary
preliminaries. In particular, we consider stochastic uncon-
strained optimization problems

min {f (x) = E ξ∼D [f ξ (x)]} ,

x∈R ^{d}

(2)

where ξ is a random variable with distribution D.
Such problems often arise in machine learning, where
f ξ (x) represents the loss function on the data sample ξ
(Shalev-Shwartz & Ben-David, 2014).

Assumptions on f . We start with a very mild assumption
since without it, problem (2) does not make sense.
Assumption 1.2. We assume that there exist some set Q ⊆
R ^{d} such that f is uniformly lower-bounded on Q: f ∗ =
^{inf} x∈Q ^{f} ^{(x)} ^{>} −∞.

Another class of problems that we consider this work is un-
constrained variational inequality problems (VIP), i.e., non-
linear equations (Harker & Pang, 1990; Ryu & Yin, 2021):

find x ^{∗} ∈ R ^{d} such that F (x ^{∗} ) = 0,

Moreover, when working with minimization problems (2),
we always assume smoothness of f .
Assumption 1.3. We assume that there exist some set Q ⊆
R ^{d} and constant L > 0 such that for all x, y ∈ Q

(3)

where F (x) = E ξ∼D [F ξ (x)]. These problems arise in
adversarial/game formulations of machine learning tasks
(Goodfellow et al., 2014; Gidel et al., 2019).
p
^{Notation.} ^{We} ^{use} ^{standard} ^{notation:} kxk ^{=} hx, ^{xi} ^{de-}
notes the standard Euclidean norm in R ^{d} , E ξ [·] denotes
an expectation w.r.t. the randomness coming from random
^{variable} ^{ξ,} ^{B} R ^{(x)} ^{=} {y ∈ ^{R} ^{d} | ky −xk ≤ ^{R}} ^{is} ^{a} ^{ball} ^{with}
center at x and radius R. We define restricted gap-function
as Gap R (x) = max y∈B R (x ∗ ) hF (y), x − yi – a standard
convergence criterion for monotone VIP (Nesterov, 2007).
e hides poly-
^{Finally,} O(·) ^{hides} ^{numerical} ^{factors} ^{and} O(·)
logarithmic and numerical factors.

k∇f ^{(x)} − ∇f ^{(y)k} ≤

k∇f ^{(x)k}

≤

Lkx − yk,

2L (f (x) − f ∗ ) ,

(6)

(7)

We notice here that (7) follows from (6) for Q = R ^{d} , but in
the general case, the implication is slightly more involved
(see the details in Appendix B). When Q is a compact set,
the function f is allowed to be non-L-smooth on the whole
R ^{d} , which is related to local-Lipschitzness of the gradients
(Patel et al., 2022; Patel & Berahas, 2022).

In each particular special case, we also make one of the fol-
lowing assumptions about the structured non-convexity of
the objective function. The previous two assumptions hold
for a very broad class of functions. The next assumption –
Polyak-Łojasiewicz condition (Polyak, 1963; Lojasiewicz,
1963) – narrows the class of non-convex functions.
Assumption 1.4. We assume that there exist some set
Q ⊆ R ^{d} and constant μ > 0 such that f satisfies Polyak-
Łojasiewicz (PŁ) condition/inequality on Q, i.e., for all
x ∈ Q and x ∗ = arg min x∈R d f (x)

Stochastic oracle. We assume that at given point x we
have an access to the unbiased stochastic oracle returning
∇f ξ (x) or F ξ (x) that satisfy the following conditions.

k∇f ^{(x)k} ^{2} ≥ ^{2μ} ^{(f} ^{(x)} − ^{f} ^{(x} ^{∗} ^{))} ^{.}

Assumption 1.1. We assume that there exist some set Q ⊆
R ^{d} and values σ ≥ 0, α ∈ (1, 2] such that for all x ∈ Q

(8)

When function f is μ-strongly convex, it satisfies PŁ condi-
tion. However, PŁ inequality can hold even for non-convex
functions. Some analogs of this assumption have been ob-
served for over-parameterized models (Liu et al., 2022).

(i) for problem (2) E ξ∼D [∇f ξ (x)] = ∇f (x) and

α

2

^{where} ^{f} ∗ ^{=} ^{inf} x∈Q ^{f} ^{(x)} ^{>} −∞.

Assumptions on a subset. Although we consider uncon-
strained problems, our analysis does not require any as-
sumptions to hold on the whole space. For our purposes,
it is sufficient to introduce all assumptions only on some
subset of R ^{d} , since we prove that the considered methods
do not leave some ball around the solution or some level-set
of the objective function with high probability. This allows
us to consider quite large classes of problems.

E ξ∼D [k∇f ξ (x) − ∇f (x)k ] ≤ σ ^{α} ,

(5)

(4)

We also consider another relaxation of convexity.

2

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Assumption 1.5. We assume that there exist some set
Q ⊆ R ^{d} and constant μ ≥ 0 such that f is μ-quasi-strongly
convex, i.e., for all x ∈ Q and x ∗ = arg min x∈R d f (x)

^{f} ^{(x} ^{∗} ^{)} ≥ ^{f} ^{(x)} ^{+} h∇f ^{(x),} ^{x} ^{∗} − ^{xi} ^{+}

Another structured non-monotonicity assumption that we
consider in this paper is star-cocoercivity.
Assumption 1.10. We assume that there exist some set
Q ⊆ R ^{d} and constant l > 0 such that F is star-cocoercive
on Q, i.e., for all x ∈ Q and x ∗ such that F (x ∗ ) = 0

μ
kx − x ^{∗} k ^{2} . (9)
2

kF (x)k ^{2} ≤ lhF (x), x − x ^{∗} i.

As PŁ condition, this assumption holds for any μ-strongly
convex function but does not imply convexity. Neverthe-
less, for the above two assumptions, some standard deter-
ministic methods such as Gradient Descent (GD) converge
linearly; see more details and examples in (Necoara et al.,
2019).

(14)

This assumption can be seen as a relaxation of the stan-
dard cocoercivity: kF (x) − F (y)k ^{2} ≤ lhF (x) − F (y), x −
yi. However, unlike cocoercivity, star-cocoercivity im-
plies neither monotonicity nor Lipschitzness of operator F
(Loizou et al., 2021, Appendix A.6).

In the analysis of the accelerated method, we also need stan-
dard (strong) convexity.

1.2. Closely Related Works and Our Contributions

Assumption 1.6. We assume that there exist some set Q ⊆
R ^{d} and constant μ ≥ 0 such that f is μ-strongly convex,
i.e., for all x, y ∈ Q

In this subsection, we overview closely related works and
describe the contributions of our work. Additional related
works are discussed in Appendix A.

^{f} ^{(y)} ≥ ^{f} ^{(x)} ^{+} h∇f ^{(x),} ^{y} − ^{xi} ^{+}

μ
ky − xk 2 .
2

(10)

Convex optimization and monotone VIPs. Classical
high-probability results for (strongly) convex minimization
(Nemirovski et al., 2009; Ghadimi & Lan, 2012) and mono-
tone VIP (Juditsky et al., 2011) are derived under the so-
called light-tails assumption, meaning that the noise in
the stochastic gradients/operators is assumed to be sub-
2
Gaussian: E ξ∼D [exp( k∇f ξ ^{(x)−∇f} ^{(x)k} / σ ^{2} )] ≤ exp(1) or
2
E ξ∼D [exp( kF ξ ^{(x)−F} ^{(x)k} / σ ^{2} )] ≤ exp(1). In these settings,
optimal (up to logarithmic factors) rates of convergence are
derived in the mentioned papers.

When μ = 0 function f is called convex.

Assumptions on F . In the context of solving (3), we as-
sume Lipschitzness of F – a standard assumption for VIP.

Assumption 1.7. We assume that there exist some set Q ⊆
R ^{d} and constant L > 0 such that for all x, y ∈ Q

kF (x) − F (y)k ≤ Lkx − yk,

(11)

The first high-probability results with logarithmic depen-
dence ^{2} on ^{1} / β under just bounded variance assumption are
given by Nazin et al. (2019), where the authors show non-
accelerated rates of convergence for a version of Mirror
Descent with a special truncation operator for smooth con-
vex and strongly convex problems defined on the bounded
sets. Then, Davis et al. (2021) derive accelerated rates in
the strongly convex case using robust distance estimation
techniques. Gorbunov et al. (2020; 2021) propose an accel-
erated method with clipping for unconstrained (strongly)
convex problems with Lipschitz / Hölder continuous gradi-
ents and derive the first high-probability results for clipped-
SGD. In the context of VIP, Gorbunov et al. (2022a) derive
the first high-probability results for the stochastic methods
for solving VIP under bounded variance assumption and
different assumptions on structured non-monotonicity.

Similarly to the case of minimization problems, we make
one or two of the following assumptions about the struc-
tured non-monotonicity of the operator F . The first as-
sumption we consider is the standard monotonicity.

Assumption 1.8. We assume that there exist some set Q ⊆
R ^{d} such that F is monotone on Q, i.e., for all x, y ∈ Q

hF (x) − F (y), x − yi ≥ 0.

(12)

Monotonicity can be seen as an analog of convexity for VIP.
When (12) holds with μkx − yk ^{2} in the r.h.s. instead of just
0, operator F is called μ-strongly monotone.

Next,
we
consider
quasi-strong
monotonicity
2019;
Song et al.,
2020;
(Mertikopoulos & Zhou,
Loizou et al., 2021) – a relaxation of strong mono-
tonicity. There exist examples of non-monotone problems
such that the assumption below holds (Loizou et al., 2021,
Appendix A.6).

2
Note that from in-expectation convergence guarantee, one
can always get a high-probability one using Markov’s inequality.
For example, under bounded variance, smoothness, and strong
convexity assumptions SGD achieves Ekx ^{k} − x ^{∗} k ^{2} ≤ ε after
e
^{L} / μ , ^{σ} ^{2} / με }) iterations. Therefore, taking k such
k = O(max{
k
that Ekx − x ^{∗} k ^{2} ≤ εβ we get from Markov’s inequality that
P{kx ^{k} − x ^{∗} k ^{2} ≤ ε} ≤ β. However, in this case, we get bound
e
^{L} / μ , ^{σ} ^{2} / μεβ }), having undesirable inverse-power
k = O(max{
dependence on β.

Assumption 1.9. We assume that there exist some set
Q ⊆ R ^{d} and constant μ > 0 such that F is μ-quasi
strongly monotone on Q, i.e., for all x ∈ Q and x ∗ such
that F (x ∗ ) = 0 we have

hF (x), x − x ∗ i ≥ μkx − x ∗ k ^{2} .

(13)

3

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Table 1: Summary of known and new high-probability complexity results for solving smooth problem (2). Column 0 “Setup” ∗ indicates the assumptions made in addition

to Assumptions 1.1 and 1.3. All assumptions are made only on some ball around the solution with radius ∼ R ≥ kx − x k (unless the opposite is indicated). By the
complexity we mean the number of stochastic oracle calls needed for a method to guarantee that P{Metric ≤ ε} ≥ 1 − β for some ε > 0, β ∈ (0, 1] and “Metric”
is taken from the corresponding column. For simplicity, we omit numerical and logarithmic factors in the complexity bounds. Column “α” shows the allowed values of α,
“UD?” shows whether the analysis works on unbounded domains, and “UG?” indicates whether the analysis works without assuming boundedness of the gradient. Notation:
L = Lipschitz constant; D = diameter of the domain (for the result from (Nazin et al., 2019)); σ = parameter from Assumption 1.1; R = any upper bound on kx ^{0} − x ^{∗} k; μ
^{=} ^{(quasi-)strong} ^{convexity/Polyak-Łojasiewicz} ^{parameter;} ^{∆} ^{=} ^{any} ^{upper} ^{bound} ^{on} ^{f} ^{(x} ^{0} ^{)} − ^{f} ∗ ^{;} ^{G} ^{=} ^{parameter} ^{such} ^{that} ^{E} ξ∼D k∇f ξ ^{(x)k} ^{α} ≤ ^{G} ^{α} ^{(for} ^{the} ^{result} ^{from}
(Cutkosky & Mehta, 2021)). The results of this paper are highlighted in blue.

Setup

Method

Citation

Metric

RSMD

(Nazin et al., 2019) ^{(1)}
(Gorbunov et al., 2020)
(Gorbunov et al., 2021)
(Gorbunov et al., 2020)
(Gorbunov et al., 2021)

f (x K ) − f (x ∗ )

clipped-SGD

As. 1.6
(μ = 0)

As. 1.6
(μ > 0)

clipped-SSTM

(2)

K

∗

f (y ) − f (x )

f (x ) − f (x )

Theorems 3.2 & F.2

f (y K ) − f (x ∗ )

(Nazin et al., 2019)

proxBoost

(Davis et al., 2021) ^{(1)}
(Gorbunov et al., 2020)
(Gorbunov et al., 2021)
(Gorbunov et al., 2020)
(Gorbunov et al., 2021)

R-clipped-SGD

clipped-SGD

clipped-NMSGD

clipped-SGD

K

(1)

restarted-RSMD

clipped-SGD

As. 1.4

∗

Theorems 3.1 & E.6

MSGD

(1)

K

f (x ) − f (x )

clipped-SGD

R-clipped-SSTM

As. 1.2

∗

clipped-SSTM

R-clipped-SSTM

As. 1.5
(μ > 0)

K

f (x ) − f (x )

f (x K ) − f (x ∗ )

K

∗

K

∗

K

∗ 2

f (y ) − f (x )

kx

(Li & Orabona, 2020) ^{(1)}

Theorems 3.1 & E.4 ^{(5)}

∗

f (y ) − f (x )

Theorems 3.1 & E.8

Theorems 3.1 & E.2 ^{(5)}

K

f (x ) − f (x )

Theorems 3.2 & F.3

(Cutkosky & Mehta, 2021) ^{(1)}

∗

1
K+1



1
K+1

1
K+1

K
P

k=0
K
P

k=0
K
P

− x k

k∇f ^{(x} ^{k} ^{)k} ^{2}
 2
(4)
k∇f ^{(x} ^{k} ^{)k}

k=0

k∇f ^{(x} ^{k} ^{)k} ^{2}

f (x K ) − f (x ∗ )

Complexity
o
n
LD 2 σ 2 D 2
ε ,
ε 2
o
n
2 σ 2 R 2
max ^{LR}
ε ,
ε 2
q

LR 2 σ 2 R 2
max
2
ε ,
ε
n
 α o
2
α−1
max ^{LR}
, σR
ε
ε

q
α

2
LR
^{σR} α−1
max
ε ,
ε
o
n
2
max ^{L}
, σ
nq μ με 2 o
(2)
L σ
max
μ , με
o
n
σ 2
max ^{L}
μ , με
nq
o
L σ 2
max
μ , με
q
 2  α 
L
2(α−1)
σ
max
μ ,
με


 2  α
2(α−1)
σ
max ^{L}
μ , μ 2 ε
o
n 2 2
4
max ^{L} ε ^{∆} , ^{σ}
ε 2

max

max

max





 2  3α−2
2α−2
G
ε

L∆
ε ,

L
μ ,

 √



L∆σ
ε

Lσ 2
μ 2 ε





α 
α−1


α
2(α−1)

α

UD?

UG?

2

✗

✓

2

✓

✓

2

✓

✓

(1, 2]

✓

✓

(1, 2]

✓

✓

2

✗

✓

2

✓

✓

2

✓

✓

2

✓

✓

(1, 2]

✓

✓

(1, 2]

✓

✓

✗ (3)

✓

✓

(1, 2]

✓

✗

(1, 2]

✓

✓

(1, 2]

✓

✓

All assumptions are made on the whole domain.
Complexity has extra logarithmic factor of ln( ^{L} / μ ).

h

i
Li & Orabona (2020) assume that the noise is sub-Gaussian: E exp k∇fξ ^{(x)−∇f} ^{(x)k} ^{2} / σ ^{2}
≤ exp(1) for all x from the domain.
 2

P K
P K
(4)
k
k
2
1
1
^{We} ^{notice} ^{that} K+1
k∇f
(x
)k
≤
k∇f
(x
)k
and
in
the
worst
case
the left-hand side is K + 1 times smaller than the right-hand
k=0
k=0
K+1
side.
√
√
(5)
All assumptions are made on the level set Q = {x ∈ R ^{d} | ∃y ∈ R ^{d} : f (y) ≤ f ∗ + 2∆ and kx − yk ≤ ^{∆} / 20 L }.

(3)

in-expectation lower bound (Zhang et al., 2020b) and de-
terministic lower bound (Nemirovskij & Yudin, 1983). In
other words, we derive the first optimal high-probability
complexity results for smooth strongly convex optimiza-
tion. Noticeably, the derived results have clear separa-
tion between accelerated part and stochastic part that em-
phasizes a potential of clipped-SSTM for efficient par-
allelization. Next, we derive high-probability results for
clipped-SGD for smooth star-convex and quasi-strongly
convex objectives under Assumption 1.1. Finally, under
the same assumption, we prove the high-probability conver-
gence of Clipped Stochastic Extragradient (clipped-SEG)
(Korpelevich, 1976; Juditsky et al., 2011; Gorbunov et al.,
2022a) for Lipschitz monotone and quasi-strongly mono-
tone VIP and also obtain high-probability results for
Clipped Stochastic Gradient Descent-Ascent (clipped-
SGDA) for star-cocoercive and monotone / quasi-strongly
monotone VIP. In the special case of α = 2, our analy-
sis recovers SOTA high-probability results under bounded
variance assumption.

However, there are no high-probability results (with log-
arithmic dependence on the confidence level) for smooth
(strongly) convex minimization problems and Lipschitz
VIP without imposing bounded variance assumption. Only
recently, Zhang & Cutkosky (2022) derived optimal regret-
bounds under Assumption 1.1 in the convex case with
bounded gradients on R ^{d} . However, the bounded gradients
assumption is quite restrictive when assumed on the whole
space. Thus, a noticeable gap in the stochastic optimization
literature remains.

^{Contribution.} We obtain new high-probability conver-
gence results under Assumption 1.1 for smooth convex min-
imization problems and Lipschitz VIP; see the summary in
Tables 1 and 2. In particular, for Clipped Stochastic Sim-
ilar Triangles Method (clipped-SSTM) (Gorbunov et al.,
2020) and its restarted version, we derive high-probability
convergence results for smooth convex and strongly convex
problems. The high-probability complexity in the strongly
convex case matches (up to logarithmic factors) the known

4

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Table 2: Summary of known and new high-probability complexity results for solving 0 (3). Column
“Setup” indicates the assumptions made in addition to Assumption 1.1.
∗

All assumptions are made only on some ball around the solution with radius ∼ R ≥ kx − x k (unless the opposite is indicated). By the complexity we mean the number
of stochastic oracle calls needed for a method to guarantee that P{Metric ≤ ε} ≥ 1 − β for some ε > 0, β ∈ (0, 1] and “Metric” is taken from the corresponding column.
For simplicity, we omit numerical and logarithmic factors in the complexity bounds. Column “α” shows the allowed values of α, “UD?” shows whether the analysis works on
P K
1
e ^{k} (for clipped-SEG),
unbounded domains, and “UG?” indicates whether the analysis works without assuming boundedness of the gradient. Notation: x
e K
avg ^{=} K+1
k=0 ^{x}
P
K
k
1
x K
=
x
(for
clipped-SGDA);
L
=
Lipschitz
constant;
D
=
diameter
of
the
domain
(used
in
(Juditsky
et
al.,
2011));
Gap
(x)
=
max
y∈X hF (y), x−yi,
D
avg
k=0
K+1
where X is a bounded domain with diameter D where the problem is defined (used in (Juditsky et al., 2011)); D = diameter of the domain (for the result from (Juditsky et al.,
2011)); σ = parameter from Assumption 1.1; R = any upper bound on kx ^{0} − x ^{∗} k; μ = quasi-strong monotonicity parameter; l = star-cocoercivity parameter. The results of
this paper are highlighted in blue.

Setup

As. 1.7 & 1.8

As. 1.7 & 1.9

As. 1.8 & 1.10

Method

Citation

Metric

Mirror-Prox

(Juditsky et al., 2011) ^{(1)}

Gap D (e
x K
avg ^{)}

clipped-SEG

(Gorbunov et al., 2022a)

Gap R (e
x K
avg ^{)}

clipped-SEG

Theorems 4.1 & G.2

Gap R (e
x K
avg ^{)}

clipped-SEG

(Gorbunov et al., 2022a)

kx k − x ∗ k 2

clipped-SEG

Theorems 4.1 & G.4

kx k − x ∗ k 2

clipped-SGDA

(Gorbunov et al., 2022a)

Gap R (x ^{K}
avg ^{)}

clipped-SGDA

Theorems 4.2 & H.3

Gap R (x ^{K}
avg ^{)}

clipped-SGDA

(Gorbunov et al., 2022a)

As. 1.10

clipped-SGDA

As. 1.9 & 1.10

(1)

(2)

Theorems 4.2 & H.4

clipped-SGDA

(Gorbunov et al., 2022a)

clipped-SGDA

Theorems 4.2 & H.6

1
K+1

1
K+1

K
P

k

k=0
K
P

k=0
K

kx

kF (x )k

Complexity
o
n
LD 2 σ 2 D 2
2
ε ,
ε
o
n
2 σ 2 R 2
max ^{LR}
ε ,
ε 2
n
o
α

2
^{σR} α−1
max ^{LR}
ε ,
ε
o
n
σ 2
max ^{L}
μ , μ 2 ε

 2  α ) 
σ
2(α−1
max ^{L}
μ , μ 2 ε
n 2
o
2 2
max ^{lR}
, σ ε R
2
n 2 ε
 α o
^{σR} α−1
max ^{lR}
ε ,
ε
n 2 2 2 2 2 o
max ^{l} ε ^{R} , ^{l} ^{σ} ε 2 ^{R}

2

kF (x k )k 2

max

∗ 2

− x k

kx K − x ∗ k 2

α

UD?

UG?

✗ (2)

✗

✓

✓

max

max

n 2

l R 2
ε ,

n


lσR

ε

l
σ 2
μ , μ 2 ε

α o
α−1

2

✓

(1, 2]

✓

✓

2

✓

✓

(1, 2]

✓

✓

2

✓

✓

(1, 2]

✓

✓

2

✓

✓

(1, 2]

✓

✓

2

✓

✓

(1, 2]

✓

✓

o

max
 
 α ) 
2(α−1
σ 2
l
μ , μ 2 ε

All assumptions are made on the whole domain.
h

i
Juditsky et al. (2011) assume that the noise is sub-Gaussian: E exp kFξ ^{(x)−F} ^{(x)k} ^{2} / σ ^{2}
≤ exp(1) for all x from the domain.

Gradient clipping received a lot of attention in the ma-
chine learning community due to its successful empiri-
cal applications in the training of deep neural networks
(Pascanu et al., 2013; Goodfellow et al., 2016). The clip-
^{ping} ^{operator} ^{is} ^{defined} ^{as} ^{clip(x,} ^{λ)} ^{=} ^{min} {1, ^{λ} ^{/} kxk } ^{x}
(clip(x, λ) = 0, when x = 0). From the theoretical
perspective, gradient clipping is used for multiple different
purposes: to handle structured non-smoothness in the ob-
jective function (Zhang et al., 2020a), to robustify aggrega-
tion (Karimireddy et al., 2021) and to provide privacy guar-
antees (Abadi et al., 2016) in the distributed training. More-
over, as we already mentioned before, gradient clipping
is used to handle heavy-tailed noise (satisfying Assump-
tion 1.1) in the stochastic gradients (Zhang et al., 2020b)
and, in particular, to derive better high-probability guar-
antees under bounded variance assumption (Nazin et al.,
2019; Gorbunov et al., 2020). However, there are no re-
sults showing the necessity of modifying standard meth-
ods like SGD and its accelerated variants to achieve high-
probability convergence with logarithmic dependence on
the confidence level under bounded variance assumption.

Non-convex optimization. Under the light-tails and
smoothness assumption Li & Orabona (2020) derive high-
probability convergence rates to the first-order station-
ary point for SGD. These rates match the known in-
expectation guarantees for SGD and are optimal up
to logarithmic factors (Arjevani et al., 2022). Recently,
Cutkosky & Mehta (2021) derived the first high-probability
results for non-convex optimization under Assumption 1.1
for a version of SGD with gradient clipping and normal-
ization of the momentum. The
P K results are k obtained for the
1
^{non-standard} ^{metric} ^{–} K+1
k=0 k∇f ^{(x} ^{)k} ^{–} ^{and} ^{match}
in-expectation lower bound for the expected (non-squared)
norm of the gradient from (Zhang et al., 2020b). However,
Cutkosky & Mehta (2021) make an additional assumption
that the norm of the gradient is bounded ^{3} on R ^{d} , which is
quite restrictive.

^{Contribution.} We derive the first high-probability result
with logarithmic dependence on the confidence level for
finding first-order stationary points of smooth (possibly,
non-convex) functions without bounded gradients assump-
tion. The result is derived for simple clipped-SGD. More-
over, we extend the analysis to the functions satisfying
Polyak-Łojasiewicz condition; see Table 1 for the sum-
mary.

^{Contribution.} We construct an example of a strongly con-
vex smooth problem and stochastic oracle with bounded
variance such that to achieve
P{kx ^{k} −x ∗ k ^{2} > ε} ≤ β SGD
√ 
2
σ
requires Ω / μ εβ iterations, i.e., the algorithm has
inverse-power dependence on the confidence level. This
justifies the importance of using some non-linearity such
as gradient clipping to achieve logarithmic dependence on

3

1.1,
More
precisely,
instead
of
Assumption
Cutkosky & Mehta (2021) assume E ξ∼ k∇f ξ (x)k ^{α} ≤ G ^{α}
for some G > 0. This assumption implies Assumption 1.1 and
boundedness of k∇f (x)k.

5

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance



2(α−1) /α 2
μ ∆ / Lσ 2 A 2(α−1) /α ln 2 (B K ) } ,
Θ max{2, ^{(K+1)}

the confidence level even in the bounded variance case.

√

2. Failure of Standard SGD

It is known that SGD x ^{k+1} = x ^{k} − γ∇f ξ k (x ^{k} ) can di-
verge in expectation, when Assumption 1.1 is satisfied with
α < 2 (Zhang et al., 2020b, Remark 1). However, it does
converge in expectation when α = 2, i.e., when the vari-
ance is bounded. In contrast, there are no high-probability
convergence results for SGD having logarithmic depen-
dence on ^{1} / β . The next theorem establishes the impossi-
bility of deriving such high-probability results.

λ k = Θ( exp(−γμ(1+ ^{k} / 2 ))R / γA ).
1 P k
k 2
^{Then} ^{to} ^{guarantee} K+1
k=0 k∇f ^{(x} ^{)k} ≤ ^{ε} ^{in} ^{Case} ^{1,}
K
∗
K
f (x ) − f (x ) ≤ ε in Case 2, f (x̄ ) − f (x ∗ ) ≤ ε in
P K
1
k
K
− x ∗ k 2 ≤ ε in
^{Case} ^{3} ^{with} ^{x̄} ^{K} ^{=} K+1
k=0 ^{x} ^{,} kx
Case 4 with probability ≥ 1 − β clipped-SGD requires


! α  
 L∆ ^{√} L∆σ ^{α−1} 
e  max
 (16)
Case 1: O
,

 ε
ε
( 
 α )!
^{2} 2(α−1)
L
Lσ
e max
Case 2: O
(17)
,
μ
μ 2 ε
(
 α )!

LR ^{2} σR α−1
e
,
Case 3: O max
(18)
ε
ε
)!
( 
α
 2(α−1)
2
L
σ
e max
(19)
Case 4: O
,
μ μ 2 ε

Theorem 2.1. For any ε > 0 and sufficiently small β ∈
(0, 1) there exist problem (2) such that Assumptions 1.1, 1.3,
and 1.6 hold with Q = R ^{d} , α = 2, 0 < μ ≤ L and for the
iterates produced by SGD with any stepsize γ > 0


 k
σ
∗ 2
√
.
P kx − x k ≥ ε ≤ β =⇒ k = Ω
μ εβ

The proof is deferred to Appendix D. We believe that sim-
ilar examples can be constructed for any stochastic first-
order methods having linear dependence on the stochastic
gradients in their update rules. Thus, Theorem 2.1 mo-
tivates the use of non-linear operators such as gradient
clipping in stochastic methods to achieve logarithmic de-
pendence on the confidence level in the high-probability
bounds.

oracle calls.

3. Main Results for Minimization Problems

The complete formulation of the result and full proofs are
deferred to Appendix E. As one can see from Table 1,
for α = 2 the derived complexity bounds match the best-
known ones for clipped-SGD in the setups where it was an-
alyzed. Next, we emphasize that the second term under the
maximum in (19) (quasi-strongly convex functions) is opti-
mal up to logarithmic factors (Zhang et al., 2020b). In the
convex case, there are no lower bounds, but we conjecture
that the second term in (18) is optimal (up to logarithms) in
this case as well.

3.1. SGD with Clipping

We start with clipped-SGD:


x ^{k+1} = x ^{k} − γ · clip ∇f ξ k (x ^{k} ), λ k ,

√

λ k = Θ( ^{exp(−γμ(1+} ^{k} ^{/} 2 ^{))} ^{∆} / LγA ).
Case 3.
Let Assumptions 1.1, 1.3, 1.6 with
μ = 0 hold for Q = B 3R (x ∗ ), R ≥ kx ^{0} − x ∗ k
^{and} ^{0} ^{<} ^{γ} ≤ O(min{ ^{1} ^{/} ^{LA} ^{,} ^{R} ^{/} ^{σK} ^{1} ^{/α} ^{A} ^{(α−1)} ^{/α} }),
λ k = λ = Θ( R / γA ).
^{Case} ^{4.} Let Assumptions 1.1, 1.3, 1.5 with μ > 0
hold for Q = B 3R (x ∗ ), R ≥ kx ^{0} − x ∗ k and
^{0}  ^{<} ^{γ} ^{=} O ^{(min{} ^{1} ^{/} ^{LA} ^{,} ^{ln(B} ^{K} ^{)} ^{/} ^{μ(K+1)} }), ^{B}
 K =
2(α−1) /α 2 2
2 2(α−1) /α
2
(K+1)
μ
R
Θ max{2,
/ σ A
ln (B K ) } ,

(15)

where ξ ^{k} is sampled from D k independently from previous
steps. We emphasize here and below that distribution of
the noise is allowed to be dependent on k: we require just
independence of ξ ^{k} from the the previous steps. Our main
convergence results for clipped-SGD are summarized in
the following theorem.

Next, in the case of PŁ-functions, we are not aware of any
high-probability convergence results in the literature. In the
special case of α = 2, the derived complexity bound (17)
matches the best-known in-expectation complexity bound
for SGD (Karimi et al., 2016; Khaled & Richtárik, 2020)
and the first term coincides (up to logarithms) with the
lower bound for deterministic first-order methods in this
setup (Yue et al., 2022).

Theorem 3.1 (Convergence of clipped-SGD). Let k ≥ 0
and β ∈ (0, 1] are such that A = ln ^{4(K+1)}
≥ 1.
β
Case 1.
Let Assumptions 1.1, 1.2, 1.3 hold for
Q = {x ∈ R d | √
∃y ∈ R d :
f (y) ≤
√
f ∗ + 2∆ and kx − yk ≤ ^{∆} / 20 √ L }, ∆ ≥ f (x ^{0} ) − f  ∗
√
and 0 < γ ≤ O min{ 1 / LA , ∆ / σ LK ^{1} ^{/α} A ^{(α−1)} ^{/α} } ,
√ √
^{λ} k ^{=} ^{λ} ^{=} ^{Θ(} ^{∆} ^{/} LγA ^{).}
Case 2.
Let Assumptions 1.1, 1.3, 1.4 hold for
Q = {x ∈ R d | √
∃y ∈ R d :
f (y) ≤
√
f ∗ + 2∆ and kx − yk ≤ ^{∆} / 20 L }, ∆ ≥ f (x ^{0} ) − f ∗
^{and} ^{0} ^{<} ^{γ} ^{=} O ^{(min{} ^{1} ^{/} ^{LA} ^{,} ^{ln(B} ^{K} ^{)} ^{/} ^{μ(K+1)} }), ^{B} K ^{=}

Finally, in the non-convex case, bound (16) is the first
high-probability result under Assumption 1.1 without the
additional assumption of the boundedness of the gradi-
ents. For α = 2 it matches (up to logarithms) in-

6

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

The derived high-probability bound matches (see the proof
in Appendix F.1) the best-known one in the case of α =
2. For α < 2 there are no lower bounds in the con-
vex case. However, the first term in (23) is optimal and
matches the deterministic lower bound in the convex case
(Nemirovskij & Yudin, 1983). The second term is the same
as in the bound for clipped-SGD (18) and we conjecture
that it cannot be improved.

expectation lower bound (Arjevani et al., 2022). How-
ever, when α  < 2, bound (16)
 is inferior to the ex-

e G ^{2} / ε ^{(3α−2)} ^{/} ^{2(α−1)} by Cutkosky & Mehta
isting one O
(2021), which relies on the stronger assumption that
^{E} ξ∼D k∇f ξ ^{(x)k} ^{α} ≤ ^{G} ^{α} ^{for} ^{some} ^{G} ^{>} ^{0} ^{and} ^{all}
x ∈ R ^{d} , and also do not match the lower bound
by Zhang et al. (2020b) derived for Ek∇f (x ^{k} )k, where
x ^{k} is the output of the stochastic first-order method.
It is also worth mentioning that Cutkosky & Mehta
(2021) use a different performance metric: P̂ K =
 2

P K
1
k
k∇f
(x
)k
. This metric is always smaller
k=0
K+1
1 P K
^{than} P K ^{=} K+1 k=0 k∇f ^{(x} ^{k} ^{)k} ^{2} ^{,} ^{which} ^{we} ^{use} ^{in} ^{our}
result. In the worst case, P K can be K +1 times larger than
P̂ K . Moreover, the lower bound from (Zhang et al., 2020b)
is derived for Ek∇f (x ^{k} )k that is also always smaller than
the standard quantity of interest Ek∇f (x ^{k} )k ^{2} . Therefore,
the question of optimality of the bound (16) remains open
for α < 2. Moreover, it will also be interesting to modify
our analysis in this case to derive a better bound for metric
P̂ K than (16).

In the strongly convex case, we consider clipped-SSTM
with restarts (R-clipped-SSTM). This method consists of
τ stages. On the t-th stage R-clipped-SSTM runs clipped-
SSTM for K 0 iterations from the starting point x̂ ^{t} , which
is the output from the previous stage (x̂ ^{t} = x ^{0} ), and de-
fines the obtained point as x̂ ^{t+1} ; see Algorithm 3 in Ap-
pendix F.2. For this procedure we have the following re-
sult.

Theorem 3.3 (Convergence of R-clipped-SSTM). Let
Assumptions 1.1, 1.3, 1.6 with μ > 0 hold for Q =
B 3R (x ∗ ), R ≥ kx ^{0} − x ∗ k ^{2} and R-clipped-SSTM
μR 2
runs clipped-SSTM
p ^{τ} 2 ^{=} ⌈log 2 ^{(} ^{/} α ^{2ε} ^{)⌉} ^{times.} ^{Let}
e
^{LR} ^{t−1} ^{/} ^{ε} t ^{,} ^{(} ^{σR} ^{t−1} ^{/} ^{ε} t ^{)} ^{/} ^{(α−1)} }), ^{a} t ^{=}
K t = Θ(max{
α+1 /α
e
e ^{R} / α tk+1 ) be the param-
σK t
Θ(max{1,
^{/} ^{LR} t }), ^{λ} ^{tk} ^{=} ^{Θ(}
eters for the stage t of R-clipped-SSTM, where R t−1 =
2
2 − ^{(t−1)} ^{/} ^{2} R, ε t = μR t−1 / 4 , ln ^{4τ} β ^{K} ^{t} ≥ 1 for all t = 1, . . . , τ
and some β ∈ (0, 1]. Then to guarantee f (x̂ ^{τ} )−f (x ∗ ) ≤ ε
with probability ≥ 1 − β R-clipped-SSTM requires
(s   α )!
L σ ^{2} 2(α−1)
e max
O
oracle calls. (24)
,
μ με

3.2. Acceleration

Next, we focus on the accelerated version of clipped-
SGD called Clipped Stochastic Similar Triangles Method
clipped-SSTM (Gorbunov et al., 2020). The method
constructs three sequences of points {x ^{k} } k≥0 , {y ^{k} } k≥0 ,
{z ^{k} } k≥0 satisfying the following update rules: x ^{0} = y ^{0} =
z ^{0} and

x k+1 =

z

k+1

^{A} k ^{y} ^{k} ^{+} ^{α} k+1 ^{z} ^{k}
,
^{A} k+1

(20)

k+1

k

= z − α k+1 · clip ∇f ξ k (x

y k+1 =

k

^{A} k ^{y} ^{+} ^{α} k+1 ^{z}
^{A} k+1

k+1

,



), λ k ,

Moreover, with probability ≥ 1 − β the iterates of R-
clipped-SSTM at stage t stay in the ball B 2R t−1 (x ∗ ).

(21)

The obtained complexity bound (see the proof in Ap-
pendix F.2) is the first optimal (up to logarithms) high-
probability complexity bound under Assumption 1.1 for
the smooth strongly convex problems. Indeed, the first
term cannot be improved in view of the deterministic lower
bound by Nemirovskij & Yudin (1983), and the second
term is optimal due to Zhang et al. (2020b).

(22)

where A 0 = α 0 = 0, α k+1 = ^{k+2}
2aL ^{,} ^{A} ^{k+1} ^{=} ^{A} ^{k} ^{+} ^{α} ^{k+1} ^{,}
and ξ ^{k} is sampled from D k independently from previous
steps. Our main convergence result for clipped-SSTM is
given in the following theorem.
Theorem 3.2 (Convergence of clipped-SSTM). Let
Assumptions 1.1, 1.3, 1.6 with μ = 0 hold for
Q = B 3R (x ∗ ), R ≥ kx ^{0} − x ∗ k ^{2} and a =
(α+1) /α (α−1) /α
A
Θ(max{A ^{2} , ^{σK}
^{/} ^{LR} }), ^{λ} k ^{=} ^{Θ(} ^{R} ^{/} ^{(α} k+1 ^{A)} ^{),}
4K
where A = ln β , β ∈ (0, 1] are such that A ≥ 1. Then
to guarantee f (y ^{K} ) − f (x ∗ ) ≤ ε with probability ≥ 1 − β
clipped-SSTM requires
(r

 α )!
LR ^{2} σR α−1
e
oracle calls. (23)
,
O max
ε
ε

4. Main Results for Variational Inequalities

4.1. Clipped Stochastic Extragradient

For (quasi strongly) monotone VIPs we consider Clipped
Stochastic Extragradient method (clipped-SEG):

x
e ^{k} = x ^{k} − γ · clip(F ξ 1 k (x ^{k} ), λ k ),

x ^{k+1} = x ^{k} − γ · clip(F ξ 2 k (e
x k ), λ k ),

(25)

(26)

where ξ 1 ^{k} , ξ 2 ^{k} are sampled from D k independently from
previous steps. Our main convergence results for clipped-
SEG are summarized below.

Moreover, with probability ≥
1 − β the iter-
ates of clipped-SSTM stay in the ball B 2R (x ∗ ):
k K
k K
∗
{x k } K+1
k=0 ^{,} {y } k=0 ^{,} {z } k=0 ⊆ ^{B} ^{2R} ^{(x} ^{).}

7

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

λ k = λ = Θ ( R / γA ), where A = ln ^{4(K+1)}
, β ∈ (0, 1] are
β
such that A ≥ 1.
Case 3.
Let Assumptions 1.1, 1.10, 1.9 with
μ > 0 hold for Q = B 2R (x ∗ ) and 0 <
γ  =
O ^{(min{} ^{1} ^{/} ^{lA} ^{,} ^{ln(B} ^{K} ^{)} ^{/} ^{μ(K+1)} }), ^{B} K 
=

Theorem 4.1 (Convergence of clipped-SEG). curiosity
^{Case} ^{1.} Let Assumptions 1.1, 1.3, 1.8 hold for Q =

B 4R (x ∗ ) and 0 < γ = O min{ 1 / LA , R / K ^{1} ^{/α} σA ^{(α−1)} ^{/α} } ,
λ k = λ = Θ ( R / γA ), where A = ln ^{6(K+1)}
≥ 1,
β
β ∈ (0, 1].
Case 2.
Let Assumptions 1.1, 1.3, 1.9 with
μ > 0 hold for Q = B 3R (x ∗ ) and 0 <
γ  =
O ^{(min{} ^{1} ^{/} ^{LA} ^{,} ^{ln(B} ^{K} ^{)} ^{/} ^{μ(K+1)} }), ^{B} K 
=
2(α−1) /α 2 2
μ R / σ 2 A 2(α−1) /α ln 2 (B K ) } ,
Θ max{2, ^{(K+1)}

Θ max{2, ^{(K+1)}

One can find the proofs in Appendix H. The derived high-
probability results generalize the existing SOTA results
from the case of α = 2 (Gorbunov et al., 2022a) to the case
of α < 2.

The proofs are deferred to Appendix G. When α = 2,
the above bounds recover SOTA high-probability bounds
for monotone and quasi-strongly monotone Lipschitz VIP
(Gorbunov et al., 2022a). For the case of α < 2 (27) and
(28) are the first high-probability results for the mentioned
classes. Next, the first terms in these complexity bounds are
optimal (up to logarithms) due to the lower bounds for the
deterministic methods (Ouyang & Xu, 2021; Zhang et al.,
2022). The second term in (28) is also optimal (up to loga-
rithms) due to the lower bounds for stochastic strongly con-
vex minimization (Zhang et al., 2020b). Similarly to the
convex case in minimization, we conjecture that the sec-
ond term in (27) cannot be improved in the monotone case
as well.

5. Key Lemma and Intuition Behind the
Proofs

The proofs of all results in this paper follow a very similar
pattern. To illustrate the main idea, we consider the anal-
ysis of clipped-SGD in the non-convex case. Mimicking
the proof of deterministic GD we derive the following in-
equality:

γ

K
X

k=0

4.2. Clipped Stochastic Gradient Descent-Ascent

x

= x − γ · clip(F ξ k (x ), λ k ),

K
X

k=0

h∇f ^{(x} ^{k} ^{),} ^{θ} k i ^{+} ^{Lγ} ^{2}

(32)

K−1
X

k=0

kθ k k 2 ,

e ξ k (x k ) − ∇f (x k ).
where ∆ k = f (x ^{k} ) − f ∗ and θ k = ∇f
In other words, we separate the deterministic part of the
method from its stochastic part. To obtain the result of
Theorem 3.1 (Case 1) it remains to upper bound with high-
probability the sums from the second line of the formula
above. We do it with the help of Bernstein’s inequality
(Lemma B.2). However, it requires several preliminary
steps. In particular, Bernstein’s inequality needs the ran-
dom variables to be bounded. The magnitudes of sum-
mands depend on ∇f (x ^{k} ) that can be arbitrarily large
due to the stochasticity in x ^{k} . However, (32) allows to
bound ∆ K+1 inductively and, using smoothness, to bound

(29)

where ξ ^{k} is sampled from D k independently from previous
steps. For this method we derive the following convergence
guarantees.

Theorem 4.2 (Convergence of clipped-SGDA). curios
^{Case} ^{1.} Let Assumptions 1.1, 1.10, 1.8 hold for Q =

B 2R (x ∗ ) and 0 < γ = O min{ 1 / lA , R / K ^{1} ^{/α} σA ^{(α−1)} ^{/α} } ,
λ k = λ = Θ ( ^{R} / γA ), β ∈ (0, 1] are such that A ≥ 1.
^{Case} ^{2.} Let Assumptions 1.1, 1.10 hold for Q = B 2R (x ∗  )
and 0 < γ = O min{ 1 / lA , R / K ^{1} ^{/α} σA ^{(α−1)} ^{/α} } ,

k∇f ^{(x} ^{k} ^{)k} ^{2} ^{/} ^{∆} 0 − ^{∆} K+1

− γ

In the star-cocoercive case, we focus on Clipped Stochastic
Gradient Descent-Ascent (clipped-SGDA):

k

,

oracle calls.

oracle calls.

k

μ ^{2} R ^{2} / σ 2 A 2(α−1) /α ln 2 (B K ) }

,
λ k = Θ( exp(−γμ(1+ k / 2 ))R / γA ), where A = ln ^{4(K+1)}
β
β ∈ (0, 1] are such that A ≥ 1.
Then to guarantee Gap R (e
x K
avg ) ≤ ε in ^{Case} ^{1} with
P
K
1 P k
1
k
K
e ^{,} K+1 k=0 kF ^{(x} ^{k} ^{)k} ^{2} ≤ ^{lε} ^{in}
x
e avg ^{=} K+1 k=0 ^{x}
K
∗ 2
^{Case} ^{2,} kx − x k ≤ ε in ^{Case} ^{3} with probability
≥ 1 − β clipped-SGDA requires
(
 α )!

lR ^{2} σR α−1
e
(30)
Case 1 and 2: O max
,
ε
ε
( 
)!
α
 2(α−1)
2
l
σ
e max
Case 2: O
(31)
,
μ μ 2 ε

,
λ k = Θ( exp(−γμ(1+ k / 2 ))R / γA ), where A = ln ^{6(K+1)}
β
β ∈ (0, 1] are such that A ≥ 1.
Then to guarantee Gap R (e
x K
avg ) ≤ ε in ^{Case} ^{1} with
P
K
1
K
k
K
x
e avg ^{=} K+1 k=0 ^{x}
e , kx − x ∗ k ^{2} ≤ ε in ^{Case} ^{2} with
probability ≥ 1 − β clipped-SEG requires
(
 α )!

LR ^{2} σR α−1
e
(27)
,
Case 1: O max
ε
ε
( 
)!
α
 2(α−1)
2
L
σ
e max
Case 2: O
,
(28)
μ μ 2 ε

k+1

2(α−1) /α

8

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

k∇f ^{(x} ^{K+1} ^{)k.} ^{Secondly,} ^{Bernstein’s} ^{inequality} ^{requires}
knowing the bounds on the bias and variance of the clipped
stochastic estimator. For such purposes, we derive the
following result, which is a generalization of Lemma F.5
from (Gorbunov et al., 2020); see also Lemma 10 from
(Zhang et al., 2020b).

ACM SIGSAC conference on computer and communica-
tions security, pp. 308–318, 2016. (Cited on page 5)

Arjevani, Y., Carmon, Y., Duchi, J. C., Foster, D. J., Srebro,
N., and Woodworth, B. Lower bounds for non-convex
stochastic optimization. Mathematical Programming, pp.
1–50, 2022. (Cited on pages 5 and 7)

e =
Lemma 5.1. Let X be a random vector in R ^{d} and X
e
e
clip(X, λ). Then, k X − E[ X]k ≤ 2λ. Moreover, if for
some σ ≥ 0 and α ∈ (1, 2] we have E[X] = x ∈ R ^{d} ,
^{E[kX} − ^{xk} ^{α} ^{]} ≤ ^{σ} ^{α} ^{,} ^{and} kxk ≤ ^{λ} ^{/} ^{2} ^{,} ^{then}

E

E





e − x
E[ X]

e − x
X

e − E[ X]
e
X

2

2





≤

2 α σ α
,
λ α−1

(33)

≤

18λ ^{2−α} σ ^{α} ,

(34)

≤

18λ ^{2−α} σ ^{α} .

(35)

Bennett, G. Probability inequalities for the sum of indepen-
dent random variables. Journal of the American Statisti-
cal Association, 57(297):33–45, 1962. (Cited on page 14)

Cutkosky, A. and Mehta, H. High-probability bounds for
non-convex stochastic optimization with heavy tails. Ad-
vances in Neural Information Processing Systems, 34,
2021. (Cited on pages 1, 4, 5, and 7)

Davis, D., Drusvyatskiy, D., Xiao, L., and Zhang, J. From
low probability to high confidence in stochastic convex
optimization. Journal of Machine Learning Research, 22
(49):1–38, 2021. (Cited on pages 1, 3, and 4)

This lemma can be useful on its own for analyses involving
clipping operators. Moreover, our high-probability analy-
sis does not rely on the choice of clipping explicitly: in the
e ≤ λ and inequalities (33)-(35).
proofs, we use only k Xk
Therefore, our results hold for the methods considered in
this work with any other non-linearity φ λ (x) (not neces-
sary clipping), if it satisfies the conditions from the above
e = φ λ (X).
lemma for X

Dvurechenskii, P., Dvinskikh, D., Gasnikov, A., Uribe, C.,
and Nedich, A. Decentralize and randomize: Faster al-
gorithm for wasserstein barycenters. Advances in Neu-
ral Information Processing Systems, 31, 2018. (Cited on

page 40)

Dzhaparidze, K. and Van Zanten, J. On bernstein-type in-
equalities for martingales. Stochastic processes and their
applications, 93(1):109–117, 2001. (Cited on page 14)

6. Discussion

Freedman, D. A. et al. On tail probabilities for martingales.
the Annals of Probability, 3(1):100–118, 1975. (Cited on

In this work, we contributed to the stochastic optimization
literature via deriving new high-probability results under
Assumption 1.1. Our results can be extended to the min-
imization of functions with Hölder continuous gradients
using similar ideas to (Gorbunov et al., 2021). Another
prominent direction is in obtaining new high-probability
results for other types of non-linearities, e.g., like in
(Polyak & Tsypkin, 1980; Jakovetic et al., 2022).

page 14)

Gasnikov, A. and Nesterov, Y. Universal fast gradi-
ent method for stochastic composit optimization prob-
lems. arXiv preprint arXiv:1604.05275, 2016. (Cited

on page 40)

Ghadimi, S. and Lan, G. Optimal stochastic approximation
algorithms for strongly convex stochastic composite op-
timization i: A generic algorithmic framework. SIAM
Journal on Optimization, 22(4):1469–1492, 2012. (Cited

Acknowledgements

This work was partially supported by a grant for research
centers in the field of artificial intelligence, provided by the
Analytical Center for the Government of the Russian Fed-
eration in accordance with the subsidy agreement (agree-
ment identifier 000000D730321P5Q0002) and the agree-
ment with the Moscow Institute of Physics and Technology
dated November 1, 2021 No. 70-2021-00138.

on pages 2 and 3)

Ghadimi, S. and Lan, G. Stochastic first-and zeroth-order
methods for nonconvex stochastic programming. SIAM
Journal on Optimization, 23(4):2341–2368, 2013. (Cited

on page 2)

Gidel, G., Berard, H., Vignoud, G., Vincent, P., and
Lacoste-Julien, S. A variational inequality perspective
on generative adversarial networks. International Con-
ference on Learning Representations, 2019. (Cited on

References

Abadi, M., Chu, A., Goodfellow, I., McMahan, H. B.,
Mironov, I., Talwar, K., and Zhang, L. Deep learning
with differential privacy. In Proceedings of the 2016

page 2)

9

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y.
Generative adversarial nets. In Ghahramani, Z., Welling,
M., Cortes, C., Lawrence, N., and Weinberger, K. Q.
(eds.), Advances in Neural Information Processing Sys-
tems, volume 27. Curran Associates, Inc., 2014. (Cited

conference on machine learning and knowledge discov-
ery in databases, pp. 795–811. Springer, 2016. (Cited on

page 6)

Karimireddy, S. P., He, L., and Jaggi, M. Learning from
history for byzantine robust optimization. In Interna-
tional Conference on Machine Learning, pp. 5311–5319.
PMLR, 2021. (Cited on page 5)

on page 2)

Goodfellow, I., Bengio, Y., and Courville, A. Deep learn-
ing. MIT press, 2016. (Cited on page 5)

Khaled, A. and Richtárik, P. Better theory for sgd in
the nonconvex world. arXiv preprint arXiv:2002.03329,
2020. (Cited on page 6)

Gorbunov, E., Danilova, M., and Gasnikov, A. Stochastic
optimization with heavy-tailed noise via accelerated gra-
dient clipping. Advances in Neural Information Process-
ing Systems, 33:15042–15053, 2020. (Cited on pages 1, 3,

Korpelevich, G. M. The extragradient method for finding
saddle points and other problems. Matecon, 12:747–756,
1976. (Cited on page 4)

4, 5, 7, 9, 14, 40, and 48)

Li, X. and Orabona, F.
A high probability analy-
sis of adaptive sgd with momentum. arXiv preprint
arXiv:2007.14294, 2020. (Cited on pages 4 and 5)

Gorbunov, E., Danilova, M., Shibaev, I., Dvurechen-
sky, P., and Gasnikov, A. Near-optimal high prob-
ability complexity bounds for non-smooth stochastic
optimization with heavy-tailed noise. arXiv preprint
arXiv:2106.05958, 2021. (Cited on pages 1, 3, 4, 9, 40,

Liu, C., Zhu, L., and Belkin, M. Loss landscapes and op-
timization in over-parameterized non-linear systems and
neural networks. Applied and Computational Harmonic
Analysis, 59:85–116, 2022. (Cited on page 2)

and 43)

Gorbunov, E., Danilova, M., Dobre, D., Dvurechensky,
P., Gasnikov, A., and Gidel, G. Clipped stochastic
methods for variational inequalities with heavy-tailed
noise. arXiv preprint arXiv:2206.01095, 2022a. (Cited

Loizou, N., Berard, H., Gidel, G., Mitliagkas, I., and
Lacoste-Julien, S. Stochastic gradient descent-ascent
and consensus optimization for smooth games: Conver-
gence analysis under expected co-coercivity. Advances
in Neural Information Processing Systems, 34, 2021.

on pages 1, 3, 4, 5, 8, 51, 52, 59, 60, 69, 70, 77, 79, and 80)

Gorbunov, E., Loizou, N., and Gidel, G. Extragradient
method: O( ^{1} / K ) last-iterate convergence for monotone
variational inequalities and connections with cocoerciv-
ity. In International Conference on Artificial Intelligence
and Statistics, pp. 366–402. PMLR, 2022b. (Cited on

(Cited on page 3)

Lojasiewicz, S. A topological property of real analytic sub-
sets. Coll. du CNRS, Les équations aux dérivées par-
tielles, 117(87-89):2, 1963. (Cited on page 2)

pages 38, 51, and 69)

Mertikopoulos, P. and Zhou, Z. Learning in games
with continuous action sets and unknown payoff func-
tions. Mathematical Programming, 173(1):465–507,
2019. (Cited on page 3)

Harker, P. T. and Pang, J.-S. Finite-dimensional variational
inequality and nonlinear complementarity problems: a
survey of theory, algorithms and applications. Mathe-
matical programming, 48(1):161–220, 1990. (Cited on

page 2)

Nazin, A. V., Nemirovsky, A., Tsybakov, A. B., and Ju-
ditsky, A. Algorithms of robust stochastic optimization
based on mirror descent method. Automation and Re-
mote Control, 80(9):1607–1627, 2019. (Cited on pages 1,

Jakovetic, D., Bajovic, D., Sahu, A. K., Kar, S., Milose-
vic, N., and Stamenkovic, D. Nonlinear gradient map-
pings and stochastic optimization: A general framework
with applications to heavy-tail noise. arXiv preprint
arXiv:2204.02593, 2022. (Cited on page 9)

3, 4, and 5)

Necoara, I., Nesterov, Y., and Glineur, F. Linear conver-
gence of first order methods for non-strongly convex op-
timization. Mathematical Programming, 175(1):69–107,
2019. (Cited on page 3)

Juditsky, A., Nemirovski, A., and Tauvel, C. Solving varia-
tional inequalities with stochastic mirror-prox algorithm.
Stochastic Systems, 1(1):17–58, 2011. (Cited on pages 3,

4, and 5)

Nemirovski, A., Juditsky, A., Lan, G., and Shapiro, A. Ro-
bust stochastic approximation approach to stochastic pro-
gramming. SIAM Journal on optimization, 19(4):1574–
1609, 2009. (Cited on pages 2 and 3)

Karimi, H., Nutini, J., and Schmidt, M. Linear conver-
gence of gradient and proximal-gradient methods under
the Polyak-Lojasiewicz condition. In Joint European

10

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Nemirovskij, A. S. and Yudin, D. B. Problem complexity
and method efficiency in optimization. 1983. (Cited on

Vural, N. M., Yu, L., Balasubramanian, K., Volgushev, S.,
and Erdogdu, M. A. Mirror descent strikes again: Opti-
mal stochastic convex optimization under infinite noise
variance. In Conference on Learning Theory, pp. 65–102.
PMLR, 2022. (Cited on page 13)

pages 4, 7, and 13)

Nesterov, Y. Dual extrapolation and its applications to solv-
ing variational inequalities and related problems. Mathe-
matical Programming, 109(2):319–344, 2007. (Cited on

Yue, P., Fang, C., and Lin, Z. On the lower bound of min-
imizing Polyak-Lojasiewicz functions. arXiv preprint
arXiv:2212.13551, 2022. (Cited on page 6)

page 2)

Nesterov, Y. et al. Lectures on convex optimization, volume
137. Springer, 2018. (Cited on page 14)

Zhang, J. and Cutkosky, A. Parameter-free regret in
high probability with heavy tails.
arXiv preprint
arXiv:2210.14355, 2022. (Cited on page 4)

Ouyang, Y. and Xu, Y. Lower complexity bounds of first-
order methods for convex-concave bilinear saddle-point
problems. Mathematical Programming, 185(1):1–35,
2021. (Cited on page 8)

Zhang, J., He, T., Sra, S., and Jadbabaie, A. Why
gradient clipping accelerates training: A theoret-
ical justification for adaptivity.
In International
Conference on Learning Representations, 2020a. URL
https://openreview.net/forum?id=BJgnXpVYwS.

Pascanu, R., Mikolov, T., and Bengio, Y. On the difficulty
of training recurrent neural networks. In International
conference on machine learning, pp. 1310–1318, 2013.

(Cited on page 5)

(Cited on pages 5 and 19)

Zhang, J., Karimireddy, S. P., Veit, A., Kim, S., Reddi, S. J.,
Kumar, S., and Sra, S. Why are adaptive methods good
for attention models? Advances in Neural Information
Processing Systems, 33, 2020b. (Cited on pages 2, 4, 5, 6,

Patel, V. and Berahas, A. S. Gradient descent in the ab-
sence of global lipschitz continuity of the gradients: Con-
vergence, divergence and limitations of its continuous
approximation. arXiv preprint arXiv:2210.02418, 2022.

7, 8, 9, and 13)

(Cited on page 2)

Zhang, J., Hong, M., and Zhang, S. On lower iteration
complexity bounds for the convex concave saddle point
problems. Mathematical Programming, 194(1-2):901–
935, 2022. (Cited on page 8)

Patel, V., Zhang, S., and Tian, B. Global convergence and
stability of stochastic gradient descent. Advances in Neu-
ral Information Processing Systems, 35:36014–36025,
2022. (Cited on page 2)

Polyak, B. T. Gradient methods for the minimisation
of functionals. USSR Computational Mathematics and
Mathematical Physics, 3(4):864–878, 1963. (Cited on

page 2)

Polyak, B. T. and Tsypkin, Y. Z. Optimal pseudogradient
adaptation algorithms. Avtomatika i Telemekhanika, (8):
74–84, 1980. (Cited on page 9)

Robbins, H. and Monro, S. A stochastic approximation
method. The annals of mathematical statistics, pp. 400–
407, 1951. (Cited on page 1)

Ryu, E. K. and Yin, W. Large-scale convex optimization
via monotone operators, 2021. (Cited on page 2)

Shalev-Shwartz, S. and Ben-David, S. Understanding ma-
chine learning: From theory to algorithms. Cambridge
university press, 2014. (Cited on page 2)

Song, C., Zhou, Z., Zhou, Y., Jiang, Y., and Ma, Y. Op-
timistic dual extrapolation for coherent non-monotone
variational inequalities. Advances in Neural Information
Processing Systems, 33:14303–14314, 2020. (Cited on

page 3)

11

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Contents

1

1 Introduction

1.1

Technical Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2

1.2

Closely Related Works and Our Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

2 Failure of Standard SGD

6

3 Main Results for Minimization Problems

6

3.1

SGD with Clipping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

3.2

Acceleration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

4 Main Results for Variational Inequalities

7

4.1

Clipped Stochastic Extragradient . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7

4.2

Clipped Stochastic Gradient Descent-Ascent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

8

5 Key Lemma and Intuition Behind the Proofs

8

6 Discussion

9

A Additional Related Work

13

B Useful Facts

14

C Proof of Lemma 5.1

15

D Proof of Theorem 2.1

17

E Missing Proofs for clipped-SGD

19

E.1 Non-Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

19

E.2 Polyak-Łojasiewicz Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

25

E.3 Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

32

E.4 Quasi-Strongly Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

38

F Missing Proofs for clipped-SSTM and R-clipped-SSTM

40

F.1

Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

40

F.2

Strongly Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

48

G Missing Proofs for clipped-SEG

51

G.1 Monotone Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

51

G.2 Quasi-Strongly Monotone Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

59

H Missing Proofs for clipped-SGDA

69

H.1 Monotone Star-Cocoercive Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

69

H.2 Star-Cocoercive Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

77

H.3 Quasi-Strongly Monotone Star-Cocoercive Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

79

12

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

A. Additional Related Work

In this section, we provide an overview of the existing in-expectation convergence results under Assumption 1.1.

Convex minimization. The first in-expectation result under Assumption 1.1 is given by Nemirovskij & Yudin (1983),
^{who} ^{derive} ^{4} O(ε ^{−} ^{α} ^{/} ^{(α−1)} ^{)} ^{complexity} ^{for} ^{Mirror} ^{Descent} ^{applied} ^{to} ^{the} ^{minimization} ^{of} ^{convex} ^{functions} ^{with} ^{bounded}
gradients. This result was recently extended by Vural et al. (2022) to the uniformly convex functions, and matching lower
^{bounds} ^{were} ^{derived.} ^{In} ^{the} ^{strongly} ^{convex} ^{case,} ^{Zhang} ^{et} ^{al.} ^{(2020b)} ^{prove} O(ε ^{−} ^{α} ^{/} ^{2(α−1)} ^{)} ^{complexity} ^{for} ^{clipped-SGD.}
However, all these results rely on the boundedness of the gradient. To the best of our knowledge, there are no results for
smooth convex problems under Assumption 1.1 without assuming that the gradient is bounded even in terms of expectation.

^{Non-convex} ^{minimization.} ^{In} ^{the} ^{non-convex} ^{smooth} ^{case,} ^{Zhang} ^{et} ^{al.} ^{(2020b)} ^{prove} O(ε ^{−} ^{(3α−2)} ^{/} ^{(α−1)} ^{)} ^{complexity}
for clipped-SGD to produce a point x such that Ek∇f (x)k ≤ ε. In the same work, the authors derive
p the matching lower
bound. However, both upper and lower bounds are derived for Ek∇f (x)k which is smaller than Ek∇f (x)k ^{2} . The later
one is stronger and is more standard performance metric for stochastic non-convex optimization. Therefore, the question
of deriving lower and matching upper bounds for the standard metric remains open.

4

In this section, we hide in O(·) all dependencies except the dependency on ε.

13

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

B. Useful Facts

Smoothness.

If f is L-smooth on convex set Q ⊆ R ^{d} , then for all x, y ∈ Q (Nesterov et al., 2018)

^{f} ^{(y)} ≤ ^{f} ^{(x)} ^{+} h∇f ^{(x),} ^{y} − ^{xi} ^{+}

L
ky − xk 2 .
2

(36)

In particular, if x and y = x − L ^{1} ∇f (x) lie in Q, then the above inequality gives

f (y) ≤ f (x) −

1
1
1
k∇f ^{(x)k} ^{2} ^{+}
k∇f ^{(x)k} ^{2} ^{=} ^{f} ^{(x)} −
k∇f ^{(x)k} ^{2}
L
2L
2L

and

k∇f ^{(x)k} ^{2} ≤ ^{2L} ^{(f} ^{(x)} − ^{f} ^{(y))} ≤ ^{2L} ^{(f} ^{(x)} − ^{f} ∗ ^{)}

^{under} ^{the} ^{assumption} ^{that} ^{f} ∗ ^{=} ^{inf} x∈Q ^{f} ^{(x)} ^{>} −∞. ^{In} ^{other} ^{words,} ^{(7)} ^{holds} ^{for} ^{any} ^{x} ∈ ^{Q} ^{such} ^{that} ^{(x−} L ^{1} ∇f ^{(x))} ∈ ^{Q.}
For example, if x ∗ is an optimum of f , then L-smoothness on B 2R (x ∗ ) implies that (7) holds on B R (x ∗ ): indeed, for any
x ∈ B R (x ∗ ) we have

x −

(6)
1
1
∇f ^{(x)} − ^{x} ^{∗} ≤ kx − ^{x} ^{∗} k ^{+} k∇f ^{(x)k} ≤ ^{2kx} − ^{x} ^{∗} k ≤ ^{2R.}
L
L

This derivation means that, in the worst case, to have (7) on a set Q we need to assume smoothness on a slightly larger set.

Parameters in clipped-SSTM.
A k .

To analyze clipped-SSTM we use the following lemma about its parameters α k and

Lemma B.1 (Lemma E.1 from (Gorbunov et al., 2020)). Let sequences {α k } k≥0 and {A k } k≥0 satisfy

α 0 = A 0 = 0,

^{A} k+1 ^{=} ^{A} k ^{+} ^{α} k+1 ^{,}

^{α} k+1 ^{=}

k +2
2aL

∀k ≥ 0,

(37)

where a > 0, L > 0. Then for all k ≥ 0

^{A} k+1

^{A} k+1

(k + 1)(k + 4)
,
4aL
2
≥ aLα k+1 .

=

(38)

(39)

Bernstein inequality. One of the final steps in our proofs is in the proper application of the following lemma known as
Bernstein inequality for martingale differences (Bennett, 1962; Dzhaparidze & Van Zanten, 2001; Freedman et al., 1975).

Lemma B.2. Let the sequence of random variables {X i } i≥1 form a martingale difference sequence, i.e.


def
E [X i | X i−1 , . . . , X 1 ] = 0 for all i ≥ 1. Assume that conditional variances σ i ^{2} = E X i ^{2} | X i−1 , . . . , X 1 exist and
are bounded and assume also that there exists deterministic constant c > 0 such that |X i | ≤ c almost surely for all i ≥ 1.
Then for all b > 0, G > 0 and n ≥ 1
)
( n


n
X
X
b 2
2
σ i ≤ G ≤ 2 exp −
X i > b and
P
.
(40)
2G + 2cb / 3
i=1
i=1

14

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

C. Proof of Lemma 5.1

e = clip(X, λ). Then,
Lemma C.1 (Lemma 5.1). Let X be a random vector in R ^{d} and X

e − E[ X]
e ≤ 2λ.
X

Moreover, if for some σ ≥ 0 and α ∈ [1, 2)

E[X] = x ∈ R ^{d} ,

(41)

E[kX − xk ^{α} ] ≤ σ ^{α}

(42)

≤

2 α σ α
,
λ α−1

(43)

≤

18λ ^{2−α} σ ^{α} ,

(44)

≤

18λ ^{2−α} σ ^{α} .

(45)

^{and} kxk ≤ ^{λ} ^{/} ^{2} ^{,} ^{then}

E

E





e − x
E[ X]

e − x
X

e − E[ X]
e
X

2

2





Proof. Proof of (41): by definition of a clipping operator, we have

h i
e − E X
e
X

h i
e + E X
e
X

≤

^{=} kclip(X, ^{λ)k} ^{+} kE ^{[clip(X,} ^{λ)]k}






λ
λ
X + E min 1,
X
≤
min 1,
kXk
kXk
^{=} ^{min} {kXk ^{,} ^{λ}} ^{+} ^{E} ^{[min} {kXk ^{,} ^{λ}]}
≤ λ + λ = 2λ.

Proof of (43): To start the proof, we introduce two indicator random variables. Let

^{χ} ^{=} ^{I} {X:kXk>λ} ^{=}

(

^{1,} ^{if} kXk ^{>} ^{λ,}
^{,} ^{η} ^{=} ^{I} { X:kX−xk> ^{λ} } ^{=}
2
0, otherwise

^{Moreover,} ^{since} kXk ≤ kxk ^{+} kX − ^{xk}
Using that

we obtain

kxk≤ ^{λ} ^{/} ^{2}

≤

(

1, if kX − xk > λ 2 ,
.
0, otherwise

λ
2 + kX − xk, we have χ ≤ η. We are now in a position to show (43).



λ
e = min 1, ^{λ}
X
X = χ
X + (1 − χ)X,
kXk
kXk

h i
e − x
E X

(46)

=

=

≤

=

 


λ
− 1 X − x
E X + χ
kXk
 
 
λ
− 1 X
E χ
kXk
 


λ
E χ
− ^{1} kXk
kXk


 
λ
kXk ^{.}
E χ 1 −
kXk

15

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

^{Since} ^{1} − ^{λ} ^{/} kXk ∈ ^{(0,} ^{1)} ^{when} ^{χ} 6 ^{=} ^{0,} ^{we} ^{derive}
h i
e − x
E X
≤ E [χkXk]

χ≤η

≤
≤

(∗)

≤

(42)

≤

E [ηkXk]
E [ηkX − xk + ηkxk]

 α  α−1
α 1 / α
α
^{+} kxkE ^{[η]}
(E [kX − xk ])
E η α−1
1−α
 α  α
λ
σ E η 1−α
+ E [η] ,
2

where in (∗) we applied Hölder’s inequality. By Markov’s inequality,




 α 
λ α
λ
α
1−α
E η
= P kX − xk > α
= E [η] = P kX − xk >
2
2
α
2
≤
E [kX − xk ^{α} ]
α
λ
  α
2σ
.
≤
λ

Thus, in combination with the previous chain of inequalities, we finally have
  α
  α−1
h i
λ 2σ
2 α σ α
2σ
e
E X − x
≤ σ
+
^{=} α−1 ^{.}
λ
2 λ
λ

e − xk ≤ k Xk
e ^{+} kxk ≤ ^{λ} ^{+} ^{λ} ^{=} ^{3λ} ^{,} ^{we} ^{have}
Proof of (44): Using k X
2
2
h
i
h
i
e − xk 2
e − xk α k X
e − xk 2−α
E k X
=
E k X
  2−α h
i
3λ
e − xk α χ + k X
e − xk α (1 − χ)
≤
E k X
2

  2−α 
α
3λ
λ
α
E χ
X − x + kX − xk (1 − χ)
=
2
kXk
  2−α  
 α

3λ
λ
≤
^{X} ^{+} kxk
E χ
+ kX − xk α (1 − χ)
2
kXk





 α

λ
2−α
kxk≤ 2
3λ
3λ
≤
E χ
+ σ α ,
2
2

where in the last inequality we applied (42) and 1 − χ ≤ 1. By (47) and χ ≤ η, we obtain
  α   2−α
i
h
3λ
9λ 2 2σ
2
e
+
σ α
≤
E k X − xk
4
λ
2


9λ 2
2 α σ α
α
≤
2 + α
4
3
λ α

≤ 18λ ^{2−α} σ ^{α} .

Proof of (45): Using variance decomposition and (44), we have


i
h
2
e − xk ^{2} ≤ 18λ ^{2−α} σ ^{α} .
e
e
E X − E[ X]
≤ E k X

16

(47)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

D. Proof of Theorem 2.1

In this section, we give an example of the problem for which SGD without clipping leads to a weak high-probability
convergence guarantee even under the strong assumption of bounded variance. Theorem below formally states our result,
showing that, in the worst-case, the bound for SGD scales worse than that of clipped-SGD in terms of the probability β.

Theorem D.1. For any ε > 0, β ∈ (0, 1), and SGD parameterized by the number of steps K and stepsize γ, there exists
problem (2) such that Assumptions 1.1, 1.3, and 1.6 hold with α = 2, 0 < μ ≤ L and for the iterates produced by SGD
with any stepsize 0 < γ ≤ ^{1} / μ


P kx K − x ∗ k 2 ≥ ε ≤ β =⇒ K = Ω



σ
√
μ βε



.

(48)

2

Proof. To prove the above theorem, we consider the simple one-dimensional problem f (x) = ^{μx} / 2 . It is easy to see
that the considered problem is μ-strongly convex, μ-smooth, and has optimum at x ∗ = 0. We construct the noise in an
adversarial way with respect to the parameters of the SGD. Concretely, the noise depends on the number of iterates N ,
stepsize γ, target precision ε, the starting point x ^{0} , and bound on the variance σ ^{2} such that

∇f ξ k (x k ) = μx k − σz k ,

where


0,


 

1
 −A, ^{with} ^{probability} 2A
2 ,
z k = 
1

0
with
probability
1
−
 
A 2 ,

 
1
A,
with probability 2A
2 ,

where A = max

n √

2 ε
γσ , 1

if k < K − 1 or (1 − γμ) ^{K} |x ^{0} | >

√

ε,

∀k ∈ {0, ^{1,} ^{.} ^{.} ^{.} ^{,} ^{K} − ^{1},}

otherwise

(49)

o
 


. We note that E z ^{k} = 0. Therefore, E ∇f ξ k (x ^{k} ) = μx ^{k} = ∇f (x ^{k} ). Furthermore,



 
1 2
1 2
Var z ^{k} = E (z ^{k} ) ^{2} ≤
A +
A = 1,
2A 2
2A 2

which implies that Assumption 1.1 holds for α = 2. We note that our construction depends on the parameters of the
algorithm and the target value ε. However, our analysis of the methods with clipping works in such generality.

Let us now analyze the properties of the introduced problem. We are interested in the situation when


P kx K − x ∗ k 2 ≥ ε ≤ β

√
for β ∈ (0, 1). We first prove that this implies that (1 − γμ) ^{K} |x ^{0} | ≤ ε. To do that we proceed by contradiction and
assume that
√
(1 − γμ) ^{K} |x ^{0} | > ε.
(50)

^{By} ^{construction,} ^{this} ^{implies} ^{that} ^{z} k ^{=} ^{0,} ∀k ∈ {0, ^{1,} ^{.} ^{.} ^{.} ^{,} ^{K}.} ^{This,} ^{in} ^{turn,} ^{implies} ^{that} ^{x} ^{K} ^{=} ^{(1} − ^{γμ)} ^{K} ^{x} ^{0} ^{,} ^{and,} ^{further,}
by (50) and since x ∗ = 0, that



P kx K − x ∗ k 2 ≥ ε = P kx K k 2 ≥ ε = 1.

√

√

ln |x 0 ε |
ln |x 0 ε |
0
√
|
1
√ . Using
Thus, the contradiction shows that ^{(1} − ^{γμ)} |x | ≤ ^{ε,} which yields ^{K} ≥ ln(1−γμ)
^{≥} −γμ
≥ γμ
= ln |x
ε

K

0

0

|
1
√ , we obtain
(49) with K ≥ γμ
log ^{|x}
ε

kx ^{K} − x ∗ k ^{2} = ((1 − γμ) ^{K} x ^{0} + γσz K ) ^{2} .

17

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Furthermore,

√



√
P kx ^{K} − x ^{∗} k ^{2} ≥ ε = P (1 − γμ) ^{K} x ^{0} + γσz K ≥ ε


√
√
= P γσz K ≥ ε − (1 − γμ) ^{K} x ^{0} + P γσz K ≤ − ε − (1 − γμ) ^{K} x ^{0}


√
√
≥ P γσz K ≥ ε + (1 − γμ) ^{K} x ^{0} + P γσz K ≤ − ε − (1 − γμ) ^{K} x ^{0}

√
^{=} ^{P} |γσz K | ≥ ^{ε} ^{+} ^{(1} − ^{γμ)} ^{K} ^{x} ^{0}

√ 

√
2 ε
.
≥ ^{P} |γσz K | ≥ ^{2} ^{ε} ^{=} ^{P} |z K | ≥
γσ

Now if ^{2} γσ ^{ε} < 1 then A = 1. Therefore,


√ 

2 ε
≤ P kx K − x ∗ k 2 > ε < β,
1 = P |z K | ≥
γσ

√

yielding contradiction, which implies that if P kx ^{K} − x ∗ k ^{2} > ε < β for our constructed problem, then ^{2} γσ ^{ε} ≥ 1, i.e.,

√

√

γ ≤ ^{2} σ ^{ε} . For γ ≤ ^{2} σ ^{ε} , we have

√


√ 
 K
1
γ 2 σ 2
2 ε
∗ 2
= 2 =
.
β ≥ P kx − x k ≥ ε ≥ P |z K | ≥
γσ
A
4ε

0

|
1
√ yields
log ^{|x}
This implies that γ ≤ ^{2} σ ^{βε} . Combining this inequality with K ≥ γμ
ε

K ≥

σ
|x 0 |
√ log √
ε
2μ βε

and concludes the proof.

18

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

E. Missing Proofs for clipped-SGD

In this section, we provide all the missing details and proofs of the results for clipped-SGD. For brevity, we will use the
e ξ k (x ^{k} ) = clip(∇f ξ k (x ^{k} ), λ k ).
following notation: ∇f

Algorithm 1 Clipped Stochastic Gradient Descent (clipped-SGD) (Pascanu et al., 2013)

Input: starting point x ^{0} , number of iterations K, stepsize γ > 0, clipping levels {λ k } ^{K−1}
k=0 ^{.}
1: for k = 0, . . . , K − 1 do

e ξ k (x ^{k} ) = clip ∇f ξ k (x ^{k} ), λ k using a fresh sample ξ ^{k} ∼ D k
2:
Compute ∇f
k+1
k
e ξ k (x k )
3:
x
= x − γ ∇f
4: end for
Output: x ^{K}

E.1. Non-Convex Functions

We start the analysis of clipped-SGD in the non-convex case with the following lemma that follows the proof of determin-
istic GD and separates the stochasticity from the determinisitc part of the method.

√

√

Lemma E.1. Let Assumptions 1.2 and 1.3 hold on Q = {x ∈ R ^{d} | ∃y ∈ R ^{d} : f (y) ≤ f ∗ + 2∆ and kx − yk ≤ ^{∆} / 20 L },
where ∆ ≥ ∆ 0 = f (x ^{0} ) − f ∗ , and let stepsize γ satisfy γ < L ^{2} . If x ^{k} ∈ Q for all k = 0, 1, . . . , K, K ≥ 0, then after K
iterations of clipped-SGD we have

 K−1

Lγ X
γ 1 −
k∇f ^{(x} ^{k} ^{)k} ^{2}
2

k=0

≤

(f (x ^{0} ) − f ∗ ) − (f (x ^{K} ) − f ∗ ) − γ(1 − Lγ)

+

θ k

def

=

Lγ
2

2 K−1
X

k=0

K−1
X

k=0

h∇f ^{(x} ^{k} ^{),} ^{θ} k i

kθ k k 2 ,

(51)

e ξ k (x k ) − ∇f (x k ).
∇f

(52)

e ξ k (x ^{k} ) and smoothness of f (1.3) we get that for all k = 0, 1, . . . , K − 1
Proof. Using x ^{k+1} = x ^{k} − γ ∇f

f (x k+1 )

≤

=

(52)

=

=

^{L} k+1
kx
− x k k 2
2
2
e ξ k (x k )i + Lγ k ∇f
e ξ k (x k )k 2
f (x ^{k} ) − γh∇f (x ^{k} ), ∇f
2
Lγ 2
f (x ^{k} ) − γk∇f (x ^{k} )k ^{2} − γh∇f (x ^{k} ), θ k i +
kθ k k 2
2
Lγ 2
k∇f ^{(x} ^{k} ^{)k} ^{2} ^{+} ^{Lγ} ^{2} h∇f ^{(x} ^{k} ^{),} ^{θ} k i
+
2


Lγ 2
Lγ
k
k∇f ^{(x} ^{k} ^{)k} ^{2} − ^{γ(1} − ^{Lγ)h∇f} ^{(x} ^{k} ^{),} ^{θ} k i ^{+}
kθ k k 2 .
f (x ) − γ 1 −
2
2

^{f} ^{(x} ^{k} ^{)} ^{+} h∇f ^{(x} ^{k} ^{),} ^{x} ^{k+1} − ^{x} ^{k} i ^{+}

We rearrange the terms and get



Lγ
γ 1 −
k∇f ^{(x} ^{k} ^{)k} ^{2}
2

≤

f (x ^{k} ) − f (x ^{k+1} ) − γ(1 − Lγ)h∇f (x ^{k} ), θ k i +

19

Lγ 2
kθ k k 2 .
2

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Finally, summing up these inequalities for k = 0, . . . , K − 1, we get
 K−1

K−1
K−1
X
X

Lγ X
k∇f ^{(x} ^{k} ^{)k} ^{2} ≤
f (x ^{k} ) − f (x ^{k+1} ) − γ(1 − Lγ)
h∇f ^{(x} ^{k} ^{),} ^{θ} k i
γ 1 −
2

k=0

k=0

+

Lγ
2

k=0

2 K−1
X

k=0

kθ k k 2

(f (x ^{0} ) − f ∗ ) − (f (x ^{K} ) − f ∗ ) − γ(1 − Lγ)

=

+

Lγ
2

2 K−1
X

k=0

K−1
X

k=0

h∇f ^{(x} ^{k} ^{),} ^{θ} k i

kθ k k 2 ,

which concludes the proof.

Using this lemma, we prove the main convergence result for clipped-SGD in the non-convex case.
√
√
^{Theorem} ^{E.2.} ^{Let} ^{Assumptions} ^{1.1,} ^{1.2,} ^{1.3} ^{hold} ^{on} ^{Q} ^{=} {x ∈ ^{R} ^{d} | ∃y ∈ ^{R} ^{d} ^{:} ^{f} ^{(y)} ≤ ^{f} ∗ ^{+2∆} ^{and} kx−yk ≤ ^{∆} ^{/} ^{20} ^{L} },
where ∆ ≥ ∆ 0 = f (x ^{0} ) − f ∗ , stepsize




√




1
∆
γ ≤ min
,
,
(53)
α−1


4(K+1)
√

α 
1
1
80L
ln
4(K+1)



β

27 α 20σ LK α ln

β

and clipping level

λ k = λ =

√
∆

,
√
20 Lγ ln 4(K+1)
β

(54)

≥ 1. Then, after K iterations of clipped-SGD the iterates with
for some K ≥ 0 and β ∈ (0, 1] such that ln ^{4(K+1)}
β
probability at least 1 − β satisfy

K

1 X
2∆

.
k∇f ^{(x} ^{k} ^{)k} ^{2} ≤ 
K +1
γ 1 − Lγ (K + 1)

k=0

(55)

2

In particular, when γ equals the minimum from (53), then the iterates produced by clipped-SGD after K iterations with
probability at least 1 − β satisfy
 


√
α−1
K 
K
K

α
X
L∆σ
ln
L∆
ln
1
β
β
 ,
(56)
,
k∇f ^{(x} ^{k} ^{)k} ^{2} ^{=} O  ^{max}
α−1

 K
K +1
α
K

k=0

1
^{meaning} ^{that} ^{to} ^{achieve} K+1



K
P

k=0

k∇f ^{(x} ^{k} ^{)k} ^{2} ≤ ^{ε} ^{with} ^{probability} ^{at} ^{least} ^{1} − ^{β} ^{clipped-SGD} ^{requires}


 L∆

L∆
ln
,
K = O  max
 ε
βε

√

L∆σ
ε

α
! α−1



1
ln 
β

 
α 
! α−1
√

L∆σ
 

ε

iterations/oracle calls.

(57)

Proof. Let ∆ k = f (x ^{k} ) − f ∗ for all k ≥ 0. Next, our goal is to show by induction that ∆ l ≤ 2∆ with high probability,
which allows to apply the result of Lemma E.1 and then use Bernstein’s inequality to estimate the stochastic part of the
upper-bound. More precisely, for each k = 0, . . . , K + 1 we consider probability event E k defined as follows: inequalities

t−1

t−1

l=0

l=1

X
Lγ 2 X
kθ l k ^{2} − γ(1 − Lγ)
h∇f ^{(x} ^{l} ^{),} ^{θ} l i ≤
2

∆ t

20

≤

∆,

(58)

2∆

(59)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

hold for all t = 0, 1, . . . , k simultaneously. We want to prove via induction that P{E k } ≥ 1 − ^{kβ} / (K+1) for all k =
0, 1, . . . , K + 1. For k = 0 the statement is trivial. Assume that the statement is true for some k = T − 1 ≤ K:
P{E T −1 } ≥ 1 − ^{(T} −1)β / (K+1) . One needs to prove that P{E T } ≥ 1 − ^{T} ^{β} / (K+1) . First, we notice that probability event
E T −1 implies that ∆ t ≤ 2∆ for all t = 0, 1, . . . , T − 1, i.e., x ^{t} ∈ {y ∈ R ^{d} | f (y) ≤ f ∗ + 2∆} for t = 0, 1, . . . , T − 1.
Moreover, due to the choice of clipping level λ we have
√
√
∆
∆
(54)
T
T −1
T −1
e
√
≤ √ .
kx − x
k = γk ∇f ξ T −1 (x
)k ≤ γλ =
4K
20 L ln β
20 L

Therefore, E T −1 implies {x ^{k} } Tk=0 ⊆ Q, meaning that the assumptions of Lemma E.1 are satisfied and we have

A

t−1
X

l=0

k∇f ^{(x} ^{l} ^{)k} ^{2}

≤

A

def

=

∆ 0 − ∆ t − γ(1 − Lγ)



Lγ (53)
γ 1 −
≥ 0
2

t−1
X

t−1

h∇f ^{(x} ^{l} ^{),} ^{θ} l i ^{+}

k=0

Lγ 2 X
kθ l k 2 ,
2

(60)

l=0

(61)

for all t = 0, 1, . . . , T simultaneously and for all t = 1, . . . , T − 1 this probability event also implies that
!
t−1
t−1
t−1
2 X
X
X
(58), 2∆
(60) 1
Lγ
∆ − γ(1 − Lγ)
h∇f ^{(x} ^{l} ^{),} ^{θ} l i ^{+}
.
kθ l k 2 ≤
k∇f ^{(x} ^{l} ^{)k} ^{2} ≤
A
2
A

k=0

l=0

Taking into account that A

T P
−1

t=0

(62)

l=0

k∇f ^{(x} ^{t} ^{)k} ^{2} ≥ ^{0,} ^{we} ^{also} ^{derive} ^{that} ^{E} T −1 ^{implies}

∆ T ≤ ∆ +

T
−1
T −1
X
Lγ 2 X
h∇f ^{(x} ^{t} ^{),} ^{θ} t i.
kθ t k ^{2} − γ(1 − Lγ)
^{2} t=0
t=0

Next, we define random vectors

η t =

(

∇f (x t ),
0,

(63)

√
^{if} k∇f ^{(x} ^{t} ^{)k} ≤ ^{2} ^{L∆,}
otherwise,

for all t = 0, 1, . . . , T − 1. By definition these random vectors are bounded with probability 1
√
kη t k ≤ 2 L∆.

(64)

Moreover, for t = 1, . . . , T − 1 event E T −1 implies
p
√
(53),(54) λ
(7) q
,
k∇f ^{(x} ^{l} ^{)k} ≤ ^{2L(f} ^{(x} ^{l} ^{)} − ^{f} ∗ ^{)} ^{=} ^{2L∆} l ≤ ^{2} ^{L∆} ≤
2

(65)

meaning that E T −1 implies that η t = ∇f (x ^{t} ) for all t = 0, 1, . . . , T − 1. Next, we define the unbiased part and the bias of
θ t as θ t ^{u} and θ t ^{b} , respectively:
h
h
i
i
e ξ t (x t ) − ∇f (x t ).
e ξ t (x t ) , θ t b = E ξ t ∇f
e ξ t (x t ) − E ξ t ∇f
(66)
θ t u = ∇f

We notice that θ t = θ t ^{u} + θ t ^{b} . Using new notation, we get that E T −1 implies

∆ T

≤ ^{∆} −γ(1 − ^{Lγ)}

|

T
−1
X

t=0

{z

1

+ Lγ 2

|

T
−1
X

t=0

hθ t ^{u} ^{,} ^{η} t i −γ(1 − ^{Lγ)}

} |

T
−1
X

{z

t=0

hθ t b , η t i + Lγ 2

2

T
−1
i
h
X
2
2
θ t b .
E ξ t kθ t u k + Lγ 2

{z

4

}

|

t=0

{z

5

21

}

}

|

T
−1 
X

t=0

i
h
2
2
kθ t u k − E ξ t kθ t u k

{z

3

}

(67)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

It remains to derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5, i.e., to finish our inductive
proof we need to show that 1 + 2 + 3 + 4 + 5 ≤ ∆ with high probability. In the subsequent parts of the proof, we will
need to use many times the bounds for the norm and second moments of θ t ^{u} and θ t ^{b} . First, by definition of clipping operator,
we have with probability 1 that
kθ t ^{u} k ≤ 2λ.
(68)

^{Moreover,} ^{since} ^{E} T −1 ^{implies} ^{that} k∇f ^{(x} ^{t} ^{)k} ≤ ^{λ} ^{/} ^{2} ^{for} ^{t} ^{=} ^{0,} ^{1,} ^{.} ^{.} ^{.} ^{,} ^{T} − ^{1} ^{(see} ^{(65)),} ^{then,} ^{in} ^{view} ^{of} ^{Lemma} ^{5.1,} ^{we}
have that E T −1 implies

2 α σ α
,
λ α−1
2−α α
18λ
σ .

kθ t b k ≤
 u 2 
≤
E ξ t kθ t k

(69)

(70)

Upper bound for 1. By definition of θ t ^{u} , we have E ξ t [θ t ^{u} ] = 0 and

E ξ t [−γ(1 − Lγ)hθ t ^{u} , η t i] = 0.

Next, sum 1 has bounded with probability 1 terms:

(64),(68)

(53)

|γ(1 − ^{Lγ)} hθ t ^{u} ^{,} ^{η} t i | ≤ ^{γkθ} t ^{u} k · kη t k

≤

√
(54)
4γλ L∆ =

∆

def

5 ln 4(K+1)
β

= c.

(71)

def

The summands also have bounded conditional variances σ t ^{2} = E ξ t [γ ^{2} (1 − Lγ) ^{2} hθ t ^{u} , η t i ^{2} ]:

 (64)

 (53)



σ t ^{2} ≤ E ξ t γ ^{2} (1 − Lγ) ^{2} kθ t ^{u} k ^{2} · kη t k ^{2} ≤ 4γ ^{2} (1 − Lγ) ^{2} L∆E ξ t kθ t ^{u} k ^{2} ≤ 4γ ^{2} L∆E ξ t kθ t ^{u} k ^{2} .

(72)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {−γ(1 − ^{Lγ)} hθ t ^{u} ^{,} ^{η} t i} ^{T} t=0
is a bounded martingale difference sequence with bounded
2 T −1
^{conditional} ^{variances} {σ t } t=0 ^{.} ^{Next,} ^{we} ^{apply} ^{Bernstein’s} ^{inequality} ^{(Lemma} ^{B.2)} ^{with} ^{X} t ^{=} −γ(1 − ^{Lγ)} hθ t ^{u} ^{,} ^{η} t i,
∆ 2
parameter c as in (71), b = ^{∆}
4(K+1) ^{:}
5 , G =

150 ln

(

∆
^{P} |1| ^{>}
5

β

T
−1
X

and

t=0

σ t 2 ≤

∆ 2

150 ln ^{4(K+1)}
β

)


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
2(K + 1)

Equivalently, we have

β
,
P {E 1 } ≥ 1 −
2(K + 1)

for E 1 =

(

T
−1
X

either

t=0

σ t 2 >

∆ 2

∆
^{or} |1| ≤
5

150 ln ^{4(K+1)}
β

)

.

(73)

In addition, E T −1 implies that

T
−1
X

σ t 2

t=0

(72)

≤

(54)

=

4γ 2 L∆

T
−1
X

 (70)

E ξ t kθ t ^{u} k ^{2} ≤ 72γ ^{2} L∆σ ^{α} T λ ^{2−α}

t=0
4−α α

√ α
σ T L γ ^{α} (53)
∆ 2
.
≤
4(K+1)
50 ln 2−α β
150 ln ^{4(K+1)}
β

9 · 20

α

√

∆

(74)

Upper bound for 2. From E T −1 it follows that

2

=

(54)

=

−γ(1 − ^{Lγ)}

40 α
·
10

T
−1
X

(53)

hθ t b , η t i ≤ γ

T
−1
X

t=0
t=0
√ 2−α √ α α
α
L γ (53) ∆
σ T ∆

ln 1−α 4(K+1)
β

≤

22

5

kθ t b k · kη t k

.

(64),(69) 2 · 2 ^{α} γσ ^{α} T

≤

√
L∆

λ α−1

(75)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Upper bound for 3. First, we have

ii
h

h
= 0.
E ξ t Lγ 2 kθ t u k 2 − E ξ t kθ t u k 2

Next, sum 3 has bounded with probability 1 terms:
i
h

2
2
≤
Lγ 2 kθ t u k − E ξ t kθ t u k

i
h

2
Lγ 2 kθ t u k 2 + E ξ t kθ t u k

(68)

def
The summands also have bounded conditional variances σ
e t 2 = E ξ t

σ
e t 2

50 ln 2 4(K+1)
β

5 ln

≤

∆

def

5 ln 4(K+1)
β

= c.

(76)


i 2 
h

2
u
u 2
2 4
:
L γ kθ t k − E ξ t kθ t k

i i
h
h
u 2
2
u 2
t kθ k
t
≤
Lγ
kθ
k
−
E
E
ξ
ξ
t
t
4(K+1)

∆

(76)

≤

∆

(54)

8Lγ ^{2} λ ^{2} =

≤

β

2Lγ ^{2} ∆

5 ln 4(K+1)
β



E ξ t kθ t u k 2 ,

(77)

io ^{T} ^{−1}
h

n
u 2
u 2
2
t
kθ
k
is a bounded martingale difference
kθ
k
−
E
since ln ^{4K}
≥
1.
In
other
words,
we
showed
that
Lγ
ξ
t
t
β

t=0

−1
sequence
conditional
variances {e
^{σ} t ^{2} } ^{T} t=0
. Next, we apply Bernstein’s inequality (Lemma B.2) with X t =
i
h
 with bounded
2
∆ 2
u
u 2
2
, parameter c as in (76), b = ^{∆}
Lγ kθ t k − E ξ t kθ t k
4(K+1) ^{:}
5 , G =

150 ln

(

^{P} |3| ^{>}

∆
5

T
−1
X

and

t=0

Equivalently, we have

β
P {E 3 } ≥ 1 −
,
2(K + 1)

σ
e t 2 ≤

∆ 2

150 ln ^{4(K+1)}
β

for E 3 =

(

either

t=0

T
−1
X

σ
e t 2 >

b 2
2G + 2cb / 3

∆ 2

150 ln ^{4(K+1)}
β



=

β
.
2(K + 1)

∆
^{or} |3| ≤
5

)

 u 2  (70) 36Lγ ^{2} ∆λ ^{2−α} σ ^{α} T
t kθ k
≤
E
ξ
t
5 ln 4(K+1)
5 ln 4(K+1)
t=0
β
β
√ 4−α √ α α
α
2
α
(53)
σ T ∆
∆
L γ
9 · 20
·
≤
.
3−α 4(K+1)
500
ln
150 ln ^{4(K+1)}

≤

(54)

=

.

(78)

T
−1
X

2Lγ ^{2} ∆

(77)

σ
e t 2

β


≤ 2 exp −

t=0

In addition, E T −1 implies that

T
−1
X

)

β

(79)

β

Upper bound for 4. From E T −1 it follows that

4 =

√ α α α √ 2−α
h
i (70)
α
(53) ∆
L γ σ T ∆
(54) ^{9} · ^{20}
u 2
2 2−α α
Lγ
E ξ t kθ t k ≤ 18Lγ λ
σ T =
≤
·
.
2−α 4(K+1)
200
5
ln
t=0

2

T
−1
X

(80)

β

Upper bound for 5. From E T −1 it follows that

5

= Lγ 2

T
−1
X

θ t b

2 (69) 4

σ T Lγ ^{2} (54) 1600 ^{α} σ ^{2α} T L ^{α} γ ^{2α} ∆ ^{1−α} (53) ∆
=
·
.
≤
400
5
λ 2(α−1)
ln 2(1−α) 4(K+1)

α 2α

≤

t=0

β

Now, we have the upper bounds for 1, 2, 3, 4, 5. In particular, probability event E T −1 implies

(67)

∆ T ≤ ∆ + 1 + 2 + 3 + 4 + 5,

(75) ∆

2 ≤

T
−1
X

t=0

(74)

σ t 2 ≤

5

(80) ∆

,

4 ≤

∆ 2

150 ln

,
4(K+1)

,

5
T
−1
X

t=0

β

23

(81) ∆

5 ≤

(79)

σ
e t 2 ≤

5

,

∆ 2

150 ln ^{4(K+1)}
β

.

(81)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Moreover, we also have (see (73), (78) and our induction assumption)

P{E T −1 } ≥ 1 −

(T − 1)β
,
K +1

P{E 1 } ≥ 1 −

β
,
2(K + 1)

β
,
2(K + 1)

P{E 3 } ≥ 1 −

where

E 1

E 3

=

=

(

(

either

T
−1
X

t=0

either

T
−1
X

t=0

Thus, probability event E T −1 ∩ E 1 ∩ E 3 implies

∆ T

σ t 2 >

≤

∆+

σ
e t 2 >

∆ 2

150 ln ^{4(K+1)}
β

∆ 2

150 ln ^{4(K+1)}
β

∆
^{or} |1| ≤
5

∆
^{or} |3| ≤
5

)

)

,

.

∆ ∆ ∆ ∆ ∆
+
+
+
+
= 2∆,
5
5
5
5
5

which is equivalent to (58) and (59) for t = T , and


Tβ
.
P{E T } ≥ P {E T −1 ∩ E 1 ∩ E 3 } = 1 − P E T −1 ∪ E 1 ∪ E 3 ≥ 1 − P{E T −1 } − P{E 1 } − P{E 3 } ≥ 1 −
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

K

(62)
1 X
2∆
2∆
(53)

= 
k∇f ^{(x} ^{k} ^{)k} ^{2} ≤
Lγ
K +1
A(K + 1)
(K + 1)
γ 1 −

k=0

2

and {x ^{k} } ^{K}
k=0 ⊆ ^{Q,} ^{which} ^{follows} ^{from} ^{(59).}

Finally, if



√


1
∆
,
,
γ ≤ min
 α−1

4(K+1)
√

α 
1
1


4(K+1)

 80L ln β
α
α
27 20σ LK
ln β






then with probability at least 1 − β

K

1 X
k∇f ^{(x} ^{k} ^{)k} ^{2}
K +1

k=0

1
^{To} ^{get} K+1

K
P

k=0

2∆
4∆


≤
Lγ
γ(K + 1)
γ 1 − 2 (K + 1)



 α−1
√
√

α 
1
1
4(K+1)


4(K+1)
 320∆L ln

80 ∆27 α σ LK α ln β
β
= max
,


K +1
K +1








√
α−1

 L∆ ln K
L∆σ ln α ^{K}
β
β
 .
,
= O  max
α−1

 K
K α

≤

k∇f ^{(x} ^{k} ^{)k} ^{2} ≤ ^{ε} ^{with} ^{probability} ^{at} ^{least} ^{1} − ^{β} ^{it} ^{is} ^{sufficient} ^{to} ^{choose} ^{K} ^{such} ^{that} ^{both} ^{terms} ^{in} ^{the}

^{maximum} ^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}


 L∆ L∆
K = O  max
ln
,
 ε
εβ

which concludes the proof.


α
! α−1
√
L∆σ
1
ln 
ε
β

24

 
α 
! α−1
√

L∆σ
  ,

ε

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

E.2. Polyak-Łojasiewicz Functions

In this subsection, we provide a high-probability analysis of clipped-SGD in the case of Polyak-Łojasiewicz functions. As
in the non-convex case, we start with the lemma that handles optimization part of the algorithm and separates it from the
stochastic one.

√

√

Lemma E.3. Let Assumptions 1.3 and 1.4 hold on Q = {x ∈ R ^{d} | ∃y ∈ R ^{d} : f (y) ≤ f ∗ + 2∆ and kx − yk ≤ ^{∆} / 20 L },
where ∆ = f (x ^{0} ) − f ∗ , and let stepsize γ satisfy γ ≤ L ^{1} . If x ^{k} ∈ Q for all k = 0, 1, . . . , K + 1, K ≥ 0, then after K
iterations of clipped-SGD for all x ∈ Q we have

f (x K+1 ) − f ∗

≤

(1 − γμ) ^{K+1} (f (x ^{0} ) − f ∗ ) − γ(1 − Lγ)

+

Lγ
2

K
2 X

k=0

K
X

^{(1} − ^{γμ)} ^{K−k} h∇f ^{(x} ^{k} ^{),} ^{θ} k i

k=0

(1 − γμ) ^{K−k} kθ k k ^{2} ,

(82)

where θ k is defined in (52).

e ξ k (x ^{k} ) and smoothness of f (1.3) we get that for all k = 0, 1, . . . , K
Proof. Using x ^{k+1} = x ^{k} − γ ∇f

f (x k+1 )

≤

≤

(52)

=

1
γ≤ L

≤

(8)

≤

^{L} k+1
kx
− x k k 2
2
2
e ξ k (x k )k 2
e ξ k (x k )i + Lγ k ∇f
f (x ^{k} ) − γh∇f (x ^{k} ), ∇f
2


Lγ
Lγ 2
k
f (x ) − γ 1 −
kθ k k 2
k∇f ^{(x} ^{k} ^{)k} ^{2} − ^{γ(1} − ^{Lγ)h∇f} ^{(x} ^{k} ^{),} ^{θ} k i ^{+}
2
2

^{f} ^{(x} ^{k} ^{)} ^{+} h∇f ^{(x} ^{k} ^{),} ^{x} ^{k+1} − ^{x} ^{k} i ^{+}

Lγ 2
γ
k∇f ^{(x} ^{k} ^{)k} ^{2} − ^{γ(1} − ^{Lγ)h∇f} ^{(x} ^{k} ^{),} ^{θ} k i ^{+}
kθ k k 2
2
2
Lγ 2
kθ k k 2 .
f (x ^{k} ) − γμ(f (x ^{k} ) − f ∗ ) − γ(1 − Lγ)h∇f (x ^{k} ), θ k i +
2

f (x k ) −

By rearranging the terms and subtracting f ∗ , we obtain

f (x k+1 ) − f ∗

≤

(1 − γμ)(f (x ^{k} ) − f ∗ ) − γ(1 − Lγ)h∇f (x ^{k} ), θ k i +

Lγ 2
kθ k k 2 .
2

Unrolling the recurrence, we obtain (82).

^{Theorem} ^{E.4.} ^{Let} ^{Assumptions} ^{1.1,} ^{1.3,} ^{1.4} ^{hold} ^{on} ^{Q} ^{=} {x ∈ ^{R} ^{d} | ∃y ∈ ^{R} ^{d} ^{:} ^{f} ^{(y)} ≤ ^{f} ∗ ^{+2∆} ^{and} kx−yk ≤
where ∆ ≥ ∆ 0 = f (x ^{0} ) − f ∗ , stepsize
(
)
1
ln(B K )
0 < γ ≤ min
,
,
μ(K + 1)
250L ln ^{4(K+1)}
β


2(α−1)


(K + 1) α μ 2 ∆


B K = max 2,
2(α−1)
4(K+1)
 264600 α ^{2} Lσ ^{2} ln α
ln 2 (B K ) 
β

 






 



2(α−1)

 
2

α
K
μ
∆

)! 
(
= Θ  max 1,
,
 
2(α−1)

 
2(α−1)




2 ∆
α
μ
K
2
K


2


max 2,
2(α−1)
 Lσ ln α

β ln
Lσ 2 ln α
( Kβ )

√

√
∆ / 20 L },

(83)

(84)

(85)

and clipping level

√
exp(−γμ(1 + ^{k} / 2 )) ∆
,
λ k =
√
120 Lγ ln ^{4(K+1)}
β

25

(86)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

for some K > 0 and β ∈ (0, 1] such that ln ^{4(K+1)}
≥ 1. Then, after K iterations of clipped-SGD the iterates with
β
probability at least 1 − β satisfy

(87)
f x ^{K+1} − f ∗ ≤ 2 exp(−γμ(K + 1))∆.

In particular, when γ equals the minimum from (83), then the iterates produced by clipped-SGD after K iterations with
probability at least 1 − β satisfy
)!  
(


 
2(α−1)
2(α−1)
2


α
μ
∆
K
2


K


! Lσ 2 ln α
max 2,
2(α−1)



β ln

 
K
2
α


Lσ ln

(
)
μK
β
K

 , (88)
f x − f ∗ = O  max ∆ exp −
,
2(α−1)

K


2
L
ln
α


K
μ


β








meaning that to achieve f x ^{K} − f ∗ ≤ ε with probability at least 1 − β clipped-SGD requires
!
α
  ^{2}  2(α−1)

 α !
  
α
L
L
Lσ
∆
1 Lσ ^{2} 2(α−1)
∆
K = O
ln
,
ln α−1 (B ε ) ,
ln
ln
ln
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

iterations/oracle calls, where

B ε = max










2,

ε ln

 

1
β

∆

Lσ 2
μ 2 ε

(89)






 .
α
 2(α−1)




Proof. As in the previous results, the proof is based on the induction argument and shows that the iterates do not leave
some set with high probability. More precisely, for each k = 0, 1, . . . , K + 1 we consider probability event E k as follows:
inequalities
∆ t ≤ 2 exp(−γμt)∆
(90)

hold for t = 0, 1, . . . , k simultaneously, where ∆ t = f (x ^{t} ) − f ∗ . We want to prove P{E k } ≥ 1 − ^{kβ} / (K+1) for all
k = 0, 1, . . . , K + 1 by induction. The base of the induction is trivial: for k = 0 we have ∆ 0 ≤ ∆ < 2∆ by definition.
Next, assume that for k = T − 1 ≤ K the statement holds: P{E T −1 } ≥ 1 − ^{(T} −1)β / (K+1) . Given this, we need to
prove P{E T } ≥ 1 − ^{T} ^{β} / (K+1) . Since ∆ t ≤ 2 exp(−γμt)∆ ≤ 2∆, we have x ^{t} ∈ {y ∈ R ^{d} | f (y) ≤ f ∗ + 2∆} for
t = 0, 1, . . . , T − 1, where function f is L-smooth. Thus, E T −1 implies

k∇f ^{(x} ^{t} ^{)k}

(7)

≤

for all t = 0, 1, . . . , T − 1. Moreover

T

p
(83),(86) λ t
(90) p
2L(f (x ^{t} ) − f ∗ ) ≤ 2 L exp(−γμt)∆ ≤
2

T −1

kx − x

(86)

e ξ T −1 (x T −1 )k ≤ γλ T −1 ≤
k = γk ∇f

√
∆
√ ,
20 L

meaning that E T −1 implies x ^{T} ∈ {x ∈ R ^{d} | ∃y ∈ R ^{d} : f (y) ≤ f ∗ + 2∆ and kx − yk ≤
and (1 − γμ) ^{T} ≤ exp(−γμT ), we obtain that E T −1 implies

∆ T

≤

exp(−γμT )∆ − γ(1 − Lγ)

+

Lγ
2

−1
2 T
X

l=0

(91)

√

√
^{∆} / 20 L }. Using Lemma E.3

T
−1
X

l=0

^{(1} − ^{γμ)} ^{T} ^{−1−l} h∇f ^{(x} ^{l} ^{),} ^{θ} l i

(1 − γμ) ^{T} −1−l kθ l k ^{2} .

To handle the sums above, we introduce a new notation:
(
√
√
∇f ^{(x} ^{t} ^{),} ^{if} k∇f ^{(x} ^{t} ^{)k} ≤ ^{2} ^{L} ^{exp(−} ^{γμt} ^{/} ^{2} ^{)} ^{∆,}
η t =
0,
otherwise,

26

(92)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

for t = 0, 1, . . . , T − 1. These vectors are bounded almost surely:
√
√
kη t k ≤ 2 L exp(− ^{γμt} / 2 ) ∆

(93)

for all t = 0, 1, . . . , T − 1. In other words, E T −1 implies η t = ∇f (x ^{t} ) for all t = 0, 1, . . . , T − 1, meaning that from
E T −1 it follows that

∆ T

≤

exp(−γμT )∆ − γ(1 − Lγ)

+

Lγ
2

−1
2 T
X

l=0

T
−1
X

l=0

(1 − γμ) ^{T} −1−l hη l , θ l i

(1 − γμ) ^{T} −1−l kθ l k ^{2} .

To handle the sums appeared on the right-hand side of the previous inequality we consider unbiased and biased parts of θ l :
h
h
i
i
e ξ t (x t ) − ∇f (x t ).
e ξ t (x t ) , θ b = E ξ t ∇f
e ξ t (x t ) − E ξ t ∇f
(94)
θ t u = ∇f
t

for all l = 0, . . . , T − 1. By definition we have θ l = θ l ^{u} + θ l ^{b} for all l = 0, . . . , T − 1. Therefore, E T −1 implies

∆ T

≤

^{exp(−γμT} ^{)∆} −γ(1 − ^{Lγ)}

+ Lγ 2

|

+ Lγ 2

|

T
−1
X

l=0

|

T
−1
X

l=0

^{(1} − ^{γμ)} ^{T} ^{−1−l} hη l ^{,} ^{θ} l ^{u} i −γ(1 − ^{Lγ)}

{z

} |

1

l=0

(1 − γμ) ^{T} −1−l hη l , θ l ^{b} i

{z

2

T
−1
X




(1 − γμ) ^{T} −1−l E ξ l kθ l ^{u} k ^{2} + Lγ ^{2}
(1 − γμ) ^{T} −1−l kθ l ^{u} k ^{2} − E ξ l kθ l ^{u} k ^{2}

{z

}

3

T
−1
X

l=0

T
−1
X

(1 − γμ) ^{T} −1−l kθ l ^{b} k ^{2} .

{z

|

l=0

{z

4

}

}

(95)

}

5

where we also apply inequality ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} to upper bound kθ l k ^{2} . It remains to
derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5, i.e., to finish our inductive proof we need
to show that 1 + 2 + 3 + 4 + 5 ≤ exp(−γμT )∆ with high probability. In the subsequent parts of the proof, we will
need to use many times the bounds for the norm and second moments of θ t ^{u} and θ t ^{b} . First, by definition of clipping operator,
we have with probability 1 that
kθ l u k ≤ 2λ l .
(96)

^{Moreover,} ^{since} ^{E} T −1 ^{implies} ^{that} k∇f ^{(x} ^{l} ^{)k} ^{2} ≤ ^{λ} ^{l} ^{/} ^{2} ^{for} ^{all} ^{l} ^{=} ^{0,} ^{1,} ^{.} ^{.} ^{.} ^{,} ^{T} − ^{1} ^{(see} ^{(91)),} ^{from} ^{Lemma} ^{5.1} ^{we} ^{also} ^{have}
that E T −1 implies

θ l b ≤

for all l = 0, 1, . . . , T − 1.

Upper bound for 1.

2 α σ α
,
λ α−1
l

i
h
2
σ α ,
E ξ l kθ l ^{u} k ≤ 18λ ^{2−α}
l

(97)

(98)

By definition of θ l ^{u} , we have E ξ l [θ l ^{u} ] = 0 and


E ξ l −γ(1 − ^{Lγ)(1} − ^{γμ)} ^{T} ^{−1−l} hη l ^{,} ^{θ} l ^{u} i ^{=} ^{0.}

Next, sum 1 has bounded with probability 1 terms:

| − γ(1 − Lγ)(1 − γμ) ^{T} −1−l hη l , θ l ^{u} i|

(83)

≤

(93),(96)

≤

(83),(86)

≤

27

γ exp(−γμ(T − 1 − l))kη l k · kθ l ^{u} k
√
4 L∆γ exp(−γμ(T − 1 − ^{l} / 2 ))λ l
exp(−γμT )∆ def
= c.
5 ln 4(K+1)
β

(99)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance



def
The summands also have bounded conditional variances σ l ^{2} = E ξ l γ ^{2} (1 − Lγ) ^{2} (1 − γμ) ^{2T} −2−2l hη l , θ l ^{u} i ^{2} :

σ l 2



E ξ l γ ^{2} (1 − Lγ) ^{2} exp(−γμ(2T − 2 − 2l))kη l k ^{2} · kθ l ^{u} k ^{2}


4γ ^{2} L∆ exp(−γμ(2T − 2 − l))E ξ l kθ l ^{u} k ^{2}


10γ ^{2} L∆ exp(−γμ(2T − l))R ^{2} E ξ l kθ l ^{u} k ^{2} .

≤

(93),(83)

≤

(83)

≤

(100)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {−γ(1 − ^{Lγ)(1} − ^{γμ)} ^{T} ^{−1−l} hη l ^{,} ^{θ} l ^{u} i} ^{T} l=0
is a bounded martingale difference sequence
2 T −1
^{with} ^{bounded} ^{conditional} ^{variances} {σ l } l=0 ^{.} ^{Next,} ^{we} ^{apply} ^{Bernstein’s} ^{inequality} ^{(Lemma} ^{B.2)} ^{with} ^{X} l ^{=} −γ(1 −

2

)∆
Lγ)(1 − γμ) ^{T} −1−l hη l , θ l ^{u} i, parameter c as in (99), b = 15 exp(−γμT )∆, G = ^{exp(−2γμT}
4(K+1) ^{:}

150 ln

(

T −1

X
1
exp(−2γμT )∆ ^{2}
^{P} |1| ^{>} ^{exp(−γμT} ^{)∆} ^{and}
σ l 2 ≤
5
150 ln ^{4(K+1)}

l=0

β

)


≤ 2 exp −

β

b 2
2G + 2cb / 3



=

β
.
2(K + 1)

Equivalently, we have

β
P{E 1 } ≥ 1 −
,
2(K + 1)

for E 1 =

(

either

T
−1
X

exp(−2γμT )∆ ^{2}
σ l 2 >
150 ln ^{4(K+1)}
l=0
β

)
1
^{or} |1| ≤ ^{exp(−γμT} ^{)∆} ^{.} ^{(101)}
5

In addition, E T −1 implies that

T
−1
X

l=0

σ l 2

(100)

10γ ^{2} L∆ exp(−2γμT )

≤

T
−1
X

l=0

^{(98),T} ≤K+1

180γ ^{2} L∆ exp(−2γμT )σ ^{α}

≤



E ξ l kθ l u k 2
exp(−γμl)

K
X

l=0

λ 2−α
l
exp(−γμl)

√ α √ 4−α
K
exp(−2γμT )σ ^{α} X
180γ L ∆

α

(86)

=

180γ

=

120 2−α ln ^{2−α} ^{4(K+1)}
β
√ α √ 4−α
α

L

∆

exp(−2γμT )σ

l=0

K
α X

1
· (exp(−γμ(1 + l / 2 ))) ^{2−α}
exp(−γμl)

exp(γμ(α − 2)) · exp

120 2−α ln ^{2−α} ^{4(K+1)}
l=0
β
√ α √ 4−α
α
α
180γ L ∆
exp(−2γμT )σ (K + 1) exp( ^{γμαK}
2 )

≤



γμαl
2



120 2−α ln ^{2−α} ^{4(K+1)}
β

exp(−2γμT )∆ ^{2}

(83)

≤

150 ln ^{4(K+1)}
β

,

(102)

where we also show that E T −1 implies

√ α √ 4−α
(K + 1) exp( ^{γμαK}
γ α L ∆
λ 2−α
2 )
l
.
≤
γ L∆
4(K+1)
2−α
exp(−γμl)
120 ^{2−α} ln
l=0
β

2

K
X

28

(103)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Upper bound for 2.

(83)

2

≤

(93),(97)

≤

(86)

=

From E T −1 it follows that

γ exp(−γμ(T − 1))

T
−1
X

l=0

kη l k · kθ l b k
exp(−γμl)

T
−1
X
√
2 ^{1+α} γ exp(−γμ(T − 1)) ∆σ ^{α}

1
α−1
γμl / 2 )
λ
exp(−
l=0 ^{l}

T
−1
X
√ 1−α √ 2−α
2 ^{1+α} · 120 ^{α−1} L
∆
exp(−γμ(T − 1))γ ^{α} σ ^{α} ln ^{α−1} ^{4(K+1)}
β

exp( ^{γμl} / 2 )

exp (−γμ(1 + ^{l} / 2 ))


K
X
√ 1−α √ 2−α
γμαl
α−1 4(K+1)
1+α
α−1
α α
2
· 120
exp
L
∆
exp(−γμ(T − 1))γ σ ln
β
2
l=0


√ 1−α √ 2−α
γμαK
α−1 4(K+1)
1+α
α−1
α α
(K + 1) exp
2
· 120
L
∆
exp(−γμ(T − 1))γ σ ln
β
2
1
exp(−γμT )∆.
5

α−1

l=0

^{T} ≤K+1

≤

≤

(83)

≤

Upper bound for 3.

From E T −1 it follows that

3

=

(98)

2

Lγ exp(−γμ(T − 1))

T
−1
X

l=0



E ξ l kθ l u k 2
exp(−γμl)

T
−1
X

λ 2−α
l
exp(−γμl)

≤

18Lγ ^{2} exp(−γμ(T − 1))σ ^{α}

(103)

√ α √ 2−α
18γ L ∆
exp(−γμ(T − 1))σ ^{α} (K + 1) exp( ^{γμαK}
2 )

≤

(83)

≤

Upper bound for 4.

(104)

α

l=0

120 2−α ln ^{2−α} ^{4(K+1)}
β

1
exp(−γμT )∆.
5

(105)

First, we have

h

i
Lγ ^{2} (1 − γμ) ^{T} −1−l E ξ l kθ l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} = 0.

Next, sum 4 has bounded with probability 1 terms:



Lγ ^{2} (1 − γμ) ^{T} −1−l kθ l ^{u} k ^{2} − E ξ l kθ l ^{u} k ^{2}

(96)

≤

(86)

=

≤

def

=

8Lγ ^{2} exp(−γμT )λ ^{2} l
exp(−γμ(1 + l))
exp(−γμ(T + 1))∆

1800 ln ^{2} ^{4(K+1)}
β

exp(−γμT )∆

5 ln 4(K+1)
β

c.

The summands also have conditional variances
h
 2 i

def
σ
b l ^{2} = E ξ l L ^{2} γ ^{4} (1 − γμ) ^{2T} −2−2l kθ l ^{u} k ^{2} − E ξ l kθ l ^{u} k ^{2}

29

(106)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

that are bounded

σ
b l 2

Lγ ^{2} exp(−2γμT )∆

(106)

≤

≤

5 exp(−γμ(1 + l)) ln ^{4(K+1)}
β
2

2Lγ exp(−2γμT )∆

5 exp(−γμ(1 + l)) ln ^{4(K+1)}
β

E ξ l




 
kθ l u k 2 − E ξ l kθ l u k 2



E ξ l kθ l u k 2 .

(107)



 T −1
In other words, we showed that Lγ ^{2} (1 − γμ) ^{T} −1−l kθ l ^{u} k ^{2} − E ξ l kθ l ^{u} k ^{2}
is a bounded martingale difference
l=0
2 T −1
sequence with bounded conditional variances {b
^{σ} l } l=0 ^{.} ^{Next,} ^{we} ^{apply} ^{Bernstein’s} ^{inequality} ^{(Lemma} ^{B.2)} ^{with} ^{X} l ^{=}
 u 2 
)∆ 2
2
^{T} −1−l
u 2
Lγ (1 − γμ)
kθ l k − E ξ l kθ l k , parameter c as in (106), b = 5 ^{1} exp(−γμT )∆, G = ^{exp(−2γμT}
4(K+1) ^{:}

150 ln

(

T −1

X
exp(−2γμT )∆ ^{2}
1
σ
b l 2 ≤
^{P} |4| ^{>} ^{exp(−γμT} ^{)∆} ^{and}
5
150 ln ^{4(K+1)}

l=0

β

)


≤ 2 exp −

b 2
2G + 2cb / 3



=

β

β
.
2(K + 1)

Equivalently, we have

β
P{E 4 } ≥ 1 −
,
2(K + 1)

for E 4 =

(

T
−1
X

either

l=0

In addition, E T −1 implies that

T
−1
X

l=0

σ
b l 2

(107)

≤

^{(98),T} ≤K+1

≤

(103)

≤

(53)

≤

Upper bound for 5.

5

=

Lγ 2

≤

^{(86),T} ≤K+1

≤

≤

≤

(53)

≤

150 ln ^{4(K+1)}
β

)
1
^{or} |4| ≤ ^{exp(−γμT} ^{)∆} ^{.} ^{(108)}
5



T −1
2Lγ ^{2} exp(−γμ(2T − 1))∆ X E ξ l kθ l ^{u} k ^{2}
exp(−γμl)
5 ln 4(K+1)

l=0

β

K

36Lγ ^{2} exp(−γμ(2T − 1))∆σ ^{α} X

5 ln 4(K+1)
β

l=0

λ 2−α
l
exp(−γμl)

√ α
√ 4−α α
36 L γ ^{α} exp(−γμ(2T − 1)) ∆
σ (K + 1) exp( ^{γμαK}
2 )

exp(−2γμT )∆ ^{2}

150 ln ^{4(K+1)}
β

5 · 120 2−α ln ^{3−α} ^{4(K+1)}
β

.

(109)

From E T −1 it follows that

T
−1
X

l=0

(97)

σ
b l 2 >

exp(−2γμT )∆ ^{2}

exp(−γμ(T − 1 − l))kθ l ^{b} k ^{2}

2 ^{2α} Lγ ^{2} exp(−γμ(T − 1))σ ^{2α}

T
−1
X

1

λ ^{2α−2} exp(−γμl)
l=0 ^{l}

√ 2α



K
X
2 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} L exp(−γμT )σ ^{2α} ln ^{2α−2} ^{4(K+1)}
l
β
exp γμ(2α − 2) 1 +
exp(γμl)
√ 2α−2
2
∆
l=0
√ 2α
K
X
4 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} L exp(−γμT )σ ^{2α} ln ^{2α−2} ^{4(K+1)}
β
exp(γμαl)
√ 2α−2
∆
l=0
√ 2α
(K + 1) exp(γμαK)
4 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} L exp(−γμT )σ ^{2α} ln ^{2α−2} ^{4(K+1)}
β
√ 2α−2
∆
1
exp(−γμT )∆.
(110)
5

30

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Now, we have the upper bounds for 1, 2, 3, 4, 5. In particular, probability event E T −1 implies

(95)

(104) 1

2 ≤

∆ T ≤ exp(−γμT )∆ + 1 + 2 + 3 + 4 + 5,

(105) 1

exp(−γμT )∆,

5
T
−1
X

l=0

3 ≤

5

exp(−γμT )∆,

^{(102)} exp(−2γμT )∆ ^{2}

σ l 2 ≤

150 ln ^{4(K+1)}
β

T
−1
X

,

l=0

(110) 1

5 ≤

5

exp(−γμT )∆,

^{(109)} exp(−2γμT )∆ ^{2}

σ
b l 2 ≤

150 ln ^{4(K+1)}
β

.

Moreover, we also have (see (101), (108) and our induction assumption)

P{E T −1 } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
2(K + 1)

(T − 1)β
,
K +1

P{E 4 } ≥ 1 −

β
,
2(K + 1)

where

E 1

E 4

=

=

(

either

T
−1
X

σ l 2 >

l=0

(

either

T
−1
X

l=0

σ
b l 2 >

exp(−2γμT )∆ ^{2}

150 ln ^{4(K+1)}
β

exp(−2γμT )∆ ^{2}

150 ln ^{4(K+1)}
β

)
1
^{or} |1| ≤ ^{exp(−γμT} ^{)∆} ^{,}
5
)
1
^{or} |4| ≤ ^{exp(−γμT} ^{)∆} ^{.}
5

Thus, probability event E T −1 ∩ E 1 ∩ E 4 implies

∆ T

(95)

≤
≤

exp(−γμT )∆ + 1 + 2 + 3 + 4 + 5
2 exp(−γμT )∆,

which is equivalent to (90) for t = T , and

P{E T } ≥ P{E T −1 ∩ E 1 ∩ E 4 } = 1 − P{E T −1 ∪ E 1 ∪ E 4 } ≥ 1 −

Tβ
.
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

f (x ^{K+1} ) − f ∗ ≤ 2 exp(−γμ(K + 1))∆.

Finally, if

γ

=

B K

=

=

)
ln(B K )
,
,
min
μ(K + 1)
250L ln ^{4(K+1)}
β


2(α−1)


(K + 1) α μ 2 ∆


max 2,
6(K+1)
 264600 α ^{2} Lσ 2 ln ^{2(α−1)}
α
ln 2 (B K ) 
β
 











2(α−1)
 

2


α
μ
∆
K

)!
(
2,
O 
max


 
2(α−1)


2(α−1)



2 ∆

α
2
K
μ
K


2 ln α


Lσ
max
2,
ln
2(α−1)


β
K
Lσ 2 ln α
( β )

(

1

31

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

then with probability at least 1 − β

f (x K+1 ) − f ∗

≤

=

=

2 exp(−γμ(K + 1))∆
)
!
(
1
μ(K + 1)
,
2∆ max exp −
B K
250L ln ^{4(K+1)}
β
(
)!  


 
2(α−1)
2(α−1)
2


α
K
2
μ
∆


K
2
α


! Lσ ln
max 2,
2(α−1)



β ln

 
K
2


Lσ ln α ( β )
μK

 .
,
O  max ∆ exp −
2(α−1)

K


2
L
ln
α


K
μ


β







To get kx ^{K+1} − x ∗ k ^{2} ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
!
α
  ^{2}  2(α−1)

 α !
  
α
L
Lσ
∆
1 Lσ ^{2} 2(α−1)
∆
L
ln
,
ln α−1 (B ε ) ,
ln
ln
ln
K = O
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

where

B ε = max

This concludes the proof.










2,

ε ln

 

1
β

∆

Lσ 2
μ 2 ε






 .
α
 2(α−1)




E.3. Convex Functions

Now, we focus on the case of convex functions. We start with the following lemma.

Lemma E.5. Let Assumptions 1.3 and 1.6 with μ = 0 hold on Q = B 2R (x ∗ ), where R ≥ kx ^{0} − x ∗ k, and let stepsize γ
satisfy γ ≤ L ^{1} . If x ^{k} ∈ Q for all k = 0, 1, . . . , K + 1, K ≥ 0, then after K iterations of clipped-SGD we have


γ f (x K ) − f (x ∗ ) ≤

kx 0 − x ∗ k 2 − kx K+1 − x ∗ k 2
K +1
K
K
2γ X k
γ 2 X
−
hx − x ∗ − γ∇f (x ^{k} ), θ k i +
kθ k k 2 ,
K +1
K +1

k=0

(111)

k=0

K

x K

=

1 X k
x ,
K +1

(112)

k=0

where θ k is defined in (52).

e ξ k (x ^{k} ), we derive for all k = 0, 1, . . . , K that
Proof. Using x ^{k+1} = x ^{k} − γ ∇f

kx k+1 − x ∗ k 2

=

=

(10),μ=0

≤

(7)

≤

γ≤ 1 / L

≤

e ξ k (x k )i + γ 2 k ∇f
e ξ k (x k )k 2
kx ^{k} − x ∗ k ^{2} − 2γhx ^{k} − x ∗ , ∇f

kx ^{k} − ^{x} ^{∗} k ^{2} − ^{2γhx} ^{k} − ^{x} ^{∗} ^{,} ∇f ^{(x} ^{k} ^{)i} − ^{2γhx} ^{k} − ^{x} ^{∗} ^{,} ^{θ} k i ^{+} ^{γ} ^{2} k∇f ^{(x} ^{k} ^{)} ^{+} ^{θ} k k ^{2}

kx ^{k} − x ∗ k ^{2} − 2γ f (x ^{k} ) − f (x ∗ ) − 2γhx ^{k} − x ∗ − γ∇f (x ^{k} ), θ k i

^{+γ} ^{2} k∇f ^{(x} ^{k} ^{)k} ^{2} ^{+} ^{γ} ^{2} kθ k k ^{2}


kx ^{k} − x ∗ k ^{2} − 2γ (1 − γL) f (x ^{k} ) − f (x ∗ ) − 2γhx ^{k} − x ∗ − γ∇f (x ^{k} ), θ k i

+γ 2 kθ k k 2


kx ^{k} − x ∗ k ^{2} − γ f (x ^{k} ) − f (x ∗ ) − 2γhx ^{k} − x ∗ − γ∇f (x ^{k} ), θ k i + γ ^{2} kθ k k ^{2} .

32

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Summing up the above inequalities for k = 0, 1, . . . , K and rearranging the terms, we get

K

γ X
f (x k ) − f (x ∗ )
K +1

k=0

K

≤

k=0

+

γ 2
K +1

k=0

K
X

k=0

kθ k k 2

K

kx − x k − kx K+1 − x ∗ k 2
2γ X k
−
hx − x ∗ − γ∇f (x ^{k} ), θ k i
K +1
K +1

0

=

K


1 X
2γ X k
kx k − x ∗ k 2 − kx k+1 − x ∗ k 2 −
hx − x ^{∗} − γ∇f (x ^{k} ), θ k i
K +1
K +1

∗ 2

k=0

2

+

γ
K +1

K
X

k=0

kθ k k 2 .

Finally, we use the definition of x ^{K} and Jensen’s inequality and get the result.

Using this lemma we prove the main convergence result for clipped-SGD.

Theorem E.6 (Case 3 from Theorem 3.1). Let Assumptions 1.1, 1.3 and 1.6 with μ = 0 hold on Q = B 2R (x ∗ ), where
R ≥ kx ^{0} − x ∗ k, and








R
1
,
,
(113)
γ ≤ min
 α−1

4(K+1)

α 
1
1


4(K+1)

 80L ln β
108 α · 20σK α ln β

λ k ≡ λ =

R

40γ ln ^{4(K+1)}
β

,

(114)

for some K > 0 and β ∈ (0, 1] such that ln ^{4K}
β ≥ 1. Then, after K iterations of clipped-SGD the iterates with probability
at least 1 − β satisfy
2R 2
∗
√
and {x ^{k} } ^{K}
(115)
f (x K ) − f (x ∗ ) ≤
k=0 ⊆ ^{B} 2R ^{(x} ^{).}
γ(K + 1)

In particular, when γ equals the minimum from (53), then the iterates produced by clipped-SGD after K iterations with
probability at least 1 − β satisfy
 


K 
 LR 2 ln K σR ln α−1
α
β
β
 ,
(116)
f (x ^{K} ) − f (x ∗ ) = O  max
,
α−1


K
α
K

meaning that to achieve f (x ^{K} ) − f (x ∗ ) ≤ ε with probability at least 1 − β clipped-SGD requires
(
 α

 ^{α} !)!

LR ^{2} σR α−1
1 σR α−1
,
K = O max
iterations/oracle calls.
ln
ε
ε
β
ε

(117)

Proof. Let R k = kx ^{k} − x ∗ k for all k ≥ 0. Next, our goal is to show by induction that R l ≤ 2R with high probability,
which allows to apply the result of Lemma E.5 and then use Bernstein’s inequality to estimate the stochastic part of the
upper-bound. More precisely, for each k = 0, . . . , K + 1 we consider probability event E k defined as follows: inequalities

−2γ

t−1
X

l=0

hx ^{l} − x ∗ − γ∇f (x ^{l} ), θ l i + γ ^{2}

t−1
X

l=0

kθ l k 2

≤

R t

≤

R 2 ,

(118)

√
2R

(119)

hold for all t = 0, 1, . . . , k simultaneously. We want to prove via induction that P{E k } ≥ 1 − ^{kβ} / (K+1) for all k =
0, 1, . . . , K + 1. For k = 0 the statement is trivial. Assume that the statement is true for some k = T − 1 ≤ K:

33

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

P{E T −1 } ≥ 1 − ^{(T} −1)β / (K+1) . One needs to prove that P{E T } ≥ 1 − ^{T} ^{β} / (K+1) . First, we notice that probability event
E T −1 implies that x t ∈ B √ 2R (x ∗ ) for all t = 0, 1, . . . , T − 1. Moreover, E T −1 implies

e ξ T −1 (x T −1 )k ≤ kx T −1 − x ∗ k + γk ∇f
e ξ T −1 (x T −1 )k ≤
kx T − x ∗ k = kx T −1 − x ∗ − γ ∇f

(114)
√
2R + γλ ≤ 2R,

i.e., x ^{0} , x ^{1} , . . . , x ^{T} ∈ B 2R (x ∗ ). Therefore, E T −1 implies {x ^{k} } Tk=0 ⊆ Q, meaning that the assumptions of Lemma E.5 are
satisfied and we have


γ f (x t−1 ) − f (x ∗ ) ≤

kx 0 − x ∗ k 2 − kx t − x ∗ k 2
t
t−1
t−1
X
2γ
γ 2 X
−
hx ^{l} − x ∗ − γ∇f (x ^{l} ), θ l i +
kθ l k 2
t
t

l=0

(120)

l=0

for all t = 1, . . . , T simultaneously and for all t = 1, . . . , T − 1 this probability event also implies that
!
t−1
t−1
X
X
(118) 2R ^{2}
1
t−1
∗
2
l
∗
l
2
2
f (x ) − f (x ) ≤
hx − x − γ∇f (x ), θ l i + γ
R − 2γ
kθ l k
.
≤
γt
γt

l=0

(121)

l=0

Taking into account that f (x ^{T} −1 ) − f (x ∗ ) ≥ 0, we also derive from (120) that E T −1 implies

R T 2 ≤ R 2 − 2γ

t−1
X

l=0

hx ^{l} − x ∗ − γ∇f (x ^{l} ), θ l i + γ ^{2}

t−1
X

l=0

kθ l k 2 .

(122)

Next, we define random vectors

η t =

(

x ^{t} − x ∗ − γ∇f (x ^{t} ),
0,

if kx ^{t} − x ∗ − γ∇f (x ^{t} )k ^{2} ≤ 2R,
otherwise,

for all t = 0, 1, . . . , T − 1. By definition, these random vectors are bounded with probability 1

kη t k ≤ 2R.

(123)

Moreover, for t = 0, . . . , T − 1 event E T −1 implies

(6)

k∇f ^{(x} ^{t} ^{)k}

kx ^{t} − x ∗ − γ∇f (x ^{t} )k

(119) √

(113),(114) λ

≤

Lkx ^{t} − x ^{∗} k ≤

≤

kx ^{t} − x ∗ k + γk∇f (x ^{t} )k ≤

2LR

≤

(124) √

2

,

(124)

(113)

2R(1 + Lγ) ≤ 2R.

Next, we define the unbiased part and the bias of θ t as θ t ^{u} and θ t ^{b} , respectively:
i
i
h
h
e ξ t (x t ) − E ξ t ∇f
e ξ t (x t ) , θ t b = E ξ t ∇f
e ξ t (x t ) − ∇f (x t ).
θ t u = ∇f

(125)

We notice that θ t = θ t ^{u} + θ t ^{b} . Using new notation, we get that E T −1 implies

R T 2

≤

^{R} ^{2} −2γ

|

T
−1
X

t=0

hθ t ^{u} ^{,} ^{η} t i −2γ

{z

} |

1

+ 2γ 2

|

T
−1
X

t=0

T
−1
X

t=0

hθ t b , η t i + 2γ 2

{z

}

|

t=0

2

|

T
−1 
X

t=0

4

}

{z

5

{z

3

T
−1
i
h
X
2
2
E ξ t kθ t u k + 2γ 2
θ t b .

{z

h
i
2
2
kθ t u k − E ξ t kθ t u k

}

}

(126)

It remains to derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5, i.e., to finish our inductive
proof we need to show that 1 + 2 + 3 + 4 + 5 ≤ R ^{2} with high probability. In the subsequent parts of the proof, we

34

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

will need to use many times the bounds for the norm and second moments of θ t ^{u} and θ t ^{b} . First, by definition of clipping
operator, we have with probability 1 that
kθ t ^{u} k ≤ 2λ.
(127)

^{Moreover,} ^{since} ^{E} T −1 ^{implies} ^{that} k∇f ^{(x} ^{t} ^{)k} ≤ ^{λ} ^{/} ^{2} ^{for} ^{t} ^{=} ^{0,} ^{1,} ^{.} ^{.} ^{.} ^{,} ^{T} − ^{1} ^{(see} ^{(124)),} ^{then,} ^{in} ^{view} ^{of} ^{Lemma} ^{5.1,} ^{we}
have that E T −1 implies

2 α σ α
,
λ α−1
18λ ^{2−α} σ ^{α} .

kθ t b k ≤


E ξ t kθ t u k 2 ≤

(128)

(129)

Upper bound for 1. By definition of θ t ^{u} , we have E ξ t [θ t ^{u} ] = 0 and

E ξ t [−2γhθ t ^{u} , η t i] = 0.

Next, sum 1 has bounded with probability 1 terms:

(123),(127)

|2γ hθ t ^{u} ^{,} ^{η} t i | ≤ ^{2γkθ} t ^{u} k · kη t k

≤

R 2

(114)

8γλR =

def

5 ln 4(K+1)
β

= c.

(130)

def

The summands also have bounded conditional variances σ t ^{2} = E ξ t [4γ ^{2} hθ t ^{u} , η t i ^{2} ]:



 (123)

σ t ^{2} ≤ E ξ t 4γ ^{2} kθ t ^{u} k ^{2} · kη t k ^{2} ≤ 16γ ^{2} R ^{2} E ξ t kθ t ^{u} k ^{2} .

(131)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {−2γ hθ t ^{u} ^{,} ^{η} t i} ^{T} t=0
is a bounded martingale difference sequence with bounded conditional
2 T −1
^{variances} {σ t } t=0 ^{.} ^{Next,} ^{we} ^{apply} ^{Bernstein’s} ^{inequality} ^{(Lemma} ^{B.2)} ^{with} ^{X} t ^{=} −2γ hθ t ^{u} ^{,} ^{η} t i, ^{parameter} ^{c} ^{as} ^{in} ^{(130),}
2
R 4
b = R 5 , G =
4(K+1) ^{:}

150 ln

β

(

R 2
^{P} |1| ^{>}
5

T
−1
X

and

t=0

σ t 2 ≤

R 4

150 ln ^{4(K+1)}
β

)


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
2(K + 1)

Equivalently, we have

β
,
P {E 1 } ≥ 1 −
2(K + 1)

for E 1 =

(

either

T
−1
X

σ t 2 >

t=0

R 4

150 ln ^{4(K+1)}
β

R 2
^{or} |1| ≤
5

)

.

(132)

In addition, E T −1 implies that

T
−1
X

(131)

σ t 2

≤

t=0

16γ ^{2} R ^{2}

T
−1
X

t=0


 (129)
E ξ t kθ t ^{u} k ^{2} ≤ 288γ ^{2} R ^{2} σ ^{α} T λ ^{2−α}

9 · 40 α R 4−α σ α T γ α (113)
R 4
.
≤
2−α 4(K+1)
50 ln
150 ln ^{4(K+1)}
β
β

(114)

=

(133)

Upper bound for 2. From E T −1 it follows that

2

=

(114)

=

−2γ

T
−1
X

hθ t b , η t i ≤ 2γ

t=0
α
α

T
−1
X

t=0

kθ t b k · kη t k

(123),(128) 4 · 2 ^{α} γσ ^{α} T R

≤

80
σ T R 2−α γ α (113) R 2
^{·} 1−α 4(K+1) ^{≤}
.
10 ln
5

β

Upper bound for 3. First, we have

ii
h

h
= 0.
E ξ t 2γ 2 kθ t u k 2 − E ξ t kθ t u k 2

35

λ α−1

(134)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Next, sum 3 has bounded with probability 1 terms:
i
h

2
2
≤
2γ 2 kθ t u k − E ξ t kθ t u k

i
h

2
2γ 2 kθ t u k 2 + E ξ t kθ t u k

R 2
def
≤
= c.
4(K+1)
2 4(K+1)
100 ln
5 ln β
β

i 2 
h

def
2
2
:
The summands also have bounded conditional variances σ
e t 2 = E ξ t 4γ 4 kθ t u k − E ξ t kθ t u k

(127)

h
h
i i
2
u 2
u 2
t
t kθ k
E
2γ
kθ
k
−
E
≤
ξ
ξ
t
t
4(K+1)

R 2

(135)

σ
e t 2

R 2

(114)

16γ ^{2} λ ^{2} =

≤

≤

5 ln

4γ 2 R 2

5 ln 4(K+1)
β

β

(135)



E ξ t kθ t u k 2 ,

(136)

io ^{T} ^{−1}
h

n
u 2
u 2
2
t
since ln ^{4(K+1)}
kθ
k
is a bounded martingale dif-
kθ
k
−
E
≥
1.
In
other
words,
we
showed
that
2γ
ξ
t
t
β

t=0

−1
ference sequence
with bounded
conditional
variances {e
^{σ} t ^{2} } ^{T} t=0
. Next, we apply Bernstein’s inequality (Lemma B.2) with
i
h


X t = 2γ 2 kθ t u k 2 − E ξ t kθ t u k 2

(

R 2
^{P} |3| ^{>}
5

2

, parameter c as in (135), b = ^{R} 5 , G =

T
−1
X

and

t=0

Equivalently, we have

β
,
P {E 3 } ≥ 1 −
2(K + 1)

σ
e t 2 ≤

R 4

150 ln ^{4(K+1)}
β

for E 3 =

(

)


≤ 2 exp −

T
−1
X

either

t=0

In addition, E T −1 implies that

T
−1
X

t=0

σ
e t 2

R 4
:
150 ln ^{4(K+1)}
β

σ
e t 2 >

b 2
2G + 2cb / 3

R 4



=

β
.
2(K + 1)

R 2
^{or} |3| ≤
5

150 ln ^{4(K+1)}
β

)

.

(137)

T
−1
X

4γ 2 R 2

 u 2  (129) 72γ ^{2} R ^{2} λ ^{2−α} σ ^{α} T
t kθ k
≤
E
ξ
t
5 ln 4(K+1)
5 ln 4(K+1)
t=0
β
β

(136)

≤

R 4
9 · 40 α σ α T R 4−α γ α (113)
.
^{·} 3−α 4(K+1) ^{≤}
1000 ln
150 ln ^{4(K+1)}

(114)

=

β

(138)

β

Upper bound for 4. From E T −1 it follows that

= 2γ 2

4

h
i (129)
α
γ α σ α T R 2−α (113) R 2
(114) ^{9} · ^{40}
2
E ξ t kθ t u k
^{·} 2−α 4(K+1) ^{≤}
.
≤ 36γ ^{2} λ ^{2−α} σ ^{α} T =
400
5
ln
t=0

T
−1
X

(139)

β

Upper bound for 5. From E T −1 it follows that

5

= 2γ 2

T
−1
X

θ t b

2 (128) 2 · 4

≤

t=0

α 2α

σ

T γ ^{2} (114) 6400 ^{α} σ ^{2α} T γ ^{2α} R ^{2−2α} (113) R ^{2}
=
≤
·
.
800 ln ^{2(1−α)} ^{4(K+1)}
5

λ 2(α−1)

β

Now, we have the upper bounds for 1, 2, 3, 4, 5. In particular, probability event E T −1 implies

(126)

R T 2 ≤ R 2 + 1 + 2 + 3 + 4 + 5,

(134) R ^{2}

2 ≤

T
−1
X

t=0

(133)

σ t 2 ≤

5

,

(139) R ^{2}

4 ≤

R 4

150 ln

,
4(K+1)

,

5
T
−1
X

t=0

β

36

(140) R ^{2}

5 ≤

(138)

σ
e t 2 ≤

5

,

R 4

150 ln ^{4(K+1)}
β

.

(140)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Moreover, we also have (see (132), (137) and our induction assumption)

(T − 1)β
,
K +1

P{E T −1 } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
2(K + 1)

P{E 3 } ≥ 1 −

β
,
2(K + 1)

where

E 1

E 3

=

=

(

(

either

T
−1
X

t=0

either

T
−1
X

t=0

Thus, probability event E T −1 ∩ E 1 ∩ E 3 implies

R T 2

σ t 2 >

≤

R 2 +

σ
e t 2 >

R 4

150 ln ^{4(K+1)}
β

R 4

150 ln ^{4(K+1)}
β

R 2
^{or} |1| ≤
5

R 2
^{or} |3| ≤
5

)

)

,

.

R 2
R 2
R 2
R 2
R 2
+
+
+
+
= 2R 2 ,
5
5
5
5
5

which is equivalent to (118) and (119) for t = T , and


Tβ
.
P{E T } ≥ P {E T −1 ∩ E 1 ∩ E 3 } = 1 − P E T −1 ∪ E 1 ∪ E 3 ≥ 1 − P{E T −1 } − P{E 1 } − P{E 3 } ≥ 1 −
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

(121)

f (x K ) − f (x ∗ ) ≤

2R 2
γ(K + 1)

and {x ^{k} } ^{K}
k=0 ⊆ ^{Q,} ^{which} ^{follows} ^{from} ^{(119).}

Finally, if

γ ≤ min

then with probability at least 1 − β

f (x K ) − f (x ∗ ) ≤

=

=











R
1
,
,

 α−1
4(K+1)

α 
1
1


4(K+1)
 80L ln β

108 α · 20σK α ln

β

2R 2
γ(K + 1)


 α−1


α 
1
1
4(K+1)


4(K+1)
 160LR ^{2} ln

40 · 108 α σRK α ln β
β
max
,


K +1
K +1








K 
 LR 2 ln K σR ln α−1
α
β
β
 .
O  max
,
α−1


K
K α

To get f (x ^{K} ) − f (x ∗ ) ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
(
 α

 ^{α} !)!

LR ^{2} LR ^{2} σR α−1
1 σR α−1
ln
,
K = O max
,
ln
ε
εβ
ε
β
ε

which concludes the proof.

37

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

E.4. Quasi-Strongly Convex Functions

Finally, we consider clipped-SGD under smoothness and quasi-strong convexity assumptions. As the next lemma shows,
the gradient of such function is quasi-strongly monotone and star-cocoercive operator.

Lemma E.7. Consider differentiable function f : R ^{d} → R. If f satisfies Assumption 1.5 on some set Q with parameter
μ, then operator F (x) = ∇f (x) satisfies Assumption 1.9 on Q with parameter ^{μ} / 2 . If f satisfies Assumptions 1.3 and 1.5
with μ = 0 on some set Q, then operator F (x) = ∇f (x) satisfies Assumption 1.10 on Q with l = 2L.

Proof. We start with the first part. Assumption 1.5 on set Q means that for any x ∈ Q

^{f} ^{(x} ^{∗} ^{)} ≥ ^{f} ^{(x)} ^{+} h∇f ^{(x),} ^{x} ^{∗} − ^{xi} ^{+}

μ
kx − x ∗ k 2 .
2

For F (x) = ∇f (x) it implies that for all x ∈ Q

hF (x), x − x ∗ i ≥ f (x) − f (x ∗ ) +

μ
μ
kx − x ∗ k 2 ≥ kx − x ∗ k 2 ,
2
2

i.e., Assumption 1.9 holds on Q with parameter ^{μ} / 2 for operator F (x).

Next, we prove the second part. Assume that f satisfies Assumptions 1.3 and 1.5 with μ = 0 on some set Q. Our goal
is to show that F (x) = ∇f (x) satisfies Assumption 1.10 on Q. In view of (Gorbunov et al., 2022b, Lemma C.6), this is
^{equivalent} ^{to} ^{showing} ^{that} ^{operator} ^{Id} − L ^{1} ^{F} ^{is} ^{non-expansive} ^{around} ^{x} ^{∗} ^{,} ^{i.e.,} ^{we} ^{need} ^{to} ^{show} ^{that} k(Id − L ^{1} ^{F} ^{)(x)} −
(Id − L ^{1} F )(x ∗ )k ≤ kx − x ∗ k for any x ∈ Q. We have



Id −

1
F
L





2
1
(x) − Id − F (x ∗ )
L

2

1
F (x)
L
1
2
kx − x ∗ k ^{2} − hx − x ∗ , F (x)i + 2 kF (x)k ^{2}
L
L
1
2
∗
∗ 2
kx − ^{x} k − hx − ^{x} ^{,} ∇f ^{(x)i} ^{+} 2 k∇f ^{(x)k} ^{2}
L
L
2
2
∗ 2
∗
kx − x k − (f (x) − f (x )) + (f (x) − f (x ∗ ))
L
L
kx − x ∗ k 2 .

x − x ∗ −

=

=

=

(9),(7)

≤

=

This finishes the proof.

Therefore, using the result of Theorem H.6 with l := 2L and μ := ^{μ} / 2 , we get the convergence result for clipped-SGD
under smoothness and quasi-strong convexity assumptions.

Theorem E.8 (Case 4 in Theorem 3.1). Let Assumptions 1.1, 1.3, 1.5, hold for Q = B 2R (x ∗ ) = {x ∈ R ^{d} | kx − x ∗ k ≤
2R}, where R ≥ kx ^{0} − x ∗ k, and
(
)
2 ln(B K )
1
,
0 < γ ≤ min
,
(141)
μ(K + 1)
800L ln ^{4(K+1)}
β


2(α−1)


(K + 1) α μ 2 R 2


(142)
B K = max 2,
4(K+1)
 4 · 5400 α ^{2} σ 2 ln ^{2(α−1)}
α
ln 2 (B K ) 
β

 














2(α−1)



2 2

α
K
μ
R
(
)!
= O 
max
2,
,
(143)

 
2(α−1)



2(α−1)




2 R 2
α
K
2
μ

K


2


max 2,
2(α−1)
 σ ln α
 

β ln
σ 2 ln α ( K
β )

λ k

=

exp(−γ( ^{μ} / 2 )(1 + ^{k} / 2 ))R

120γ ln ^{4(K+1)}
β

,

(144)

38

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

for some K ≥ 0 and β ∈ (0, 1] such that ln ^{4(K+1)}
≥ 1. Then, after K iterations the iterates produced by clipped-SGD
β
with probability at least 1 − β satisfy

kx ^{K+1} − x ∗ k ^{2} ≤ 2 exp(−γ( μ / 2 )(K + 1))R ^{2} .

(145)

In particular, when γ equals the minimum from (141), then the iterates produced by clipped-SGD after K iterations with
probability at least 1 − β satisfy
)!  
(


 
2(α−1)
2(α−1)
2 2


α
μ
R
K
2


K
2


! σ ln α
max 2,
2(α−1)



β ln
 

K
2 ln
α


σ
( β )
μK
K
∗ 2
2
 ,
kx − x k = O 
,
max
R
exp
−
(146)
2(α−1)


K


2
l
ln
α


μ
K


β







meaning that to achieve kx ^{K} − x ∗ k ^{2} ≤ ε with probability at least 1 − β clipped-SGD requires
!
α
  ^{2}  2(α−1)

 α !
 2  
α
L
L
σ
R 2
R
1 σ ^{2} 2(α−1)
α−1
K = O
ln
,
ln
ln
ln
(B ε )
ln
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

iterations/oracle calls, where

B ε = max










2,

ε ln

 

1
β

39

R 2

4σ 2
μ 2 ε






 .
α
 2(α−1)




(147)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

F. Missing Proofs for clipped-SSTM and R-clipped-SSTM

In this section, we provide the complete formulation of the main results for clipped-SSTM and R-clipped-SSTM
and the

e ξ k (x ^{k+1} ) = clip ∇f ξ k (x ^{k+1} ), λ k .
missing proofs. For brevity, we will use the following notation: ∇f

Algorithm 2 Clipped Stochastic Similar Triangles Method (clipped-SSTM) (Gorbunov et al., 2020)

Input: starting point x ^{0} , number of iterations K, stepsize parameter a > 0, clipping levels {λ k } ^{K−1}
k=0 ^{,} ^{smoothness} ^{constant}
L.
1: Set A 0 = α 0 = 0, y ^{0} = z ^{0} = x ^{0}
2: for k = 0, . . . , K − 1 do
3:
Set α k+1 = ^{k+2}
2aL ^{,} ^{A} ^{k+1} ^{=} ^{A} ^{k} ^{+} ^{α} ^{k+1}

k

4:

5:

6:

k

k+1 ^{z}
x k+1 = ^{A} k ^{y} A ^{+α}
k+1

e ξ k (x ^{k+1} ) = clip ∇f ξ k (x ^{k+1} ), λ k using a fresh sample ξ ^{k} ∼ D k
Compute ∇f
e ξ k (x k+1 )
z ^{k+1} = z ^{k} − α k+1 ∇f

7:
y k+1 =
8: end for

A k y ^{k} +α k+1 z ^{k+1}
^{A} k+1

Output: y ^{K}

F.1. Convex Functions

We start with the following lemma, which is a special case of Lemma 6 from (Gorbunov et al., 2021). This result can be
seen the “optimization” part of the analysis of clipped-SSTM: the proof follows the same steps as the analysis of determin-
istic Similar Triangles Method (Gasnikov & Nesterov, 2016; Dvurechenskii et al., 2018) and separates stochasticity from
the deterministic part of the method.

Lemma F.1 (Special case of Lemma 4.1 from (Gorbunov et al., 2021)). Let Assumptions 1.3 and 1.6 with μ = 0 hold
on Q = B 3R (x ∗ ), where R ≥ kx ^{0} − x ∗ k, and let stepsize parameter a satisfy a ≥ 1. If x ^{k} , y ^{k} , z ^{k} ∈ B 3R (x ∗ ) for all
k = 0, 1, . . . , N , N ≥ 0, then after N iterations of clipped-SSTM for all z ∈ B 3R (x ∗ ) we have


A N f (y ^{N} ) − f (z)

≤

N −1

X
1 0
1
kz − zk 2 − kz N − zk 2 +
α k+1 θ k+1 , z − z ^{k} + α k+1 ∇f (x ^{k+1} )
2
2

k=0

+

N
−1
X

k=0

^{θ} k+1

def

=

^{α} ^{2} k+1 kθ k+1 k ^{2} ^{,}

e ξ k (x k+1 ) − ∇f (x k+1 ).
∇f

(148)

(149)

e ξ k (x ^{k+1} ) we get that for all z ∈ B 3R (x ∗ )
Proof. For completeness, we provide the full proof. Using z ^{k+1} = z ^{k} − α k+1 ∇f
and k = 0, 1, . . . , N − 1
D
E
E
D
D
E
e ξ k (x k+1 ), z k+1 − z
e ξ k (x ^{k+1} ), z ^{k} − z ^{k+1} + α k+1 ∇f
e ξ k (x k+1 ), z k − z
^{=} ^{α} k+1 ∇f
^{α} k+1 ∇f
E
D
e ξ k (x k+1 ), z k − z k+1 + z k+1 − z k , z − z k+1
^{=} ^{α} k+1 ∇f
E
D
e ξ k (x k+1 ), z k − z k+1 − ^{1} kz k − z k+1 k 2
^{=} ^{α} k+1 ∇f
2
1
1 k
(150)
+ kz − zk 2 − kz k+1 − zk 2 ,
2
2

^{where} ^{in} ^{the} ^{last} ^{step} ^{we} ^{apply} ^{2ha,} ^{bi} ^{=} ka ^{+} ^{bk} ^{2} − kak ^{2} − kbk ^{2} ^{with} ^{a} ^{=} ^{z} ^{k+1} − ^{z} ^{k} ^{and} ^{b} ^{=} ^{z} − ^{z} ^{k+1} ^{.} ^{The} ^{update} ^{rules}
(22) and (20) give the following formula:

y k+1

=



^{A} k ^{y} ^{k} ^{+} ^{α} k+1 ^{z} ^{k}
^{α} k+1 k+1
^{α} k+1 k+1
A k y ^{k} + α k+1 z ^{k+1}
=
+
z
− z k = x k+1 +
z
− z ^{k} . (151)
^{A} k+1
^{A} k+1
^{A} k+1
^{A} k+1

40

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

It implies

D
E
e ξ k (x k+1 ), z k − z
^{α} k+1 ∇f

(149),(150)

≤

(151)

=

(36)

≤

(151)

=

1
α k+1 ∇f (x ^{k+1} ), z ^{k} − z ^{k+1} − kz ^{k} − z ^{k+1} k ^{2}
2
1
1
+α k+1 θ k+1 , z ^{k} − z ^{k+1} + kz ^{k} − zk ^{2} − kz ^{k+1} − zk ^{2}
2
2
1
A k+1 ∇f (x ^{k+1} ), x ^{k+1} − y ^{k+1} − kz ^{k} − z ^{k+1} k ^{2}
2
1
1
+α k+1 θ k+1 , z ^{k} − z ^{k+1} + kz ^{k} − zk ^{2} − kz ^{k+1} − zk ^{2}
2
2
 ^{A} k+1 ^{L} k+1
1
A k+1 f (x ^{k+1} ) − f (y ^{k+1} ) +
kx
− y k+1 k 2 − kz k − z k+1 k 2
2
2
1 k
^{1} k+1
2
k
k+1
+ kz − zk − kz
− zk 2
^{+α} k+1 ^{θ} k+1 ^{,} ^{z} − ^{z}
2
2


 ^{1} ^{α} ^{2} k+1 ^{L}
A k+1 f (x ^{k+1} ) − f (y ^{k+1} ) +
− 1 kz k − z k+1 k 2
^{2} ^{A} k+1
1
1
+α k+1 θ k+1 , z ^{k} − z ^{k+1} + kz ^{k} − zk ^{2} − kz ^{k+1} − zk ^{2} ,
2
2

where in the third inequality we use x ^{k+1} , y ^{k+1} ∈ B 3R (x ∗ ). Since A k+1 ≥ aL k+1 α ^{2} k+1 (Lemma B.1) and a ≥ 1 we can
continue our derivation as follows:
E
D

e ξ k (x k+1 ), z k − z
≤ A k+1 f (x ^{k+1} ) − f (y ^{k+1} ) + α k+1 θ k+1 , z ^{k} − z ^{k+1}
^{α} k+1 ∇f

1
1
+ kz k − zk 2 − kz k+1 − zk 2 .
2
2

(152)

Convexity of f gives

D

e ξ k (x k+1 ), y k − x k+1
∇f

The definition of x ^{k+1} (20) implies

E

(149)

=

∇f (x ^{k+1} ), y ^{k} − x ^{k+1} + θ k+1 , y ^{k} − x ^{k+1}

≤

f (y ^{k} ) − f (x ^{k+1} ) + θ k+1 , y ^{k} − x ^{k+1} .



α k+1 x ^{k+1} − z ^{k} = A k y ^{k} − x ^{k+1}

since A k+1 = A k + α k+1 . Putting all inequalities together, we derive that

D
E
e ξ k (x k+1 ), x k+1 − z
^{α} k+1 ∇f

=

(154)

=

(153),(152)

≤

(154)

=

=

D
E
D
E
e ξ k (x k+1 ), z k − z
e ξ k (x ^{k+1} ), x ^{k+1} − z ^{k} + α k+1 ∇f
^{α} k+1 ∇f
D
E
D
E
e ξ k (x k+1 ), z k − z
e ξ k (x ^{k+1} ), y ^{k} − x ^{k+1} + α k+1 ∇f
A k ∇f


A k f (y ^{k} ) − f (x ^{k+1} ) + A k θ k+1 , y ^{k} − x ^{k+1}

+A k+1 f (x ^{k+1} ) − f (y ^{k+1} ) + α k+1 θ k+1 , z ^{k} − z ^{k+1}
1
1
+ kz k − zk 2 − kz k+1 − zk 2
2
2

A k f (y ^{k} ) − A k+1 f (y ^{k+1} ) + α k+1 θ k+1 , x ^{k+1} − z ^{k}

+α k+1 f (x ^{k+1} ) + α k+1 θ k+1 , z ^{k} − z ^{k+1}
1
1
+ kz k − zk 2 − kz k+1 − zk 2
2
2
A k f (y ^{k} ) − A k+1 f (y ^{k+1} ) + α k+1 f (x ^{k+1} )
1
1
+α k+1 θ k+1 , x ^{k+1} − z ^{k+1} + kz ^{k} − zk ^{2} − kz ^{k+1} − zk ^{2} .
2
2

41

(153)

(154)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Rearranging the terms, we get

E

D
e ξ k (x k+1 ), z − x k+1 + ^{1} kz k − zk 2
α k+1 f (x ^{k+1} ) + ∇f
2
^{1} k+1
k+1
k+1
2
− z
− ^{zk} ^{+} ^{α} k+1 ^{θ} k+1 ^{,} ^{x}
− kz
2

(149)
= α k+1 f (x ^{k+1} ) + ∇f (x ^{k+1} ), z − x ^{k+1}
1
1
+α k+1 θ k+1 , z − x ^{k+1} + kz ^{k} − zk ^{2} − kz ^{k+1} − zk ^{2}
2
2
+α k+1 θ k+1 , x ^{k+1} − z ^{k+1}
1
1
≤ α k+1 f (z) + kz ^{k} − zk ^{2} − kz ^{k+1} − zk ^{2} + α k+1 θ k+1 , z − z ^{k+1} ,
2
2
P −1
where in the last inequality we use the convexity of f . Taking into account A 0 = α 0 = 0 and A N = ^{N}
k=0 ^{α} k+1 ^{we} ^{sum}
up these inequalities for k = 0, . . . , N − 1 and get

A k+1 f (y ^{k+1} ) − A k f (y ^{k} )

A N f (y N )

≤

=

(149)

=

≤

N −1

X
1
1
α k+1 θ k+1 , z − z ^{k+1}
A N f (z) + kz ^{0} − zk ^{2} − kz ^{N} − zk ^{2} +
2
2

k=0

1
1
A N f (z) + kz ^{0} − zk ^{2} − kz ^{N} − zk ^{2} +
2
2

1
1
A N f (z) + kz ^{0} − zk ^{2} − kz ^{N} − zk ^{2} +
2
2

+

N
−1
X

k=0

N
−1
X

k=0

N
−1
X

k=0

E
D
e ξ k (x k+1 )
^{α} k+1 ^{θ} k+1 ^{,} ^{z} − ^{z} ^{k} ^{+} ^{α} k+1 ∇f

α k+1 θ k+1 , z − z ^{k} + α k+1 ∇f ξ k (x ^{k+1} )

2

^{α} ^{2} k+1 kθ k+1 k ^{,}

which concludes the proof.

Using this lemma we prove the main convergence result for clipped-SSTM.
Theorem F.2 (Full version of Theorem 3.2). Let Assumptions 1.1, 1.3 and 1.6 with μ = 0 hold on Q = B 3R (x ∗ ), where
R ≥ kx ^{0} − x ∗ k, and


α−1
1
4K 

α ln α
900σ(K
+
1)K
4K
β
,
a ≥ max 48600 ln ^{2}
,
(155)


β
LR

λ k =

R

30α k+1 ln ^{4K}
β

,

(156)

for some K > 0 and β ∈ (0, 1] such that ln ^{4K}
β ≥ 1. Then, after K iterations of clipped-SSTM the iterates with
probability at least 1 − β satisfy

f (y K ) − f (x ∗ ) ≤

6aLR ^{2}
K(K + 3)

k K
k K
∗
and {x ^{k} } ^{K+1}
k=0 ^{,} {z } k=0 ^{,} {y } k=0 ⊆ ^{B} ^{2R} ^{(x} ^{).}

(157)

In particular, when parameter a equals the maximum from (155), then the iterates produced by clipped-SSTM after K
iterations with probability at least 1 − β satisfy

 

K 
 LR 2 ln 2 K σR ln α−1
α
β
β
 ,
f (y ^{K} ) − f (x ∗ ) = O  max
,
(158)
α−1


K 2
K α

meaning that to achieve f (y ^{K} ) − f (x ∗ ) ≤ ε with probability at least 1 − β clipped-SSTM requires
r
 α

 α !!

LR ^{2} LR ^{2} σR α−1
1 σR α−1
iterations/oracle calls.
ln
ln
,
K = O
ε
εβ
ε
β
ε

42

(159)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

e 0 = R 0 ,
Proof. The proof starts similarly to the proof of Theorem 4.1 from (Gorbunov et al., 2021). Let R k = kz ^{k} −x ∗ k, R
k+1 k k
e
e
R k+1 = max{ R k , R k+1 } for all k ≥ 0. We first show by induction that for all k ≥ 0 the iterates x
, z , y lie
A 0 y 0 +α 1 z 0
0
∗
0
0 e
1
= z . Next, assume that
in B R e k (x ). The induction base is trivial since y = z , R 0 = R 0 , and x =
A 1
e l we have that z ^{l} ∈ B R (x ∗ ) ⊆ B e (x ∗ ). Since y ^{l}
x ^{l} , z ^{l−1} , y ^{l−1} ∈ B e (x ∗ ) for some l ≥ 1. By definitions of R l and R

^{R} l−1

R l

l

is a convex combination of y ^{l−1} ∈ B R e l−1 (x ∗ ) ⊆ B R e l (x ∗ ), z ^{l} ∈ B R e l (x ∗ ) and B R e l (x ∗ ) is a convex set we conclude that
y ^{l} ∈ B R e l (x ∗ ). Finally, since x ^{l+1} is a convex combination of y ^{l} and z ^{l} we have that x ^{l+1} lies in B R e l (x ∗ ) as well.

e l ≤ 3R with high probability, which allows us to apply the result of Lemma F.1
Next, our goal is to show by induction that R
and then use Bernstein’s inequality to estimate the stochastic part of the upper-bound. More precisely, for each k =
0, . . . , K we consider probability event E k defined as follows: inequalities

t−1
X

l=0

α l+1 θ l+1 , x ∗ − z ^{l} + α l+1 ∇f ξ l (x ^{l+1} ) +

R t ≤ 2R

t−1
X

l=0

2

^{α} ^{2} l+1 kθ l+1 k ≤ ^{R} ^{2} ^{,}

(160)

(161)

hold for all t = 0, 1, . . . , k simultaneously. We want to prove via induction that P{E k } ≥ 1 − ^{kβ} / K for all k = 0, 1, . . . , K.
For k = 0 the statement is trivial: the left-hand side of (160) equals zero and R ≥ R 0 by definition. Assume that the
statement is true for some k = T − 1 ≤ K − 1: P{E T −1 } ≥ 1 − ^{(T} −1)β / K . One needs to prove that P{E T } ≥ 1 − ^{T} ^{β} / K .
e t ≤ 2R for all t = 0, 1, . . . , T − 1. Moreover, it implies that
First, we notice that probability event E T −1 implies that R

(21)

(156)

e ξ T −1 (x ^{T} )k ≤ 2R + α T λ T −1 ≤ 3R.
kz T − x ∗ k ≤ kz T − x ∗ k + α T k ∇f

Therefore, E T −1 implies {x ^{k} } Tk=0 , {z ^{k} } Tk=0 , {y ^{k} } Tk=0 ⊆ B 3R (x ∗ ), meaning that the assumptions of Lemma F.1 are satis-
fied and we have


A t f (y t ) − f (x ∗ )

≤

t−1

t−1

l=0

l=0

X
1 2 1 2 X
^{α} ^{2} l+1 kθ l+1 k ^{2} (162)
α l+1 θ l+1 , x ∗ − z ^{l} + α l+1 ∇f (x ^{l+1} ) +
R 0 − R t +
2
2

for all t = 0, 1, . . . , T simultaneously and for all t = 1, . . . , T − 1 this probability event also implies that

f (y t ) − f (x ∗ )

(160),(162) ^{1} R ^{2} − ^{1} R ^{2} + R ^{2}
2 0
2 t

≤

A t

≤

3R 2
6aLR ^{2}
=
.
2A t
t(t + 3)

(163)

Taking into account that f (y ^{T} ) − f (x ∗ ) ≥ 0, we also derive that E T −1 implies

R T 2

≤ R 0 2 + 2

|

T
−1
X

t=0

α t+1 θ t+1 , x ∗ − z ^{t} + α t+1 ∇f (x ^{t+1} ) + 2

{z

T
−1
X

t=0

^{α} ^{2} t+1 kθ t+1 k

}

2B T

≤ R 2 + 2B T .

2

(164)

Before we estimate B T , we need to derive a few useful inequalities. We start with showing that E T −1 implies
k∇f ^{(x} ^{t+1} ^{)k} ≤ ^{λ} ^{t} ^{/} ^{2} ^{for} ^{all} ^{t} ^{=} ^{0,} ^{1,} ^{.} ^{.} ^{.} ^{,} ^{T} − ^{1.} ^{For} ^{t} ^{=} ^{0} ^{we} ^{have} ^{x} ^{1} ^{=} ^{x} ^{0} ^{and}

4K

(6)

k∇f ^{(x} ^{1} ^{)k} ^{=} k∇f ^{(x} ^{0} ^{)k} ≤ ^{Lkx} ^{0} − ^{x} ^{∗} k ≤

43

R
λ 0 60 ln β
=
·
aα 1
2
a

(155) λ 0

≤

2

.

(165)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Next, for t = 1, . . . , T − 1 event E T −1 implies

k∇f ^{(x} ^{t+1} ^{)k}

≤

(6),(7)

≤

(154),(163)

≤

≤

=

(38),(156)

≤

=

≤

k∇f ^{(x} ^{t+1} ^{)} − ∇f ^{(y} ^{t} ^{)k} ^{+} k∇f ^{(y} ^{t} ^{)k}
p
Lkx ^{t+1} − y ^{t} k + 2L (f (y ^{t} ) − f (x ∗ ))
s
^{Lα} t+1 t+1
12aL ^{2} R ^{2}
t
kx
− z k +
A t
t(t + 3)
s
4LRα t+1
12aL ^{2} R ^{2}
+
A t
t(t + 3)


s
2 4K
2 α 2
240Lα ^{2} t+1 ln ^{4K}
12aL
ln
R
t+1
β
β 

+ 60
A
t(t
+
3)
60α t+1 ln ^{4K}
t
β
v


u


t+2 ^{2} 2 4K
t+2 ^{2}
4K
u
2
λ t  ^{240L} 2aL ^{ln} β
t ^{12aL} 2aL ^{ln} β 
+ 60


t(t+3)
2
t(t + 3)

4aL




s
4K
2
3(t + 2) ^{2} ln ^{4K}
λ t  240(t + 2) ln β
β 
+ 60
2
t(t + 3)a
t(t + 3)a
!
√
4K
(155) λ t
90 3 ln 4K
λ t 540 ln β
β
√
+
,
≤
2
a
a
2

(166)

2

9
where in the last row we use ^{(t+2)}
t(t+3) ≤ 4 ^{for} ^{all} ^{t} ≥ ^{1.} ^{Therefore,} ^{probability} ^{event} ^{E} T −1 ^{implies} ^{that}

kx ^{∗} − ^{z} ^{t} ^{+} ^{α} t+1 ∇f ^{(x} ^{t+1} ^{)k} ≤ kx ^{∗} − ^{z} ^{t} k ^{+} ^{α} t+1 k∇f ^{(x} ^{t+1} ^{)k}

(161),(165),(166)

≤

2R +

R
≤ 3R
60 ln 4K
β

(167)

for all t = 0, 1, . . . , T − 1. Next, we define random vectors

η t =

(

x ∗ − z ^{t} + α t+1 ∇f (x ^{t+1} ), if kx ∗ − z ^{t} + α t+1 ∇f (x ^{t+1} )k ≤ 3R,
0,
otherwise,

for all t = 0, 1, . . . , T − 1. By definition these random vectors are bounded with probability 1

kη t k ≤ 3R

(168)

and probability event E T −1 implies that η t = x ∗ − z ^{t} + α t+1 ∇f (x ^{t+1} ) for all t = 0, 1, . . . , T − 1. Then, form E T −1 it
follows that

B T

=

T
−1
X

t=0

^{α} t+1 hθ t+1 ^{,} ^{η} t i ^{+}

T
−1
X

t=0

2

^{α} ^{2} t+1 kθ t+1 k ^{.}

u
b
Next, we define the unbiased part and the bias of ^{θ} t+1 as ^{θ} t+1
and ^{θ} t+1
respectively:

h
i
u
e ξ t (x t+1 ) ,
e ξ t (x t+1 ) − E ξ t ∇f
^{θ} t+1
= ∇f

44

h
i
b
e ξ t (x t+1 ) − ∇f (x t+1 ).
^{θ} t+1
= E ξ t ∇f

(169)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

u
b
We notice that ^{θ} t+1 ^{=} ^{θ} t+1
^{+} ^{θ} t+1
. Using new notation, we get that E T −1 implies

B T

T
−1
X

=

u
b
^{α} t+1 ^{θ} t+1
^{+} ^{θ} t+1
, η t +

t=0

T
−1
X

≤

u
b
^{α} ^{2} t+1 ^{θ} t+1
^{+} ^{θ} t+1

2

t=0

u
, η t +
^{α} t+1 ^{θ} t+1

t=0

|

T
−1
X

{z

}

1

+2

|

T
−1
X

^{α} ^{2} t+1 ^{E} ^{ξ} ^{t}

t=0

{z

T
−1
X

b
, η t + 2
^{α} t+1 ^{θ} t+1

t=0

h

|

{z

u
^{θ} t+1

2

i

+2

}

4

|

T
−1
X

|

}

2

T
−1
X

^{α} ^{2} t+1

t=0

u
^{θ} t+1

2

{z

− E ξ t

h

2

u
^{θ} t+1

2

{z

.

i

}

3

b
^{α} ^{2} t+1 ^{θ} t+1

t=0



(170)

}

5

It remains to derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5, i.e., to finish our inductive
proof we need to show that 1 + 2 + 3 + 4 + 5 ≤ R ^{2} with high probability. In the subsequent parts of the proof, we
u
b
will need to use many times the bounds for the norm and second moments of ^{θ} t+1
and ^{θ} t+1
. First, by definition of clipping
operator, we have with probability 1 that
u
k ≤ 2λ t .
(171)
kθ t+1

^{Moreover,} ^{since} ^{E} T −1 ^{implies} ^{that} k∇f ^{(x} ^{t+1} ^{)k} ≤ ^{λ} ^{t} ^{/} ^{2} ^{for} ^{t} ^{=} ^{0,} ^{1,} ^{.} ^{.} ^{.} ^{,} ^{T} − ^{1} ^{(see} ^{(165)} ^{and} ^{(166)),} ^{then,} ^{in} ^{view} ^{of}
Lemma 5.1, we have that E T −1 implies

b
kθ t+1
k
 u 2 
^{E} ^{ξ} ^{t} kθ t+1 k

2 α σ α
,
λ α−1
t

(172)

≤ 18λ ^{2−α}
σ α .
t

(173)

≤

u
u
Upper bound for ^{1.} By definition of θ t+1
, we have E ξ t ^{[θ} t+1
] = 0 and



u
, η t = 0.
^{E} ξ ^{t} ^{α} t+1 ^{θ} t+1

Next, sum 1 has bounded with probability 1 terms:

u
u
k · kη t k
^{,} ^{η} t | ≤ ^{α} t+1 kθ t+1
|α t+1 ^{θ} t+1

(168),(171)

≤

(156)

^{6α} t+1 ^{λ} t ^{R} ^{=}

^{R} ^{2} def
= c.
5 ln 4K
β

(174)

2

def

u
, η t ]:
The summands also have bounded conditional variances ^{σ} t ^{2} ^{=} E ξ t ^{[α} ^{2} t+1 ^{θ} t+1

 (168)

 u 2 
u
^{σ} t ^{2} ≤ ^{E} ^{ξ} ^{t} ^{α} ^{2} t+1 kθ t+1
k ^{2} · kη ^{t} k ^{2} ≤ ^{9α} ^{2} t+1 ^{R} ^{2} ^{E} ^{ξ} ^{t} kθ t+1
k .

(175)

−1
u
^{,} ^{η} ^{t} } ^{T} t=0
is a bounded martingale difference sequence with bounded condi-
In other words, we showed that {α t+1 ^{θ} t+1
2 T −1
u
tional variances {σ t } t=0 . Next, we apply Bernstein’s inequality (Lemma B.2) with ^{X} t ^{=} ^{α} t+1 ^{θ} t+1
, η t , parameter c as
R 2
R 4
^{in} ^{(174),} ^{b} ^{=} 5 ^{,} ^{G} ^{=} 150 ln 4K ^{:}

β

(

R 2
^{P} |1| ^{>}
5

and

T
−1
X

t=0

σ t 2 ≤

R 4
150 ln ^{4K}
β

)


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
2K

Equivalently, we have

β
,
P {E 1 } ≥ 1 −
2K

for E 1 =

(

either

T
−1
X

t=0

45

σ t 2 >

R 4
150 ln ^{4K}
β

R 2
^{or} |1| ≤
5

)

.

(176)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

In addition, E T −1 implies that

T
−1
X

(175)

σ t 2

≤

t=0

(156)

≤

≤

9R

2

T
−1
X

^{α} ^{2} t+1 ^{E} ^{ξ} ^{t}

t=0



u
kθ t+1
k 2

T
−1
X

T
−1
X
 (173)
α 2
≤ 162σ R
α ^{2} t+1 λ ^{2−α}
t

t=0

T
−1
X
162σ ^{α} R ^{4−α}
162σ ^{α} R ^{4−α}
α
α
=
(t + 2) α
t+1
2−α · 2 α a α L α ln 2−α 4K
30 2−α ln 2−α 4K
30
β t=0
β t=0

1 162σ ^{α} R ^{4−α} T (T + 1) ^{α} (155)
R 4
·
.
≤
a α
150 ln ^{4K}
60L α ln ^{2−α} ^{4K}
β
β

(177)

Upper bound for 2. From E T −1 it follows that

2

T
−1
X

≤

t=0

b
^{α} t+1 kθ t+1
k · kη t k

(168),(172)

≤

3R · 2 α σ α

T
−1
X

30
α t+1 ^{(156)}
α
α−1 ≤ ^{12Rσ} ·
λ
t=0 ^{t}

α−1

T
−1
X
ln α−1 4K
β

R α−1

t=0

T
−1
α 2−α
2
X
T (T + 1) α ln α−1 4K
360σ ^{α} R ^{2−α} ln ^{α−1} ^{4K}
1 180σ R
β
β (155) R
α
≤
·
.
(t
+
2)
≤
2 α a α L α
a α
L α
5
t=0

≤

α α
t+1

(178)

Upper bound for 3. First, we have


h
ii
h
2
2
u
u
= 0.
− ^{E} ^{ξ} ^{t} ^{θ} t+1
^{E} ^{ξ} ^{t} ^{2α} ^{2} t+1 ^{θ} t+1

Next, sum 3 has bounded with probability 1 terms:

h
i
2
2
u
u
^{2α} ^{2} t+1 ^{θ} t+1
− ^{E} ^{ξ} ^{t} ^{θ} t+1

≤

(171)

≤

h
i

2
u
u
^{2α} ^{2} t+1 kθ t+1
k ^{2} ^{+} ^{E} ^{ξ} ^{t} ^{θ} t+1

(156)

16α ^{2} t+1 λ ^{2} t ≤

^{R} ^{2} def
= c.
5 ln 4K
β

(179)



h
i 2 
2
2
def
u
u
:
− ^{E} ^{ξ} ^{t} ^{θ} t+1
The summands also have bounded conditional variances σ
e t ^{2} ^{=} ^{E} ^{ξ} ^{t} ^{4α} ^{4} t+1 ^{θ} t+1

h
R 2
2
t 2α
E
ξ
t+1
5 ln 4K
β

(179)

σ
e t 2

≤

u
^{θ} t+1

2

− E ξ k

h

u
^{θ} t+1

2

i i

 u 2 
≤ ^{α} ^{2} t+1 ^{R} ^{2} ^{E} ^{ξ} ^{t} kθ t+1
k ,

(180)

n

h
io ^{T} ^{−1}
2
2
2
u
u
t
since ln ^{4K}
≥
1.
In
other
words,
we
showed
that
2α
θ
θ
−
E
is a bounded martingale
ξ
t+1
t+1
t+1
β

t=0

−1
difference sequence
^{σ} t ^{2} } ^{T} t=0
. Next, we apply Bernstein’s inequality (Lemma B.2)
 with bounded h conditional
i variances {e

with ^{X} t ^{=} ^{2α} ^{2} t+1

u
^{θ} t+1

2

u
^{θ} t+1

− E ξ t

(

^{P} |3| ^{>}

R 2
5

and

2

β

T
−1
X

t=0

Equivalently, we have

β
P {E 3 } ≥ 1 −
,
2K

σ
e t 2 ≤

for E 3 =

(

R 4
150 ln ^{4K}
β

either

t=0

σ
e t 2

(180)

≤

R 2

T
−1
X

t=0

)

T
−1
X

t=0

In addition, E T −1 implies that

T
−1
X

4

2

^{,} ^{parameter} ^{c} ^{as} ^{in} ^{(179),} ^{b} ^{=} ^{R} 5 ^{,} ^{G} ^{=} 150 ^{R} ln 4K ^{:}


≤ 2 exp −

σ
e t 2 >

b 2
2G + 2cb / 3

R 4
150 ln ^{4K}
β



=

R 2
^{or} |3| ≤
5

T
−1
X
 u 2 
 u 2  (177)
≤
^{α} ^{2} t+1 ^{E} ^{ξ} ^{t} kθ t+1
k ≤ 9R 2
^{α} ^{2} t+1 ^{E} ^{ξ} ^{t} kθ t+1
k

t=0

46

β
.
2K

)

.

R 4
.
150 ln ^{4K}
β

(181)

(182)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Upper bound for 4. From E T −1 it follows that

4

= 2

T
−1
X

h

^{α} ^{2} t+1 ^{E} ^{ξ} ^{t}

t=0

u
^{θ} t+1

2

i

h
i
X
R 2
R 2
1
2 (177)
u
2
2
t
θ
·
9R
α
E
.
≤
≤
ξ
t+1
t+1
R 2
5
150 ln ^{4K}
β
t=0

T −1

≤

(183)

Upper bound for 5. From E T −1 it follows that

5 =

2

T
−1
X

b
^{α} ^{2} t+1 ^{θ} t+1

t=0

=

2

2α+1

2

≤ 2 2α+1 σ 2α

T
−1
X

^{α} ^{2} t+1 (156) ^{2}
=
λ 2α−2
t=0 ^{t}

T
−1
X
· 30 2α−2 σ 2α ln 2α−2 4K
β

2α+1

R 2α−2

α 2α
t+1

t=0
2α−2 4K T −1
2α−2 4K
2α
2α
2
X
· 30
σ ln
1 1800σ T (T + 1) ln
β
β (155) R
2α
·
≤
.
(t
+
2)
≤
2 2α a 2α L 2α R 2α−2
a 2α
L 2α R 2α−2
5
t=0

2α−2 2α

(184)

Now, we have the upper bounds for 1, 2, 3, 4, 5. In particular, probability event E T −1 implies

(170)

B T ≤ R 2 + 1 + 2 + 3 + 4 + 5,

(178) R ^{2}

2 ≤

T
−1
X

t=0

(177)

σ t 2 ≤

5

,

(183) R ^{2}

4 ≤

,

5
T
−1
X

R 4
,
150 ln ^{4K}
β

t=0

(184) R ^{2}

5 ≤

(182)

σ
e t 2 ≤

5

,

R 4
.
150 ln ^{4K}
β

Moreover, we also have (see (176), (181) and our induction assumption)

P{E T −1 } ≥ 1 −

(T − 1)β
,
K

P{E 1 } ≥ 1 −

β
,
2K

P{E 3 } ≥ 1 −

β
,
2K

where

E 1

E 3

=

=

(

(

either

T
−1
X

t=0

either

T
−1
X

t=0

Thus, probability event E T −1 ∩ E 1 ∩ E 3 implies

B T

R T 2

≤

(164)

≤

σ t 2 >

R 2 +

σ
e t 2 >

R 4
150 ln ^{4K}
β

R 2
^{or} |1| ≤
5

R 4
150 ln ^{4K}
β

R 2
^{or} |3| ≤
5

)

)

,

.

R 2
R 2
R 2
R 2
R 2
+
+
+
+
= 2R 2 ,
5
5
5
5
5

R ^{2} + 2R ^{2} ≤ (2R) ^{2} ,

which is equivalent to (160) and (161) for t = T , and


Tβ
.
P{E T } ≥ P {E T −1 ∩ E 1 ∩ E 3 } = 1 − P E T −1 ∪ E 1 ∪ E 3 ≥ 1 − P{E T −1 } − P{E 1 } − P{E 3 } ≥ 1 −
K

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K we have P{E k } ≥ 1 − ^{kβ} / K . In particular, for
k = K we have that with probability at least 1 − β

(163)

f (y K ) − f (x ∗ ) ≤

6aLR ^{2}
K(K + 3)

k K
k K
∗
and {x ^{k} } ^{K+1}
k=0 ^{,} {z } k=0 ^{,} {y } k=0 ⊆ ^{B} 2R ^{(x} ^{),} ^{which} ^{follows} ^{from} ^{(161).}

47

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Finally, if




1

α−1

4K 900σ(K + 1)K α ln α
,
a = max 48600 ln ^{2}

β
LR

then with probability at least 1 − β

f (y K ) − f (x ∗ ) ≤

=



4K 
β



,



α−1
1
4K 
2 2 4K

α ln α
5400σR(K
+
1)K
291600LR
ln
6aLR
β
β
= max
,


K(K + 3)
K(K + 3)
K(K + 3)




K 
 LR 2 ln 2 K σR ln α−1
α
β
β
 .
,
O  max
α−1


K 2
α
K

2

To get f (y ^{K} ) − f (x ∗ ) ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
r
 α

 α !!

LR ^{2} LR ^{2} σR α−1
1 σR α−1
ln
K = O
ln
,
ε
εβ
ε
β
ε

that concludes the proof.

F.2. Strongly Convex Functions

In the strongly convex case, we consider the restarted version of clipped-SSTM (R-clipped-SSTM). The main result is
summarized below.

Algorithm 3 Restarted clipped-SSTM (R-clipped-SSTM) (Gorbunov et al., 2020)

Input: starting point x ^{0} , number of restarts τ , number of steps of clipped-SSTM between restarts {K t } τt=1 , stepsize
K 1 −1
K 2 −1
K τ −1
parameters {a t } τt=1 , clipping levels {λ ^{1} k } k=0
^{,} {λ ^{2} k } k=0
^{,} ^{.} ^{.} ^{.} ^{,} {λ ^{τk} } k=0
, smoothness constant L.
0
0
1: x̂ = x
2: for t = 1, . . . , τ do
K t −1
, and
3:
Run ^{clipped-SSTM} (Algorithm 2) for K t iterations with stepsize parameter a t , clipping levels {λ tk } k=0
t−1
t
starting point x̂ . Define the output of clipped-SSTM by x̂ .
4: end for
Output: x̂ ^{τ}

Theorem F.3 (Full version of Theorem 3.3). Let Assumptions 1.1, 1.3, 1.6 with μ > 0 hold for Q = B 3R (x ∗ ), where
R ≥ kx ^{0} − x ∗ k ^{2} and R-clipped-SSTM runs clipped-SSTM τ times. Let
q

 

s
α
α !


 α−1
 α−1
2 τ


2
LR
2160
t−1
^{LR} t−1
5400σR t−1
4τ 5400σR t−1
 ,
, 2
K t = 
ln
(185)
ln
√
 max  1080
 
ε t
ε t β
ε t
β
ε t




2
^{μR} t−1
μR 2
4K t τ
R
ε t =
, ln
, R t−1 = (t−1) / 2 , τ = log 2
≥ 1,
(186)
4
2ε
β
2


1
α−1
4K t τ 
α

α
900σ(K
+
1)K
ln
t
4K
τ
t
β
t
,
(187)
,
a t = max 48600 ln ^{2}


β
LR t

λ tk =

R t
t
30α k+1 ln ^{4K} β ^{t} ^{τ}

for t = 1, . . . , τ . Then to guarantee f (x̂ ^{τ} ) − f (x ∗ ) ≤ ε with probability ≥ 1 − β R-clipped-SSTM requires
(s
√
α
  α
 ^{2} !  ^{2}  2(α−1)
 2 
 ^{2} !)!
L
L
σ
μR
μR
1 σ ^{2} 2(α−1)
μR
O max
ln √
,
ln
ln
ln
ln
μβ
μ
ε
ε
με
β με
ε

48

(188)

(189)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

iterations/oracle calls. Moreover, with probability ≥ 1 − β the iterates of R-clipped-SSTM at stage t stay in the ball
^{B} ^{2R} t−1 ^{(x} ^{∗} ^{).}

Proof. We show by induction that for any t = 1, . . . , τ with probability at least 1 − ^{tβ} / τ inequalities

f (x̂ ^{l} ) − f (x ^{∗} ) ≤ ε l ,

kx̂ ^{l} − ^{x} ^{∗} k ^{2} ≤ ^{R} l ^{2} ^{=}

R 2
2 l

(190)

hold for l = 1, . . . , t simultaneously. First, we prove the base of the induction. Theorem F.2 implies that with probability
at least 1 − ^{β} / τ


1
4K 1 τ 
 291600LR 2 ln ^{2} ^{4K} 1 ^{τ} 5400σR(K 1 + 1)K α ln ^{α−1}
α
2
6a
LR
1
(187)
1
β
β
f (x̂ ^{1} ) − f (x ^{∗} ) ≤
= max
,


K 1 (K 1 + 3)
K 1 (K 1 + 3)
K 1 (K 1 + 3)


4K 1 τ 
 291600LR 2 ln ^{2} ^{4K} 1 ^{τ} 5400σR ln ^{α−1}
α
β
β
,
≤ max
α−1


K 1 2
α
K 1

(185)

≤

ε 1 =

μR 2
4

and, due to the strong convexity,

kx̂ ^{1} − ^{x} ^{∗} k ^{2} ≤

2(f (x̂ ^{1} ) − f (x ∗ ))
R 2
≤
= R 1 2 .
μ
2

The base of the induction is proven. Now, assume that the statement holds for some t = T < τ , i.e., with probability at
least 1 − ^{T} ^{β} / τ inequalities
R 2
(191)
^{f} ^{(x̂} ^{l} ^{)} − ^{f} ^{(x} ^{∗} ^{)} ≤ ^{ε} l ^{,} kx̂ ^{l} − ^{x} ^{∗} k ^{2} ≤ ^{R} l ^{2} ^{=} l
2
^{hold} ^{for} ^{l} ^{=} ^{1,} ^{.} ^{.} ^{.} ^{,} ^{T} ^{simultaneously.} ^{In} ^{particular,} ^{with} ^{probability} ^{at} ^{least} ^{1} − ^{T} ^{β} ^{/} ^{τ} ^{we} ^{have} kx̂ ^{T} − ^{x} ^{∗} k ^{2} ≤ ^{R} T ^{2} ^{.} ^{Applying}
Theorem F.2 and using union bound for probability events, we get that with probability at least 1 − ^{(T} ^{+1)β} / τ

f (x̂ ^{T} ^{+1} ) − f (x ∗ )

6a T +1 LR T 2
K T +1 (K T +1 + 3)


1
4K T +1 τ 
 291600LR 2 ln ^{2} ^{4K} T +1 ^{τ} 5400σR T (K T +1 + 1)K α ln ^{α−1}
α
T
T +1
β
β
,
max

 K T +1 (K T +1 + 3)
K T +1 (K T +1 + 3)


4K T +1 τ 
 291600LR 2 ln ^{2} ^{4K} T +1 ^{τ} 5400σR T ln ^{α−1}
α
T
β
β
max
,
α−1


K T 2 +1
α
K T +1

≤

(187)

=

≤

(185)

≤

ε T +1 =

μR T 2
4

and, due to the strong convexity,

kx̂ ^{T} ^{+1} − ^{x} ^{∗} k ^{2} ≤

R 2
2(f (x̂ ^{T} ^{+1} ) − f (x ∗ ))
≤ T = R T 2 +1 .
μ
2

Thus, we finished the inductive part of the proof. In particular, with probability at least 1 − β inequalities

f (x̂ ^{l} ) − f (x ^{∗} ) ≤ ε l ,

kx̂ ^{l} − ^{x} ^{∗} k ^{2} ≤ ^{R} l ^{2} ^{=}

R 2
2 l

hold for l = 1, . . . , τ simultaneously, which gives for l = τ that with probability at least 1 − β

f (x̂ ^{τ} ) − f (x ∗ ) ≤ ε τ =

μR τ 2 −1
μR ^{2} (186)
= τ +1 ≤ ε.
4
2

49

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

It remains to calculate the overall number of oracle calls during all runs of clipped-SSTM. We have
 
 s

 q

α
α !


 α−1
 α−1
2 τ
τ
τ

 LR 2
^{LR} t−1
X
X
^{τ} ^{σR} t−1
t−1
 , ^{σR} t−1

ln  √
ln
K t = O 
max


ε t
ε t β
ε t
β
ε t
t=1
t=1
(s
√ ! 
α
^{α} !)!

 α−1
 α−1
τ
X
L
Lτ
τ
σ
σ
ln
,
ln √
= O
max
μ
μβ
^{μR} t−1
^{β} ^{μR} t−1
t=1
( s
α
√ ! τ 


 ^{α} !)!
t
X σ · 2 ^{t} / 2 α−1
τ σ · 2 / 2 α−1
L
Lτ
ln
= O max τ
,
ln √
μ
μβ
μR
β
μR
t=1
(s
)!
√
α
 α−1

 α ! τ
 2 
 2 ! 
τ
αt
σ
μR
L
L
^{τ} ^{σ} · ^{2} ^{/} ^{2} ^{α−1} X 2(α−1)
μR
= O max
ln √
,
ln
ln
2
ln
μ
ε
μβ
ε
μR
β
μR
t=1
!
)!
(s
√
 α

 α
 2 
 2 ! 
α
ατ
L
L
τ
σ α−1
σ α−1
μR
μR
ln
· 2 2(α−1) 2 2(α−1)
= O max
ln √
,
ln
ln
μ
ε
μβ
ε
μR
β μR
(s
√
α
  α
 2 
 ^{2} !  ^{2}  2(α−1)
 ^{2} !)!
σ
μR
μR
1 σ ^{2} 2(α−1)
μR
L
L
ln √
,
,
ln
ln
ln
ln
= O max
μ
ε
μβ
ε
με
β με
ε

which concludes the proof.

50

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

G. Missing Proofs for clipped-SEG

In this section, we provide the complete formulation of the main results for clipped-SSTM
and

 and R-clipped-SSTM
x k ) =
the missing proofs. For brevity, we will use the following notation: F e ξ 1 k (x ^{k} ) = clip F ξ 1 k (x ^{k} ), λ k and F e ξ 2 k (e


clip F ξ 2 k (e
x k ), λ k .

Algorithm 4 Clipped Stochastic Extragradient (clipped-SEG) (Gorbunov et al., 2022a)

Input: starting point x ^{0} , number of iterations K, stepsize γ > 0, clipping levels {λ k } ^{K−1}
k=0 ^{.}
1: for k = 0, . . . , K do


2:
Compute F e ξ 1 k (x ^{k} ) = clip F ξ 1 k (x ^{k} ), λ k using a fresh sample ξ 1 ^{k} ∼ D k
3:
x
e k = x k − γ F e ξ 1 k (x k )


4:
Compute F e ξ 2 k (e
x ^{k} ) = clip F ξ 2 k (e
x ^{k} ), λ k using a fresh sample ξ 2 ^{k} ∼ D k
5:
x k+1 = x k − γ F e ξ 2 k (e
x k )
6: end for
K
P
1
x
e K
Output: x ^{K+1} or x
e K
avg ^{=} K+1

k=0

G.1. Monotone Problems

We start with the following lemma derived by Gorbunov et al. (2022b). Since this lemma handles only deterministic part
of the algorithm, the proof is the same as in the original work.
Lemma G.1 (Lemma C.1 from (Gorbunov et al., 2022b)). Let Assumptions 1.7 and 1.8 hold for Q = B 4R (x ∗ ), where
√
e ^{k} lie in B 4R (x ∗ ) for all k = 0, 1, . . . , K for some K ≥ 0, then for all
R ≥ kx ^{0} − x ∗ k and 0 < γ ≤ ^{1} / 2L . If x ^{k} and x
∗
u ∈ B 4R (x ) the iterates produced by clipped-SEG satisfy

K

hF (u), x
e K
avg − ^{ui}

x
e K
avg

θ k

ω k

≤

X

kx 0 − uk 2 − kx K+1 − uk 2
γ
+
kθ k k ^{2} + 2kω k k ^{2}
2γ(K + 1)
2(K + 1)

k=0

+

def

=

1
K +1

K

K
X

hx k − u − γF (e
x k ), θ k i,

(192)

k=0

1 X k
x
e ,
K +1

(193)

k=0

def

=

def

=

F (e
x k ) − F e ξ 2 k (e
x k ),

(194)

F (x k ) − F e ξ 1 k (x k ).

(195)

Using this lemma we prove the main convergence result for clipped-SEG in the monotone case.
Theorem G.2 (Case 1 in Theorem 4.1). Let Assumptions 1.1, 1.7, 1.8 hold for Q = B 4R (x ∗ ), where R ≥ kx ^{0} − x ∗ k, and


2−α


1
20 α R
0 < γ ≤ min
,
,
(196)
α−1
 160L ln ^{6(K+1)} 10800 α ^{1} (K + 1) α ^{1} σ ln α ^{6(K+1)} 

β

λ k ≡ λ =

R

20γ ln ^{6(K+1)}
β

β

,

(197)

for some K ≥ 0 and β ∈ (0, 1] such that ln ^{6(K+1)}
≥ 1. Then, after K iterations the iterates produced by clipped-SEG
β
with probability at least 1 − β satisfy

Gap R (e
x K
avg ^{)} ≤

9R 2
2γ(K + 1)

∗
∗
and {x ^{k} } ^{K+1}
x k } K+1
k=0 ⊆ ^{B} ^{3R} ^{(x} ^{),} {e
k=0 ⊆ ^{B} ^{4R} ^{(x} ^{),}

51

(198)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where x
e K
avg is defined in (193). In particular, when γ equals the minimum from (196), then the iterates produced by
clipped-SEG after K iterations with probability at least 1 − β satisfy
 


K 
 LR 2 ln K σR ln α−1
α
β
β
 ,
 max
,
(199)
Gap R (e
x K
α−1
avg ^{)} ^{=} O


K
α
K

meaning that to achieve Gap R (e
x K
avg ) ≤ ε with probability at least 1 − β clipped-SEG requires
!
 α

LR ^{2} LR ^{2} σR α−1 σR
ln
K = O
iterations/oracle calls.
ln
,
ε
εβ
ε
εβ

(200)

Proof. The proof follows similar steps as the proof of Theorem C.1 from (Gorbunov et al., 2022a). The key difference is
related to the application of Bernstein inequality and estimating biases and variances of stochastic terms.

Let R k = kx ^{k} −x ∗ k for all k ≥ 0. As in the previous results, the proof is based on the induction argument and showing that
the iterates do not leave some ball around the solution with high probability. More precisely, for each k = 0, 1, . . . , K + 1
we consider probability event E k as follows: inequalities
(
)
t−1
t−1
X
X

0
2
l
l
2
2
2
hx − u − γF (e
x ), θ l i + γ
kθ l k + 2kω l k
max ∗ kx − uk + 2γ
≤ 9R 2 ,
(201)

u∈B R (x )

l=0

|

{z

l=0

}

A t

γ

t−1
X

l=0

θ l ≤ R

(202)

hold for t = 0, 1, . . . , k simultaneously. We want to prove P{E k } ≥ 1 − ^{kβ} / (K+1) for all k = 0, 1, . . . , K + 1 by induction.
The base of the induction is trivial: for k = 0 we have kx ^{0} − uk ^{2} ≤ 2kx ^{0} − x ∗ k ^{2} + 2kx ∗ − uk ^{2} ≤ 4R ^{2} ≤ 9R ^{2} and
P k−1
kγ l=0 ^{θ} l k ^{=} ^{0} ^{for} ^{any} ^{u} ∈ ^{B} R ^{(x} ^{∗} ^{).} ^{Next,} ^{assume} ^{that} ^{for} ^{k} ^{=} ^{T} − ^{1} ≤ ^{K} ^{the} ^{statement} ^{holds:} P{E T −1 } ≥
1 − ^{(T} −1)β / (K+1) . Given this, we need to prove P{E T } ≥ 1 − ^{T} ^{β} / (K+1) . We start with showing that E T −1 implies
R t ≤ 3R for all t = 0, 1, . . . , T (also by induction). For t = 0 this is already shown. Now, assume that R t ≤ 3R for all
t = 0, 1, . . . , t ′ for some t ′ < T . Then for t = 0, 1, . . . , t ′

ke
x t − x ∗ k

=

≤

kx t − x ∗ − γ F e ξ 1 t (x t )k ≤ kx t − x ∗ k + γk F e ξ 1 t (x t )k

(197)

kx t − x ∗ k + γλ ≤ 3R +

R

20 ln 6(K+1)
β

≤ 4R.

(203)

Therefore, the conditions of Lemma G.1 are satisfied and we have that E T −1 implies
n
o
′
′
max ∗ 2γ(t ^{′} + 1)hF (u), x
e ^{t} avg − ^{ui} ^{+} kx ^{t} ^{+1} − ^{uk} ^{2}
u∈B R (x )
)
(
t ′
P
l
l
0
2
x ), θ l i
≤ max ∗ kx − uk + 2γ hx − u − γF (e

u∈B R (x )

l=0

+γ 2

t ′
P

l=0

(201)

≤ 9R 2 ,

kθ l k ^{2} + 2kω l k ^{2}



meaning that

′

kx t +1 − x ∗ k 2 ≤

max ∗

u∈B R (x )

o
n
′
′
2γ(t ′ + 1)hF (u), x
e ^{t} avg − ^{ui} ^{+} kx ^{t} ^{+1} − ^{uk} ^{2} ≤ ^{9R} ^{2} ^{,}

i.e., R t ′ +1 ≤ 3R. In other words, we derived that probability event E T −1 implies R t ≤ 3R and

max ∗ 2γ(t + 1)hF (u), x
e ^{t} avg − ui + kx ^{t+1} − uk ^{2} ≤ 9R ^{2}

u∈B R (x )

52

(204)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

for all t = 0, 1, . . . , T . In addition, due to (203) E T −1 also implies that ke
x ^{t} − x ∗ k ≤ 4R for all t = 0, 1, . . . , T . Thus,
E T −1 implies

kx t − x ∗ − γF (e
x t )k

(11)

≤

x t − x ∗ k
kx ^{t} − x ∗ k + γkF (e
x ^{t} )k ≤ 3R + γLke

≤

3R + 4RγL ≤ 5R,

(196)

(203)

(205)

for all t = 0, 1, . . . , T . Next, we introduce random vectors
(
x t − x ∗ − γF (e
x t ), if kx t − x ∗ − γF (e
x ^{t} )k ≤ 5R,
η t =
0,
otherwise,

for all t = 0, 1, . . . , T . These vectors are bounded almost surely:

kη t k ≤ 5R

(206)

for all t = 0, 1, . . . , T . Moreover, due to (205), probability event E T −1 implies η t = x ^{t} − x ∗ − γF (e
x ^{t} ) for all t =
0, 1, . . . , T and
(
)
T
−1
T
−1
T
−1
X
X
X

0
2
∗
hx − u, θ l i + 2γ
hx l − x ∗ − γF (e
x l ), θ l i + γ 2
A T =
max ∗ kx − uk + 2γ
kθ l k ^{2} + 2kω l k ^{2}

u∈B R (x )

≤ 4R 2 + 2γ

max

u∈B R (x ∗ )

= 4R ^{2} + 2γR

T
−1
X

(*

l=0

x ∗ − u,

θ l + 2γ

l=0

T
−1
X

l=0

T
−1
X

l=0

θ l

+)

l=0

+ 2γ

hη l , θ l i + γ 2

T
−1
X

l=0

T
−1
X

l=0

l=0

hη l , θ l i + γ 2

T
−1
X

kθ l k ^{2} + 2kω l k ^{2}

l=0


kθ l k ^{2} + 2kω l k ^{2} ,



where A T is defined in (201).

To handle the sums appeared in the right-hand side of the previous inequality we consider unbiased and biased parts of
θ l , ω l :
h
h
i
i
def
def
θ l u = E ξ 2 l F e ξ 2 l (e
x l ) − F e ξ 2 l (e
x l ), θ l b = F (e
x l ) − E ξ 2 l F e ξ 2 l (e
x l ) ,
(207)
i
i
h
h
def
def
ω l u = E ξ 1 l F e ξ 1 l (x l ) − F e ξ 1 l (x l ), ω l b = F (x l ) − E ξ 1 l F e ξ 1 l (x l ) ,
(208)

for all l = 0, . . . , T − 1. By definition we have θ l = θ l ^{u} + θ l ^{b} , ω l = ω l ^{u} + ω l ^{b} for all l = 0, . . . , T − 1. Therefore, E T −1
implies

A T

≤

4R ^{2} + 2γR

T
−1
X

θ l + 2γ

l=0

+ 2γ 2

|

+ 2γ 2

|

+ 2γ 2

|

T
−1 
X

l=0

|

T
−1
X

l=0

hη l , θ l u i + 2γ

{z

}

1

l=0

{z

l=0

hη l , θ l b i

{z

2

}

}





kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2}

{z

4

T
−1
X

l=0





E ξ 2 l kθ l u k 2 + 2E ξ 1 l kω l u k 2

3

T
−1 
X

|

T
−1
X


kθ l ^{b} k ^{2} + 2kω l ^{b} k ^{2} ,

{z

5

53

}

}

(209)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where we also apply inequality ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} to upper bound kθ l k ^{2} and kω l k ^{2} . It
P T −1
remains to derive good enough high-probability upper-bounds for the terms 2γR
l=0 ^{θ} l ^{,} ^{1,} ^{2,} ^{3,} ^{4,} ^{5,} ^{i.e.,} ^{to} ^{finish}
P T −1
2
our inductive proof we need to show that 2γR
l=0 ^{θ} l ^{+} ^{1} ^{+} ^{2} ^{+} ^{3} ^{+} ^{4} ^{+} ^{5} ≤ ^{5R} ^{with} ^{high} ^{probability.} ^{In} ^{the}

u
b
subsequent parts of the proof, we will need use many times the bounds for the norm and second moments of ^{θ} t+1
and ^{θ} t+1
.
First, by definition of clipping operator we have with probability 1 that

kθ l ^{u} k ≤ 2λ,

kω l ^{u} k ≤ 2λ.

(210)

Moreover, since E T −1 implies that

(203)

(11)

(197) ^{λ}

R

(196)

(11)

kF (x ^{l} )k ≤ Lkx ^{l} − x ^{∗} k ≤ 3LR ≤

40γ ln ^{6(K+1)}
β

R

(196)

x ^{l} − x ^{∗} k ≤ 4LR ≤
kF (e
x ^{l} )k ≤ Lke

=

2

,

(197) ^{λ}

40γ ln ^{6(K+1)}
β

=

2

for t = 0, 1, . . . , T − 1. Then, in view of Lemma 5.1, we have that E T −1 implies

θ l b ≤

for all l = 0, 1, . . . , T − 1.

Upper bound for 1.

2 α σ α
^{ω} ^{l} ^{b} ^{≤} α−1 ^{,}
λ i
h
E ξ 1 l kω l k ^{2} ≤ 18λ ^{2−α} σ ^{α} ,
i
h
2
E ξ 1 l kω l ^{u} k ≤ 18λ ^{2−α} σ ^{α} ,

2 α σ α
,
λ α−1

i
h
E ξ 2 l kθ l k ^{2} ≤ 18λ ^{2−α} σ ^{α} ,
i
h
2
E ξ 2 l kθ l ^{u} k ≤ 18λ ^{2−α} σ ^{α} ,

(211)

(212)

(213)

By definition of θ l ^{u} , we have E ξ 2 l [θ l ^{u} ] = 0 and

E ξ 2 l [2γhη l , θ l ^{u} i] = 0.

Next, sum 1 has bounded with probability 1 terms:

|2γhη l ^{,} ^{θ} l ^{u} i| ≤ ^{2γkη} l k · kθ l ^{u} k

(206),(210)

≤

(197)

20γRλ =

R 2

def

= c.

ln 6(K+1)
β

(214)



def
The summands also have bounded conditional variances σ l ^{2} = E ξ 2 l 4γ ^{2} hη l , θ l ^{u} i ^{2} :

 (206)



σ l ^{2} ≤ E ξ 2 l 4γ ^{2} kη l k ^{2} · kθ l ^{u} k ^{2} ≤ 100γ ^{2} R ^{2} E ξ 2 l kθ l ^{u} k ^{2} .

(215)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {2γhη l ^{,} ^{θ} l ^{u} i} ^{T} l=0
is a bounded martingale difference sequence with bounded conditional
T
−1
2
variances {σ l } l=0 . Next, we apply Bernstein’s inequality (Lemma B.2) with X l = 2γhη l , θ l ^{u} i, parameter c as in (214),
R 4
b = R 2 , G =
6(K+1) ^{:}

6 ln

β

(

2

^{P} |1| ^{>} ^{R} ^{and}

T
−1
X

l=0

σ l 2 ≤

R 4

6 ln 6(K+1)
β

)



b 2
≤ 2 exp −
2G + 2cb / 3



=

β
.
3(K + 1)

Equivalently, we have

β
,
P{E 1 } ≥ 1 −
3(K + 1)

for E 1 =

(

either

T
−1
X

l=0

54

σ l 2 >

R 4

6 ln 6(K+1)
β

or

|1| ≤ ^{R}

2

)

.

(216)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

In addition, E T −1 implies that

T
−1
X

σ l 2

l=0

(215)

T
−1
X

 ^{(213),T} ≤K+1

E ξ 2 l kθ l u k 2
≤
1800(K + 1)γ ^{2} R ^{2} λ ^{2−α} σ ^{α}

≤

100γ ^{2} R ^{2}

(197)

1800(K + 1)γ ^{α} σ ^{α} R ^{4−α} (196)
R 4
≤
.
20 2−α ln 2−α ^{6(K+1)}
6 ln 6(K+1)
β
β

l=0

≤

(217)

Upper bound for 2. From E T −1 it follows that

2

≤

2γ

T
−1
X

l=0

kη l k · kθ l b k

^{(206),(211),T} ≤K+1 10 · 2 ^{α} (K + 1)γRσ ^{α}

≤

λ α−1

(196)
10 · 2 ^{α} · 20 ^{α−1} (K + 1)γ ^{α} σ ^{α} ln ^{α−1} ^{6(K+1)}
β
≤ R 2 .
α−2
R

(197)

=

(218)

Upper bound for 3. From E T −1 it follows that

2γ

2

T
−1
X

l=0

4γ

2

T
−1
X

l=0

^{(212),T} ≤K+1

E ξ 2 l [kθ l ^{u} k ^{2} ]

≤

^{(212),T} ≤K+1

E ξ 1 l [kω l ^{u} k ^{2} ]

≤

(219),(220)

≤

3

Upper bound for 4.

(197)

36γ ^{2} (K + 1)λ ^{2−α} σ ^{α} =

(197)

72γ ^{2} (K + 1)λ ^{2−α} σ ^{α} =

36γ ^{α} (K + 1)σ ^{α}

20 2−α ln 2−α ^{6(K+1)}
β

72γ ^{α} (K + 1)σ ^{α}

20 2−α ln 2−α ^{6(K+1)}
β

(196)

≤

(196)

≤

1 2
R ,
12

(219)

1 2
R ,
12

(220)

1 2
R .
6

(221)

By the construction we have
h
i



2γ ^{2} E ξ 1 l ,ξ 2 l kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2} = 0.

Next, sum 1 has bounded with probability 1 terms:





2γ ^{2} kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2}

≤

(210)

≤

(197)

≤



2γ 2 kθ l u k 2 + 2γ 2 E ξ 2 l kθ l u k 2


+4γ ^{2} kω l ^{u} k ^{2} + 4γ ^{2} E ξ 1 l kω l ^{u} k ^{2}

48γ ^{2} λ ^{2}
R 2

6 ln 6(K+1)
β

def

= c.

(222)

The summands also
 have bounded conditional variances



 2

2 def
4
:
σ
e l = 4γ E ξ 1 l ,ξ 2 l kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2}

σ
e l 2

(222)

≤

γ 2 R 2

3 ln

E l l
6(K+1) ^{ξ} 1 ^{,ξ} 2

2

≤

β
2

2γ R

3 ln 6(K+1)
β

h

 i



kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2}



E ξ 1 l ,ξ 2 l kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} .

(223)


n



o ^{T} ^{−1}
In other words, we showed that 2γ ^{2} kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2}
is a bounded martingale

l=0

−1
^{difference} ^{sequence} ^{with} ^{bounded} ^{conditional} ^{variances} {σ l ^{2} } ^{T} l=0
. Next, we apply Bernstein’s inequality (Lemma B.2)

55

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance






with X l = 2γ ^{2} kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 2E ξ 1 l kω l ^{u} k ^{2} , parameter c as in (222), b =

1 2
6 R ,

G =

.

(224)

4

216 ln

R
6(K+1) ^{:}
β

(

T −1

X
1
R 4
^{P} |4| ^{>} ^{R} ^{2} ^{and}
σ
e l 2 ≤
6
216 ln ^{6(K+1)}

l=0

β

)


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
3(K + 1)

Equivalently, we have

β
,
P{E 4 } ≥ 1 −
3(K + 1)

for E 4 =

(

T
−1
X

either

l=0

In addition, E T −1 implies that

T
−1
X

l=0

T
−1
X

2γ 2 R 2

(223)

σ
e l 2

≤

^{(213),T} ≤K+1

≤

σ
e l 2 >

R 4

216 ln ^{6(K+1)}
β

1
^{or} |4| ≤ ^{R} ^{2}
6





E ξ 1 l ,ξ 2 l kθ l ^{u} k ^{2} + 2kω l ^{u} k ^{2}
3 ln 6(K+1)
l=0
β
2 2 2−α α

36(K + 1)γ R λ

σ

ln 6(K+1)
β
36(K + 1)γ ^{α} R ^{4−α} σ ^{α} (196)

(197)

≤

≤

20 2−α ln 3−α ^{6(K+1)}
β

R 4

216 ln ^{6(K+1)}
β

.

)

(225)

Upper bound for 5. From E T −1 it follows that

5

2γ 2

=

T
−1
X

l=0

(197)

=

Upper bound for 2γR

P T −1

l=0

6 · 2

θ l .

2α

kθ l ^{b} k ^{2} + 2kω l ^{b} k ^{2}

 ^{(211),T} ≤K+1 6 · 2 ^{2α} γ ^{2} σ ^{2α} (K + 1)
≤
λ 2α−2

· 20 2α−2 γ 2α σ 2α (K + 1) ln 2α−2 6(K+1)
(196) 1
β
≤ R 2 .
2α−2
R
6

(226)

To upper-bound this sum, we introduce new random vectors:

 l−1
P
 γ P θ , if γ l−1
θ r ≤ R,
r
ζ l =
r=0
r=0

0,
otherwise

for l = 1, 2, . . . , T − 1. These vectors are bounded with probability 1:

kζ l k ≤ R.

(227)

Therefore, taking into account (202), we derive that E T −1 implies
v
u
2
T
−1
T
−1
u
X
X
t
2
θ l
2γR
= 2R γ
θ l

l=0

l=0

=

=

(207)

≤

v
+
* l−1
u T −1
T
−1
u X
X
X
t
2
2
kθ l k + 2γ
γ
θ r , θ l
2R γ

l=0

l=0

l=0

l=0

r=0

v
u T −1
T
−1
u X
X
2R t γ 2
kθ l k 2 + 2γ
hζ l , θ l i

v
u
T
−1
T
−1
X
X
u
u
3
+
4
+
5
+
2γ
hζ
,
θ
i
2R u
+
2γ
hζ l , θ l b i.
l
l
u
t
l=0
l=0
|
{z
} |
{z
}

6

56

7

(228)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Similarly to the previous parts of the proof, we bound 6 and 7.

By definition of θ l ^{u} , we have E ξ 2 l [θ l ^{u} ] = 0 and

Upper bound for 6.

E ξ 2 l [2γhζ l , θ l ^{u} i] = 0.

Next, sum 6 has bounded with probability 1 terms:

|2γhζ l ^{,} ^{θ} l ^{u} i| ≤ ^{2γkη} l k · kθ l ^{u} k

(227),(210)

≤

R 2

(197)

4γRλ ≤

def

= c.

4 ln 6(K+1)
β

(229)



def
The summands also have bounded conditional variances σ̂ l ^{2} = E ξ 2 l 4γ ^{2} hζ l , θ l ^{u} i ^{2} :

 (227)



σ̂ l 2 ≤ E ξ 2 l 4γ 2 kζ l k 2 · kθ l u k 2 ≤ 4γ 2 R 2 E ξ 2 l kθ l u k 2 .

(230)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {2γhζ l ^{,} ^{θ} l ^{u} i} ^{T} l=0
is a bounded martingale difference sequence with bounded conditional
2 T −1
^{variances} {σ̂ l } l=0 ^{.} ^{Next,} ^{we} ^{apply} ^{Bernstein’s} ^{inequality} ^{(Lemma} ^{B.2)} ^{with} ^{X} l ^{=} ^{2γhζ} l ^{,} ^{θ} l ^{u} i, ^{parameter} ^{c} ^{as} ^{in} ^{(229),}
2
R 4
b = R 4 , G =
6(K+1) ^{:}

96 ln

β

(

T −1

X
R 4
1
σ̂ l 2 ≤
^{P} |5| ^{>} ^{R} ^{2} ^{and}
4
96 ln 4(K+1)

l=0

Equivalently, we have

E 6 =

(

β

T
−1
X

either

l=0

In addition, E T −1 implies that

T
−1
X

σ̂ l 2

l=0

(230)

2

≤

σ̂ l 2 >

4γ R

2

T
−1
X

l=0

)


≤ 2 exp −

R 4

96 ln 6(K+1)
β

b 2
2G + 2cb / 3



1
^{or} |5| ≤ ^{R} ^{2}
4

=

)

β
.
3(K + 1)

.

(231)

 ^{(213),T} ≤K+1

≤
72(K + 1)γ ^{2} R ^{2} λ ^{2−α} σ ^{α}
E ξ 2 l kθ l u k 2

72(K + 1)γ ^{α} R ^{4−α} σ ^{α} (196)
R 4
.
≤
6(K+1)
20 2−α ln 2−α ^{6(K+1)}
96
ln
β
β

(197)

=

(232)

Upper bound for 7. From E T −1 it follows that

7

≤

2γ

T
−1
X

l=0

kζ l k · kθ l b k

=

Now, we have the upper bounds for 2γR

(209)

P T −1

l=0

2γR

T
−1
X

T
−1
X

l=0

(221) 1

3 ≤

R 4

T
−1
X

6 ln

β

l=0

θ l + 1 + 2 + 3 + 4 + 5,

l=0

√
≤ 2R 3 + 4 + 5 + 6 + 7,

2 ≤ R 2 ,

,
6(K+1)

(233)

(228)

θ l

l=0

(218)

(217)

λ α−1

θ l , 1, 2, 3, 4, 5. In particular, probability event E T −1 implies

A T ≤ 4R ^{2} + 2γR

σ l 2 ≤

≤

2 ^{α+1} · 20 ^{α−1} (K + 1)γ ^{α} σ ^{α} ln ^{α−1} ^{6(K+1)}
(196) 1
β
≤ R 2 .
α−2
R
4

(197)

T
−1
X

^{(227),(211),T} ≤K+1 2 ^{α+1} (K + 1)γRσ ^{α}

(226) 1

R 2 ,

5 ≤

(225)

R 4

6

σ
e l 2 ≤

216 ln

57

6

R 2 ,

,
6(K+1)

β

(233) 1

7 ≤

T
−1
X

l=0

4

R 2 ,

(232)

σ̂ l 2 ≤

R 4

96 ln 6(K+1)
β

.

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Moreover, we also have (see (216), (224), (231) and our induction assumption)

(T − 1)β
,
K +1
β
β
P{E 4 } ≥ 1 −
, P{E 6 } ≥ 1 −
,
3(K + 1)
3(K + 1)

P{E T −1 } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
3(K + 1)

where

E 1

E 4

E 6

(

=

(

=

(

=

either

T
−1
X

σ l 2 >

l=0

either

T
−1
X

l=0

either

T
−1
X

σ
e l 2 >

σ̂ l 2 >

l=0

R 4

6 ln 6(K+1)
β

R 4

216 ln ^{6(K+1)}
β

R 4

96 ln 6(K+1)
β

or

|1| ≤ ^{R}

2

)

,

)
1 2
^{or} |4| ≤ ^{R} ^{,}
6
)
1 2
^{or} |6| ≤ ^{R} ^{.}
4

Thus, probability event E T −1 ∩ E 1 ∩ E 4 ∩ E 6 implies
r
T
−1
X
1 2 1 2 1 2 1 2 1 2
R + R + R + R + R = R,
≤
γ
θ l
6
6
6
4
4
l=0
r
1 2 1 2 1 2 1 2 1 2
R + R + R + R + R
A T ≤ 4R 2 + 2R
6
6
6
4
4
1 2 1 2 1 2
2
2
+R + R + R + R + R
6
6
6
≤ 9R 2 ,

(234)

(235)

which is equivalent to (201) and (202) for t = T , and

P{E T } ≥ P{E T −1 ∩ E 1 ∩ E 4 ∩ E 6 } = 1 − P{E T −1 ∪ E 1 ∪ E 4 ∪ E 6 } ≥ 1 −

Tβ
.
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

Gap R (e
x K
=
max ∗ hF (u), x
e K
avg ^{)}
avg − ^{ui}

u∈B R (x )

≤

(204)

≤


1
e ^{t} avg − ui + kx ^{K+1} − uk ^{2}
max ∗ 2γ(K + 1)hF (u), x
2γ(K + 1) u∈B R (x )
9R 2
.
2γ(K + 1)

Finally, if

γ = min

then with probability at least 1 − β

Gap R (e
x K
avg ^{)}




2−α
α




1
20
R
,
6(K+1) 
 160L ln ^{6(K+1)} 10800 α ^{1} (K + 1) α ^{1} σ ln ^{α−1}
α

β

β



6(K+1) 
 720LR 2 ln ^{6(K+1)} 9σR ln ^{α−1}
α
9R 2
β
β
≤
= max
,
α−1
2−α

2γ(K + 1)
K +1
2 · 20 α (K + 1) α 
 


K 
 LR 2 ln K σR ln α−1
α
β
β
 .
= O  max
,
α−1


K
K α

58

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

To get Gap R (e
x K
avg ) ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
!
 α

LR ^{2} LR ^{2} σR α−1 σR
ln
,
ln
K = O
ε
εβ
ε
εβ

that concludes the proof.

G.2. Quasi-Strongly Monotone Problems

As in the monotone case, we use another lemma from (Gorbunov et al., 2022a) that handles the deterministic part of
clipped-SEG in the quasi-strongly monotone case.
Lemma G.3 (Lemma C.3 from (Gorbunov et al., 2022a)). Let Assumptions 1.7, 1.9 hold for Q = B 3R (x ∗ ) = {x ∈ R ^{d} |
kx − x ∗ k ≤ 3R}, where R ≥ kx ^{0} − x ∗ k, and 0 < γ ≤ ^{1} / 2(L+2μ) . If x ^{k} and x
e ^{k} lie in B 3R (x ∗ ) for all k = 0, 1, . . . , K for
some K ≥ 0, then the iterates produced by clipped-SEG satisfy

kx K+1 − x ∗ k 2

≤ (1 − γμ) ^{K+1} kx ^{0} − x ∗ k ^{2} − 4γ ^{3} μ

+2γ

K
X

K
X

k=0

(1 − γμ) ^{K−k} hF (x ^{k} ), ω k i

(1 − γμ) ^{K−k} hx ^{k} − x ∗ − γF (e
x k ), θ k i

k=0

+γ 2

K
X

k=0

where θ k , ω k are defined in (194), (195).


(1 − γμ) ^{K−k} kθ k k ^{2} + 4kω k k ^{2} ,

(236)

Using this lemma we prove the main convergence result for clipped-SEG in the quasi-strongly monotone case.
Theorem G.4 (Case 2 in Theorem 4.1). Let Assumptions 1.1, 1.7, 1.9, hold for Q = B 3R (x ∗ ) = {x ∈ R ^{d} | kx − x ∗ k ≤
3R}, where R ≥ kx ^{0} − x ∗ k, and
)
(
ln(B K )
1
,
,
(237)
0 < γ ≤ min
μ(K + 1)
650L ln ^{6(K+1)}
β


2(α−1)


(K + 1) α μ 2 R 2


(238)
B K = max 2,
2(α−1)
6(K+1)
 264600 α ^{2} σ ^{2} ln α
ln 2 (B K ) 
β

 














2(α−1)



2 2

α
K
μ
R
)!
(
= O 
max
2,
,
(239)

 
2(α−1)



2(α−1)




2 R 2
α
μ
K
2

K


2


max 2,
2(α−1)
 σ ln α
 

β ln
σ 2 ln α ( K
β )

λ k

=

exp(−γμ(1 + ^{k} / 2 ))R

120γ ln ^{6(K+1)}
β

,

(240)

≥ 1. Then, after K iterations the iterates produced by clipped-SEG
for some K ≥ 0 and β ∈ (0, 1] such that ln ^{6(K+1)}
β
with probability at least 1 − β satisfy

kx ^{K+1} − x ∗ k ^{2} ≤ 2 exp(−γμ(K + 1))R ^{2} .

(241)

In particular, when γ equals the minimum from (237), then the iterates produced by clipped-SEG after K iterations with
probability at least 1 − β satisfy
(
)!  


 
2(α−1)
2(α−1)
2 2


α
K
2
μ
R


K


! σ 2 ln α
max 2,
2(α−1)



β ln
 

K
2
α


σ ln
(
)
μK
β
K
∗ 2
2

 ,
,
kx − x k = O  max R exp −
(242)
2(α−1)

K


2
L
ln
α


K
μ


β







59

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

meaning that to achieve kx ^{K} − x ∗ k ^{2} ≤ ε with probability at least 1 − β clipped-SEG requires
!
α
  ^{2}  2(α−1)

 α !
 2  
α
L
σ
R 2
R
1 σ ^{2} 2(α−1)
L
ln
,
ln
ln
ln α−1 (B ε )
ln
K = O
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

iterations/oracle calls, where

B ε = max










2,

ε ln

 

1
β

R 2

σ 2
μ 2 ε

(243)






 .
α
 2(α−1)




Proof. Again, we will closely follow the proof of Theorem C.3 from (Gorbunov et al., 2022a) and the main difference will
be reflected in the application of Bernstein inequality and estimating biases and variances of stochastic terms.

Let R k = kx ^{k} −x ∗ k for all k ≥ 0. As in the previous results, the proof is based on the induction argument and showing that
the iterates do not leave some ball around the solution with high probability. More precisely, for each k = 0, 1, . . . , K + 1
we consider probability event E k as follows: inequalities

R t ^{2} ≤ 2 exp(−γμt)R ^{2}

(244)

hold for t = 0, 1, . . . , k simultaneously. We want to prove P{E k } ≥ 1 − ^{kβ} / (K+1) for all k = 0, 1, . . . , K + 1 by
induction. The base of the induction is trivial: for k = 0 we have R 0 ^{2} ≤ R ^{2} < 2R ^{2} by definition. Next, assume that for
k = T − 1 ≤ K the statement holds: P{E T −1 } ≥ 1 − ^{(T} −1)β / (K+1) . Given this, we need to prove P{E T } ≥ 1 − ^{T} ^{β} / (K+1) .
Since R t ^{2} ≤ 2 exp(−γμt)R ^{2} ≤ 9R ^{2} , we have x ^{t} ∈ B 3R (x ∗ ), where operator F is L-Lipschitz. Thus, E T −1 implies

kF (x t )k ≤

(244) √

Lkx ^{t} − x ^{∗} k ≤

2L exp(− ^{γμt} / 2 )R

(237),(240) λ
t

≤

2

(245)

and

kω t k 2

(245) 5

2k F e ξ 1 (x ^{t} )k ^{2} + 2kF (x ^{t} )k ^{2} ≤

≤

2

^{(240)} exp(−γμt)R ^{2}

λ 2 t ≤

4γ 2

(246)

for all t = 0, 1, . . . , T − 1, where we use that ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} .

Next, we need to prove that E T −1 implies ke
x ^{t} − x ∗ k ≤ 3R and show several useful inequalities related to θ t . Lipschitzness
of F probability event E T −1 implies

ke
x t − x ∗ k 2

kx ^{t} − x ∗ − γ F e ξ 1 (x ^{t} )k ^{2} ≤ 2kx ^{t} − x ∗ k ^{2} + 2γ ^{2} k F e ξ 1 (x ^{t} )k ^{2}

=

2R t 2 + 4γ 2 kF (x t )k 2 + 4γ 2 kω t k 2

≤

(11)

≤

2(1 + 2γ ^{2} L ^{2} )R t ^{2} + 4γ ^{2} kω t k ^{2}

≤

7 exp(−γμt)R ^{2} ≤ 9R ^{2}

(237),(246)

(247)

and

kF (e
x t )k

≤

Lke
x t − x ∗ k ≤

(237),(240) λ
√
t
7L exp(− ^{γμt} / 2 )R
≤
2

(248)

for all t = 0, 1, . . . , T − 1. Therefore, E T −1 implies that x ^{t} , x
e ^{t} ∈ B 3R (x ∗ ) for all t = 0, 1, . . . , T − 1. Using Lemma G.3
T
and (1 − γμ) ≤ exp(−γμT ), we obtain that E T −1 implies

R T 2

≤

exp(−γμT )R ^{2} − 4γ ^{3} μ

+2γ

T
−1
X

l=0

+γ 2

l=0

(1 − γμ) ^{T} −1−l hF (x ^{l} ), ω l i

(1 − γμ) ^{T} −1−l hx ^{l} − x ∗ − γF (e
x l ), θ l i

T
−1
X

l=0

T
−1
X


(1 − γμ) ^{T} −1−l kθ l k ^{2} + 4kω l k ^{2} .

60

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

To handle the sums above, we introduce a new notation:
(
√
F (x ^{t} ), if kF (x ^{t} )k ≤ 2L exp(− ^{γμt} / 2 )R,
ζ t =
0,
otherwise,
(
√
x t − x ∗ − γF (e
x t ), if kx t − x ∗ − γF (e
x ^{t} )k ≤ 7(1 + γL) exp(− ^{γμt} / 2 )R,
η t =
0,
otherwise,

(249)

(250)

for t = 0, 1, . . . , T − 1. These vectors are bounded almost surely:
√
√
kζ t k ≤ 2L exp(− ^{γμt} / 2 )R, kη t k ≤ 7(1 + γL) exp(− ^{γμt} / 2 )R
√
for all t = 0, 1, . . . , T − 1. We also notice that E T −1 implies kF (x ^{t} )k ≤ 2L exp(− ^{γμt} / 2 )R (due to (245)) and

kx t − x ∗ − γF (e
x t )k

≤

(247),(248)

≤

(251)

kx ^{t} − x ∗ k + γkF (e
x t )k
√
7(1 + γL) exp(− ^{γμt} / 2 )R

for t = 0, 1, . . . , T − 1. In other words, E T −1 implies ζ t = F (x ^{t} ) and η t = x ^{t} − x ∗ − γF (e
x ^{t} ) for all t = 0, 1, . . . , T − 1,
meaning that from E T −1 it follows that

R T 2

≤

T
−1
X

exp(−γμT )R ^{2} − 4γ ^{3} μ

+2γ

l=0

T
−1
X

l=0

(1 − γμ) ^{T} −1−l hζ l , ω l i

(1 − γμ) ^{T} −1−l hη l , θ l i + γ ^{2}

T
−1
X

l=0


(1 − γμ) ^{T} −1−l kθ l k ^{2} + 4kω l k ^{2} .

To handle the sums appeared on the right-hand side of the previous inequality we consider unbiased and biased parts of
θ l , ω l :
h
h
i
i
def
def
x l ) − E ξ 2 l F e ξ 2 l (e
θ l u = E ξ 2 l F e ξ 2 l (e
x l ) − F e ξ 2 l (e
x l ), θ l b = F (e
x l ) ,
(252)
h
h
i
i
def
def
(253)
ω l u = E ξ 1 l F e ξ 1 l (x l ) − F e ξ 1 l (x l ), ω l b = F (x l ) − E ξ 1 l F e ξ 1 l (x l ) ,

for all l = 0, . . . , T − 1. By definition we have θ l = θ l ^{u} + θ l ^{b} , ω l = ω l ^{u} + ω l ^{b} for all l = 0, . . . , T − 1. Therefore, E T −1
implies

R T 2

≤

2

3

^{exp(−γμT} ^{)R} −4γ ^{μ}

+ 2γ

|

T
−1
X

l=0

+ 2γ 2

|

+ 2γ 2

|

+ 2γ 2

|

|

T
−1
X

l=0

(1 − γμ)

hζ l ^{,} ^{ω} l ^{u} i −4γ ^{3} ^{μ}

{z

} |

^{T} −1−l

1

(1 − γμ) ^{T} −1−l hη l , θ l ^{u} i + 2γ

{z

}

3

l=0

{z

}

2

{z

4

{z

}

}






(1 − γμ) ^{T} −1−l kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 4E ξ 1 l kω l ^{u} k ^{2}

T
−1
X

{z

6

T
−1
X

l=0

(1 − γμ) ^{T} −1−l hζ l , ω l ^{b} i

(1 − γμ) ^{T} −1−l hη l , θ l ^{b} i

5

l=0

l=0






(1 − γμ) ^{T} −1−l E ξ 2 l kθ l ^{u} k ^{2} + 4E ξ 1 l kω l ^{u} k ^{2}

T
−1
X

l=0

|

T
−1
X

T
−1
X


(1 − γμ) ^{T} −1−l kθ l ^{b} k ^{2} + 4kω l ^{b} k ^{2} .

{z

7

61

}

}

(254)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where we also apply inequality ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} to upper bound kθ l k ^{2} and kω l k ^{2} . It
remains to derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5, 6, 7, i.e., to finish our inductive
proof we need to show that 1 + 2 + 3 + 4 + 5 + 6 + 7 ≤ exp(−γμT )R ^{2} with high probability. In the subsequent
u
b
parts of the proof, we will need to use many times the bounds for the norm and second moments of ^{θ} t+1
and ^{θ} t+1
. First,
by definition of clipping operator, we have with probability 1 that

kθ l u k ≤ 2λ l ,

kω l u k ≤ 2λ l .

(255)

Moreover, since E T −1 implies that kF (x ^{l} )k ≤ ^{λ} l / 2 and kF (e
x ^{l} )k ≤ ^{λ} l / 2 for all l = 0, 1, . . . , T − 1 (see (245) and (248)),
from Lemma 5.1 we also have that E T −1 implies

θ l b ≤

ω l b ≤

i
h
2
σ α ,
E ξ 2 l kθ l k ≤ 18λ ^{2−α}
l
i
h
σ α ,
E ξ 2 l kθ l ^{u} k ^{2} ≤ 18λ ^{2−α}
l

for all l = 0, 1, . . . , T − 1.

Upper bound for 1.

2 α σ α
,
λ α−1
l
i
h
2
σ α ,
E ξ 1 l kω l k ≤ 18λ ^{2−α}
l
i
h
σ α ,
E ξ 1 l kω l ^{u} k ^{2} ≤ 18λ ^{2−α}
l

2 α σ α
,
λ α−1
l

(256)

(257)

(258)

By definition of ω l ^{u} , we have E ξ 1 l [ω l ^{u} ] = 0 and



E ξ 1 l −4γ ^{3} ^{μ(1} − ^{γμ)} ^{T} ^{−1−l} hζ l ^{,} ^{ω} l ^{u} i ^{=} ^{0.}

Next, sum 1 has bounded with probability 1 terms:

| − 4γ ^{3} μ(1 − γμ) ^{T} −1−l hζ l , ω l ^{u} i|

≤

(251),(255)

≤

(237),(240)

≤

4γ ^{3} μ exp(−γμ(T − 1 − l))kζ l k · kω l ^{u} k
√
8 2γ ^{3} μL exp(−γμ(T − 1 − ^{l} / 2 ))Rλ l
exp(−γμT )R ^{2} def
= c.
7 ln 6(K+1)
β

(259)



def
The summands also have bounded conditional variances σ l ^{2} = E ξ 1 l 16γ ^{6} μ ^{2} (1 − γμ) ^{2T} −2−2l hζ l , ω l ^{u} i ^{2} :

σ l 2

≤

(251)

≤

(237)

≤



E ξ 1 l 16γ ^{6} μ ^{2} exp(−γμ(2T − 2 − 2l))kζ l k ^{2} · kω l ^{u} k ^{2}



36γ ^{6} μ ^{2} L ^{2} exp(−γμ(2T − 2 − l))R ^{2} E ξ 1 l kω l ^{u} k ^{2}

4γ ^{2} exp(−γμ(2T − l))R ^{2}

2809 ln ^{6(K+1)}
β



E ξ 1 l kω l u k 2 .

(260)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {−4γ ^{3} ^{μ(1} − ^{γμ)} ^{T} ^{−1−l} hζ l ^{,} ^{ω} l ^{u} i} ^{T} l=0
is a bounded martingale difference sequence with
2 T −1
^{bounded} ^{conditional} ^{variances} {σ l } l=0 ^{.} ^{Next,} ^{we} ^{apply} ^{Bernstein’s} ^{inequality} ^{(Lemma} ^{B.2)} ^{with} ^{X} l ^{=} −4γ ^{3} ^{μ(1} −

4

)R
γμ) ^{T} −1−l hζ l , ω l ^{u} i, parameter c as in (259), b = 17 exp(−γμT )R ^{2} , G = ^{exp(−2γμT}
6(K+1) ^{:}

294 ln

(

T −1

X
1
exp(−2γμT )R ^{4}
^{P} |1| ^{>} ^{exp(−γμT} ^{)R} ^{2} ^{and}
σ l 2 ≤
7
294 ln ^{6(K+1)}

l=0

β

)

β



b 2
≤ 2 exp −
2G + 2cb / 3



=

β
.
3(K + 1)

Equivalently, we have

β
,
P{E 1 } ≥ 1 −
3(K + 1)

for E 1 =

(

either

T
−1
X

exp(−2γμT )R
σ l 2 >
294 ln ^{6(K+1)}
l=0
β

62

4

1
^{or} |1| ≤ ^{exp(−γμT} ^{)R} ^{2}
7

)

. (261)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

In addition, E T −1 implies that

T
−1
X

 u 2 
T −1
4γ ^{2} exp(−2γμT )R ^{2} X E ξ 1 l kω l k
exp(−γμl)
2809 ln ^{6(K+1)}

(260)

σ l 2

≤

l=0

l=0

β

^{(258),T} ≤K+1

≤

2

K
2 α X

72γ exp(−2γμT )R σ

2809 ln ^{6(K+1)}
β

α

l=0

72γ exp(−2γμT )R

(240)

≤

λ 2−α
l
exp(−γμl)

K
4−α α X

σ

1

exp(−γμl)
2809 · 120 2−α ln ^{3−α} ^{6(K+1)}
l=0
β

· (exp(−γμ(1 + l / 2 ))) ^{2−α}

K

72γ ^{α} exp(−2γμT )R ^{4−α} σ ^{α} X

≤

2809 · 120 2−α ln ^{3−α} ^{6(K+1)}
l=0
β

exp(γμ(α − 2)) · exp

72γ ^{α} exp(−2γμT )R ^{4−α} σ ^{α} (K + 1) exp

≤

2809 · 120 2−α ln ^{3−α} ^{6(K+1)}
β

exp(−2γμT )R ^{4}

(237)

≤

294 ln ^{6(K+1)}
β



γμαK
2





γμαl
2



,

(262)

where we also show that E T −1 implies

γ 2 R 2

K
X

l=0

γ ^{α} R ^{4−α} (K + 1) exp( ^{γμαK}
λ 2−α
2 )
l
≤
.
6(K+1)
2−α
2−α
exp(−γμl)
120
ln

(263)

β

Upper bound for 2. From E T −1 it follows that

2

≤

(251),(256)

≤

(240)

=

^{T} ≤K+1

≤

≤

(237)

≤

4γ 3 μ

T
−1
X

l=0

2 2+α ·

exp(−γμ(T − 1 − l))kζ l k · kω l ^{b} k

T
−1
X
√
2 exp(−γμ(T − 1))γ ^{3} μLR

σ α

λ ^{α−1} exp(− γμl / 2 )
l=0 ^{l}

√
T
−1
X
2 ^{2+α} · 120 ^{α−1} 2 exp(−γμ(T − 1))γ ^{2+α} μLσ ^{α} ln ^{α−1} ^{6(K+1)}
β

R α−2

1

α−1

exp (−γμ(1 + ^{l} / 2 ))
√


K
X
2 ^{3+α} · 120 ^{α−1} 2 exp(−γμ(T − 1))γ ^{2+α} μLσ ^{α} ln ^{α−1} ^{6(K+1)}
γμαl
β
exp
R α−2
2
l=0


√
γμαK
(K
+
1)
exp
2 ^{3+α} · 120 ^{α−1} 2 exp(−γμ(T − 1))γ ^{2+α} μLσ ^{α} ln ^{α−1} ^{6(K+1)}
β
2

l=0

· exp(− ^{γμl} / 2 )

R α−2

1
exp(−γμT )R ^{2} ,
7

(264)

where we also show that E T −1 implies

T
−1
X

120
1
γR
≤
α−1
λ
exp(− ^{γμl} / 2 )
l=0 ^{l}

Upper bound for 3.

α−1 6(K+1)
γ (K + 1) exp( ^{γμαK}
2 ) ln
β

α−1 α

R α−2

By definition of θ l ^{u} , we have E ξ 2 l [θ l ^{u} ] = 0 and



E ξ 2 l 2γ(1 − γμ) ^{T} −1−l hη l , θ l ^{u} i = 0.

63

.

(265)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Next, sum 3 has bounded with probability 1 terms:

|2γ(1 − ^{γμ)} ^{T} ^{−1−l} hη l ^{,} ^{θ} l ^{u} i|

≤

(251),(255)

≤

(237),(240)

≤

2γ exp(−γμ(T − 1 − l))kη l k · kθ l ^{u} k
√
4 7γ(1 + γL) exp(−γμ(T − 1 − ^{l} / 2 ))Rλ l
exp(−γμT )R ^{2} def
= c.
7 ln 6(K+1)
β

(266)



def
The summands also have bounded conditional variances σ
e l ^{2} = E ξ 2 l 4γ ^{2} (1 − γμ) ^{2T} −2−2l hη l , θ l ^{u} i ^{2} :


σ
e l ^{2} ≤ E ξ 2 l 4γ ^{2} exp(−γμ(2T − 2 − 2l))kη l k ^{2} · kθ l ^{u} k ^{2}

(251)

≤

(237)

≤



49γ ^{2} (1 + γL) ^{2} exp(−γμ(2T − 2 − l))R ^{2} E ξ 2 l kθ l ^{u} k ^{2}


50γ ^{2} exp(−γμ(2T − l))R ^{2} E ξ 2 l kθ l ^{u} k ^{2} .

(267)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {2γ(1 − ^{γμ)} ^{T} ^{−1−l} hη l ^{,} ^{θ} l ^{u} i} ^{T} l=0
is a bounded martingale difference sequence with bounded
2 T −1
conditional variances {e
σ l } l=0 . Next, we apply Bernstein’s inequality (Lemma B.2) with X l = 2γ(1 − γμ) ^{T} −1−l hη l , θ l ^{u} i,

4

)R
parameter c as in (266), b = 17 exp(−γμT )R ^{2} , G = ^{exp(−2γμT}
6(K+1) ^{:}

294 ln

(

β

T −1

X
1
exp(−2γμT )R ^{4}
^{P} |3| ^{>} ^{exp(−γμT} ^{)R} ^{2} ^{and}
σ
e l 2 ≤
7
294 ln ^{6(K+1)}

l=0

β

)



b 2
≤ 2 exp −
2G + 2cb / 3



=

β
.
3(K + 1)

Equivalently, we have

β
,
P{E 3 } ≥ 1 −
3(K + 1)

for E 3 =

(

T
−1
X

exp(−2γμT )R
σ
e l 2 >
294 ln ^{6(K+1)}
l=0
β

either

In addition, E T −1 implies that

T
−1
X

l=0

σ
e l 2

(267)

≤

^{(258),T} ≤K+1

≤

(263)

≤

(237)

≤

2

50γ exp(−2γμT )R

900γ ^{2} exp(−2γμT )R ^{2} σ ^{α}

900γ exp(−2γμT )R

exp(−2γμT )R ^{4}

294 ln ^{6(K+1)}
β

2γ exp(−γμ(T − 1))

(265)

≤

(237)

≤

)

. (268)

exp(−γμl)

K
X

λ 2−α
l
exp(−γμl)

σ (K + 1) exp( ^{γμαK}
2 )

4−α α

120 2−α ln ^{2−α} ^{6(K+1)}
β

≤

≤

1
^{or} |3| ≤ ^{exp(−γμT} ^{)R} ^{2}
7



E ξ 2 l kθ l u k 2

l=0

α

From E T −1 it follows that

(251),(256)

T
−1
X

l=0

Upper bound for 4.

4

2

4

T
−1
X

l=0

.

(269)

kη l k · kθ l b k
exp(−γμl)

T
−1
X
√
2 ^{1+α} 7γ(1 + γL) exp(−γμ(T − 1))Rσ ^{α}

1

λ ^{α−1} exp(− γμl / 2 )
l=0 ^{l}



√
ln α−1 6(K+1)
2 ^{3+α} · 120 ^{α−1} 7γ ^{α} (1 + γL) exp(−γμT )(K + 1) exp ^{γμαK}
2
β

R α−2

1
exp(−γμT )R ^{2} .
7

(270)

64

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

From E T −1 it follows that

Upper bound for 5.

5

=

(258)

2

2γ exp(−γμ(T − 1))

l=0





E ξ 2 l kθ l u k 2 + 4E ξ 1 l kω l u k 2

exp(−γμl)

T
−1
X

λ 2−α
l
exp(−γμl)

≤

180γ ^{2} exp(−γμ(T − 1))σ ^{α}

(263)

180γ ^{α} R ^{2−α} exp(−γμ(T − 1))σ ^{α} (K + 1) exp( ^{γμαK}
2 )

≤

l=0

120 2−α ln ^{2−α} ^{6(K+1)}
β

1
exp(−γμT )R ^{2} .
7

(237)

≤

Upper bound for 6.

T
−1
X

(271)

First, we have

h



i
2γ ^{2} (1 − γμ) ^{T} −1−l E ξ 1 l ,ξ 2 l kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 4E ξ 1 l kω l ^{u} k ^{2} = 0.

Next, sum 6 has bounded with probability 1 terms:





2γ ^{2} (1 − γμ) ^{T} −1−l kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 4E ξ 1 l kω l ^{u} k ^{2}

(255)

≤

(240)

≤

def

=

80γ ^{2} exp(−γμT )λ ^{2} l
exp(−γμ(1 + l))
exp(−γμT )R ^{2}

7 ln 6(K+1)
β

c.

(272)

The summands also have conditional variances




 2

def
σ
b l ^{2} = E ξ 1 l ,ξ 2 l 4γ ^{4} (1 − γμ) ^{2T} −2−2l kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 4E ξ 1 l kω l ^{u} k ^{2}

that are bounded

σ
b l 2

2γ ^{2} exp(−2γμT )R ^{2}

(272)

≤

≤

7 exp(−γμ(1 + l)) ln

E l l
6(K+1) ^{ξ} 1 ^{,ξ} 2

β

4γ ^{2} exp(−2γμT )R ^{2}

7 exp(−γμ(1 + l)) ln ^{6(K+1)}
β

In other words, we showed that

n

h



 i

kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 4E ξ 1 l kω l ^{u} k ^{2}



E ξ 1 l ,ξ 2 l kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} .

(273)





o ^{T} ^{−1}
2γ ^{2} (1 − γμ) ^{T} −1−l kθ l ^{u} k ^{2} + 4kω l ^{u} k ^{2} − E ξ 2 l kθ l ^{u} k ^{2} − 4E ξ 1 l kω l ^{u} k ^{2}
is a

l=0

−1
bounded martingale difference sequence with bounded
^{σ} l ^{2} } ^{T} l=0
. Next, we apply
Bernstein’s in-
 conditional variances {b


 u 2 
2
^{T} −1−l
u 2
u 2
u 2
equality (Lemma B.2) with X l = 2γ (1 − γμ)
kθ l k + 4kω l k − E ξ 2 l kθ l k − 4E ξ 1 l kω l k , parameter c as

4

)R
in (272), b = 7 ^{1} exp(−γμT )R ^{2} , G = ^{exp(−2γμT}
6(K+1) ^{:}

294 ln

(

β

T −1

X
1
exp(−2γμT )R ^{4}
^{P} |6| ^{>} ^{exp(−γμT} ^{)R} ^{2} ^{and}
σ
b l 2 ≤
7
294 ln ^{6(K+1)}

l=0

β

)


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
3(K + 1)

Equivalently, we have

β
,
P{E 6 } ≥ 1 −
3(K + 1)

for E 6 =

(

either

T
−1
X

exp(−2γμT )R
σ
b l 2 >
294 ln ^{6(K+1)}
l=0
β

65

4

1
^{or} |6| ≤ ^{exp(−γμT} ^{)R} ^{2}
7

)

. (274)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

In addition, E T −1 implies that

T
−1
X

l=0

σ
b l 2

(273)

≤

^{(258),T} ≤K+1

≤

≤

≤

^{(240),T} ≤K+1

≤

≤

≤

(237)

≤

360γ exp(−γμ(2T − 1))R

σ (K + 1) exp( ^{γμαK}
2 )

4−α α

exp(−2γμT )R ^{4}

294 ln ^{6(K+1)}
β

.

(275)

From E T −1 it follows that

2γ 2

T
−1
X

l=0

(256)

l=0

α

λ 2−α
l
exp(−γμl)

7 · 120 2−α ln ^{3−α} ^{6(K+1)}
β

(237)

=

K

360γ exp(−γμ(2T − 1))R ^{2} σ ^{α} X

2

7 ln 6(K+1)
β

≤

7

l=0

β

(263)

Upper bound for 7.

 u 2

T −1
u 2
4γ ^{2} exp(−γμ(2T − 1))R ^{2} X E ξ 1 l ,ξ 2 l kθ l k + 4kω l k
exp(−γμl)
7 ln 6(K+1)

exp(−γμ(T − 1 − l)) kθ l ^{b} k ^{2} + 4kω l ^{b} k ^{2}

2α 2

10 · 2 γ exp(−γμ(T − 1))σ

2α

T
−1
X



1
2α−2
λ
exp(−γμl)
l=0 ^{l}

K
X
20 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} exp(−γμT )σ ^{2α} ln ^{2α−2} ^{6(K+1)}
β

R 2α−2

l=0

K
X
40 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} exp(−γμT )σ ^{2α} ln ^{2α−2} ^{6(K+1)}
β

R 2α−2




l
exp(γμl)
exp γμ(2α − 2) 1 +
2

exp(γμαl)

l=0

(K + 1) exp(γμαK)
40 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} exp(−γμT )σ ^{2α} ln ^{2α−2} ^{6(K+1)}
β

R 2α−2

1
exp(−γμT )R ^{2} .
7

(276)

Now, we have the upper bounds for 1, 2, 3, 4, 5, 6, 7. In particular, probability event E T −1 implies

(254)

R T ^{2} ≤ exp(−γμT )R ^{2} + 1 + 2 + 3 + 4 + 5 + 6 + 7,

(264) 1

(270) 1

exp(−γμT )R ^{2} ,
7
7
(271) 1
(276) 1
5 ≤
exp(−γμT )R ^{2} , 7 ≤
exp(−γμT )R ^{2} ,
7
7
T
−1
T
−1
T
−1
X
X
X
^{(269)} exp(−2γμT )R ^{4}
^{(275)} exp(−2γμT )R ^{4}
^{(262)} exp(−2γμT )R ^{4}
2
,
σ
e
,
σ
b l 2 ≤
.
≤
σ l 2 ≤
l
6(K+1)
6(K+1)
294 ln β
294 ln β
294 ln ^{6(K+1)}
l=0
l=0
l=0
β

2 ≤

exp(−γμT )R ^{2} ,

4 ≤

Moreover, we also have (see (261), (268), (274) and our induction assumption)

(T − 1)β
,
K +1
β
β
P{E 3 } ≥ 1 −
, P{E 6 } ≥ 1 −
,
3(K + 1)
3(K + 1)

P{E T −1 } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
3(K + 1)

66

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where

E 1

=

E 3

=

E 6

=

(

(

(

either

either

either

T
−1
X

exp(−2γμT )R
σ l 2 >
294 ln ^{6(K+1)}
l=0
β

4

T
−1
X

exp(−2γμT )R
σ
e l 2 >
294 ln ^{6(K+1)}
l=0
β

4

exp(−2γμT )R
σ
b l 2 >
294 ln ^{6(K+1)}
l=0
β

4

T
−1
X

1
^{or} |1| ≤ ^{exp(−γμT} ^{)R} ^{2}
7

1
^{or} |3| ≤ ^{exp(−γμT} ^{)R} ^{2}
7

1
^{or} |6| ≤ ^{exp(−γμT} ^{)R} ^{2}
7

)

)

)

,

,

.

Thus, probability event E T −1 ∩ E 1 ∩ E 3 ∩ E 6 implies

R T 2

(254)

≤

≤

exp(−γμT )R ^{2} + 1 + 2 + 3 + 4 + 5 + 6 + 7

2 exp(−γμT )R ^{2} ,

which is equivalent to (244) for t = T , and

P{E T } ≥ P{E T −1 ∩ E 1 ∩ E 3 ∩ E 6 } = 1 − P{E T −1 ∪ E 1 ∪ E 3 ∪ E 6 } ≥ 1 −

Tβ
.
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

kx ^{K+1} − x ∗ k ^{2} ≤ 2 exp(−γμ(K + 1))R ^{2} .

Finally, if

γ

=

B K

=

=

)
ln(B K )
,
,
min
μ(K + 1)
650L ln ^{6(K+1)}
β


2(α−1)


(K + 1) α μ 2 R 2


max 2,
6(K+1)
 264600 α ^{2} σ 2 ln ^{2(α−1)}
α
ln 2 (B K ) 
β
 















2(α−1)



2 2

α
μ
R
K
)!
(
2,
O 
max

 
2(α−1)



2(α−1)




2 2
α
2
K






max 2, ^{K} 2(α−1) ^{μ} ^{R}


 σ 2 ln α
β ln
K
2
α
σ ln
( β )

(

1

then with probability at least 1 − β

kx K+1 − x ∗ k 2

≤

=

=

2 exp(−γμ(K + 1))R ^{2}
(
!
)
μ(K + 1)
1
2
2R max exp −
,
B K
650L ln ^{6(K+1)}
β
)!  
(


 
2(α−1)
2(α−1)
2 2


α
μ
R
K
2


K
2


! σ ln α
max 2,
2(α−1)



β ln
 

K
2 ln
α


σ
(
)
μK
β
2
 .
,
O 
max
R
exp
−
2(α−1)


K


L ln β


K α μ 2









To get kx ^{K+1} − x ∗ k ^{2} ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
!
α
  ^{2}  2(α−1)

 α !
 2  
α
L
σ
R 2
R
1 σ ^{2} 2(α−1)
L
ln
,
ln α−1 (B ε ) ,
ln
ln
ln
K = O
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

67

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where

B ε = max

This concludes the proof.










2,

ε ln

 

1
β

68

R 2

σ 2
μ 2 ε






 .
α
 2(α−1)




-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

H. Missing Proofs for clipped-SGDA

In this section, we provide the complete formulation of the main results for
 clipped-SGDA and the missing proofs. For
brevity, we will use the following notation: F e ξ k (x ^{k} ) = clip F ξ k (x ^{k} ), λ k .

Algorithm 5 Clipped Stochastic Gradient Descent Ascent (clipped-SGDA) (Gorbunov et al., 2022a)

Input: starting point x ^{0} , number of iterations K, stepsize γ > 0, clipping levels {λ k } ^{K−1}
k=0 ^{.}
1: for k = 0, . . . , K do

2:
Compute F e ξ k (x ^{k} ) = clip F ξ k (x ^{k} ), λ k using a fresh sample ξ ^{k} ∼ D k
3:
x k+1 = x k − γ F e ξ k (x k )
4: end for
K
P
1
Output: x ^{K+1} or x ^{K}
x K
avg ^{=} K+1

k=0

H.1. Monotone Star-Cocoercive Problems

We start with the following lemma derived by Gorbunov et al. (2022b). Since this lemma handles only deterministic part
of the algorithm, the proof is the same as in the original work.

Lemma H.1 (Lemma D.1 from (Gorbunov et al., 2022b)). Let Assumptions 1.8 and 1.10 hold for Q = B 3R (x ∗ ), where
R ≥ kx ^{0} − x ∗ k and 0 < γ ≤ ^{2} / l . If x ^{k} lies in B 3R (x ∗ ) for all k = 0, 1, . . . , K for some K ≥ 0, then for all u ∈ B 3R (x ∗ )
the iterates produced by clipped-SGDA satisfy

K

hF (u), x ^{K}
avg − ^{ui}

≤

X

γ
kx 0 − uk 2 − kx K+1 − uk 2
+
kF (x k )k 2 + kω k k 2
2γ(K + 1)
2(K + 1)

k=0

+

x K
avg

def

=

1
K +1

K

K
X

k=0

hx k − u − γF (x k ), ω k i,

(277)

1 X k
x ,
K +1

(278)

k=0

ω k

def

=

F (x k ) − F e ξ k (x k ).

(279)

K
P

Also we need to use the following lemma to estimate the term

k=0

of the main theorem.

kF (x ^{k} )k ^{2} from the right hand side of (277) in the proof

def

Lemma H.2 (Lemma D.2 from (Gorbunov et al., 2022b)). Let Assumption 1.10 hold for Q = B 3R (x ∗ ), where R ≥ R 0 =
kx ^{0} − x ∗ k and 0 < γ ≤ ^{2} / l . If x ^{k} lies in B 3R (x ∗ ) for all k = 0, 1, . . . , K for some K ≥ 0, then the iterates produced by
clipped-SGDA satisfy

γ
K +1



 X
K
2
− γ
kF (x k )k 2
l

k=0

K

≤

2γ X k
kx 0 − x ∗ k 2 − kx K+1 − x ∗ k 2
+
hx − x ∗ − γF (x k ), ω k i
K +1
K +1

k=0

2

+

γ
K +1

K
X

k=0

kω k k 2 ,

(280)

where ω k is defined in (279).

Using those lemmas, we prove the main convergence result for clipped-SGDA in the monotone star-cocoercive case.

Theorem H.3 (Case 1 in Theorem 4.2). Let Assumptions 1.1, 1.8, 1.10 hold for Q = B 3R (x ∗ ), where R ≥ kx ^{0} − x ∗ k,

69

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

and

0 <γ

λ k ≡ λ

≤ min

=




1

 170l ln ^{6(K+1)}

β

R

60γ ln ^{6(K+1)}
β

R

,

1

α−1

1

97200 α (K + 1) α σ ln α

,




6(K+1) 
β

,

(281)

(282)

≥ 1. Then, after K iterations the iterates produced by clipped-SGDA
for some K ≥ 0 and β ∈ (0, 1] such that ln ^{6(K+1)}
β
with probability at least 1 − β satisfy

Gap R (x ^{K}
avg ^{)} ≤

5R 2
γ(K + 1)

∗
and {x ^{k} } ^{K+1}
k=0 ⊆ ^{B} ^{3R} ^{(x} ^{),}

(283)

where x ^{K}
avg is defined in (278). In particular, when γ equals the minimum from (281), then the iterates produced by
clipped-SGDA after K iterations with probability at least 1 − β satisfy
 


K 
 lR 2 ln K σR ln α−1
α
β
β
 max
 ,
Gap R (e
x K
(284)
,
α−1
avg ^{)} ^{=} O


K
K α

meaning that to achieve Gap R (e
x K
avg ) ≤ ε with probability at least 1 − β clipped-SGDA requires
 α

 α !!

lR ^{2} lR ^{2} σR α−1
1 σR α−1
ln
,
K = O
iterations/oracle calls.
ln
ε
εβ
ε
β
ε

(285)

Proof. The proof follows similar steps as the proof of Theorem D.1 from (Gorbunov et al., 2022a). The key difference is
related to the application of Bernstein inequality and estimating biases and variances of stochastic terms.

Let R k = kx ^{k} −x ∗ k for all k ≥ 0. As in the previous results, the proof is based on the induction argument and showing that
the iterates do not leave some ball around the solution with high probability. More precisely, for each k = 0, 1, . . . , K + 1
we consider probability event E k as follows: inequalities

kx t − x ∗ k 2 ≤ 2R 2

and γ

t−1
X

l=0

ω l ≤ R

(286)

hold for t = 0, 1, . . . , k simultaneously. We want to prove that P{E k } ≥ 1 − ^{kβ} / (K+1) for all k = 0, 1, . . . , K + 1 by
P −1
^{induction.} ^{The} ^{base} ^{of} ^{the} ^{induction} ^{is} ^{trivial:} ^{for} ^{k} ^{=} ^{0} ^{we} ^{have} ^{R} 0 ^{2} ≤ ^{2R} ^{2} ^{by} ^{definition} ^{and} l=0 ^{ω} l ^{=} ^{0.} ^{Next,}
assume that the statement holds for k = T ≤ K, i.e., we have P{E T } ≥ 1 − ^{T} ^{β} / (K+1) . Given this, we need to prove
that P{E T +1 } ≥ 1 − ^{(T} ^{+1)β} / (K+1) . Since probability event E T implies R t ^{2} ≤ 2R ^{2} , we have x ^{t} ∈ B 2R (x ∗ ) for all
t = 0, 1, . . . , T . According to this, the assumptions of Lemma H.2 hold and E T implies (γ < ^{1} / l )

T
X
γ
kF (x t )k 2
^{l(T} ^{+} ^{1)} t=0

kx 0 − x ∗ k 2 − kx T +1 − x ∗ k 2
T +1

≤

+

T
T
γ 2 X
2γ X t
hx − x ∗ − γF (x t ), ω t i +
kω t k 2
^{T} ^{+} ^{1} t=0
^{T} ^{+} ^{1} t=0

(287)

and by l-star-cocoersivity we have

kF (x t )k

≤

(286) √

lkx ^{t} − x ∗ k ≤

2lR

(281),(282) λ

≤

2

T
X

kω t k 2 .

for all t = 0, 1, . . . , T . Using (287), we obtain

R T 2 +1 ≤ R 0 2 + 2γ

T
X

t=0

hx t − x ∗ − γF (x t ), ω t i + γ 2

70

t=0

(288)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Due to (288), we have

kx t − x ∗ − γF (x t )k

≤

kx ^{t} − x ∗ k + γkF (x ^{t} )k

≤

2R + 2Rγl ≤ 3R,

(286)

(14),(286)

≤

(281)

2R + γlkx ^{t} − x ∗ k

(289)

for all t = 0, 1, . . . , T . To handle the sum above, we introduce a new vector
(
x ^{t} − x ∗ − γF (x ^{t} ), if kx ^{t} − x ∗ − γF (x ^{t} )k ≤ 3R,
η t =
0,
otherwise,

for all t = 0, 1, . . . , T . This vector η t is bounded with probability 1:

kη t k ≤ 3R

(290)

for all t = 0, 1, . . . , T . We also notice that probability event E T implies η t = x ^{t} − x ∗ − γF (x ^{t} ) for all t = 0, 1, . . . , T
Thus, thanks to (289), E T implies

R T 2 +1 ≤ R 2 + 2γ

T
X

t=0

hη t , ω t i + γ 2

T
X

t=0

kω t k 2 .

To handle the sums appeared on the right-hand side of the previous inequality we consider unbiased and biased parts of ω t :
h
h
i
i
def
def
(291)
ω t u = E ξ t F e ξ t (x t ) − F e ξ t (x t ), ω t b = F (x t ) − E ξ t F e ξ t (x t )

for all t = 0, . . . , T . Also, by definition we have ω t = ω t ^{u} + ω t ^{b} for all t = 0, . . . , T . Therefore, E T implies

R T 2 +1

≤

R 2 + 2γ

|

t=0

hη t , ω t u i + 2γ

{z

T
X

t=0

|

}

1

+ 2γ 2

|

T
X

T
X

t=0

hη t , ω t b i + 2γ 2

{z

}

2

|

T
X

t=0



E ξ t kω t u k 2

{z

3

T
X



kω t u k 2 − E ξ t kω t u k 2 + 2γ 2
kω t b k 2 .

{z

4

We notice that the above inequality does not rely on monotonicity of F .

}

|

t=0

{z

5

}

(292)

}

According to the induction assumption, from probability event E T we have x ^{t} ∈ B 2R (x ∗ ) for all t = 0, 1, . . . , T . Thus,
the assumptions of Lemma H.1 hold and probability event E T implies
(
)
T
X
0
2
t
t
T
hx − u − γF (x ), ω t i
2γ(T + 1)Gap R (x avg ) ≤
max ∗ kx − uk + 2γ

u∈B R (x )

+γ 2

t=0

T
X

t=0

=

max

u∈B R (x ∗ )

+2γ

(

T
X

t=0

+γ 2

T
X

t=0


kF (x t )k 2 + kω t k 2 ,

0

2

kx − uk + 2γ

T
X

t=0

∗

hx − u, ω t i

hx t − x ∗ − γF (x t ), ω t i


kF (x t )k 2 + kω t k 2 .

71

)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

As we mentioned before, E T implies η t = x ^{t} − x ∗ − γF (x ^{t} ) for all t = 0, 1, . . . , T as well as (287) and γ < ^{1} / l . Due to
that, probability event E T implies
( T
)
X
 0
∗
2
T
hx − u, ω t i
2γ(T + 1)Gap R (x avg ) ≤
max ∗ kx − uk + 2γ max ∗

u∈B R (x )

u∈B R (x )

≤

T

X
γ
kF (x t )k 2 + γ 2
kω t k 2
+2γ
hη t , ω t i +
^{l} t=0
t=0
t=0
+)
(*
T
X
∗
2
x − u,
ω t
4R + 2γ max ∗

u∈B R (x )

+R 2 + 4γ

T
X

t=0

≤

t=0

T
X

T
X

5R ^{2} + 2γR

t=0

hη t , ω t i + 2γ 2

T
X

t=0

T
X

t=0

kω t k 2

ω t + 2 · (1 + 2 + 3 + 4 + 5) ,

(293)

where we also aplly inequality ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} to upper bound kω t k ^{2} .
P T
It remains to derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5 and 2γR
t=0 ^{ω} t ^{,} ^{i.e.,}
P
T
2
to finish our inductive proof we need to show that 1 + 2 + 3 + 4 + 5 ≤ R ^{2} and 2γR
t=0 ^{ω} t ≤ ^{2R} ^{with} ^{high}
probability.In the subsequent parts of the proof, we will need to use many times the bounds for the norm and second
moments of ω t ^{u} , ω t ^{b} . First, by Lemma C.1, we have with probability 1 that

kω t u k ≤ 2λ

(294)

for all t = 0, 1, . . . , T . Moreover, due to Lemma C.1, we also have that E T implies

for all t = 0, 1, . . . , T .

2 α σ α
^{ω} ^{t} ^{b} ^{≤} α−1 ^{,}
h
i λ
b 2
t
≤ 18λ ^{2−α} σ ^{α} ,
ω t
E ξ
i
h
E ξ t kω t ^{u} k ^{2} ≤ 18λ ^{2−α} σ ^{α}

(295)

(296)

(297)

By definition of ω t ^{u} , we have E ξ t [ω t ^{u} ] = 0 and

Upper bound for 1.

E ξ t [2γhη t , ω t ^{u} i] = 0.

Next, the sum 1 has bounded with probability 1 term:

|2γhη t ^{,} ^{ω} t ^{u} i| ≤ ^{2γkη} t k · kω t ^{u} k

(290),(294)

≤

R 2

(282)

12γRλ ≤

5 ln 6(K+1)
β

def

= c.

(298)



def
Moreover, these summands also have bounded conditional variances σ t ^{2} = E ξ t 4γ ^{2} hη t , ω t ^{u} i ^{2} :



 (290)

σ t ^{2} ≤ E ξ t 4γ ^{2} kη t k ^{2} · kω t ^{u} k ^{2} ≤ 36γ ^{2} R ^{2} E ξ t kω t ^{u} k ^{2} .

(299)

^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {2γhη t ^{,} ^{ω} t ^{u} i} t≥0 ^{is} ^{a} ^{bounded} ^{martingale} ^{difference} ^{sequence} ^{with} ^{bounded} ^{conditional}
variances {σ t ^{2} } t≥0 . Next, we apply Bernstein’s inequality (Lemma B.2) with X t = 2γhη t , ω t ^{u} i, parameter c as in (298),
2
R 4
b = R 5 , G =
6(K+1) ^{:}

150 ln

β

(

T
X
R 4
R 2
and
σ t 2 ≤
^{P} |1| ^{>}
5
150 ln ^{6(K+1)}
t=0

β

)

72


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
3(K + 1)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Equivalently, we have

β
, for E 1 =
P{E 1 } ≥ ^{1} − 3(K+1)

(

T
X

either

σ t 2 >

t=0

R 2
^{or} |1| ≤
5

R 4

150 ln ^{6(K+1)}
β

)

.

(300)

In addition, E T implies that

T
X

(299)

σ t 2

36γ ^{2} R ^{2}

≤

t=0

T
X

t=0

^{(297),T} ≤K+1

≤

648γ R σ (K + 1)λ ^{2−α}

≤

648γ ^{α} R ^{4−α} σ ^{α} (K + 1) ln ^{α−2}

(282)

2



E ξ t kω t u k 2

2 α

R 4

(281)

≤

150 ln ^{6(K+1)}
β

6(K + 1)
β

.

(301)

From E T it follows that

Upper bound for 2.

T
X

kη l k · kω t b k

^{(290),(295),T} ≤K+1

σ α
^{6} · ^{2} ^{α} ^{γR(K} ^{+} ^{1)} α−1
λ

≤

2γ

(282)

12 · 120 ^{α−1} γ ^{α} σ ^{α} R ^{2−α} (K + 1) ln ^{α−1}

2

t=0

=

≤

6(K + 1) ^{(281)} R ^{2}
.
≤
β
5

(302)

From E T it follows that

Upper bound for 3.

3

=

2γ

2

T
X

t=0

(282)

≤

Upper bound for 4.


 ^{(297),T} ≤K+1
E ξ t kω t u k 2
≤
36γ ^{2} λ ^{2−α} σ ^{α} (K + 1)

36γ ^{α} R ^{2−α} σ ^{α} (K + 1) ln ^{α−2}

6(K + 1) ^{(281)} R ^{2}
≤
.
β
5

(303)

First, we have




2γ 2 E ξ t kω t u k 2 − E ξ t kω t u k 2 = 0.

Next, the sum 4 has bounded with probability 1 terms:



2γ 2 kω t u k 2 − E ξ t kω t u k 2

 (294)

2γ 2 kω t u k 2 + E ξ t kω t u k 2
≤ 16γ ^{2} λ ^{2}

≤

R 2

R 2

(282)

≤
6(K+1)

def

= c.
225 ln β
h

 2 i
def
that are bounded
The summands also have conditional variances σ
e t 2 = 4γ 4 E ξ t kω t u k 2 − E ξ t kω t u k 2

(304)

σ
e t 2 ≤

2γ 2 R 2

225 ln

E t
6(K+1) ^{ξ}

β



≤

 

kω t u k 2 − E ξ t kω t u k 2 ≤

5 ln 6(K+1)
β

4γ 2 R 2

225 ln ^{6(K+1)}
β



E ξ t kω t u k 2 .

(304)

(305)

^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {kω t ^{u} k ^{2} − ^{E} ξ ^{t} ^{[kω} t ^{u} k ^{2} ^{]}} t≥0 ^{is} ^{a} ^{bounded} ^{martingale} ^{difference} ^{sequence} ^{with} ^{bounded}
conditional variances {e
σ t ^{2} } t≥0 .Next, we apply Bernstein’s inequality (Lemma B.2) with X t = kω t ^{u} k ^{2} − E ξ t [kω t ^{u} k ^{2} ],
2
R 4
parameter c as in (304), b = ^{R} 5 , G =
6(K+1) ^{:}

150 ln

(

β

T
X
R 4
R 2
and
σ
e t 2 ≤
^{P} |4| ^{>}
5
150 ln ^{6(K+1)}
t=0

β

)

73


≤ 2 exp −

b 2
2G + 2cb / 3



=

β
.
3(K + 1)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Equivalently, we have

β
, for E 4 =
P{E 4 } ≥ ^{1} − 3(K+1)

(

T
X

either

t=0

In addition, E T implies that

T
X

t=0

≤

225 ln ^{6(K+1)}
t=0
β

≤

≤

)

.

(306)


 ^{(297),T} ≤K+1 8γ ^{2} R ^{2} (K + 1) 2−α α
≤
λ
σ
E ξ t kω t u k 2
25 ln 6(K+1)
β

(307)

From E T it follows that

5

2γ 2

=

T
X

t=0

P T

kω t b k 2

^{(295),T} ≤K+1

≤

σ 2α
2 ^{2α+1} · 60 ^{2α−2} γ ^{2} (K + 1) 2α−2
λ

(282)

=

2 2α+1 · 60 2α−2 γ 2α (K + 1)

(281)

R 2
.
5

≤

Upper bound for γ

150 ln ^{6(K+1)}
β

^{8} α 4−α
6(K + 1)
γ R
(K + 1)σ ^{α} ln ^{α−3}
25
β
4
R
.
150 ln ^{6(K+1)}
β

(282)

(281)

Upper bound for 5.

T
X

4γ 2 R 2

(305)

σ
e t 2

σ
e t 2 >

R 2
^{or} |4| ≤
5

R 4

t=0 ^{ω} ^{t}

σ 2α
6(K + 1)
ln 2α−2
R 2α−2
β

(308)

. To estimate this term from above, we consider a new vector:

 l−1
P
 γ P ω , if γ l−1
ω r ≤ R,
r
ζ l =
r=0
 r=0
0,
otherwise

for l = 1, 2, . . . , T − 1.This vector is bounded almost surely:

kζ l k ≤ R.

(309)

Thus, by (286), probability event E T implies

γ

T
X

ω l

=

v
u
2
T
u
t γ 2 X ω
l

l=0

l=0

=

=

(292)

≤

v
+
* l−1
u
T
T
u X
X
X
t γ 2
2
kω k + 2γ
γ
ω ,ω

l

r

l=0

l=0

l=0

l=0

l

r=0

v
u
T
T
u X
X
t γ 2
kω l k 2 + 2γ
hζ l , ω l i

v
u
T
T
X
X
u
u
u 3 + 4 + 5 + 2γ
+
2γ
hζ l , ω l b i.
hζ
,
ω
i
l
l
u
t
l=0
l=0
{z
} |
{z
}
|

6

Following similar steps as before, we bound 6 and 7.

74

7

(310)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Upper bound for 6.

By definition of ω u ^{t} , we have E ξ t [ω t ^{u} ] = 0 and

E ξ t [2γhζ t , ω t ^{u} i] = 0.

Next, sum 6 has bounded with probability 1 terms:

|2γhζ t ^{,} ^{ω} t ^{u} i| ≤ ^{2γkζ} t k · kω t ^{u} k

(309),(294)

≤

R 2

(282)

4γRλ ≤

def

= c.

5 ln 6(K+1)
β

(311)



def
The summands also have bounded conditional variances σ
b t 2 = E ξ t 4γ 2 hζ t , ω t u i 2 :

 (309)



σ
b t 2 ≤ E ξ t 4γ 2 kζ t k 2 · kω t u k 2 ≤ 4γ 2 R 2 E ξ t kω t u k 2 .

(312)

^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {2γhζ t ^{,} ^{ω} t ^{u} i} t≥0 ^{is} ^{a} ^{bounded} ^{martingale} ^{difference} ^{sequence} ^{with} ^{bounded} ^{conditional}
2
variances {b
σ t ^{2} } t≥0 . Applying Bernstein’s inequality (Lemma B.2) with X t = 2γhζ t , ω t ^{u} i, parameter c as in (311), b = ^{R} 5 ,
R 4
G =
6(K+1) ^{:}

150 ln

β

(

T
X
R 2
R 4
^{P} |6| ^{>}
σ
b t 2 ≤
and
5
150 ln ^{6(K+1)}
t=0

β

)


≤ 2 exp −



=

or

R 2
|6| ≤
5

b 2
2G + 2cb / 3

β
.
3(K + 1)

Equivalently, we have

β
for E 6 =
P{E 6 } ≥ ^{1} − 3(K+1)

(

T
X

either

R 4

t=0

σ
b t 2 >

T
X



E ξ t kω t u k 2

150 ln ^{6(K+1)}
β

)

.

(313)

In addition, E T implies that

T
X

t=0

σ
b t 2

(312)

≤

^{(297),T} ≤K+1

4γ 2 R 2

t=0

≤

72γ ^{2} R ^{2} σ ^{α} (K + 1)λ ^{2−α}

≤

72γ ^{α} R ^{4−α} σ ^{α} (K + 1) ln ^{α−2}

(282)

R 4

(281)

≤

Upper bound for 7.

150 ln ^{6(K+1)}
β

6(K + 1)
β

.

(314)

From E T it follows that

7

T
X

kζ t k · kω t b k

^{(309),(295),T} ≤K+1

σ α
^{8} · ^{2} ^{α} ^{γR(K} ^{+} ^{1)} α−1
λ

≤

2γ

(282)

16 · 120 ^{α−1} γ ^{α} σ ^{α} R ^{2−α} (K + 1) ln ^{α−1}

=

t=0

≤

75

6(K + 1) ^{(281)} R ^{2}
≤
.
β
5

(315)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Now, we have the upper bounds for 1, 2, 3, 4, 5, 6, 7. In particular, probability event E T −1 implies

(292)

R T 2 +1 ≤ R 2 + 1 + 2 + 3 + 4 + 5,

(293)

2γ(T + 1)Gap R (x ^{T} avg ) ≤ 5R ^{2} + 2γR

γ

(302) R

2 ≤

T
X

t=0

5

150 ln

β

≤

3 ≤

T
X

t=0

t=0

ω t + 2 · (1 + 2 + 3 + 4 + 5) ,

3 + 4 + 5 + 6 + 7,

(303) R ^{2}

,

,
6(K+1)

(310) √

ω l

l=0
2

R 4

(301)

σ t 2 ≤

T
X

T
X

5

(308) R ^{2}

,

5 ≤

R 4

(307)

σ
e t 2 ≤

5

,

150 ln

,
6(K+1)

(315) R ^{2}

7 ≤

T
X

t=0

β

Moreover, we also have (see (300), (306), (315) and our induction assumption)

Tβ
,
K +1
β
P{E 4 } ≥ 1 −
,
3(K + 1)

5

,

R 4

(314)

σ
b t 2 ≤

150 ln ^{6(K+1)}
β

.

P{E T } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
3(K + 1)

where

E 1

(

=

E 4

(

=

E 6

(

=

T
X

either

σ t 2 >

t=0

T
X

either

t=0

T
X

either

t=0

σ
e t 2 >

σ
b t 2 >

R 4

P{E 6 } ≥ 1 −

R 2
^{or} |1| ≤
5

150 ln ^{6(K+1)}
β

R 2
^{or} |4| ≤
5

R 4

150 ln ^{6(K+1)}
β

R 4

R 2
^{or} |6| ≤
5

150 ln ^{6(K+1)}
β

β
,
3(K + 1)

)

)

)

,

,

.

Thus, probability event E T ∩ E 1 ∩ E 4 ∩ E 6 implies

R T 2 +1

γ

T
X

ω l

l=0

2γ(T + 1)Gap R (x ^{T} avg )

≤ R 2 + 1 + 2 + 3 + 4 + 5 ≤ 2R 2 ,

≤

√
3 + 4 + 5 + 6 + 7 ≤ R,

≤ 6R ^{2} + 2γR

≤ 10R ^{2} ,

T
X

t=0

ω t + 2 · (1 + 2 + 3 + 4 + 5)

which gives (286) for t = T , and

P{E T +1 } ≥ P{E T ∩ E 1 ∩ E 4 ∩ E 6 } = 1 − P{E T ∪ E 1 ∪ E 4 ∪ E 6 } ≥ 1 −

Tβ
.
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

Gap R (x ^{K}
avg ^{)} ≤

Finally, if

γ = min




1
,
 170l ln ^{6(K+1)}

β

5R 2
.
γ(K + 1)

R




1
α−1
1

97200 α (K + 1) α σ ln α ^{6(K+1)}
β

76

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

then with probability at least 1 − β



1
α−1
6(K+1)
6(K+1) 
2

α
α
5
·
97200
800LR
ln
σR
ln
5R
β
β
= max
,
α−1


γ(K + 1)
K +1
(K + 1) α




K 
 lR 2 ln K σR ln α−1
α
β
β
 .
,
O  max
α−1


K
K α

2

Gap R (e
x K
avg ^{)} ≤

=

To get Gap R (e
x K
avg ) ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
 α

 α !!

lR ^{2} lR ^{2} σR α−1
1 σR α−1
K = O
ln
ln
,
ε
εβ
ε
β
ε

that concludes the proof.

H.2. Star-Cocoercive Problems

Theorem H.4 (Case 2 in Theorem 4.2). Let Assumptions 1.1, 1.10 hold for Q = B 2R (x ∗ ), where R ≥ kx ^{0} − x ∗ k, and




R
1
,
0 < γ ≤ min
,
(316)
1
α−1
1
 170l ln ^{4(K+1)}

97200 α (K + 1) α σ ln α ^{4(K+1)}
β
β

λ k ≡ λ

=

R

60γ ln ^{4(K+1)}
β

,

(317)

for some K ≥ 0 and β ∈ (0, 1] such that ln ^{4(K+1)}
≥ 1. Then, after K iterations the iterates produced by clipped-SGDA
β
with probability at least 1 − β satisfy
K
2lR ^{2}
1 X
.
(318)
kF (x k )k 2 ≤
K +1
γ(K + 1)

k=0

In particular, when γ equals the minimum from (316), then the iterates produced by clipped-SGDA after K iterations with
probability at least 1 − β satisfy
 


K 
K
 l 2 R 2 ln K lσR ln ^{α−1}
α
1 X
β
β
 ,
,
kF (x ^{k} )k ^{2} = O  max
(319)
α−1

 K +1
K +1
K α

k=0

1
^{meaning} ^{that} ^{to} ^{achieve} K+1

K = O

K
P

k=0

kF (x ^{k} )k ^{2} ≤ ε with probability at least 1 − β clipped-SGDA requires

l 2 R 2 l 2 R 2
ln
,
ε
εβ



lσR
ε

α
 α−1

ln

1
β



lσR
ε

α !!
 α−1

iterations/oracle calls.

(320)

Proof. Again, we will closely follow the proof of Theorem D.2 from (Gorbunov et al., 2022a) and the main difference will
be reflected in the application of Bernstein inequality and estimating biases and variances of stochastic terms.

Let R k = kx ^{k} − x ∗ k for all k ≥ 0. As the previous result, the proof is based on on the induction argument and showing
that the iterates do not leave some ball around the solution with high probability. More precisely, for each k = 0, . . . , K + 1
we define probability event E k as follows: inequalities

kx t − x ∗ k 2 ≤ 2R 2 ,

77

(321)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

hold for t = 0, 1, . . . , k simultaneously. We want to prove that P{E k } ≥ 1 − ^{kβ} / (K+1) for all k = 0, 1, . . . , K + 1 by
induction. One of the important things is that inequalities (287) and (292) are obtained without assuming monotonicity of
by ln 4(K+1)
),
F . Thus, if we do exactly the same steps as in the proof of Theorem H.3 (up to the replacement of ln ^{6(K+1)}
β
β
we gain that

(292)

R T 2 +1 ≤ R 2 + 1 + 2 + 3 + 4 + 5,

(302) R ^{2}

2 ≤

T
X

t=0

5

3 ≤

R 4

(301)

σ t 2 ≤

(303) R ^{2}

,

150 ln

,
4(K+1)

5
T
X

t=0

β

,

(308) R ^{2}

5 ≤

5

R 4

(307)

σ
e t 2 ≤

,

150 ln ^{4(K+1)}
β

.

Moreover, we also have (see (300), (306) and our induction assumption)

Tβ
,
K +1

P{E T } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
2(K + 1)

P{E 4 } ≥ 1 −

β
,
2(K + 1)

where

E 1

(

=

E 4

(

=

T
X

either

σ t 2 >

t=0

T
X

either

t=0

Thus probability event E T −1 ∩ E 1 ∩ E 4 implies

σ
e t 2 >

R 2
^{or} |1| ≤
5

R 4

150 ln ^{4(K+1)}
β

R 4

R 2
^{or} |4| ≤
5

150 ln ^{4(K+1)}
β

)

)

,

.

R T 2 +1 ≤ R 2 + 1 + 2 + 3 + 4 + 5 ≤ 2R 2 ,

and

P{E T +1 } ≥ P{E T ∩ E 1 ∩ E 4 } = 1 − P{E T ∪ E 1 ∪ E 4 } ≥ 1 −

Tβ
.
K +1

(322)

This finishes the inductive part of our proof, i.e. for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

K

1 X
kF (x k )k 2
K +1

k=0

Finally, if

γ = min

then with probability at least 1 − β

K

1 X
kF (x k )k 2
K +1

k=0




≤

2
l(R ^{2} − R K+1
) l(1 + 2 + 3 + 4 + 5)
+
γ(K + 1)
γ(K + 1)

≤

2lR ^{2}
.
γ(K + 1)

(287)

1

 170l ln ^{4(K+1)}

β

R

,

1

1

α−1

97200 α (K + 1) α σ ln α




4(K+1) 
β



1
4(K+1) 
 340l 2 R 2 ln ^{4(K+1)} 2 · 97200 α lσR ln ^{α−1}
α
2lR ^{2}
β
β
= max
,
≤
α−1


γ(K + 1)
K +1
(K + 1) α
 


K 
 l 2 R 2 ln K lσR ln ^{α−1}
α
β
β
 .
= O  max
,
α−1


K
K α

78

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

1
^{To} ^{get} K+1

K
P

k=0

kF (x ^{k} )k ^{2} ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the

^{maximum} ^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}

K = O

l 2 R 2 l 2 R 2
ln
,
ε
εβ



lσR
ε

α
 α−1

ln

1
β



lσR
ε

α !!
 α−1

that concludes the proof.

H.3. Quasi-Strongly Monotone Star-Cocoercive Problems

As in the monotone case, we use another lemma from (Gorbunov et al., 2022a) that handles the deterministic part of
clipped-SGDA in the quasi-strongly monotone case.
Lemma H.5 (Lemma D.3 from (Gorbunov et al., 2022a)). Let Assumptions 1.9, 1.10 hold for Q = B 2R (x ∗ ) = {x ∈ R ^{d} |
kx − x ∗ k ≤ 2R}, where R ≥ kx ^{0} − x ∗ k, and 0 < γ ≤ ^{1} / l . If x ^{k} lie in B 2R (x ∗ ) for all k = 0, 1, . . . , K for some K ≥ 0,
then the iterates produced by clipped-SGDA satisfy

kx K+1 − x ∗ k 2

≤

(1 − γμ) ^{K+1} kx ^{0} − x ∗ k ^{2} + 2γ

+γ 2

K
X

k=0

where ω k are defined in (279).

K
X

k=0

(1 − γμ) ^{K−k} hx ^{k} − x ∗ − γF (x ^{k} ), ω k i

(1 − γμ) ^{K−k} kω k k ^{2} ,

(323)

Using this lemma we prove the main convergence result for clipped-SGDA in the quasi-strongly monotone case.
Theorem H.6 (Case 2 in Theorem 4.2). Let Assumptions 1.1, 1.9, 1.10, hold for Q = B 2R (x ∗ ) = {x ∈ R ^{d} | kx − x ∗ k ≤
2R}, where R ≥ kx ^{0} − x ∗ k, and
)
(
1
ln(B K )
,
(324)
0 < γ ≤ min
,
μ(K + 1)
400l ln ^{4(K+1)}
β


2(α−1)


(K + 1) α μ 2 R 2


B K = max 2,
(325)
4(K+1)
 5400 α ^{2} σ 2 ln ^{2(α−1)}
α
ln 2 (B K ) 
β

 












 
2(α−1)



2 2

α
K
μ R
(
)!
= O 
2,
max
,
(326)

 
2(α−1)



2(α−1)




2 R 2
α
K
2
μ
K





max 2,
2(α−1)
 σ 2 ln α

 
β ln
σ 2 ln α ( K
β )

λ k

=

exp(−γμ(1 + ^{k} / 2 ))R

120γ ln ^{4(K+1)}
β

,

(327)

for some K ≥ 0 and β ∈ (0, 1] such that ln ^{4(K+1)}
≥ 1. Then, after K iterations the iterates produced by clipped-SGDA
β
with probability at least 1 − β satisfy

kx ^{K+1} − x ∗ k ^{2} ≤ 2 exp(−γμ(K + 1))R ^{2} .

(328)

In particular, when γ equals the minimum from (324), then the iterates produced by clipped-SGDA after K iterations with
probability at least 1 − β satisfy
(
)!  


 
2(α−1)
2(α−1)
2 2


α
K
2
μ
R


K


! σ 2 ln α
max 2,
2(α−1)



β ln
 

K
2
α


σ ln
(
)
μK
β
K
∗ 2
2
 ,

,
(329)
kx − x k = O  max R exp −
2(α−1)

K


2
l
ln
α


K
μ


β







79

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

meaning that to achieve kx ^{K} − x ∗ k ^{2} ≤ ε with probability at least 1 − β clipped-SGDA requires
!
α
  ^{2}  2(α−1)

 α !
 2  
α
1 σ ^{2} 2(α−1)
l
σ
R 2
R
l
ln α−1 (B ε )
ln
ln
,
ln
ln
K = O
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

iterations/oracle calls, where

B ε = max










2,

ε ln

 

1
β

R 2

σ 2
μ 2 ε

(330)






 .
α
 2(α−1)




Proof. Again, we will closely follow the proof of Theorem D.3 from (Gorbunov et al., 2022a) and the main difference will
be reflected in the application of Bernstein inequality and estimating biases and variances of stochastic terms.

Let R k = kx ^{k} −x ∗ k for all k ≥ 0. As in the previous results, the proof is based on the induction argument and showing that
the iterates do not leave some ball around the solution with high probability. More precisely, for each k = 0, 1, . . . , K + 1
we consider probability event E k as follows: inequalities

R t ^{2} ≤ 2 exp(−γμt)R ^{2}

(331)

hold for t = 0, 1, . . . , k simultaneously. We want to prove P{E k } ≥ 1 − ^{kβ} / (K+1) for all k = 0, 1, . . . , K + 1 by
induction. The base of the induction is trivial: for k = 0 we have R 0 ^{2} ≤ R ^{2} < 2R ^{2} by definition. Next, assume that for
k = T − 1 ≤ K the statement holds: P{E T −1 } ≥ 1 − ^{(T} −1)β / (K+1) . Given this, we need to prove P{E T } ≥ 1 − ^{T} ^{β} / (K+1) .
Since R t ^{2} ≤ 2 exp(−γμt)R ^{2} ≤ 2R ^{2} , we have x ^{t} ∈ B 2R (x ∗ ), where operator F is l-star-cocoersive. Thus, E T −1 implies

kF (x t )k

≤

(331) √

lkx ^{t} − x ∗ k ≤

2l exp(− ^{γμt} / 2 )R

(324),(327) λ t

≤

2

(332)

and

kω t k 2

≤

(332) 5

2k F e ξ (x ^{t} )k ^{2} + 2kF (x ^{t} )k ^{2} ≤

2

^{(327)} exp(−γμt)R ^{2}

λ 2 t ≤

4γ 2

(333)

for all t = 0, 1, . . . , T − 1, where we use that ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} .

Using Lemma H.5 and (1 − γμ) ^{T} ≤ exp(−γμT ), we obtain that E T −1 implies

R T 2

≤

exp(−γμT )R ^{2} + 2γ

T
−1
X

t=0

+γ 2

T
−1
X

t=0

(1 − γμ) ^{T} −1−t hx ^{t} − x ∗ − γF (x ^{t} ), ω t i

(1 − γμ) ^{T} −1−t kω t k ^{2} .

To handle the sums above, we introduce a new notation:
(
√
x ^{t} − x ∗ − γF (x ^{t} ), if kx ^{t} − x ∗ − γF (x ^{t} )k ≤ 2(1 + γl) exp(− ^{γμt} / 2 )R,
η t =
0,
otherwise,

for t = 0, 1, . . . , T − 1. This vector is bounded almost surely:
√
kη t k ≤ 2(1 + γl) exp(− ^{γμt} / 2 )R
√
for all t = 0, 1, . . . , T − 1. We also notice that E T −1 implies kF (x ^{t} )k ≤ 2l exp(− ^{γμt} / 2 )R (due to (332)) and

kx t − x ∗ − γF (x t )k

≤

(332)

≤

80

kx ^{t} − x ^{∗} k + γkF (x ^{t} )k
√
2(1 + γl) exp(− ^{γμt} / 2 )R

(334)

(335)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

for t = 0, 1, . . . , T − 1. In other words, E T −1 implies η t = x ^{t} − x ∗ − γF (x ^{t} ) for all t = 0, 1, . . . , T − 1, meaning that
from E T −1 it follows that

R T 2

≤ exp(−γμT )R ^{2} + 2γ

T
−1
X

t=0

(1 − γμ) ^{T} −1−t hη t , ω t i + γ ^{2}

T
−1
X

t=0

(1 − γμ) ^{T} −1−t kω t k ^{2} .

To handle the sums appeared on the right-hand side of the previous inequality we consider unbiased and biased parts of ω t :



def
ω t b = F (x t ) − E ξ 1 t F ξ t (x t ) ,



def
ω t u = E ξ t F ξ t (x t ) − F e ξ t (x t ),

(336)

for all t = 0, . . . , T − 1. By definition we have ω t = ω t ^{u} + ω t ^{b} for all t = 0, . . . , T − 1. Therefore, E T −1 implies

R T 2

≤ exp(−γμT )R ^{2} + 2γ

+ 2γ

|

+ 2γ

|

|

T
−1
X

t=0

T
−1
X

t=0

(1 − γμ) ^{T} −1−t hη t , ω t ^{u} i

{z

1

(1 − γμ) ^{T} −1−t hη t , ω t ^{b} i + 2γ ^{2}

{z

}

2

2

T
−1
X

t=0

^{T} −1−t

(1 − γμ)

{z

|

T
−1
X

kω t u k 2 − E ξ

4

t=0

}



(1 − γμ) ^{T} −1−t E ξ kω t ^{u} k ^{2}

{z

}

3

T
−1
X
 u 2 
2
+
2γ
(1 − γμ) ^{T} −1−t kω t ^{b} k ^{2} .
kω t k

}

|

t=0

{z

5

(337)

}

where we also apply inequality ka + bk ^{2} ≤ 2kak ^{2} + 2kbk ^{2} holding for all a, b ∈ R ^{d} to upper bound kω t k ^{2} . It remains to
derive good enough high-probability upper-bounds for the terms 1, 2, 3, 4, 5, i.e., to finish our inductive proof we need
to show that 1 + 2 + 3 + 4 + 5 ≤ exp(−γμT )R ^{2} with high probability. In the subsequent parts of the proof, we will
need to use many times the bounds for the norm and second moments of ω t ^{u} and ω t ^{b} . First, by Lemma 5.1, we have with
probability 1 that
kω t u k ≤ 2λ t .
(338)

Moreover, since E T −1 implies that kF (x ^{t} )k ≤ ^{λ} t / 2 and kF (x ^{t} )k ≤ ^{λ} t / 2 for all t = 0, 1, . . . , T − 1 (see (332)), from
Lemma 5.1 we also have that E T −1 implies

for all t = 0, 1, . . . , T − 1.

Upper bound for 1.

2 α σ α
^{ω} ^{t} ^{b} ≤ α−1 ^{,}
λ t
h
i
2
≤ 18λ ^{2−α}
σ α ,
E ξ t ω t b
t
i
h
2
σ α ,
E ξ t kω t ^{u} k ≤ 18λ ^{2−α}
t

(339)

(340)

(341)

By definition of ω t ^{u} , we have E ξ t [ω t ^{u} ] = 0 and


E ξ t 2γ(1 − γμ) ^{T} −1−t hη t , ω t ^{u} i = 0.

Next, sum 1 has bounded with probability 1 terms:

|2γ(1 − ^{γμ)} ^{T} ^{−1−t} hη t ^{,} ^{ω} t ^{u} i|

≤

(335),(338)

≤

(324),(327)

≤

2γ exp(−γμ(T − 1 − t))kη t k · kω t ^{u} k
√
4 2γ(1 + γl) exp(−γμ(T − 1 − ^{t} / 2 ))Rλ t
exp(−γμT )R ^{2} def
= c.
5 ln 4(K+1)
β

81

(342)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance



def
The summands also have bounded conditional variances σ t ^{2} = E ξ t 4γ ^{2} (1 − γμ) ^{2T} −2−2t hη t , ω t ^{u} i ^{2} :

σ t 2

≤

(335)

≤

(324)

≤



E ξ t 4γ ^{2} exp(−γμ(2T − 2 − 2t))kη t k ^{2} · kω t ^{u} k ^{2}


8γ ^{2} (1 + γl) ^{2} exp(−γμ(2T − 2 − t))R ^{2} E ξ t kω t ^{u} k ^{2}


10γ ^{2} exp(−γμ(2T − t))R ^{2} E ξ t kω t ^{u} k ^{2} .

(343)

−1
^{In} ^{other} ^{words,} ^{we} ^{showed} ^{that} {2γ(1−γμ) ^{T} ^{−1−t} hη t ^{,} ^{ω} t ^{u} i} ^{T} t=0
is a bounded martingale difference sequence with bounded
2 T −1
conditional variances {σ t } t=0 . Next, we apply Bernstein’s inequality (Lemma B.2) with X t = 2γ(1 − γμ) ^{T} −1−t hη t , ω t ^{u} i,
)R 4
parameter c as in (342), b = 15 exp(−γμT )R ^{2} , F = ^{exp(−2γμT}
4(K+1) ^{:}

300 ln

β

(

T
−1
X
1
exp(−2γμT )R ^{4}
^{P} |1| ^{>} ^{exp(−γμT} ^{)R} ^{2} ^{and}
σ t 2 ≤
5
300 ln ^{4(K+1)}
t=0

β

)


≤ 2 exp −

b 2
2F + 2cb / 3



=

β
.
2(K + 1)

Equivalently, we have

β
,
P{E 1 } ≥ 1 −
2(K + 1)

for E 1 =

(

T
−1
X

exp(−2γμT )R
σ t 2 >
300 ln ^{4(K+1)}
t=0
β

either

4

1
^{or} |1| ≤ ^{exp(−γμT} ^{)R} ^{2}
5

)

. (344)

In addition, E T −1 implies that

T
−1
X

t=0

σ t 2

(343)

≤

^{(341),T} ≤K+1

≤

(327)

≤

(324)

≤



E ξ t kω t u k 2
10γ exp(−2γμT )R
exp(−γμt)
t=0

2

exp(−2γμT )R ^{4}

300 ln ^{4(K+1)}
β

2γ exp(−γμ(T − 1))

(327)

≤

(324)

≤

λ 2−α
t
exp(−γμt)
t=0

120 2−α ln ^{2−α} ^{4(K+1)}
β

≤

≤

K
X

180γ ^{α} exp(−2γμT )R ^{4−α} σ ^{α} (K + 1) exp( ^{γμαK}
2 )

From E T −1 it follows that

(335),(339)

T
−1
X

180γ ^{2} exp(−2γμT )R ^{2} σ ^{α}

Upper bound for 2.

2

2

.

(345)

T
−1
X

kη t k · kω t b k
exp(−γμt)
t=0

T
−1
X
√
2 ^{1+α} 2γ(1 + γl) exp(−γμ(T − 1))Rσ ^{α}

1

λ ^{α−1} exp(− γμt / 2 )
t=0 ^{t}



√
ln α−1 4(K+1)
2 ^{3+α} · 120 ^{α−1} 2γ ^{α} (1 + γl) exp(−γμT )σ ^{α} (K + 1) exp ^{γμαT}
2
β

R α−2

1
exp(−γμT )R ^{2} .
5

(346)

82

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

Upper bound for 3.

From E T −1 it follows that



E ξ t kω t u k 2
2γ exp(−γμ(T − 1))
exp(−γμt)
t=0

=

3

(341)

T
−1
X

λ 2−α
t
exp(−γμt)
t=0

≤

144γ ^{2} exp(−γμ(T − 1))σ ^{α}

(327)

144γ ^{α} R ^{2−α} exp(−γμ(T − 1))σ ^{α} (K + 1) exp( ^{γμαK}
2 )

≤

120 2−α ln ^{2−α} ^{4(K+1)}
β

1
exp(−γμT )R ^{2} .
5

(324)

≤

Upper bound for 4.

T
−1
X

2

(347)

First, we have




2γ ^{2} (1 − γμ) ^{T} −1−t E ξ t kω t ^{u} k ^{2} − E ξ t kω t ^{u} k ^{2} = 0.

Next, sum 4 has bounded with probability 1 terms:



2γ ^{2} (1 − γμ) ^{T} −1−t kω t ^{u} k ^{2} − E ξ t kω t ^{u} k ^{2}

(338)

≤

(327)

≤

def

=

16γ ^{2} exp(−γμT )λ ^{2} l
exp(−γμ(1 + t))
exp(−γμT )R ^{2}

5 ln 4(K+1)
β

c.

(348)

The summands also have conditional variances
h
 2 i

def
σ
e t ^{2} = E ξ t 4γ ^{4} (1 − γμ) ^{2T} −2−2t kω t ^{u} k ^{2} − E ξ t kω t ^{u} k ^{2}

that are bounded

σ
e t 2

(348)

≤

≤

2γ ^{2} exp(−2γμT )R ^{2}

5 exp(−γμ(1 + t)) ln ^{4(K+1)}
β
2
2

4γ exp(−2γμT )R

5 exp(−γμ(1 + t)) ln ^{4(K+1)}
β

E ξ t



 

kω t u k 2 − E ξ t kω t u k 2



E ξ t kω t u k 2 .

(349)



 T −1
In other words, we showed that 2γ ^{2} (1 − γμ) ^{T} −1−t kω t ^{u} k ^{2} − E ξ t kω t ^{u} k ^{2} t=0 is a bounded martingale difference
−1
sequence with bounded conditional variances {e
^{σ} t ^{2} } ^{T} t=0
. Next, we apply Bernstein’s inequality (Lemma B.2) with X t =


)R 4
2γ ^{2} (1 − γμ) ^{T} −1−t kω t ^{u} k ^{2} − E ξ t kω t ^{u} k ^{2} , parameter c as in (348), b = 15 exp(−γμT )R ^{2} , G = ^{exp(−2γμT}
4(K+1) ^{:}

300 ln

(

T −1

X
exp(−2γμT )R ^{4}
1
σ
e t 2 ≤
^{P} |4| ^{>} ^{exp(−γμT} ^{)R} ^{2} ^{and}
5
294 ln ^{4(K+1)}

l=0

β

)



b 2
≤ 2 exp −
2G + 2cb / 3



=

β

β
.
2(K + 1)

Equivalently, we have

β
P{E 4 } ≥ 1 −
,
2(K + 1)

for E 4 =

(

either

T
−1
X

exp(−2γμT )R
σ
e t 2 >
300 ln ^{4(K+1)}
t=0
β

83

4

1
^{or} |4| ≤ ^{exp(−γμT} ^{)R} ^{2}
5

)

. (350)

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

In addition, E T −1 implies that

T
−1
X

l=0

σ
e t 2



T −1
4γ ^{2} exp(−γμ(2T − 1))R ^{2} X E ξ t kω l ^{u} k ^{2}
exp(−γμt)
5 ln 4(K+1)
t=0

(349)

≤

β

^{(341),T} ≤K+1

≤

72γ ^{α} exp(−γμ(2T − 1))R ^{4−α} σ ^{α} (K + 1) exp( ^{γμαK}
2 )

≤

5 · 120 2−α ln ^{3−α} ^{4(K+1)}
β

exp(−2γμT )R ^{4}

(324)

≤

5

=

2γ 2

≤

^{(327),T} ≤K+1

≤

≤

≤

(324)

≤

300 ln ^{4(K+1)}
β

.

(351)

From E T −1 it follows that

T
−1
X

l=0

(339)

λ 2−α
t
exp(−γμt)
t=0

5 ln 4(K+1)
β

(327)

Upper bound for 5.

K

72γ exp(−γμ(2T − 1))R ^{2} σ ^{α} X

2

exp(−γμ(T − 1 − t)) kω t ^{b} k ^{2}

2 · 2 ^{2α} γ ^{2} exp(−γμ(T − 1))σ ^{2α}

T
−1
X



1

λ ^{2α−2} exp(−γμt)
t=0 ^{t}



t
exp(γμt)
exp γμ(2α − 2) 1 +
2
t=0



K
X
2 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} exp(−γμ(T − 1))σ ^{2α} ln ^{2α−2} ^{4(K+1)}
β

R 2α−2

K
X
4 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} exp(−γμ(T − 3))σ ^{2α} ln ^{2α−2} ^{4(K+1)}
β

R 2α−2

exp(γμαt)

t=0

(K + 1) exp(γμαK)
4 · 2 ^{2α} · 120 ^{2α−2} γ ^{2α} exp(−γμ(T − 3))σ ^{2α} ln ^{2α−2} ^{4(K+1)}
β

R 2α−2

1
exp(−γμT )R ^{2} .
5

(352)

Now, we have the upper bounds for 1, 2, 3, 4, 5. In particular, probability event E T −1 implies

(337)

R T ^{2} ≤ exp(−γμT )R ^{2} + 1 + 2 + 3 + 4 + 5,

(346) 1

2 ≤

5

(352) 1

5 ≤

T
−1
X

t=0

5

300 ln ^{4(K+1)}
β

3 ≤

5

exp(−γμT )R ^{2} ,

exp(−γμT )R ^{2}

^{(345)} exp(−2γμT )R ^{4}

σ t 2 ≤

(347) 1

exp(−γμT )R ^{2} ,

T
−1
X

,

t=0

^{(351)} exp(−2γμT )R ^{4}

σ
e t 2 ≤

300 ln ^{4(K+1)}
β

Moreover, we also have (see (344), (350) and our induction assumption)

P{E T −1 } ≥ 1 −

P{E 1 } ≥ 1 −

β
,
2(K + 1)

(T − 1)β
,
K +1

P{E 4 } ≥ 1 −

84

β
.
2(K + 1)

.

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where

E 1

=

E 4

=

(

(

either

either

T
−1
X

exp(−2γμT )R
σ t 2 >
300 ln ^{4(K+1)}
t=0
β

4

T
−1
X

exp(−2γμT )R
σ
e t 2 >
300 ln ^{4(K+1)}
t=0
β

4

1
^{or} |1| ≤ ^{exp(−γμT} ^{)R} ^{2}
5

1
^{or} |4| ≤ ^{exp(−γμT} ^{)R} ^{2}
5

)

)

,

.

Thus, probability event E T −1 ∩ E 1 ∩ E 4 implies

R T 2

(337)

exp(−γμT )R ^{2} + 1 + 2 + 3 + 4 + 5
2 exp(−γμT )R ^{2} ,

≤
≤

which is equivalent to (331) for t = T , and

P{E T } ≥ P{E T −1 ∩ E 1 ∩ E 4 } = 1 − P{E T −1 ∪ E 1 ∪ E 4 } ≥ 1 −

Tβ
.
K +1

This finishes the inductive part of our proof, i.e., for all k = 0, 1, . . . , K + 1 we have P{E k } ≥ 1 − ^{kβ} / (K+1) . In particular,
for k = K + 1 we have that with probability at least 1 − β

kx ^{K+1} − x ∗ k ^{2} ≤ 2 exp(−γμ(K + 1))R ^{2} .

Finally, if

γ

=

B K

=

=

)
ln(B K )
,
,
min
μ(K + 1)
400l ln ^{4(K+1)}
β


2(α−1)


2 2
α
μ R
(K + 1)


max 2,
4(K+1)
 5400 α ^{2} σ 2 ln ^{2(α−1)}
α
ln 2 (B K ) 
β

 














2(α−1)



2
2

α
K
μ
R

)!
(
O  max 2,
 
2(α−1)



2(α−1)




α
μ 2 R 2
K
2



K



max
2,
ln
2(α−1)
 σ 2 ln α


β
K
2
σ ln α ( β )

(

1

then with probability at least 1 − β

kx K+1 − x ∗ k 2

≤

=

=

2 exp(−γμ(K + 1))R ^{2}
(
)
!
μ(K + 1)
1
2
2R max exp −
,
B K
400l ln ^{4(K+1)}
β
)!  
(


 
2(α−1)
2(α−1)
2 2


α
2


K


! σ 2 ln α
max 2, ^{K} 2(α−1) ^{μ} ^{R}



β ln
 

K
2


σ ln α ( β )
μK
2
 .

,
O  max R exp −
2(α−1)

K


2
l
ln
α


K
μ


β







To get kx ^{K+1} − x ∗ k ^{2} ≤ ε with probability at least 1 − β it is sufficient to choose K such that both terms in the maximum
^{above} ^{are} O(ε). ^{This} ^{leads} ^{to}
!
α
  ^{2}  2(α−1)

 α !
 2  
α
l
σ
R 2
R
1 σ ^{2} 2(α−1)
l
ln
,
ln α−1 (B ε ) ,
ln
ln
ln
K = O
μ
ε
μβ
ε
μ 2 ε
β μ 2 ε

85

-----
High-Probability Bounds for Stochastic Optimization and Variational Inequalities: the Case of Unbounded Variance

where

B ε = max

This concludes the proof.










2,

ε ln

 

1
β

86

R 2

σ 2
μ 2 ε






 .
α
 2(α−1)




-----